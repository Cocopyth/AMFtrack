{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from PIL import Image\n",
    "from scipy import sparse\n",
    "import cv2\n",
    "from pymatreader import read_mat\n",
    "# from extract_graph import dic_to_sparse\n",
    "from util import get_path, shift_skeleton\n",
    "from plotutil import show_im,overlap, show_im_rgb, plot_nodes, plot_nodes_from_list,plot_t_tp1\n",
    "from extract_graph import generate_graph_tab_from_skeleton,generate_nx_graph_from_skeleton,generate_skeleton,clean\n",
    "import networkx as nx\n",
    "from node_id import second_identification, whole_movement_identification,first_identification,relabel_nodes, clean_nodes, orient\n",
    "from extract_graph import dic_to_sparse, from_sparse_to_graph, generate_nx_graph, prune_graph, from_nx_to_tab\n",
    "from sparse_util import dilate, zhangSuen\n",
    "from realign import realign, reconnect\n",
    "from util import get_path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date0='0709_1157'\n",
    "# date1='0709_1557'\n",
    "# date2='0709_1934'\n",
    "date0='0701_1957'\n",
    "date1='0701_2357'\n",
    "date2='0702_0357'\n",
    "date3='0702_0757'\n",
    "date4='0702_1157'\n",
    "date5='0702_1557'\n",
    "plate=13\n",
    "dates=[date0,date1,date2,date3,date4,date5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_skels=[read_mat(get_path(date,plate,True))['skel'] for date in dates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_skels=[dic_to_sparse(mat_skel) for mat_skel in mat_skels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_skeleton_docs_aligned = [realign(skeleton_doc,skeleton_docs[0]) for skeleton_doc in skeleton_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "872558 872271\n",
      "107117 796\n",
      "394 60\n",
      "35 28\n",
      "17 15\n",
      "10 0\n",
      "0 0\n"
     ]
    }
   ],
   "source": [
    "skeleton_docs_aligned = [reconnect(skeleton_docs[0])]+sub_skeleton_docs_aligned "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, date in enumerate([date0,date1,date2,date3,date4,date5]):\n",
    "    sparse.save_npz(f'Data/skeleton_{date}_{plate}_full',sparse.csc_matrix(skeleton_docs_aligned[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "skeleton_docs_aligned = [sparse.dok_matrix(sparse.load_npz(f'Data/skeleton_{date}_{plate}_full.npz')) for date in dates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotutil import plot_t_tp1, compress_skeleton\n",
    "factor = 5\n",
    "final_pictures = [compress_skeleton(skeleton_docs_aligned[i],factor) for i in range(len(skeleton_docs_aligned))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ee1a219c9a14e88abcba644ef93e086",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_t_tp1([],[],poss_aligned[4],poss_aligned[5],final_pictures[3],final_pictures[4],compress=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_tabs=[from_sparse_to_graph(skeleton) for skeleton in skeleton_docs_aligned]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx_graph_poss=[generate_nx_graph(graph_tab) for graph_tab in graph_tabs]\n",
    "nx_graphs_aligned=[nx_graph_pos[0] for nx_graph_pos in nx_graph_poss]\n",
    "poss_aligned=[nx_graph_pos[1] for nx_graph_pos in nx_graph_poss]\n",
    "nx_graph_pruned=[prune_graph(nx_graph) for nx_graph in nx_graphs_aligned]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_graph(nx_graph,pos,xbegin,xend,ybegin,yend):\n",
    "    sub_nx_graph=nx.Graph.copy(nx_graph)\n",
    "    for node in nx_graph.nodes:\n",
    "        if (pos[node][0]>=xend or pos[node][0]<=xbegin or pos[node][1]>=yend or pos[node][1]<=ybegin):\n",
    "            sub_nx_graph.remove_node(node)\n",
    "    return(sub_nx_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_skeleton(nx_graph,dim,shift=(0,0)):\n",
    "    skel = sparse.dok_matrix(dim, dtype=bool)\n",
    "    for edge in nx_graph.edges.data('pixel_list'):\n",
    "        for pixel in edge[2]:\n",
    "            skel[(pixel[0]-shift[0],pixel[1]-shift[1])]=True\n",
    "    return(skel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "poss_aligned=[nx_graph_pos[1] for nx_graph_pos in nx_graph_poss]\n",
    "nx_graph_pruned=[prune_graph(nx_graph) for nx_graph in nx_graphs_aligned]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "xbegin=14000\n",
    "xend = 18000\n",
    "ybegin = 8000\n",
    "yend=16000\n",
    "sub_nx_graphs = [sub_graph(nx_graph,poss_aligned[i],xbegin,xend,ybegin,yend) for i, nx_graph in enumerate(nx_graph_pruned)]\n",
    "# sub_skeleton= [generate_skeleton(nx_graph,(xend-xbegin,yend-ybegin),(xbegin,ybegin)) for nx_graph in sub_nx_graphs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 3\n",
      "number removed first phase 19\n",
      "number removed second phase 36\n",
      "116 0 [16887  8355]\n",
      "116 1 [16893  8366]\n",
      "i= 2\n",
      "number removed first phase 13\n",
      "number removed second phase 27\n",
      "121 0 [17317  9088]\n",
      "121 1 [17312  9091]\n",
      "121 2 [17311  9107]\n",
      "i= 1\n",
      "number removed first phase 12\n",
      "number removed second phase 32\n",
      "119 0 [17318  9090]\n",
      "119 1 [17317  9088]\n",
      "119 2 [17312  9091]\n",
      "119 3 [17311  9107]\n"
     ]
    }
   ],
   "source": [
    "downstream_graphs = []\n",
    "downstream_pos = []\n",
    "begin=len(dates)-2\n",
    "downstream_graphs=[sub_nx_graphs[begin]]\n",
    "downstream_poss=[poss_aligned[begin]]\n",
    "for i in range (begin-1,0,-1):\n",
    "    print(\"i=\",i)\n",
    "    new_graphs,new_poss = second_identification(sub_nx_graphs[i],downstream_graphs[0],poss_aligned[i],downstream_poss[0],50,downstream_graphs[1:],downstream_poss[1:],tolerance=30)\n",
    "    downstream_graphs=new_graphs\n",
    "    downstream_poss=new_poss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree3_nodes = [[node for node in nx_graph.nodes if nx_graph.degree(node)>=3] for nx_graph in downstream_graphs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43151d7a8db942a99853e0d30c6f8c34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t=0\n",
    "tp1=1\n",
    "plot_t_tp1(degree3_nodes[t],degree3_nodes[tp1],downstream_poss[t],downstream_poss[tp1],sub_skeleton[t+1].todense(),sub_skeleton[tp1+1].todense(),shift=(xbegin,ybegin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 3\n",
      "number removed first phase 94\n",
      "number removed second phase 360\n",
      "2347 0 [19953  1202]\n",
      "2347 1 [19967  1222]\n",
      "i= 2\n",
      "number removed first phase 143\n",
      "number removed second phase 621\n",
      "2093 0 [19962  1191]\n",
      "2093 1 [19953  1202]\n",
      "2093 2 [19967  1222]\n",
      "i= 1\n",
      "number removed first phase 170\n",
      "number removed second phase 710\n",
      "1948 0 [19968  1200]\n",
      "1948 1 [19962  1191]\n",
      "1948 2 [19953  1202]\n",
      "1948 3 [19967  1222]\n"
     ]
    }
   ],
   "source": [
    "downstream_graphs = []\n",
    "downstream_pos = []\n",
    "begin=len(dates)-2\n",
    "downstream_graphs=[nx_graph_pruned[begin]]\n",
    "downstream_poss=[poss_aligned[begin]]\n",
    "for i in range (begin-1,0,-1):\n",
    "    print(\"i=\",i)\n",
    "    new_graphs,new_poss = second_identification(nx_graph_pruned[i],downstream_graphs[0],poss_aligned[i],downstream_poss[0],50,downstream_graphs[1:],downstream_poss[1:],tolerance=30)\n",
    "    downstream_graphs=new_graphs\n",
    "    downstream_poss=new_poss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx_graph_pruned[1:begin+1]=downstream_graphs\n",
    "poss_aligned[1:begin+1]=downstream_poss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nx_graph_pruned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(skeleton_docs_aligned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "skeleton_docs_cleaned= [generate_skeleton(nx_graph,skeleton_docs_aligned[i].shape) for i,nx_graph in enumerate(nx_graph_pruned)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, date in enumerate(dates):\n",
    "    sparse.save_npz(f'Data/skeleton_{date}_{plate}_full_clean',sparse.csc_matrix(skeleton_docs_cleaned[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabs_labeled = [from_nx_to_tab(nx_graph,poss_aligned[i]) for i, nx_graph in enumerate(nx_graph_pruned)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_nx_to_tab(nx_graph,pos):\n",
    "    column_names = [\"origin_label\",\"end_label\",\"origin_pos\", \"end_pos\", \"pixel_list\"]\n",
    "    tab = pd.DataFrame(columns=column_names)\n",
    "    for edge in nx_graph.edges:\n",
    "        origin_label=edge[0]\n",
    "        end_label=edge[1]\n",
    "        origin_pos=pos[origin_label]\n",
    "        end_pos = pos[end_label]\n",
    "        pixel_list=orient(nx_graph.get_edge_data(*edge)['pixel_list'],origin_pos)\n",
    "        new_line=pd.DataFrame({\"origin_label\":[origin_label],\"end_label\" : [end_label], \"origin_pos\":[origin_pos], \"end_pos\" : [end_pos], \"pixel_list\" : [pixel_list]})\n",
    "        tab=tab.append(new_line,ignore_index=True)\n",
    "    return(tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabs = [from_sparse_to_graph(skeleton) for skeleton in skeleton_docs_cleaned]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '//sun.amolf.nl/shimizu-data/home-folder/oyartegalvez/Drive_AMFtopology/PRINCE/20200701_1957_Plate13/Analysis/Skeleton_full_labeled.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-24ba464ee413>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mtabs_labeled\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mplate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mextension\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'_full_labeled.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mtabs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mplate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mextension\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'_full.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cleanMsc\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors)\u001b[0m\n\u001b[0;32m   3165\u001b[0m             \u001b[0mdecimal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3166\u001b[0m         )\n\u001b[1;32m-> 3167\u001b[1;33m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3169\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cleanMsc\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    188\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 190\u001b[1;33m                 \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompression_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    191\u001b[0m             )\n\u001b[0;32m    192\u001b[0m             \u001b[0mclose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cleanMsc\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors)\u001b[0m\n\u001b[0;32m    491\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 493\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    494\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m             \u001b[1;31m# No explicit encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '//sun.amolf.nl/shimizu-data/home-folder/oyartegalvez/Drive_AMFtopology/PRINCE/20200701_1957_Plate13/Analysis/Skeleton_full_labeled.csv'"
     ]
    }
   ],
   "source": [
    "for i, date in enumerate(dates):\n",
    "    tabs_labeled[i].to_csv(get_path(date,plate,True,extension='_full_labeled.csv'))\n",
    "    tabs[i].to_csv(get_path(date,plate,True,extension='_full.csv'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, date in enumerate(dates):\n",
    "    tabs_labeled[i].to_csv(f'Data/graph_{date}_{plate}_full_labeled.csv')\n",
    "    tabs[i].to_csv(f'Data/graph_{date}_{plate}_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from PIL import Image\n",
    "from scipy import sparse\n",
    "import cv2\n",
    "from pymatreader import read_mat\n",
    "from util import get_path\n",
    "from plotutil import show_im,overlap, show_im_rgb\n",
    "from extract_graph import generate_graph_tab_from_skeleton,generate_nx_graph_from_skeleton,generate_skeleton\n",
    "import networkx as nx\n",
    "from copy import deepcopy\n",
    "from sparse_util import dilate\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "def node_dist(node1,node2,nx_graph_tm1,nx_graph_t,pos_tm1,pos_t,tolerance,show=False,):\n",
    "    #!!! assumed shape == 3000,4096\n",
    "    sparse_cross1=sparse.dok_matrix((4*tolerance,4*tolerance), dtype=bool)\n",
    "    sparse_cross2=sparse.dok_matrix((4*tolerance,4*tolerance), dtype=bool)\n",
    "    for edge in nx_graph_tm1.edges(node1):\n",
    "        list_pixel=nx_graph_tm1.get_edge_data(*edge)['pixel_list']\n",
    "        if (pos_tm1[node1]!=list_pixel[0]).any():\n",
    "            list_pixel=list(reversed(list_pixel))\n",
    "#         print(list_pixel[0],pos_tm1[node1],list_pixel[-1])\n",
    "        for pixel in list_pixel[:20]:\n",
    "            sparse_cross1[np.array(pixel)-np.array(pos_tm1[node1])+np.array((50,50))]=1\n",
    "    for edge in nx_graph_t.edges(node2):\n",
    "        list_pixel=nx_graph_t.get_edge_data(*edge)['pixel_list']\n",
    "        if (pos_t[node2]!=list_pixel[0]).any():\n",
    "            list_pixel=list(reversed(list_pixel))\n",
    "#         print(list_pixel[0],pos_t[node2],list_pixel[-1])\n",
    "        for pixel in list_pixel[:20]:\n",
    "#             if np.any(np.array(pixel)-np.array(pos_tm1[node1])+np.array((50,50))>=100):\n",
    "#                 print(list_pixel[0],pos_t[node2],list_pixel[-1])\n",
    "            sparse_cross2[np.array(pixel)-np.array(pos_tm1[node1])+np.array((50,50))]=1\n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    dilation1 = cv2.dilate(sparse_cross1.todense().astype(np.uint8),kernel,iterations = 3)\n",
    "    dilation2 = cv2.dilate(sparse_cross2.todense().astype(np.uint8),kernel,iterations = 3)\n",
    "    if show:\n",
    "        plt.imshow(dilation1)\n",
    "        plt.imshow(dilation2,alpha=0.5)\n",
    "        plt.show()\n",
    "    return(np.linalg.norm(dilation1-dilation2))\n",
    "\n",
    "def first_identification(nx_graph_tm1,nx_graph_t,pos_tm1,pos_t,tolerance):\n",
    "    corresp={}\n",
    "    ambiguous=set()\n",
    "    to_remove=set()\n",
    "    degree_3sup_nodes_tm1 = [node for node in nx_graph_tm1.nodes if nx_graph_tm1.degree(node)>=3]\n",
    "    degree_3sup_nodes_t = [node for node in nx_graph_t.nodes if nx_graph_t.degree(node)>=3]\n",
    "    for node1 in degree_3sup_nodes_tm1:\n",
    "        mini=np.inf\n",
    "        for node2 in degree_3sup_nodes_t:\n",
    "            distance=np.linalg.norm(pos_tm1[node1]-pos_t[node2])\n",
    "            if distance<mini:\n",
    "                mini=distance\n",
    "                identifier=node2\n",
    "        if mini<tolerance:\n",
    "            if identifier in corresp.values():\n",
    "                ambiguous.add(node1)\n",
    "            corresp[node1]=identifier\n",
    "        else:\n",
    "            to_remove.add(node1)\n",
    "    while len(ambiguous)>0:\n",
    "        node=ambiguous.pop()\n",
    "        identifier=corresp[node]\n",
    "        candidates = [nod for nod in corresp.keys() if corresp[nod]==identifier]\n",
    "        mini=np.inf\n",
    "        for candidate in candidates:\n",
    "            distance=node_dist(candidate,identifier,nx_graph_tm1,nx_graph_t,pos_tm1,pos_t,tolerance)\n",
    "            if distance < mini:\n",
    "                right_candidate=candidate\n",
    "                mini=distance\n",
    "        for candidate in candidates:\n",
    "            if candidate!= right_candidate:\n",
    "                corresp.pop(candidate)\n",
    "                to_remove.add(candidate)\n",
    "                ambiguous.discard(candidate)\n",
    "    return(corresp,to_remove)\n",
    "    \n",
    "def relabel_nodes(corresp,nx_graph_t,pos_t):\n",
    "    invert_corresp={}\n",
    "    new_pos = {}\n",
    "    maxi=max(nx_graph_t.nodes)+1\n",
    "    for key in corresp.keys():\n",
    "        invert_corresp[corresp[key]]=key\n",
    "    def mapping(node):\n",
    "        if node in invert_corresp.keys():\n",
    "            return(invert_corresp[node])\n",
    "        else:\n",
    "            return (maxi+node)\n",
    "    for node in nx_graph_t.nodes:\n",
    "        pos=pos_t[node]\n",
    "        if node in invert_corresp.keys():\n",
    "            new_pos[invert_corresp[node]]=pos\n",
    "        else:\n",
    "            new_pos[maxi+node]=pos\n",
    "    new_graph=nx.relabel_nodes(nx_graph_t,mapping)\n",
    "    return(new_pos,new_graph)\n",
    "\n",
    "def relabel_nodes_downstream(corresp,nx_graph_list,pos_list):\n",
    "    invert_corresp={}\n",
    "    new_poss = [{} for i in range(len(nx_graph_list))]\n",
    "    new_graphs=[]\n",
    "    all_nodes = set()\n",
    "    for nx_graph in nx_graph_list:\n",
    "        all_nodes=all_nodes.union(set(nx_graph.nodes))\n",
    "    all_nodes=all_nodes.union(set(corresp.keys()))\n",
    "    all_nodes=all_nodes.union(set(corresp.values()))\n",
    "    maxi=max(all_nodes)+1\n",
    "    for key in corresp.keys():\n",
    "        invert_corresp[corresp[key]]=key\n",
    "    def mapping(node):\n",
    "        if node in invert_corresp.keys():\n",
    "            return(invert_corresp[node])\n",
    "        else:\n",
    "            return (maxi+node)\n",
    "    for i,nx_graph in enumerate(nx_graph_list):\n",
    "        for node in nx_graph.nodes:\n",
    "            pos=pos_list[i][node]\n",
    "            new_poss[i][mapping(node)]=pos\n",
    "        new_graphs.append(nx.relabel_nodes(nx_graph,mapping,copy=True))\n",
    "    return(new_graphs,new_poss)\n",
    "\n",
    "\n",
    "def reduce_labels(nx_graph_list,pos_list):\n",
    "    new_poss = [{} for i in range(len(nx_graph_list))] \n",
    "    new_graphs=[]\n",
    "    all_node_labels = set()\n",
    "    node=[node for node in nx_graph_list[0].nodes if node in nx_graph_list[1]][0]\n",
    "    for nx_graph in nx_graph_list:\n",
    "        all_node_labels=all_node_labels.union(set(nx_graph.nodes))\n",
    "    all_node_labels = sorted(all_node_labels)\n",
    "    def mapping(node):\n",
    "        return(all_node_labels.index(node))\n",
    "    for i,nx_graph in enumerate(nx_graph_list):\n",
    "        for node in nx_graph.nodes:\n",
    "            pos=pos_list[i][node]\n",
    "            new_poss[i][mapping(node)]=pos\n",
    "        new_graphs.append(nx.relabel_nodes(nx_graph,mapping,copy=True))\n",
    "    node=[node for node in new_graphs[0].nodes if new_graphs[0].degree(node)==3][0]\n",
    "    for i,nx_graph in enumerate(nx_graph_list):\n",
    "        if node in new_poss[i].keys():\n",
    "            print(node,i,new_poss[i][node])\n",
    "    return(new_graphs,new_poss)\n",
    "\n",
    "def reconnect_degree_2(nx_graph,pos):\n",
    "    degree_2_nodes = [node for node in nx_graph.nodes if nx_graph.degree(node)==2]\n",
    "    while len(degree_2_nodes)>0:\n",
    "        node = degree_2_nodes.pop()\n",
    "        neighbours = list(nx_graph.neighbors(node))\n",
    "        right_n = neighbours[0]\n",
    "        left_n = neighbours[1]\n",
    "        right_edge = nx_graph.get_edge_data(node,right_n)['pixel_list']\n",
    "        left_edge = nx_graph.get_edge_data(node,left_n)['pixel_list']\n",
    "        if np.any(right_edge[0]!=pos[node]):\n",
    "            right_edge = list(reversed(right_edge))\n",
    "        if np.any(left_edge[-1]!=pos[node]):\n",
    "            left_edge = list(reversed(left_edge))\n",
    "        pixel_list = left_edge+right_edge[1:]\n",
    "        info={'weight':len(pixel_list),'pixel_list':pixel_list}\n",
    "        if right_n!=left_n:\n",
    "            connection_data=nx_graph.get_edge_data(right_n,left_n)\n",
    "            if connection_data is None or connection_data['weight']>=info['weight']:\n",
    "                if not connection_data is None:\n",
    "                    nx_graph.remove_edge(right_n,left_n)\n",
    "                nx_graph.add_edges_from([(right_n,left_n,info)])\n",
    "        nx_graph.remove_node(node)\n",
    "        degree_2_nodes = [node for node in nx_graph.nodes if nx_graph.degree(node)==2]\n",
    "            \n",
    "def clean_nodes(nx_graph,to_remove,pos):\n",
    "    nx_graph=deepcopy(nx_graph) #could be removed to speed up\n",
    "    is_hair = True\n",
    "    i=0\n",
    "    while is_hair:\n",
    "        is_hair=False\n",
    "        to_remove_possibly=list(to_remove)\n",
    "        for node in to_remove_possibly:\n",
    "            neighbours = nx_graph.neighbors(node)\n",
    "            candidate_to_remove=[]\n",
    "            weight_candidate=[]\n",
    "            for neighbour in neighbours:\n",
    "                if nx_graph.degree(neighbour)==1:\n",
    "                    is_hair=True\n",
    "                    candidate_to_remove.append(neighbour)\n",
    "                    weight_candidate.append(len(nx_graph.get_edge_data(node,neighbour)['pixel_list']))\n",
    "            if len(candidate_to_remove)>0:\n",
    "                node_to_remove=candidate_to_remove[np.argmin(weight_candidate)]\n",
    "                nx_graph.remove_node(node_to_remove)\n",
    "                i+=1\n",
    "                if nx_graph.degree(node)==2:\n",
    "                    to_remove.discard(node)\n",
    "    print('number removed first phase',i)\n",
    "    reconnect_degree_2(nx_graph,pos) #could possibly be done faster\n",
    "    for node in to_remove:\n",
    "        if node in nx_graph:\n",
    "            neighbours = list(nx_graph.neighbors(node))\n",
    "            candidate_to_fuse=[]\n",
    "            weight_candidate=[]\n",
    "            for neighbour in neighbours:\n",
    "                candidate_to_fuse.append(neighbour)\n",
    "                weight_candidate.append(len(nx_graph.get_edge_data(node,neighbour)['pixel_list']))\n",
    "            node_to_fuse=candidate_to_fuse[np.argmin(weight_candidate)]\n",
    "            for neighbour in neighbours:\n",
    "                right_n = node_to_fuse\n",
    "                left_n = neighbour\n",
    "                right_edge = nx_graph.get_edge_data(node,right_n)['pixel_list']\n",
    "                left_edge = nx_graph.get_edge_data(node,left_n)['pixel_list']\n",
    "                if np.any(right_edge[0]!=pos[node]):\n",
    "                    right_edge = list(reversed(right_edge))\n",
    "                if np.any(left_edge[-1]!=pos[node]):\n",
    "                    left_edge = list(reversed(left_edge))\n",
    "                pixel_list = left_edge+right_edge[1:]\n",
    "                info={'weight':len(pixel_list),'pixel_list':pixel_list}\n",
    "                if right_n!=left_n:\n",
    "                    connection_data=nx_graph.get_edge_data(right_n,left_n)\n",
    "                    if connection_data is None or connection_data['weight']>=info['weight']:\n",
    "                        if not connection_data is None:\n",
    "                            nx_graph.remove_edge(right_n,left_n)\n",
    "                        nx_graph.add_edges_from([(right_n,left_n,info)])\n",
    "            nx_graph.remove_node(node)\n",
    "            i+=1\n",
    "    print('number removed second phase',i)\n",
    "    reconnect_degree_2(nx_graph,pos)\n",
    "    return(nx_graph)\n",
    "\n",
    "def orient(pixel_list,root_pos):\n",
    "    if np.all(root_pos==pixel_list[0]):\n",
    "        return(pixel_list)\n",
    "    else:\n",
    "        return list(reversed(pixel_list))\n",
    "    \n",
    "def second_identification(nx_graph_tm1,nx_graph_t,pos_tm1,pos_t,length_id=50,downstream_graphs=[],downstream_pos=[],tolerance=50):\n",
    "    reconnect_degree_2(nx_graph_t,pos_t)\n",
    "    corresp,to_remove=first_identification(nx_graph_tm1,nx_graph_t,pos_tm1,pos_t,tolerance)\n",
    "    nx_graph_tm1=clean_nodes(nx_graph_tm1,to_remove,pos_tm1)\n",
    "    downstream_graphs=[nx_graph_t]+downstream_graphs\n",
    "    downstream_pos=[pos_t]+downstream_pos\n",
    "    new_graphs,new_poss=relabel_nodes_downstream(corresp,downstream_graphs,downstream_pos)\n",
    "    pos_t = new_poss[0]\n",
    "    nx_graph_t = new_graphs[0]\n",
    "    downstream_pos=new_poss\n",
    "    downstream_graphs=new_graphs\n",
    "    corresp_tips={node : node for node in corresp.keys()}\n",
    "    tips = [node for node in nx_graph_tm1.nodes if nx_graph_tm1.degree(node)==1]\n",
    "    for tip in tips:\n",
    "        mini=np.inf\n",
    "        for edge in nx_graph_t.edges:\n",
    "            pixel_list=nx_graph_t.get_edge_data(*edge)['pixel_list']\n",
    "            if np.linalg.norm(np.array(pixel_list[0])-np.array(pos_tm1[tip]))<=5000:\n",
    "                distance=np.min(np.linalg.norm(np.array(pixel_list)-np.array(pos_tm1[tip]),axis=1))\n",
    "                if distance<mini:\n",
    "                    mini=distance\n",
    "                    right_edge = edge\n",
    "        origin = np.array(orient(nx_graph_tm1.get_edge_data(*list(nx_graph_tm1.edges(tip))[0])['pixel_list'],pos_tm1[tip]))\n",
    "        origin_vector = origin[0]-origin[-1]\n",
    "        branch=np.array(orient(nx_graph_t.get_edge_data(*right_edge)['pixel_list'],pos_t[right_edge[0]]))\n",
    "        candidate_vector = branch[-1]-branch[0]\n",
    "        dot_product = np.dot(origin_vector,candidate_vector)\n",
    "        if dot_product>=0:\n",
    "            root=right_edge[0]\n",
    "            next_node=right_edge[1]\n",
    "        else:\n",
    "            root=right_edge[1]\n",
    "            next_node=right_edge[0]\n",
    "        last_node=root\n",
    "        current_node=next_node\n",
    "        last_branch=np.array(orient(nx_graph_t.get_edge_data(root,next_node)['pixel_list'],pos_t[current_node]))\n",
    "        i=0\n",
    "        loop=[]\n",
    "        while nx_graph_t.degree(current_node)!=1 and not current_node in nx_graph_tm1.nodes: #Careful : if there is a cycle with low angle this might loop indefinitely but unprobable\n",
    "            i+=1\n",
    "            if i>=100:\n",
    "                print(i,tip,current_node,pos_t[current_node])\n",
    "            mini=np.inf\n",
    "            origin_vector = last_branch[0]-last_branch[min(length_id,len(last_branch)-1)]\n",
    "            unit_vector_origin = origin_vector / np.linalg.norm(origin_vector)\n",
    "            candidate_vectors=[]\n",
    "            for neighbours_t in nx_graph_t.neighbors(current_node):\n",
    "                if neighbours_t!=last_node:\n",
    "                    branch_candidate=np.array(orient(nx_graph_t.get_edge_data(current_node,neighbours_t)['pixel_list'],pos_t[current_node]))\n",
    "                    candidate_vector = branch_candidate[min(length_id,len(branch_candidate)-1)]-branch_candidate[0]\n",
    "                    unit_vector_candidate = candidate_vector / np.linalg.norm(candidate_vector)\n",
    "                    candidate_vectors.append(unit_vector_candidate)\n",
    "                    dot_product = np.dot(unit_vector_origin, unit_vector_candidate)\n",
    "                    angle = np.arccos(dot_product)\n",
    "                    if angle<mini:\n",
    "                        mini=angle\n",
    "                        next_node=neighbours_t\n",
    "#                     print('angle',dot_product,pos_t[last_node],pos_t[current_node],pos_t[neighbours_t],angle/(2*np.pi)*360)\n",
    "#!!!bug may happen here if two nodes are direct neighbours : I would nee to check further why it the case, optimal segmentation should avoid this issue.\n",
    "# This is especially a problem for degree 4 nodes. Maybe fuse nodes that are closer than 3 pixels.\n",
    "            if i>=100:\n",
    "                print(mini/(2*np.pi)*360, pos_t[next_node])\n",
    "                if next_node in loop:\n",
    "                    break\n",
    "                else:\n",
    "                    loop.append(next_node)\n",
    "            if len(candidate_vectors)<2:\n",
    "                print(\"candidate_vectors < 2\",nx_graph_t.degree(current_node),pos_t[current_node],[node for node in nx_graph_t.nodes if nx_graph_t.degree(node)==2])\n",
    "            competitor = np.arccos(np.dot(candidate_vectors[0],-candidate_vectors[1]))\n",
    "            if mini<competitor:\n",
    "                current_node,last_node=next_node,current_node\n",
    "            else:\n",
    "                corresp_tips[tip]=current_node\n",
    "                break\n",
    "        corresp_tips[tip]=current_node\n",
    "    new_graphs,new_poss=relabel_nodes_downstream(corresp_tips,downstream_graphs,downstream_pos)\n",
    "    downstream_pos=new_poss\n",
    "    downstream_graphs=new_graphs\n",
    "#     print(\"second relabeling\")\n",
    "#     print(len(nx_graph_tm1.nodes),len(new_graphs[0].nodes))\n",
    "    new_graphs,new_poss=reduce_labels([nx_graph_tm1]+downstream_graphs,[pos_tm1]+downstream_pos)\n",
    "#     print(\"third relabeling\")\n",
    "#     print(len(new_graphs[0].nodes),len(new_graphs[1].nodes))\n",
    "    return(new_graphs,new_poss)\n",
    "                \n",
    "\n",
    "def whole_movement_identification(nx_graph_tm1,nx_graph_t,pos_tm1,pos_t,length_id=50):\n",
    "    tips = [node for node in nx_graph_tm1.nodes if nx_graph_tm1.degree(node)==1]\n",
    "    tip_origin={tip : tip  for tip in tips}\n",
    "    pixels_from_tip={tip : [] for tip in tips}\n",
    "    for number,tip in enumerate(tips):\n",
    "#         print('tip',pos_tm1[tip],tip)\n",
    "        if number%100==0:\n",
    "            print(number/len(tips))\n",
    "        mini=np.inf\n",
    "        for edge in nx_graph_t.edges:\n",
    "            pixel_list=nx_graph_t.get_edge_data(*edge)['pixel_list']\n",
    "            if np.linalg.norm(np.array(pixel_list[0])-np.array(pos_tm1[tip]))<=5000:\n",
    "                distance=np.min(np.linalg.norm(np.array(pixel_list)-np.array(pos_tm1[tip]),axis=1))\n",
    "                if distance<mini:\n",
    "                    mini=distance\n",
    "                    right_edge = edge\n",
    "        origin = np.array(orient(nx_graph_tm1.get_edge_data(*list(nx_graph_tm1.edges(tip))[0])['pixel_list'],pos_tm1[tip]))\n",
    "        origin_vector = origin[0]-origin[-1]\n",
    "        branch=np.array(orient(nx_graph_t.get_edge_data(*right_edge)['pixel_list'],pos_t[right_edge[0]]))\n",
    "        index_nearest_pixel=np.argmin(np.linalg.norm(branch-np.array(pos_tm1[tip]),axis=1))\n",
    "        candidate_vector = branch[-1]-branch[0]\n",
    "        dot_product = np.dot(origin_vector,candidate_vector)\n",
    "#         if tip==5260:\n",
    "#             print(list(branch[index_nearest_pixel:]))\n",
    "#             print(list(branch[:index_nearest_pixel]))\n",
    "        if dot_product>=0:\n",
    "            root=right_edge[0]\n",
    "            next_node=right_edge[1]\n",
    "            pixels_from_tip[tip]+=list(branch[index_nearest_pixel:])\n",
    "        else:\n",
    "            root=right_edge[1]\n",
    "            next_node=right_edge[0]\n",
    "            pixels_from_tip[tip]+=list(reversed(list(branch[:index_nearest_pixel])))\n",
    "        #Could improve the candidate vector by chosing pixel around the forme tip but this identification should be rather unambiguous\n",
    "        last_node=root\n",
    "        current_node=next_node\n",
    "        last_branch=np.array(orient(nx_graph_t.get_edge_data(root,next_node)['pixel_list'],pos_t[current_node]))\n",
    "        def label_node_recursive(last_node,current_node,corresp_label):\n",
    "            if not current_node in corresp_label.keys() and not current_node in nx_graph_tm1.nodes:\n",
    "                corresp_label[current_node]=tip\n",
    "                pixel_list=nx_graph_t.get_edge_data(last_node,current_node)['pixel_list']\n",
    "                pixels_from_tip[tip]+=pixel_list\n",
    "                if nx_graph_t.degree(current_node)>=3:\n",
    "                    for neighbour_t in nx_graph_t.neighbors(current_node): \n",
    "                        if neighbour_t!=last_node:\n",
    "                            label_node_recursive(current_node,neighbour_t,corresp_label)\n",
    "        label_node_recursive(last_node,current_node,tip_origin)\n",
    "    return(tip_origin,pixels_from_tip)\n",
    "\n",
    "def shift(skeleton1,skeleton2):\n",
    "    skeleton1_dilated = dilate(dilate(skeleton1)).astype(np.float)\n",
    "    skeleton2_dilated = dilate(dilate(skeleton2)).astype(np.float)\n",
    "    def distance(shift):\n",
    "        distance=0\n",
    "#         print(shift)\n",
    "        for pixel in skeleton1_dilated.keys():\n",
    "#             print(pixel[0]+shift[0],pixel[1]+shift[1])\n",
    "            if (skeleton2_dilated.shape[0]>np.ceil(pixel[0]+shift[0])>=0 and skeleton2_dilated.shape[1]>np.ceil(pixel[1]+shift[1])>=0):\n",
    "                shifted_pixel = (int(pixel[0]+shift[0]),int(pixel[1]+shift[1]))\n",
    "                shifted_pixel_next = (np.ceil(pixel[0]+shift[0]),np.ceil(pixel[1]+shift[1]))\n",
    "#                 print(shifted_pixel)\n",
    "                prop=1/2*(pixel[0]+shift[0]-int(pixel[0]+shift[0])+pixel[1]+shift[1]-int(pixel[1]+shift[1]))\n",
    "                float_value=(1-prop)*skeleton2_dilated[shifted_pixel[0],shifted_pixel[1]]+prop*(skeleton2_dilated[shifted_pixel_next[0],shifted_pixel_next[1]])\n",
    "                distance+=abs(skeleton1_dilated[pixel]-float_value)\n",
    "            else:\n",
    "                distance+=1\n",
    "#         for pixel in skeleton2_dilated.keys():\n",
    "#             if (skeleton2_dilated.shape[0]>pixel[0]-shift[0]>=0 and skeleton2_dilated.shape[1]>pixel[1]-shift[1]>=0):\n",
    "#                 shifted_pixel = (int(pixel[0]-shift[0]),int(pixel[1]-shift[1]))\n",
    "#                 distance+=abs(skeleton1_dilated[shifted_pixel[0],shifted_pixel[1]]^skeleton2_dilated[pixel])\n",
    "#             else:\n",
    "#                 distance+=1\n",
    "#         print(distance)\n",
    "        return distance\n",
    "    return(minimize(distance,np.array([10,10]), method='nelder-mead',options={'xatol': 1, 'disp': True,'fatol':0.1}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cleanMsc",
   "language": "python",
   "name": "cleanmsc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
