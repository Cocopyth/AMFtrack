{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from IPython.display import clear_output\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# sys.path.insert(0, os.getenv('HOME')+'/pycode/MscThesis/')\n",
    "# sys.path.insert(0,r'C:\\Users\\coren\\Documents\\PhD\\Code\\AMFtrack')\n",
    "\n",
    "import pandas as pd\n",
    "from amftrack.util.sys import (\n",
    "    get_dates_datetime,\n",
    "    get_dirname,\n",
    "    temp_path,\n",
    "    get_data_info,\n",
    "    update_plate_info,\n",
    "    get_current_folders,\n",
    "    get_folders_by_plate_id,\n",
    ")\n",
    "\n",
    "\n",
    "import ast\n",
    "from amftrack.plotutil import plot_t_tp1\n",
    "from scipy import sparse\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import scipy.io as sio\n",
    "from pymatreader import read_mat\n",
    "from matplotlib import colors\n",
    "import cv2\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage.filters import frangi\n",
    "from skimage import filters\n",
    "from random import choice\n",
    "import scipy.sparse\n",
    "import os\n",
    "from amftrack.pipeline.functions.image_processing.extract_graph import (\n",
    "    from_sparse_to_graph,\n",
    "    generate_nx_graph,\n",
    "    sparse_to_doc,\n",
    ")\n",
    "from skimage.feature import hessian_matrix_det\n",
    "\n",
    "# from amftrack.pipeline.functions.image_processing.experiment_class_surf import Experiment\n",
    "from amftrack.pipeline.launching.run import (\n",
    "    run_transfer,\n",
    ")\n",
    "import dropbox\n",
    "from amftrack.util.dbx import upload_folders, load_dbx, download, get_dropbox_folders\n",
    "from subprocess import call\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.debug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**To transfer data from sun to dropbox**\n",
    "- select the path where the data is\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "directory_origin = \"/mnt/sun-temp/TEMP/PRINCE_Felix/\"\n",
    "directory_origin = \"/media/bisot/AMF_03/PRINCE/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "- get the folders at this path and select the folders of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "update_plate_info(directory_origin, local=True, strong_constraint=False)\n",
    "all_folders = get_current_folders(directory_origin, local=True)\n",
    "folders = all_folders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "- use the 'toward_drop.py' function including the folders of interest and using dir_drop as a parameter indicating where in dropbox the data should go\n",
    "- The delete parameter indicates wether the data should be deleted from the path of origin after succesfull upload on dropbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dir_drop = \"DATA/PRINCE\"\n",
    "delete = False\n",
    "run_transfer(\n",
    "    \"toward_drop.py\",\n",
    "    [dir_drop, delete],\n",
    "    folders,\n",
    ")\n",
    "clear_output(wait=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**To transfer data from dropbox to surfsara**\n",
    "- select the folders of interest within the folders of dropbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_folders_drop = get_dropbox_folders(\"/DATA/TransportCUT/\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# folders_drop = all_folders_drop.loc[all_folders_drop['CrossDate'].between(\"20181015\",\"20201015\")]\n",
    "folders_drop = all_folders_drop.loc[all_folders_drop[\"Plate\"] == \"52\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "folders_drop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "- select the path where the folders should go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# directory_targ = '/mnt/sun-temp/TEMP/PRINCE_Felix/'\n",
    "directory_targ = \"/mnt/sun/home-folder/bisot/PRINCE_test/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "- use the 'from_drop.py' function including the folders of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "run_transfer(\n",
    "    \"from_drop.py\",\n",
    "    [directory_targ],\n",
    "    folders_drop,\n",
    ")\n",
    "clear_output(wait=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**To transfer data from dropbox to archive**\n",
    "- use the 'from_drop.py' function including the folders of interest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "folders = all_folders.loc[all_folders[\"Plate\"].isin([792, 94])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "len(folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "unzip = \"False\"\n",
    "flatten = False\n",
    "dir_drop = \"prince_data\"\n",
    "\n",
    "directory_targ = os.path.join(directory_scratch, \"temp\") + \"/\"\n",
    "directory = directory_targ\n",
    "run_parallel_transfer(\n",
    "    \"from_drop.py\",\n",
    "    [directory_targ, dir_drop, unzip, flatten],\n",
    "    folders,\n",
    "    5,\n",
    "    \"10:00\",\n",
    "    \"staging\",\n",
    "    cpus=1,\n",
    "    node=\"staging\",\n",
    "    name_job=\"archiving.sh\",\n",
    ")\n",
    "run_parallel_transfer_to_archive(\n",
    "    folders, directory, \"2:00:00\", \"staging\", name_job=\"archiving.sh\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "run_parallel_transfer_to_archive(\n",
    "    folders, directory, \"10:00\", \"staging\", name_job=\"archiving_no_wait.sh\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "must_zip = True\n",
    "must_unzip = False\n",
    "run_parallel_transfer(\n",
    "    \"within_surf.py\",\n",
    "    [directory, directory_targ, must_zip, must_unzip],\n",
    "    folders,\n",
    "    5,\n",
    "    \"10:00\",\n",
    "    \"staging\",\n",
    "    cpus=1,\n",
    "    node=\"staging\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_dropbox_folders_new(dir_drop: str) -> pd.DataFrame:\n",
    "    data = []\n",
    "    dbx = load_dbx()\n",
    "    response = dbx.files_list_folder(dir_drop, recursive=True)\n",
    "    # for fil in response.entries:\n",
    "    listfiles = []\n",
    "    listjson = []\n",
    "    while response.has_more:\n",
    "        listfiles += [\n",
    "            file for file in response.entries if file.name.split(\"/\")[-1] == \"param.m\"\n",
    "        ]\n",
    "        response = dbx.files_list_folder_continue(response.cursor)\n",
    "    listfiles += [\n",
    "        file for file in response.entries if file.name.split(\"/\")[-1] == \"param.m\"\n",
    "    ]\n",
    "    # print([((file.path_lower.split(\".\")[0]) + \"_info.json\") for file in listfiles if (file.name.split(\".\")[-1] == \"zip\") &\n",
    "    #        (((file.path_lower.split(\".\")[0]) + \"_info.json\") not in listjson)])\n",
    "    listfiles.reverse()\n",
    "    names = [file.path_lower.split(\"/\")[-2] for file in listfiles]\n",
    "    path_drop = [os.path.join(*file.path_lower.split(\"/\")[:-1]) for file in listfiles]\n",
    "    id_uniques = [path.split(\"/\")[-2] for path in path_drop]\n",
    "    plate_num = [idi.split(\"_\")[0] for idi in id_uniques]\n",
    "    date_cross = [idi.split(\"_\")[1] for idi in id_uniques]\n",
    "    sizes = [file.size / 10**9 for file in listfiles]\n",
    "    modified = [file.client_modified for file in listfiles]\n",
    "    df = pd.DataFrame(\n",
    "        (names, sizes, modified, path_drop, plate_num, date_cross, id_uniques)\n",
    "    ).transpose()\n",
    "    df = df.rename(\n",
    "        columns={\n",
    "            0: \"folder\",\n",
    "            1: \"size\",\n",
    "            2: \"change_date\",\n",
    "            3: \"tot_path_drop\",\n",
    "            4: \"Plate\",\n",
    "            5: \"CrossDate\",\n",
    "            6: \"unique_id\",\n",
    "        }\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "all_folders_drop_new = get_dropbox_folders_new(\"/DATA/PRINCE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "all_folders_drop_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "directory_targ2 = os.path.join(directory_scratch, \"temptemp\") + \"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dbx = load_dbx()\n",
    "\n",
    "path = \"/\" + all_folders_drop_new.iloc[0][\"tot_path_drop\"]\n",
    "response = dbx.files_list_folder(path, recursive=False)\n",
    "listfiles = []\n",
    "listjson = []\n",
    "while response.has_more:\n",
    "    listfiles += [file for file in response.entries]\n",
    "    response = dbx.files_list_folder_continue(response.cursor)\n",
    "listfiles += [file for file in response.entries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "listfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "[file.path_lower for file in listfiles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def download_folders_drop(folders_drop: pd.DataFrame, directory_target):\n",
    "    dbx = load_dbx()\n",
    "    for index, row in folders_drop.iterrows():\n",
    "        path = \"/\" + row[\"tot_path_drop\"]\n",
    "        response = dbx.files_list_folder(path, recursive=False)\n",
    "        listfiles = []\n",
    "        while response.has_more:\n",
    "            listfiles += [file for file in response.entries]\n",
    "            response = dbx.files_list_folder_continue(response.cursor)\n",
    "        listfiles += [file for file in response.entries]\n",
    "        folder = row[\"folder\"]\n",
    "        path_folder = os.path.join(directory_target, folder)\n",
    "        if not os.path.exists(path_folder):\n",
    "            os.mkdir(path_folder)\n",
    "        for file in listfiles:\n",
    "            path_drop = file.path_lower\n",
    "            path_local = os.path.join(\n",
    "                directory_target, folder, path_drop.split(\"/\")[-1]\n",
    "            )\n",
    "            print(path_drop, path_local)\n",
    "\n",
    "            download(path_drop, path_local, unzip=(path_drop[-4:] == \".zip\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "download_folders_drop(all_folders_drop_new, directory_targ2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
