{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from amftrack.util.sys import (\n",
    "    get_dates_datetime,\n",
    "    get_dirname,\n",
    "    temp_path,\n",
    "    get_data_info,\n",
    "    update_plate_info,\n",
    "    get_current_folders,\n",
    "    get_folders_by_plate_id,\n",
    ")\n",
    "import ast\n",
    "from amftrack.plotutil import plot_t_tp1\n",
    "from scipy import sparse\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import scipy.io as sio\n",
    "from pymatreader import read_mat\n",
    "from matplotlib import colors\n",
    "import cv2\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage.filters import frangi\n",
    "from skimage import filters\n",
    "from random import choice\n",
    "import scipy.sparse\n",
    "import os\n",
    "from skimage.feature import hessian_matrix_det\n",
    "from amftrack.pipeline.launching.run_super import *\n",
    "from amftrack.pipeline.functions.image_processing.experiment_class_surf import (\n",
    "    Node,\n",
    "    Experiment,\n",
    "    save_graphs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "directory = directory_project\n",
    "# update_plate_info(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48f69c8768a5492683dfb3cf8e4016fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "analysed:   0%|          | 0/441 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "directory = \"/projects/0/einf914/agg/\"\n",
    "update_plate_info(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_folders = get_current_folders(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220\n"
     ]
    }
   ],
   "source": [
    "folders = all_folders.loc[all_folders[\"Plate\"] == \"737\"]\n",
    "print(len(folders))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = folders.sort_values(by=[\"datetime\"], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "***Create graphs***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 507919\n",
      "Submitted batch job 507921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: You will be charged for 1.0 node. A full node consists of 128 CPU cores, 960000 MiB of memory and 0 GPUs and can be shared by up to 4 jobs.\n",
      "sbatch: Single node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: You will be charged for 1.0 node. A full node consists of 128 CPU cores, 960000 MiB of memory and 0 GPUs and can be shared by up to 4 jobs.\n"
     ]
    }
   ],
   "source": [
    "num_parallel = 128\n",
    "time = \"5:00:00\"\n",
    "args = [directory]\n",
    "run_parallel(\n",
    "    \"extract_nx_graph.py\",\n",
    "    args,\n",
    "    folders,\n",
    "    num_parallel,\n",
    "    time,\n",
    "    \"extract_nx\",\n",
    "    cpus=128,\n",
    "    node=\"fat\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "336"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plates = [22, 10, 76, 26, 152, 102]\n",
    "\n",
    "folders = all_folders.loc[\n",
    "    (all_folders[\"/Analysis/nx_graph_pruned.p\"]) & (all_folders[\"Plate\"].isin(plates))\n",
    "]\n",
    "len(folders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Extract Width***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 508441\n",
      "Submitted batch job 508442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: You will be charged for 0.25 node. A full node consists of 128 CPU cores, 960000 MiB of memory and 0 GPUs and can be shared by up to 4 jobs.\n",
      "sbatch: Single node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: You will be charged for 0.25 node. A full node consists of 128 CPU cores, 960000 MiB of memory and 0 GPUs and can be shared by up to 4 jobs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 508443\n",
      "Submitted batch job 508444\n",
      "Submitted batch job 508445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: You will be charged for 0.25 node. A full node consists of 128 CPU cores, 960000 MiB of memory and 0 GPUs and can be shared by up to 4 jobs.\n",
      "sbatch: Single node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: You will be charged for 0.25 node. A full node consists of 128 CPU cores, 960000 MiB of memory and 0 GPUs and can be shared by up to 4 jobs.\n",
      "sbatch: Single node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: You will be charged for 0.25 node. A full node consists of 128 CPU cores, 960000 MiB of memory and 0 GPUs and can be shared by up to 4 jobs.\n"
     ]
    }
   ],
   "source": [
    "num_parallel = 128\n",
    "time = \"24:00:00\"\n",
    "skip = False\n",
    "resolution = 50\n",
    "args = [directory, skip, resolution]\n",
    "run_parallel(\n",
    "    \"extract_width.py\",\n",
    "    args,\n",
    "    folders,\n",
    "    num_parallel,\n",
    "    time,\n",
    "    \"extract_width2\",\n",
    "    cpus=32,\n",
    "    node=\"fat\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plates = [22, 10, 76, 26, 152, 102]\n",
    "\n",
    "folders = all_folders.loc[\n",
    "    (1 - all_folders[\"/Analysis/nx_graph_pruned_width.p\"])\n",
    "    & (all_folders[\"Plate\"].isin(plates))\n",
    "    & (all_folders[\"/Analysis/nx_graph_pruned.p\"])\n",
    "]\n",
    "# folders.loc[folders['folder'] == '20210110_1523_Plate30']\n",
    "# int(list(folders['folder'])[0].split('_')[-1][5:])\n",
    "len(folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "336"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plates = [22, 10, 76, 26, 152, 102]\n",
    "\n",
    "folders = all_folders.loc[\n",
    "    (all_folders[\"/Analysis/nx_graph_pruned_width.p\"])\n",
    "    & (all_folders[\"Plate\"].isin(plates))\n",
    "]\n",
    "# folders.loc[folders['folder'] == '20210110_1523_Plate30']\n",
    "# int(list(folders['folder'])[0].split('_')[-1][5:])\n",
    "len(folders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Identify Nodes***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 535639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: You will be charged for 0.25 node. A full node consists of 128 CPU cores, 960000 MiB of memory and 0 GPUs and can be shared by up to 4 jobs.\n"
     ]
    }
   ],
   "source": [
    "num_parallel = 32\n",
    "time = \"1:00:00\"\n",
    "limit = 55\n",
    "skip = False\n",
    "args = [directory, limit, skip]\n",
    "run_parallel_all_time(\n",
    "    \"extract_nodes.py\",\n",
    "    args,\n",
    "    folders,\n",
    "    num_parallel,\n",
    "    time,\n",
    "    \"node_id\",\n",
    "    cpus=32,\n",
    "    node=\"fat\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: You will be charged for 1.0 node. A full node consists of 128 CPU cores, 983040 MiB of memory and 0 GPUs and can be shared by up to 4 jobs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 1089373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: You will be charged for 1.0 node. A full node consists of 128 CPU cores, 983040 MiB of memory and 0 GPUs and can be shared by up to 4 jobs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 1089374\n",
      "Submitted batch job 1089375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: You will be charged for 1.0 node. A full node consists of 128 CPU cores, 983040 MiB of memory and 0 GPUs and can be shared by up to 4 jobs.\n"
     ]
    }
   ],
   "source": [
    "plates = list(set(list(folders[\"unique_id\"].values)))\n",
    "args = [directory]\n",
    "num_parallel = 128\n",
    "\n",
    "for unique_id in plates:\n",
    "    select = folders.loc[folders[\"unique_id\"] == unique_id]\n",
    "    time = \"2:00:00\"\n",
    "    run_parallel(\n",
    "        \"track_nodes.py\",\n",
    "        args,\n",
    "        select,\n",
    "        num_parallel,\n",
    "        time,\n",
    "        \"track_node\",\n",
    "        cpus=128,\n",
    "        node=\"fat\",\n",
    "        name_job=\"track.sh\",\n",
    "    )\n",
    "\n",
    "time = \"30:00\"\n",
    "run_parallel_all_time(\n",
    "    \"make_labeled_graphs.py\",\n",
    "    args,\n",
    "    folders,\n",
    "    num_parallel,\n",
    "    time,\n",
    "    \"make_graphs\",\n",
    "    cpus=128,\n",
    "    node=\"fat\",\n",
    "    dependency=True,\n",
    "    name_job=\"track.sh\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-01 21:39:00\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/home2/cbisot/pycode/AMFtrack/amftrack/pipeline/functions/image_processing/experiment_class_surf.py:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.folders[\"date\"], format=\"%d.%m.%Y, %H:%M:\"\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/projects/0/einf914/agg/20210901_2139_Plate34/Analysis/nx_graph_pruned_labeled.p'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/scratch-local/cbisot/ipykernel_1336691/3241373196.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mselect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfolders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mexp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'_labeled'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/gpfs/home2/cbisot/pycode/AMFtrack/amftrack/pipeline/functions/image_processing/experiment_class_surf.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, folders, suffix)\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Analysis\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34mf\"nx_graph_pruned{suffix}.p\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0mpath_save\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_snap\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_save\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m             \u001b[0mnx_graph_poss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/projects/0/einf914/agg/20210901_2139_Plate34/Analysis/nx_graph_pruned_labeled.p'"
     ]
    }
   ],
   "source": [
    "folders = folders.sort_values(\"datetime\")\n",
    "select = folders.iloc[:10]\n",
    "exp = Experiment(directory)\n",
    "exp.load(select, suffix=\"_labeled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Hyphae extraction***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 551041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: You will be charged for 0.25 node. A full node consists of 128 CPU cores, 960000 MiB of memory and 0 GPUs and can be shared by up to 4 jobs.\n"
     ]
    }
   ],
   "source": [
    "num_parallel = 32\n",
    "time = \"8:00:00\"\n",
    "limit = 55\n",
    "version = 11\n",
    "labeled = True\n",
    "args = [directory, limit, version, labeled]\n",
    "run_parallel_all_time(\n",
    "    \"hyphae_extraction.py\",\n",
    "    args,\n",
    "    folders,\n",
    "    num_parallel,\n",
    "    time,\n",
    "    \"hyphae\",\n",
    "    cpus=32,\n",
    "    node=\"fat\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
