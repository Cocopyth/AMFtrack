{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/home2/cbisot/pycode/AMFtrack/amftrack/util/dbx.py:3: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "import os  \n",
    "import sys  \n",
    "import pandas as pd\n",
    "from amftrack.util.sys import get_dates_datetime, get_dirname, temp_path, get_data_info, update_plate_info, \\\n",
    "get_current_folders, get_folders_by_plate_id\n",
    "import ast\n",
    "from amftrack.plotutil import plot_t_tp1\n",
    "from scipy import sparse\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import scipy.io as sio\n",
    "from pymatreader import read_mat\n",
    "from matplotlib import colors\n",
    "import cv2\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage.filters import frangi\n",
    "from skimage import filters\n",
    "from random import choice\n",
    "import scipy.sparse\n",
    "import os\n",
    "from skimage.feature import hessian_matrix_det\n",
    "from amftrack.pipeline.launching.run_super import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "directory = directory_project\n",
    "# update_plate_info(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63c2affb79fd496486574cb6c77cf657",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "analysed:   0%|          | 0/441 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "directory = '/projects/0/einf914/agg/'\n",
    "update_plate_info(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_folders = get_current_folders(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220\n"
     ]
    }
   ],
   "source": [
    "folders = all_folders.loc[all_folders['Plate']==\"737\"]\n",
    "print(len(folders))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "***Create graphs***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 507919\n",
      "Submitted batch job 507921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: You will be charged for 1.0 node. A full node consists of 128 CPU cores, 960000 MiB of memory and 0 GPUs and can be shared by up to 4 jobs.\n",
      "sbatch: Single node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: You will be charged for 1.0 node. A full node consists of 128 CPU cores, 960000 MiB of memory and 0 GPUs and can be shared by up to 4 jobs.\n"
     ]
    }
   ],
   "source": [
    "num_parallel = 128\n",
    "time = '5:00:00'\n",
    "args=[directory]\n",
    "run_parallel('extract_nx_graph.py',args, folders, num_parallel, time,'extract_nx',cpus = 128,node ='fat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "336"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plates = [22,10,76,26,152,102]\n",
    "\n",
    "folders = all_folders.loc[(all_folders['/Analysis/nx_graph_pruned.p'])&(all_folders['Plate'].isin(plates))]\n",
    "len(folders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Extract Width***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 508441\n",
      "Submitted batch job 508442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: You will be charged for 0.25 node. A full node consists of 128 CPU cores, 960000 MiB of memory and 0 GPUs and can be shared by up to 4 jobs.\n",
      "sbatch: Single node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: You will be charged for 0.25 node. A full node consists of 128 CPU cores, 960000 MiB of memory and 0 GPUs and can be shared by up to 4 jobs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 508443\n",
      "Submitted batch job 508444\n",
      "Submitted batch job 508445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: You will be charged for 0.25 node. A full node consists of 128 CPU cores, 960000 MiB of memory and 0 GPUs and can be shared by up to 4 jobs.\n",
      "sbatch: Single node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: You will be charged for 0.25 node. A full node consists of 128 CPU cores, 960000 MiB of memory and 0 GPUs and can be shared by up to 4 jobs.\n",
      "sbatch: Single node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: You will be charged for 0.25 node. A full node consists of 128 CPU cores, 960000 MiB of memory and 0 GPUs and can be shared by up to 4 jobs.\n"
     ]
    }
   ],
   "source": [
    "num_parallel = 128\n",
    "time = '24:00:00'\n",
    "skip = False\n",
    "resolution = 50\n",
    "args = [directory,skip,resolution]\n",
    "run_parallel('extract_width.py',args,folders,num_parallel,time,'extract_width2',cpus=32,node=\"fat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plates = [22,10,76,26,152,102]\n",
    "\n",
    "folders = all_folders.loc[(1-all_folders['/Analysis/nx_graph_pruned_width.p'])&(all_folders['Plate'].isin(plates))&(all_folders['/Analysis/nx_graph_pruned.p'])]\n",
    "# folders.loc[folders['folder'] == '20210110_1523_Plate30']\n",
    "# int(list(folders['folder'])[0].split('_')[-1][5:])\n",
    "len(folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "336"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plates = [22,10,76,26,152,102]\n",
    "\n",
    "folders = all_folders.loc[(all_folders['/Analysis/nx_graph_pruned_width.p'])&(all_folders['Plate'].isin(plates))]\n",
    "# folders.loc[folders['folder'] == '20210110_1523_Plate30']\n",
    "# int(list(folders['folder'])[0].split('_')[-1][5:])\n",
    "len(folders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Identify Nodes***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 535639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: You will be charged for 0.25 node. A full node consists of 128 CPU cores, 960000 MiB of memory and 0 GPUs and can be shared by up to 4 jobs.\n"
     ]
    }
   ],
   "source": [
    "num_parallel = 32\n",
    "time = '24:00:00'\n",
    "limit = 55\n",
    "skip = False\n",
    "args=[directory,limit,skip]\n",
    "run_parallel_all_time('extract_nodes.py',args,folders,num_parallel,time,'node_id',cpus = 32,node=\"fat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plates = list(set(list(folders['Plate'].values)))\n",
    "for plate in plates:\n",
    "    select = folders.loc[folders['Plate']==plate]\n",
    "    num_parallel = 128\n",
    "    time = '12:00:00'\n",
    "    args = [directory]\n",
    "    run_parallel('track_nodes.py', args, select, num_parallel, time, 'track_node',cpus = 128,node = \"fat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "239"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plates = [22,10,76,26,152,102]\n",
    "\n",
    "folders = all_folders.loc[(all_folders['/Analysis/nx_graph_pruned_labeled.p'])&(all_folders['Plate'].isin(plates))]\n",
    "# folders.loc[folders['folder'] == '20210110_1523_Plate30']\n",
    "# int(list(folders['folder'])[0].split('_')[-1][5:])\n",
    "len(folders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Hyphae extraction***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 551041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: You will be charged for 0.25 node. A full node consists of 128 CPU cores, 960000 MiB of memory and 0 GPUs and can be shared by up to 4 jobs.\n"
     ]
    }
   ],
   "source": [
    "num_parallel = 32\n",
    "time = '8:00:00'\n",
    "limit = 55\n",
    "version = 11\n",
    "labeled = True\n",
    "args = [directory,limit,version,labeled]\n",
    "run_parallel_all_time('hyphae_extraction.py',args,folders,num_parallel,time,'hyphae',cpus = 32,node=\"fat\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
