{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f504f673-4435-49be-9a17-b89265d32d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "import sys  \n",
    "sys.path.insert(0, '/home/cbisot/pycode/MscThesis/')\n",
    "from pymatreader import read_mat\n",
    "from scipy import sparse\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import pandas\n",
    "import cv2\n",
    "import json\n",
    "import pandas as pd\n",
    "from amftrack.pipeline.paths.directory import *\n",
    "from amftrack.util import *\n",
    "import pickle\n",
    "from joblib import Parallel, delayed\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from amftrack.pipeline.functions.post_processing.global_plate import *\n",
    "from amftrack.pipeline.functions.post_processing.global_hypha import *\n",
    "from amftrack.pipeline.functions.post_processing.time_hypha import *\n",
    "from amftrack.pipeline.functions.post_processing.time_plate import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78b3dbf3-bf6e-49ec-91a3-8b07bd94b860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/projects/0/einf914/data/'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory_project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60337d63-b021-488a-9fc2-79cf3628eec0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "directory = directory_project\n",
    "# directory = '/projects/0/einf914/agg/'\n",
    "update_analysis_info(directory)\n",
    "analysis_info = get_analysis_info(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9dff4f40-63e7-4935-8c4a-34c24611ea53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "select = analysis_info.loc[analysis_info['Plate']!=22]\n",
    "# analysis_info['Plate']=analysis_info['Plate'].fillna(758)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38caf3db-03b1-426c-88b1-6c3f8ac802fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_info['Plate']=analysis_info['Plate'].fillna(758)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f947b3eb-ba8a-4402-ab1c-18c914c1ebe8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "select = analysis_info.loc[analysis_info['Plate'].isin([94])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e612010-1a01-4e78-8920-d80ffd22244a",
   "metadata": {},
   "outputs": [],
   "source": [
    "select = analysis_info.loc[analysis_info['Plate']==792]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c8b307-fb15-4c67-857e-0aafa9f2ea77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plates = set(select_v7['Plate'].values)\n",
    "plates\n",
    "selection = []\n",
    "for plate in plates:\n",
    "    select_folder = np.min(select_v7.loc[(select_v7['Plate']==plate)]['folder_analysis'])\n",
    "    selection.append(select_folder)\n",
    "select = select_v7.loc[(select_v7['folder_analysis'].isin(selection))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9059bb-f020-4d9f-8e5f-1641ee5dab6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from shutil import copyfile\n",
    "for index,row in select.iterrows():\n",
    "    plate = row['Plate']\n",
    "    folder_target = row['folder_analysis']\n",
    "    if len(select.loc[select['Plate']==plate]['folder_analysis'])>0:\n",
    "        folder_origin = select.loc[select['Plate']==plate]['folder_analysis'].values[0]\n",
    "        src = f'{directory_project}{folder_origin}/orthog.npy'\n",
    "        dst = f'{directory_project}{folder_target}/orthog.npy'\n",
    "        if os.path.isfile(src):\n",
    "            print(dst)\n",
    "            # copyfile(src, dst)\n",
    "        else:\n",
    "            print(plate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f895fa86-1de2-4e56-b57c-bd87b16eed80",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 195252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n"
     ]
    }
   ],
   "source": [
    "time = '10:00'\n",
    "directory = directory\n",
    "list_f = [num_hypha,prop_lost_tracks_junction,prop_lost_tracks_tips,prop_lost_tracks_junction,prop_lost_tracks_tips,prop_inconsistent_root,number_of_timepoints_withing_boundaries,number_of_timepoints]\n",
    "list_args= [None,[1],[1],[10],[10]]+[[]]*len(list_f)\n",
    "overwrite = True\n",
    "num_parallel = 5\n",
    "run_parallel_post('global_plate_post_process.py', list_f,list_args,[directory,overwrite],select, num_parallel, time,'global_plate_post_process',cpus = 32,name_job = 'glob_plate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ca37270-2067-47f5-9012-098dd5a2c693",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 195518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n"
     ]
    }
   ],
   "source": [
    "time = '10:00'\n",
    "directory = directory\n",
    "list_f = []\n",
    "list_args= [[]]*len(list_f)\n",
    "overwrite = True\n",
    "num_parallel = 5\n",
    "run_parallel_post('exp_plot.py', list_f,list_args,[directory,overwrite],select, num_parallel, time,'global_plate_post_process',cpus = 128,name_job = 'glob_plate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25905d71-e019-4f51-bfa4-c9243d157559",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 195536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n"
     ]
    }
   ],
   "source": [
    "time = '20:00'\n",
    "directory = directory\n",
    "list_f = []\n",
    "list_args= [[]]*len(list_f)\n",
    "overwrite = True\n",
    "num_parallel = 5\n",
    "run_parallel_post('make_small_exp.py', list_f,list_args,[directory,overwrite],select, num_parallel, time,'global_plate_post_process',cpus = 32,name_job = 'glob_plate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58bbfa6-3b7d-4147-bd0a-85b30d4bb35a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "frames = []\n",
    "for index, row in select.iterrows():\n",
    "    ser = pd.read_json(f'{directory}{row[\"path_global_plate_info\"]}',convert_dates=True,typ='series')\n",
    "    frame = ser.to_frame(index).transpose()\n",
    "    frames.append(frame)\n",
    "global_plate_infos = pd.concat(frames)\n",
    "global_plate_infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e258f995-e688-4b82-914e-03a527c75d1a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 196680\n"
     ]
    }
   ],
   "source": [
    "time = '20:00'\n",
    "directory = directory\n",
    "list_f = [get_num_trunks,get_length,get_area, get_area_separate_connected_components,get_num_tips,get_num_nodes,get_area_study_zone,get_num_tips_study_zone,get_num_nodes_study_zone,get_length_study_zone,is_out_study]\n",
    "# list_f = [get_num_trunks]\n",
    "\n",
    "list_args= [{}]*len(list_f)\n",
    "overwrite = False\n",
    "num_parallel = 5\n",
    "run_parallel_post('time_plate_post_process.py', list_f,list_args,[directory,overwrite],select, num_parallel, time,'time_plate_post_process',cpus = 32,name_job = 'time_plate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde1df19-fd39-4b4b-889c-8e38b524ea87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "frames = []\n",
    "for index, row in select.iterrows():\n",
    "    if os.path.isfile(f'{directory}{row[\"path_time_plate_info\"]}'):\n",
    "        frame = pd.read_json(f'{directory}{row[\"path_time_plate_info\"]}',convert_dates=True).transpose()\n",
    "        frame.index.name = 't'\n",
    "        frame.reset_index(inplace=True)\n",
    "        frames.append(frame)\n",
    "time_plate_infos = pd.concat(frames,ignore_index=True)\n",
    "time_plate_infos.loc[time_plate_infos['Plate']==91]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a6dd6bc-3c7b-4bba-8912-6e25ebc81424",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 205332\n",
      "Submitted batch job 205333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: Single node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n"
     ]
    }
   ],
   "source": [
    "time = '3:00:00'\n",
    "directory = directory\n",
    "# list_f = [get_width,get_tot_length_C,get_tot_growth_C]\n",
    "# list_f = [get_timestep_anastomosis]\n",
    "# list_f = [get_tot_length_pp,get_tot_growth_pp,get_timestep_stop_growth,get_time_stop_growth,get_time_init_growth,get_mean_speed_growth,get_stop_track,get_timestep_anastomosis,get_timestep_biological_stop_growth]\n",
    "# list_f = [get_num_branch]\n",
    "# list_f = [gets_out_of_ROI]\n",
    "list_args= [{}]*len(list_f)\n",
    "overwrite = False\n",
    "num_parallel = 2\n",
    "run_parallel_post('global_hypha_post_process.py', list_f,list_args,[directory,overwrite],select, num_parallel, time,'global_hypha_post_process',cpus = 32,name_job = 'glob_hypha')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed337c3c-01e6-447e-a695-08303b2fa459",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "for index, row in select.iterrows():\n",
    "    if os.path.isfile(f'{directory}{row[\"path_global_hypha_info\"]}'):\n",
    "        frame = pd.read_json(f'{directory}{row[\"path_global_hypha_info\"]}',convert_dates=True).transpose()\n",
    "        frame.index.name = 'hypha'\n",
    "        frame.reset_index(inplace=True)\n",
    "        frames.append(frame)\n",
    "global_hypha_info = pd.concat(frames,ignore_index=True)\n",
    "# time_plate_infos.loc[time_plate_infos['Plate']==91]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f3eb48a-f947-443e-ac6c-28a068d3be75",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: Single node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: Single node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: Single node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 219433\n",
      "Submitted batch job 219434\n",
      "Submitted batch job 219435\n",
      "Submitted batch job 219436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: Single node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: Single node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: Single node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 219437\n",
      "Submitted batch job 219438\n",
      "Submitted batch job 219439\n",
      "Submitted batch job 219440\n",
      "Submitted batch job 219441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: Single node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: Single node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: Single node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: Single node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 219442\n",
      "Submitted batch job 219443\n",
      "Submitted batch job 219444\n",
      "Submitted batch job 219445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: Single node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: Single node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: Single node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 219446\n",
      "Submitted batch job 219447\n",
      "Submitted batch job 219448\n",
      "Submitted batch job 219449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 219450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: Single node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: Single node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: Single node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 219451\n",
      "Submitted batch job 219452\n",
      "Submitted batch job 219453\n",
      "Submitted batch job 219454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: Single node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: Single node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: Single node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 219455\n",
      "Submitted batch job 219456\n",
      "Submitted batch job 219457\n",
      "Submitted batch job 219458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: Single node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: Single node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: Single node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 219459\n",
      "Submitted batch job 219460\n",
      "Submitted batch job 219461\n",
      "Submitted batch job 219462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: Single node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: Single node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: Single node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: Single node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 219463\n",
      "Submitted batch job 219464\n",
      "Submitted batch job 219465\n",
      "Submitted batch job 219466\n",
      "Submitted batch job 219467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: Single node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: Single node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 219468\n",
      "Submitted batch job 219469\n",
      "Submitted batch job 219470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: Single node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: Single node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 219471\n",
      "Submitted batch job 219472\n",
      "Submitted batch job 219473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: Single node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: Single node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: Single node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: Single node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 219474\n",
      "Submitted batch job 219475\n",
      "Submitted batch job 219476\n",
      "Submitted batch job 219477\n",
      "Submitted batch job 219478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: Single node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: Single node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: Single node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: Single node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 219479\n",
      "Submitted batch job 219480\n",
      "Submitted batch job 219481\n",
      "Submitted batch job 219482\n",
      "Submitted batch job 219483\n",
      "Submitted batch job 219484\n",
      "Submitted batch job 219485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: Single node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "list_f = [get_distance_final_pos,get_timedelta,get_time_since_start,get_speed,get_timestep,get_timestep_init,get_time_init,get_degree,get_width_tip_edge,get_width_root_edge,get_width_average,has_reached_final_pos,in_ROI]\n",
    "# list_f = [local_density,local_density,local_density]\n",
    "list_f = [get_time_since_begin_exp]\n",
    "# list_f = [local_density]\n",
    "list_args= [{}]*len(list_f)\n",
    "# list_args= [[500],[1000],[2000]]+[[]]\n",
    "# list_args= [[500]]\n",
    "overwrite = False\n",
    "num_parallel = 25\n",
    "time = '5:00'\n",
    "for index, row in select.iterrows():\n",
    "    folder = row['folder_analysis']\n",
    "    path_time_plate_info = row['path_time_plate_info']\n",
    "    plate = row['Plate']\n",
    "    num_cpus = 32\n",
    "    if os.path.isfile(f'{directory}{path_time_plate_info}'):\n",
    "        whole_plate_info = pd.read_json(f'{directory}{path_time_plate_info}',\n",
    "       convert_dates=True).transpose()\n",
    "        whole_plate_info.index.name = 't'\n",
    "        whole_plate_info.reset_index(inplace=True)\n",
    "        run_parallel_post('time_hypha_post_process.py', list_f,list_args,[directory,overwrite],whole_plate_info, num_parallel, time,'time_hypha_post_process',cpus = num_cpus,name_job='time_hypha')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebab71f8-9376-401f-a872-3d00804f72bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "for index, row in select.iterrows():\n",
    "    folder = row['folder_analysis']\n",
    "    path_time_plate_info = row['path_time_plate_info']\n",
    "    plate = row['Plate']\n",
    "    if os.path.isfile(f'{directory}{path_time_plate_info}'):\n",
    "        time_plate_info = pd.read_json(f'{directory}{path_time_plate_info}',\n",
    "       convert_dates=True).transpose()\n",
    "        time_plate_info.index.name = 't'\n",
    "        time_plate_info.reset_index(inplace=True)\n",
    "        for indexo, rowt in time_plate_info.iterrows():\n",
    "            t = rowt['t']\n",
    "            path_hyph_info_t = f'{directory}{folder}/time_hypha_info/hyph_info_{t}.json'\n",
    "            if os.path.isfile(path_hyph_info_t):\n",
    "                hyph_info_t = pd.read_json(path_hyph_info_t,\n",
    "       convert_dates=True).transpose()\n",
    "                hyph_info_t['Plate']=rowt['Plate']\n",
    "                hyph_info_t['folder']=folder\n",
    "                hyph_info_t['t']=rowt['t']\n",
    "                frames.append(hyph_info_t)\n",
    "result = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac64bff9-1b03-47ed-b494-c281ab11bd86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
