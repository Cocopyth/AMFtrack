{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e73427e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, os.getenv(\"HOME\") + \"/pycode/MscThesis/\")\n",
    "from amftrack.pipeline.functions.post_processing.extract_study_zone import *\n",
    "import pandas as pd\n",
    "import ast\n",
    "from amftrack.plotutil import plot_t_tp1\n",
    "from scipy import sparse\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import scipy.io as sio\n",
    "from pymatreader import read_mat\n",
    "from matplotlib import colors\n",
    "import cv2\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage.filters import frangi\n",
    "from skimage import filters\n",
    "from random import choice\n",
    "import scipy.sparse\n",
    "import os\n",
    "from skimage.feature import hessian_matrix_det\n",
    "\n",
    "# from amftrack.pipeline.paths.directory import (\n",
    "#     run_parallel,\n",
    "#     find_state,\n",
    "#     directory_scratch,\n",
    "#     directory_project,\n",
    "# )\n",
    "from amftrack.notebooks.analysis.util import *\n",
    "from scipy import stats\n",
    "from scipy.ndimage.filters import uniform_filter1d\n",
    "from collections import Counter\n",
    "from IPython.display import clear_output\n",
    "from amftrack.notebooks.analysis.data_info import *\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "plt.rcParams.update(\n",
    "    {\"font.family\": \"verdana\", \"font.weight\": \"normal\", \"font.size\": 20}\n",
    ")\n",
    "from amftrack.plotutil import plot_node_skel\n",
    "from amftrack.notebooks.validation.util import *\n",
    "from amftrack.util.sys import *\n",
    "from amftrack.notebooks.post_processing.util import *\n",
    "import pickle\n",
    "from amftrack.pipeline.functions.image_processing.experiment_class_surf import (\n",
    "    Experiment,\n",
    "    save_graphs,\n",
    "    load_graphs,\n",
    ")\n",
    "\n",
    "directory = directory_project\n",
    "# directory = '/projects/0/einf914/agg/'\n",
    "# directory = r\"C:\\Users\\coren\\Documents\\PhD\\Code\\old_prince_data/\"\n",
    "update_analysis_info(directory)\n",
    "analysis_info = get_analysis_info(directory)\n",
    "# analysis_info['Plate']=analysis_info['Plate'].fillna(758)\n",
    "# select = analysis_info.loc[analysis_info[\"Temp\"] == \"30to25\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb55f0f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "select = analysis_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db417652",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cc8247",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from mprun_demo import sum_of_lists\n",
    "%mprun -f sum_of_lists sum_of_lists(1000000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbe2715",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%file mprun_demo.py\n",
    "def sum_of_lists(N):\n",
    "    %matplotlib widget\n",
    "    import sys  \n",
    "    sys.path.insert(0, '/home/cbisot/pycode/MscThesis/')\n",
    "    from amftrack.pipeline.functions.post_processing.extract_study_zone import *\n",
    "    import pandas as pd\n",
    "    import ast\n",
    "    from amftrack.plotutil import plot_t_tp1\n",
    "    from scipy import sparse\n",
    "    from datetime import datetime\n",
    "    import pickle\n",
    "    import scipy.io as sio\n",
    "    from pymatreader import read_mat\n",
    "    from matplotlib import colors\n",
    "    import cv2\n",
    "    import imageio\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    from skimage.filters import frangi\n",
    "    from skimage import filters\n",
    "    from random import choice\n",
    "    import scipy.sparse\n",
    "    import os\n",
    "    from skimage.feature import hessian_matrix_det\n",
    "    from amftrack.pipeline.paths.directory import run_parallel, find_state, directory_scratch, directory_project\n",
    "    from amftrack.notebooks.analysis.util import * \n",
    "    from scipy import stats\n",
    "    from scipy.ndimage.filters import uniform_filter1d\n",
    "    from collections import Counter\n",
    "    from IPython.display import clear_output\n",
    "    from amftrack.notebooks.analysis.data_info import *\n",
    "    from IPython.core.interactiveshell import InteractiveShell\n",
    "    InteractiveShell.ast_node_interactivity = \"all\"\n",
    "    plt.rcParams.update({\n",
    "        \"font.family\": \"verdana\",\n",
    "    'font.weight' : 'normal',\n",
    "    'font.size': 20})\n",
    "    from amftrack.plotutil import plot_node_skel\n",
    "    from amftrack.notebooks.validation.util import *\n",
    "    from amftrack.pipeline.paths.directory import *\n",
    "    from amftrack.util.sys import *\n",
    "    from amftrack.notebooks.post_processing.util import *\n",
    "    import pickle\n",
    "\n",
    "    directory = directory_project\n",
    "    update_analysis_info(directory)\n",
    "    analysis_info = get_analysis_info(directory)\n",
    "    select = analysis_info\n",
    "    num = 0\n",
    "    rows = [row for (index, row) in select.iterrows()]\n",
    "    for index,row in enumerate(rows):\n",
    "        path = f'{directory}{row[\"folder_analysis\"]}'\n",
    "        print(index,row[\"Plate\"])\n",
    "        try:\n",
    "            a = np.load(f'{path}/center.npy')\n",
    "        except:\n",
    "            print(index,row[\"Plate\"])\n",
    "        if index == num:\n",
    "            path_exp = f'{directory}{row[\"path_exp\"]}'\n",
    "            exp = pickle.load(open(path_exp, \"rb\"))\n",
    "            exp.dates.sort()\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972864f6-2950-4990-8282-8427ee3f42f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plates = [\n",
    "\"3_20220426\",\n",
    "\"12_20220502\",\n",
    "\"13_20220422\",\n",
    "\"16_20220419\",\n",
    "\"21_20220502\",\n",
    "\"480_20221205\",\n",
    "\"28_20230227\",\n",
    "\"206_20230303\",\n",
    "\"202_20230314\",\n",
    "\"218_20230227\",\n",
    "\"219_20230307\",\n",
    "\"229_20230330\",\n",
    "# \"240_20230328\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc8b213",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plate = \"3_20220426\"\n",
    "rows = [row for (index, row) in select.iterrows()]\n",
    "for index, row in enumerate(rows):\n",
    "    path = f'{directory}{row[\"folder_analysis\"]}'\n",
    "    try:\n",
    "        a = np.load(f\"{path}/num_trunk.npy\")\n",
    "    except:\n",
    "        print(index, row[\"Plate\"])\n",
    "    if row[\"unique_id\"] == plate:\n",
    "        path_exp = f'{directory}{row[\"path_exp\"]}'\n",
    "        exp = pickle.load(open(path_exp, \"rb\"))\n",
    "        exp.dates.sort()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3c6eeb-5343-43e0-ad36-8d2aaa301cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28b7d9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "load_graphs(exp, directory, indexes=range(0, 1))\n",
    "# exp.nx_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd434d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from amftrack.pipeline.functions.post_processing.extract_study_zone import (\n",
    "    load_study_zone,\n",
    ")\n",
    "\n",
    "load_study_zone(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c50736a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "i = 0\n",
    "dist = 150\n",
    "radius = 1000\n",
    "compress = 5\n",
    "dr_orth, dr_center = get_study_zone(exp, dist, radius, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bb0bf7-d57d-4c4f-8fb7-1fa7e9023caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_study_zone(dr_orth, dr_center, exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0af0e43-c7ba-4d94-be76-d589565cecfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_study_zone(exp):\n",
    "    exp.center = np.save(f\"{exp.save_location}/center.npy\", exp.center)\n",
    "    exp.orthog = np.save(f\"{exp.save_location}/orthog.npy\", exp.orthog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344c156f-c19d-4e45-b716-460ca6c0747e",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_study_zone(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85f6942-c69d-4ed0-8b88-b1ae9cd24f99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c5c119",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_study_zone(dr_orth, dr_center, exp, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b017fbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3f1724",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = 150\n",
    "radius = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6752042-bbf1-45a5-a12f-2702de1b68a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42cbfd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "end = 27\n",
    "plt.close(\"all\")\n",
    "compress = 25\n",
    "date = exp.dates[end]\n",
    "directory_name = get_dirname(date, exp.folders)\n",
    "path_snap = exp.directory + directory_name\n",
    "skel = read_mat(path_snap + \"/Analysis/skeleton_pruned_realigned.mat\")\n",
    "Rot = skel[\"R\"]\n",
    "trans = skel[\"t\"]\n",
    "skelet = skel[\"skeleton\"]\n",
    "output = skelet.todense()\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "output = cv2.dilate(output.astype(np.uint8), kernel, iterations=3)\n",
    "fig = plt.figure(figsize=(9, 9))\n",
    "ax = fig.add_subplot(111)\n",
    "x, y = np.array(exp.center)[0] // compress, np.array(exp.center)[1] // compress\n",
    "circle = plt.Circle((x, y), radius, alpha=0.3, color=\"red\")\n",
    "pos_line = np.array((x, y)) + dist * exp.orthog\n",
    "orth_direct = np.array([exp.orthog[1], -exp.orthog[0]])\n",
    "extension = 1000\n",
    "deb_line = pos_line + extension * orth_direct\n",
    "end_line = pos_line - extension * orth_direct\n",
    "line = pltlines.Line2D(\n",
    "    (deb_line[0], end_line[0]), (deb_line[1], end_line[1]), color=\"red\"\n",
    ")\n",
    "ax.add_patch(circle)\n",
    "ax.add_line(line)\n",
    "ax.imshow(\n",
    "    cv2.resize(output, (output.shape[1] // compress, output.shape[0] // compress)),\n",
    "    alpha=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc4ba70",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.reach_out = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcc6295-cf49-4aab-b7c9-a94efead853f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from amftrack.util.sys import get_dates_datetime, get_dirname, temp_path, path_code\n",
    "\n",
    "path_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c943110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = f'{directory}{row[\"folder_analysis\"]}'\n",
    "# np.save(f\"{path}/center\", exp.center)\n",
    "# np.save(f\"{path}/orthog\", exp.orthog)\n",
    "np.save(f\"{path}/reach_out\", exp.reach_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af319998",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "frame = exp.reach_out\n",
    "# frame = 35\n",
    "# plot_raw2(exp, frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd6fd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.num_trunk = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7197bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f'{directory}{row[\"folder_analysis\"]}'\n",
    "np.save(f\"{path}/num_trunk\", exp.num_trunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a038307f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exp.labeled = True\n",
    "load_graphs(exp, indexes=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70e597b",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "exp.folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d281a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx_graph = exp.nx_graph[60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a914b285",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "nx_graph = exp.nx_graph[t]\n",
    "threshold = 0.1\n",
    "S = [nx_graph.subgraph(c).copy() for c in nx.connected_components(nx_graph)]\n",
    "selected = [\n",
    "    g for g in S if g.size(weight=\"weight\") * len(g.nodes) / 10**6 >= threshold\n",
    "]\n",
    "selected\n",
    "polys = Polygon()\n",
    "if len(selected) >= 0:\n",
    "    area_max = 0\n",
    "    for g in selected:\n",
    "        nodes = np.array(\n",
    "            [\n",
    "                node.pos(t)\n",
    "                for node in exp.nodes\n",
    "                if node.is_in(t)\n",
    "                and np.all(is_in_study_zone(node, t, 1000, 150))\n",
    "                and (node.label in g.nodes)\n",
    "            ]\n",
    "        )\n",
    "        if len(nodes) > 3:\n",
    "            hull = spatial.ConvexHull(nodes)\n",
    "            poly = Polygon([nodes[vertice] for vertice in hull.vertices])\n",
    "            area_hull = poly.area * 1.725**2 / (1000**2)\n",
    "            polys = polys.union(poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4324190c",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = exp.dates[70]\n",
    "directory_name = get_dirname(date, exp.plate)\n",
    "path_snap = exp.directory + directory_name\n",
    "suffix = \"/Analysis/nx_graph_pruned_labeled.p\"\n",
    "path_save = path_snap + suffix\n",
    "(g, pos) = pickle.load(open(path_save, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c55a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79f0c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de92b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_raw2(exp, t, figsize=(10, 9)):\n",
    "    date = exp.dates[t]\n",
    "    directory_name = get_dirname(date, exp.plate)\n",
    "    path_snap = exp.directory + directory_name\n",
    "    im = read_mat(path_snap + \"/Analysis/raw_image.mat\")[\"raw\"]\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.imshow(im, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fb9827",
   "metadata": {},
   "outputs": [],
   "source": [
    "Node(126416, exp).show_source_image(90, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253397e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Edge(Node(126416, exp), Node(141897, exp)).show_source_image(90, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9be190",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Edge(Node(126416, exp), Node(141897, exp), exp).pixel_list(90))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c554db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_width_info(experiment, t, resolution=50, skip=False):\n",
    "    print(not skip)\n",
    "    edge_width = {}\n",
    "    graph = experiment.nx_graph[t]\n",
    "    #     print(len(list(graph.edges)))\n",
    "    # print(len(graph.edges))\n",
    "    print(len(graph.edges))\n",
    "    # list_edges = [choice(list(graph.edges)) for i in range(100)]\n",
    "    for edge in graph.edges:\n",
    "        if not skip:\n",
    "            # print(edge)\n",
    "            edge_exp = Edge(\n",
    "                Node(edge[0], experiment), Node(edge[1], experiment), experiment\n",
    "            )\n",
    "            mean = np.mean(list(get_width_edge(edge_exp, resolution, t).values()))\n",
    "            #         print(np.mean(list(get_width_edge(edge_exp,resolution,t).values())))\n",
    "            edge_width[edge] = mean\n",
    "            # print(mean)\n",
    "        else:\n",
    "            # Maybe change to Nan if it doesnt break the rest\n",
    "            edge_width[edge] = 40\n",
    "    return edge_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21df8c34",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "get_width_info(exp, 90, resolution=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257fa9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import profile_line\n",
    "from amftrack.notebooks.analysis.util import *\n",
    "from scipy.optimize import curve_fit\n",
    "import numpy as np\n",
    "\n",
    "a = 2.3196552\n",
    "from scipy import special\n",
    "\n",
    "\n",
    "def func2(x, lapse, lapse2, c, d, e):\n",
    "    return (\n",
    "        -c * (special.erf(e * (x - lapse)) - special.erf(e * (x - lapse - lapse2))) + d\n",
    "    )\n",
    "\n",
    "\n",
    "def func3(x, lapse, lapse2, c, d, e, lapse4):\n",
    "    return (\n",
    "        -c * (special.erf(e * (x - lapse)) - special.erf(e * (x - (lapse + lapse2))))\n",
    "        + d\n",
    "        + c\n",
    "        * (\n",
    "            special.erf(e * (x - (lapse + lapse2)))\n",
    "            - special.erf(e * (x - (lapse + lapse2 + lapse4)))\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def func4(x, lapse, lapse2, c, d, e, lapse4):\n",
    "    return (\n",
    "        -c * (special.erf(e * (x - lapse)) - special.erf(e * (x - (lapse + lapse2))))\n",
    "        + d\n",
    "        + c * (special.erf(e * (x - (lapse - lapse4))) - special.erf(e * (x - (lapse))))\n",
    "    )\n",
    "\n",
    "\n",
    "def func5(x, sigma, mean, fact, offset):\n",
    "    return -fact * np.exp(-((x - mean) ** 2) / sigma**2) + offset\n",
    "\n",
    "\n",
    "def func5(x, sigma, mean, fact, offset):\n",
    "    return -fact * np.exp(-((x - mean) ** 2) / sigma**2) + offset\n",
    "\n",
    "\n",
    "def get_source_image(experiment, pos, t, local, force_selection=None):\n",
    "    x, y = pos[0], pos[1]\n",
    "    ims, posimg = experiment.find_image_pos(x, y, t, local)\n",
    "    if force_selection is None:\n",
    "        dist_border = [\n",
    "            min([posimg[1][i], 3000 - posimg[1][i], posimg[0][i], 4096 - posimg[0][i]])\n",
    "            for i in range(posimg[0].shape[0])\n",
    "        ]\n",
    "        j = np.argmax(dist_border)\n",
    "    else:\n",
    "        dist_last = [\n",
    "            np.linalg.norm(\n",
    "                np.array((posimg[1][i], posimg[0][i])) - np.array(force_selection)\n",
    "            )\n",
    "            for i in range(posimg[0].shape[0])\n",
    "        ]\n",
    "        j = np.argmin(dist_last)\n",
    "    return (ims[j], (posimg[1][j], posimg[0][j]))\n",
    "\n",
    "\n",
    "def get_width_pixel(\n",
    "    edge,\n",
    "    index,\n",
    "    im,\n",
    "    pivot,\n",
    "    before,\n",
    "    after,\n",
    "    t,\n",
    "    size=20,\n",
    "    width_factor=60,\n",
    "    averaging_size=100,\n",
    "    threshold_averaging=10,\n",
    "):\n",
    "    imtab = im\n",
    "    #     print(imtab.shape)\n",
    "    #     print(int(max(0,pivot[0]-averaging_size)),int(pivot[0]+averaging_size))\n",
    "    threshold = np.mean(\n",
    "        imtab[\n",
    "            int(max(0, pivot[0] - averaging_size)) : int(pivot[0] + averaging_size),\n",
    "            int(max(0, pivot[1] - averaging_size)) : int(pivot[1] + averaging_size),\n",
    "        ]\n",
    "        - threshold_averaging\n",
    "    )\n",
    "    orientation = np.array(before) - np.array(after)\n",
    "    perpendicular = (\n",
    "        [1, -orientation[0] / orientation[1]] if orientation[1] != 0 else [0, 1]\n",
    "    )\n",
    "    perpendicular_norm = np.array(perpendicular) / np.sqrt(\n",
    "        perpendicular[0] ** 2 + perpendicular[1] ** 2\n",
    "    )\n",
    "    point1 = np.around(np.array(pivot) + width_factor * perpendicular_norm)\n",
    "    point2 = np.around(np.array(pivot) - width_factor * perpendicular_norm)\n",
    "    point1 = point1.astype(int)\n",
    "    point2 = point2.astype(int)\n",
    "    p = profile_line(imtab, point1, point2, mode=\"constant\")\n",
    "    xdata = np.array(range(len(p)))\n",
    "    ydata = np.array(p)\n",
    "    #     fig = plt.figure()\n",
    "    #     ax = fig.add_subplot(111)\n",
    "    #     ax.plot(xdata,ydata)\n",
    "    #     ax.plot(xdata, func5(xdata, *popt0), 'g-')\n",
    "    # try:\n",
    "    #     raise RuntimeError\n",
    "    # #     p00=[10,60,60,160]\n",
    "    # #     popt0, pcov = curve_fit(func5, xdata, ydata,bounds = ([0,0,0,0],4*[np.inf]),p0=p00)\n",
    "    # #     p0a=[60,10,100,180,0.1]\n",
    "    # #     popt1, pcov = curve_fit(func2, xdata, ydata,bounds = ([0,0,0,0,0],[120,120,200]+2*[np.inf]),p0=p0a)\n",
    "    # #     p0b=list(popt1)+[10]\n",
    "    # #     popt2, pcov = curve_fit(func3, xdata, ydata,bounds = ([0,0,0,0,0,0],[120,120,200]+2*[np.inf]+[120]),p0=p0b)\n",
    "    # #     residuals = ydata- func3(xdata, *popt2)\n",
    "    # #     ss_res = np.sum(residuals**2)\n",
    "    # #     ss_tot = np.sum((ydata-np.mean(ydata))**2)\n",
    "    # #     r_squared1 = 1 - (ss_res / ss_tot)\n",
    "    # #     popt3, pcov = curve_fit(func4, xdata, ydata,bounds = ([0,0,0,0,0,0],[120,120,200]+2*[np.inf]+[120]),p0=p0b)\n",
    "    # #     residuals = ydata- func4(xdata, *popt3)\n",
    "    # #     ss_res = np.sum(residuals**2)\n",
    "    # #     ss_tot = np.sum((ydata-np.mean(ydata))**2)\n",
    "    # #     r_squared2 = 1 - (ss_res / ss_tot)\n",
    "    # # #     ax.plot(xdata, func2(xdata, *popt1), 'r-')\n",
    "    # #     if r_squared1>r_squared2:\n",
    "    # # #         ax.plot(xdata, func3(xdata, *popt2), 'b-')\n",
    "    # #         popt=popt2\n",
    "    # #     else:\n",
    "    # # #         ax.plot(xdata, func4(xdata, *popt3), 'b-')\n",
    "    # #         popt=popt3\n",
    "    # #     background = popt[3]\n",
    "    # except RuntimeError:\n",
    "    #     print('failed')\n",
    "    background = np.mean(\n",
    "        (np.mean(p[: width_factor // 6]), np.mean(p[-width_factor // 6 :]))\n",
    "    )\n",
    "    #     print(popt[3],popt0[3])\n",
    "    #     width_pix = popt0[0]*popt0[2]\n",
    "    width_pix = -np.sum(\n",
    "        (np.log10(np.array(p) / background) <= 0) * np.log10(np.array(p) / background)\n",
    "    )\n",
    "    #     print(width_pix)\n",
    "    #     p0=[165,100,165,45,10,10,10]\n",
    "    #     popt, pcov = curve_fit(func, xdata, ydata,bounds = ([-np.inf,-np.inf,-np.inf,-np.inf,0,0,0],np.inf),p0=p0)\n",
    "    #     width_pix = popt[-2]\n",
    "    #     ax.plot(xdata, func(xdata, *popt), 'r-')\n",
    "    #     derivative = [p[i+1]-p[i] for i in range(len(p)-1)]\n",
    "    #     fig = plt.figure()\n",
    "    #     ax = fig.add_subplot(111)\n",
    "    #     ax.plot([np.mean(derivative[5*i:5*i+5]) for i in range(len(derivative)//5)])\n",
    "    #     problem=False\n",
    "    #     arg = len(p)//2\n",
    "    #     if p[arg]>threshold:\n",
    "    #         arg = np.argmin(p)\n",
    "    # #     we_plot=randrange(1000)\n",
    "    #     while  p[arg]<=threshold:\n",
    "    #         if arg<=0:\n",
    "    # #             we_plot=50\n",
    "    #             problem=True\n",
    "    #             break\n",
    "    #         arg-=1\n",
    "    #     begin = arg\n",
    "    #     arg = len(p)//2\n",
    "    #     if p[arg]>threshold:\n",
    "    #         arg = np.argmin(p)\n",
    "    #     while  p[arg]<=threshold:\n",
    "    #         if arg>=len(p)-1:\n",
    "    # #             we_plot=50\n",
    "    #             problem=True\n",
    "    #             break\n",
    "    #         arg+=1\n",
    "    #     end = arg\n",
    "    # #     print(end-begin,threshold)\n",
    "    #     print(np.linalg.norm(point1-point2),len(p),width_pix)\n",
    "    return a * np.sqrt(max(0, np.linalg.norm(point1 - point2) * (width_pix) / len(p)))\n",
    "\n",
    "\n",
    "def get_width_edge(edge, resolution, t, local=False, threshold_averaging=10):\n",
    "    pixel_conversion_factor = 1.725\n",
    "    pixel_list = edge.pixel_list(t)\n",
    "    pixels = []\n",
    "    indexes = []\n",
    "    source_images = []\n",
    "    poss = []\n",
    "    widths = {}\n",
    "    if len(pixel_list) > 3 * resolution:\n",
    "        for i in range(0, len(pixel_list) // resolution):\n",
    "            index = i * resolution\n",
    "            indexes.append(index)\n",
    "            pixel = pixel_list[index]\n",
    "            pixels.append(pixel)\n",
    "            source_img, pos = get_source_image(edge.experiment, pixel, t, local)\n",
    "            source_images.append(source_img)\n",
    "            poss.append(pos)\n",
    "    else:\n",
    "        indexes = [0, len(pixel_list) // 2, len(pixel_list) - 1]\n",
    "        for index in indexes:\n",
    "            pixel = pixel_list[index]\n",
    "            pixels.append(pixel)\n",
    "            source_img, pos = get_source_image(edge.experiment, pixel, t, local)\n",
    "            source_images.append(source_img)\n",
    "            poss.append(pos)\n",
    "    #     print(indexes)\n",
    "    for i, index in enumerate(indexes[1:-1]):\n",
    "        source_img = source_images[i + 1]\n",
    "        pivot = poss[i + 1]\n",
    "        _, before = get_source_image(edge.experiment, pixels[i], t, local, pivot)\n",
    "        _, after = get_source_image(edge.experiment, pixels[i + 2], t, local, pivot)\n",
    "        #         plot_t_tp1([0,1,2],[],{0 : pivot,1 : before, 2 : after},None,source_img,source_img)\n",
    "        width = get_width_pixel(\n",
    "            edge,\n",
    "            index,\n",
    "            source_img,\n",
    "            pivot,\n",
    "            before,\n",
    "            after,\n",
    "            t,\n",
    "            threshold_averaging=threshold_averaging,\n",
    "        )\n",
    "        #         print(width*pixel_conversion_factor)\n",
    "        widths[pixel_list[index]] = width * pixel_conversion_factor\n",
    "    #         if i>=1:\n",
    "    #             break\n",
    "    edge.experiment.nx_graph[t].get_edge_data(edge.begin.label, edge.end.label)[\n",
    "        \"width\"\n",
    "    ] = widths\n",
    "    return widths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4182808b",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = f'{directory}{row[\"folder_analysis\"]}'\n",
    "exp.pickle_save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ea01cb",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95900d09",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "compress = 25\n",
    "date = exp.dates[i]\n",
    "directory_name = get_dirname(date, exp.plate)\n",
    "path_snap = exp.directory + directory_name\n",
    "skel = read_mat(path_snap + \"/Analysis/skeleton_pruned_realigned.mat\")\n",
    "Rot = skel[\"R\"]\n",
    "trans = skel[\"t\"]\n",
    "skelet = skel[\"skeleton\"]\n",
    "output = skelet.todense()\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "output = cv2.dilate(output.astype(np.uint8), kernel, iterations=3)\n",
    "fig = plt.figure(figsize=(9, 9))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.imshow(\n",
    "    cv2.resize(output, (output.shape[1] // compress, output.shape[0] // compress)),\n",
    "    alpha=1,\n",
    ")\n",
    "plt.scatter(exp.center[0] // compress, exp.center[1] // compress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d798305f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Node(77, exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca17e2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_in_study_zone(Node(223, exp), t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38862888",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.all((True, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67998246",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t = 0\n",
    "compress = 25\n",
    "center = np.array(exp.center)\n",
    "poss = exp.positions[t]\n",
    "x0, y0 = exp.center\n",
    "direction = exp.orthog\n",
    "pos_line = np.array((x0, y0)) + dist * compress * direction\n",
    "x_line, y_line = pos_line[0], pos_line[1]\n",
    "orth_direct = np.array([direction[1], -direction[0]])\n",
    "x_orth, y_orth = orth_direct = orth_direct[0], orth_direct[1]\n",
    "a = y_orth / x_orth\n",
    "b = y_line - a * x_line\n",
    "nodes_exclude = []\n",
    "for node in exp.nx_graph[t].nodes:\n",
    "    dist_center = np.linalg.norm(poss[node] - center)\n",
    "    y, x = poss[node]\n",
    "    if dist_center > radius * compress or a * x + b < y:\n",
    "        nodes_exclude.append(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ef72c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "compress = 25\n",
    "date = exp.dates[i]\n",
    "directory_name = get_dirname(date, exp.plate)\n",
    "path_snap = exp.directory + directory_name\n",
    "skel = read_mat(path_snap + \"/Analysis/skeleton_pruned_realigned.mat\")\n",
    "Rot = skel[\"R\"]\n",
    "trans = skel[\"t\"]\n",
    "skelet = skel[\"skeleton\"]\n",
    "output = skelet.todense()\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "output = cv2.dilate(output.astype(np.uint8), kernel, iterations=3)\n",
    "fig = plt.figure(figsize=(9, 9))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.imshow(\n",
    "    cv2.resize(output, (output.shape[1] // compress, output.shape[0] // compress)),\n",
    "    alpha=1,\n",
    ")\n",
    "plt.scatter(exp.center[0] // compress, exp.center[1] // compress)\n",
    "plt.scatter(x_line // compress, y_line // compress)\n",
    "for node in exp.nx_graph[t].nodes:\n",
    "    if node not in nodes_exclude:\n",
    "        s = plt.scatter(*np.flip(poss[node]) // compress)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
