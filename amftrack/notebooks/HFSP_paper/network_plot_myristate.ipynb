{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382a263d-1ac6-44d1-885d-4e898f40caa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib widget\n",
    "\n",
    "from amftrack.pipeline.launching.run_super import (\n",
    "    run_launcher,\n",
    "    directory_scratch,\n",
    "    directory_project,\n",
    "    directory_project,\n",
    "    run_parallel_stitch,\n",
    "    run_parallel_transfer,\n",
    ")\n",
    "import os\n",
    "from amftrack.util.sys import (\n",
    "    get_dates_datetime,\n",
    "    get_dirname,\n",
    "    temp_path,\n",
    "    get_data_info,\n",
    "    update_plate_info,\n",
    "    update_analysis_info,\n",
    "    get_analysis_info,\n",
    "    get_current_folders,\n",
    "    get_folders_by_plate_id,\n",
    ")\n",
    "from datetime import timedelta\n",
    "\n",
    "from time import time_ns\n",
    "from amftrack.util.dbx import (\n",
    "    upload_folders,\n",
    "    load_dbx,\n",
    "    download,\n",
    "    get_dropbox_folders_prince,\n",
    ")\n",
    "from datetime import datetime\n",
    "from amftrack.pipeline.launching.run_super import (\n",
    "    run_parallel,\n",
    "    directory_scratch,\n",
    "    directory_project,\n",
    "    run_parallel_stitch,\n",
    ")\n",
    "from amftrack.util.dbx import read_saved_dropbox_state, get_dropbox_folders_prince\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from amftrack.util.sys import get_dirname, temp_path\n",
    "import pandas as pd\n",
    "import ast\n",
    "from scipy import sparse\n",
    "import scipy.io as sio\n",
    "import cv2\n",
    "import imageio.v2 as imageio\n",
    "import numpy as np\n",
    "import scipy.sparse\n",
    "import os\n",
    "from time import time\n",
    "from amftrack.pipeline.functions.image_processing.extract_skel import (\n",
    "    extract_skel_new_prince,\n",
    "    run_back_sub,\n",
    "    bowler_hat,\n",
    ")\n",
    "\n",
    "from amftrack.util.sys import get_dates_datetime, get_dirname\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "from amftrack.pipeline.functions.image_processing.experiment_class_surf import (\n",
    "    Experiment,\n",
    "    save_graphs,\n",
    "    load_graphs,\n",
    "    Edge,\n",
    "    Node,\n",
    ")\n",
    "from amftrack.pipeline.functions.image_processing.experiment_util import (\n",
    "    get_random_edge,\n",
    "    distance_point_edge,\n",
    "    plot_edge,\n",
    "    plot_edge_cropped,\n",
    "    find_nearest_edge,\n",
    "    get_edge_from_node_labels,\n",
    "    plot_full_image_with_features,\n",
    "    get_all_edges,\n",
    "    get_all_nodes,\n",
    "    find_neighboring_edges,\n",
    "    reconstruct_image,\n",
    "    reconstruct_skeletton_from_edges,\n",
    "    reconstruct_skeletton_unicolor,\n",
    "    reconstruct_image_from_general,\n",
    "    plot_full,\n",
    "    plot_edge_color_value,\n",
    ")\n",
    "from matplotlib import cm\n",
    "import matplotlib.patches as mpatches\n",
    "import networkx as nx\n",
    "from amftrack.pipeline.functions.post_processing.time_plate import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b716fc8-ef48-427f-8676-479c8dc60327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory_targ = os.path.join(directory_scratch, \"stitch_temp2\") + \"/\"\n",
    "# directory_targ = directory_project\n",
    "# directory_targ = directory_targ+'myr/'\n",
    "directory_targ = directory_project + \"myr/\"\n",
    "\n",
    "update_plate_info(directory_targ, local=True, strong_constraint=True)\n",
    "all_folders = get_current_folders(directory_targ, local=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a9e89f-7544-4b32-9411-15c161c574d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df37e979-80cc-4f52-994c-3c96c6b2c05b",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "folders = all_folders[all_folders[\"medium\"] == \"'0Myr'\"]\n",
    "folders = folders[folders[\"/Analysis/nx_graph_pruned.p\"] == True]\n",
    "folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093ec752-9743-4ef9-a1ab-0206b486d03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plates = [\n",
    "    \"63_20230510\",\n",
    "    \"34_20230221\",\n",
    "    \"61_20230510\",\n",
    "    \"64_20230508\",\n",
    "    \"33_20230221\",\n",
    "    \"35_20230227\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ffb854-c884-43b2-bb5c-63614f0a32f8",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# folders = all_folders[all_folders['unique_id'].isin(plates)]\n",
    "folders = all_folders\n",
    "folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a691c13d-10eb-4c4a-899b-88ed126071ef",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "run_parallel_stitch(\n",
    "    directory_targ,\n",
    "    folders,\n",
    "    32,\n",
    "    \"2:00:00\",\n",
    "    cpus=128,\n",
    "    node=\"fat_rome\",\n",
    "    name_job=\"stitch\",\n",
    "    dependency=False,\n",
    "    size_x=15,\n",
    "    size_y=15,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfae865e-b59b-4a9f-94c3-671181ae2740",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_folders[all_folders[\"unique_id\"].isin(plates)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b48bd5-cd95-43ff-b3d0-31f83334fdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_folders[all_folders[\"unique_id\"].isin(plates)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9755061e-69ce-47e4-afb6-072bfe5a9ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plates = all_folders[\"unique_id\"].unique()\n",
    "# plates = plates[5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025e8e06-8be3-4ca6-96e8-ae291e4d37a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "name_job = \"Myr\"\n",
    "run_launcher(\n",
    "    \"video_maker.py\",\n",
    "    [directory_targ, name_job, 20],\n",
    "    plates,\n",
    "    \"24:00:00\",\n",
    "    dependency=True,\n",
    "    name_job=\"stitch\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a671eaae-f410-40ea-8fbf-fd3f39d88acc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "results = {}\n",
    "for plate in plates:\n",
    "    folders = all_folders.loc[all_folders[\"unique_id\"] == plate].copy()\n",
    "    folders = folders.loc[folders[\"/Analysis/nx_graph_pruned_width.p\"] == True]\n",
    "    folders = folders.sort_values(by=\"datetime\")\n",
    "    folders = folders.reset_index()\n",
    "    folders[\"days_after_crossing\"] = [\n",
    "        (\n",
    "            row[\"datetime\"]\n",
    "            - datetime.datetime(\n",
    "                int(row[\"CrossDate\"][:4]),\n",
    "                int(row[\"CrossDate\"][4:6]),\n",
    "                int(row[\"CrossDate\"][6:]),\n",
    "            )\n",
    "        )\n",
    "        for index, row in folders.iterrows()\n",
    "    ]\n",
    "    abs_diff_from_14 = (folders[\"days_after_crossing\"].dt.days - 14).abs()\n",
    "\n",
    "    # Find the index of the row with the smallest difference\n",
    "    closest_index = abs_diff_from_14.idxmin()\n",
    "    exp = Experiment(directory_targ)\n",
    "    i = closest_index\n",
    "    exp.load(folders.loc[i:i], suffix=\"_width\")\n",
    "    for t in range(exp.ts):\n",
    "        exp.load_tile_information(t)\n",
    "    G = exp.nx_graph[t]\n",
    "    components = nx.connected_components(G)\n",
    "\n",
    "    # Find the largest connected component\n",
    "    largest_component = max(components, key=len)\n",
    "\n",
    "    # Create a new graph representing the largest connected component\n",
    "    largest_component_graph = G.subgraph(largest_component)\n",
    "    exp.nx_graph[t] = largest_component_graph\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73cb404-4b3d-428f-b05d-786d8f0d8c9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "data = {}\n",
    "for plate in plates[2:]:\n",
    "    folders = all_folders.loc[all_folders[\"unique_id\"] == plate]\n",
    "    folders = folders.sort_values(by=\"datetime\")\n",
    "\n",
    "    exp = Experiment(directory_targ)\n",
    "    i = 0\n",
    "    exp.load(folders.iloc[i : i + 1], suffix=\"_width\")\n",
    "    for t in range(exp.ts):\n",
    "        exp.load_tile_information(t)\n",
    "\n",
    "    G = exp.nx_graph[t]\n",
    "    components = nx.connected_components(G)\n",
    "\n",
    "    # Find the largest connected component\n",
    "    largest_component = max(components, key=len)\n",
    "\n",
    "    # Create a new graph representing the largest connected component\n",
    "    largest_component_graph = G.subgraph(largest_component)\n",
    "    exp.nx_graph[t] = largest_component_graph\n",
    "    area, length = get_area(exp, 0)[1], get_length_tot(exp, 0)[1]\n",
    "    strain = folders[\"strain\"].iloc[0]\n",
    "    unique_id = folders[\"unique_id\"].iloc[0]\n",
    "    data[unique_id] = {\"strain\": strain, \"density\": length / area}\n",
    "    print(length / area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99699f2-2712-4cb8-a2e1-ba08d2ed0dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data).transpose().to_csv(\"myristate.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53173750-9bfe-4311-a013-fe8501691e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plate = \"60_20220310\"\n",
    "folders = all_folders.loc[all_folders[\"unique_id\"] == plate]\n",
    "# folders = folders.loc[folders[\"/Analysis/nx_graph_pruned_labeled.p\"] == True]\n",
    "# folders = folders.sort_values(by=\"datetime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eed549a-de7e-4587-b262-6747a93b7c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = folders.sort_values(by=\"datetime\")\n",
    "\n",
    "exp = Experiment(directory_targ)\n",
    "i = 0\n",
    "exp.load(folders.iloc[i : i + 1], suffix=\"_width\")\n",
    "for t in range(exp.ts):\n",
    "    exp.load_tile_information(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1491090-2b27-4416-b8a7-b07d2754ec3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "G = exp.nx_graph[t]\n",
    "components = nx.connected_components(G)\n",
    "\n",
    "# Find the largest connected component\n",
    "largest_component = max(components, key=len)\n",
    "\n",
    "# Create a new graph representing the largest connected component\n",
    "largest_component_graph = G.subgraph(largest_component)\n",
    "exp.nx_graph[t] = largest_component_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4800a16-8861-4526-9f95-9fc428bc1600",
   "metadata": {},
   "outputs": [],
   "source": [
    "from amftrack.pipeline.functions.post_processing.time_plate import *\n",
    "\n",
    "area, length = get_area(exp, 0)[1], get_length_tot(exp, 0)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e368b580-6ad4-43f6-84b5-41f87c611087",
   "metadata": {},
   "outputs": [],
   "source": [
    "length / area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd648ec-5249-43d6-927a-b2ae48e11316",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_area(exp, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ca62ac-0cfd-45ef-aa07-9bc4022e39e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from amftrack.pipeline.functions.image_processing.experiment_util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f42bef-2b5d-4b5c-bad8-8dae848503be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_paper(\n",
    "    exp: Experiment,\n",
    "    t: int,\n",
    "    color_fun: Callable,\n",
    "    region=None,\n",
    "    intervals=[[1, 4], [4, 6], [6, 10], [10, 20]],\n",
    "    cmap=cm.get_cmap(\"Reds\", 100),\n",
    "    plot_cmap=False,\n",
    "    v_max=10,\n",
    "    v_min=0,\n",
    "    nodes: List[Node] = [],\n",
    "    downsizing=5,\n",
    "    dilation=5,\n",
    "    save_path=\"\",\n",
    "    color_seed=12,\n",
    "    dpi=None,\n",
    "    show_background=True,\n",
    "    label_colorbar=\"Width ($\\mu m)$\",\n",
    "    figsize=(36, 24),\n",
    "    figax=None,\n",
    "    alpha=0.5,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Plot the width for all the edges at a given timestep.\n",
    "\n",
    "    :param region: choosen region in the full image, such as [[100, 100], [2000,2000]], if None the full image is shown\n",
    "    :param color_fun: edge -> float a function of edges that needs to be color plotted\n",
    "\n",
    "    :param nodes: list of nodes to plot\n",
    "    :param downsizing: factor by which we reduce the image resolution (5 -> image 25 times lighter)\n",
    "    :param dilation: only for edges: thickness of the edges (dilation applied to the pixel list)\n",
    "    :param save_path: full path to the location where the plot will be saved\n",
    "    :param intervals: different width intervals that will be given different colors\n",
    "    :param cmap: a colormap to map width to color\n",
    "    :param plot_cmap: a boolean, whether or not to plot with cmap\n",
    "    :param v_max: the max width for the colorbar/colormap\n",
    "    \"\"\"\n",
    "    DIM_X, DIM_Y = get_dimX_dimY(exp)\n",
    "\n",
    "    if region == None:\n",
    "        # Full image\n",
    "        image_coodinates = exp.image_coordinates[t]\n",
    "        region = get_bounding_box(image_coodinates)\n",
    "        region[1][0] += DIM_X\n",
    "        region[1][1] += DIM_Y\n",
    "\n",
    "    edges = get_all_edges(exp, t)\n",
    "    if figax is None:\n",
    "        fig = plt.figure(\n",
    "            figsize=figsize\n",
    "        )  # width: 30 cm height: 20 cm # TODO(FK): change dpi\n",
    "        ax = fig.add_subplot(111)\n",
    "    else:\n",
    "        fig, ax = figax\n",
    "\n",
    "    # Give colors to edges\n",
    "    default_color = 1000\n",
    "    colors = []\n",
    "    widths = []\n",
    "    for edge in edges:\n",
    "        width = color_fun(edge)\n",
    "        widths.append(width)\n",
    "        if not plot_cmap:\n",
    "            color = default_color\n",
    "            for i, interval in enumerate(intervals):\n",
    "                if interval[0] <= width and width < interval[1]:\n",
    "                    color = i + color_seed\n",
    "            colors.append(color)\n",
    "    if plot_cmap:\n",
    "        colors = [cmap((width - v_min) / (v_max - v_min)) for width in widths]\n",
    "    # 0/ Make color legend\n",
    "    def convert(c):\n",
    "        c_ = c / 255\n",
    "        return (c_[0], c_[1], c_[2])\n",
    "\n",
    "    # 1/ Image layer\n",
    "    if show_background:\n",
    "        im, f = reconstruct_image_from_general(\n",
    "            exp,\n",
    "            t,\n",
    "            downsizing=downsizing,\n",
    "            region=region,\n",
    "            prettify=False,\n",
    "            white_background=False,\n",
    "        )\n",
    "        f_int = lambda c: f(c).astype(int)\n",
    "\n",
    "    # 2/ Edges layer\n",
    "    color_list = (\n",
    "        [(np.array(color) * 255).astype(int) for color in colors] if plot_cmap else None\n",
    "    )\n",
    "    from_edges = reconstruct_skeletton_from_edges(\n",
    "        exp,\n",
    "        t,\n",
    "        edges=edges,\n",
    "        region=region,\n",
    "        color_seeds=colors,\n",
    "        color_list=color_list,\n",
    "        downsizing=downsizing,\n",
    "        dilation=dilation,\n",
    "        timestep=False,\n",
    "    )\n",
    "    skel_im, _ = from_edges\n",
    "    if show_background:\n",
    "        new_region = [\n",
    "            f_int(region[0]),\n",
    "            f_int(region[1]),\n",
    "        ]  # should be [[0, 0], [d_x/downsized, d_y/downsized]]\n",
    "\n",
    "    # 3/ Fusing layers\n",
    "    if show_background:\n",
    "        ax.imshow(im, cmap=\"gray\", interpolation=\"none\")\n",
    "    ax.imshow(skel_im, alpha=alpha, interpolation=\"none\", aspect=\"equal\")\n",
    "\n",
    "    # 3/ Plotting the Nodes\n",
    "    size = 5\n",
    "    bbox_props = dict(boxstyle=\"circle\", fc=\"white\")\n",
    "    for node in nodes:\n",
    "        c = node.pos(t)\n",
    "        if is_in_bounding_box(c, region):\n",
    "            c = f(node.pos(t))\n",
    "            node_text = ax.text(\n",
    "                c[1],\n",
    "                c[0],\n",
    "                str(node.label),\n",
    "                ha=\"center\",\n",
    "                va=\"center\",\n",
    "                size=size,\n",
    "                bbox=bbox_props,\n",
    "            )\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291ec37c-0f27-466a-a6f5-4ddd95f653c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plates = [\n",
    "    \"62_20230511\",\n",
    "    \"49_20230510\",\n",
    "    \"60_20230508\",\n",
    "    \"68_20230501\",\n",
    "    \"14_20230301\",\n",
    "    \"58_20230511\",\n",
    "    \"1_20230221\",\n",
    "    \"51_20230511\",\n",
    "    \"48_20230301\",\n",
    "    \"33_20230221\",\n",
    "    \"46_20230221\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9450c9-b8d9-41f5-bdf8-0fd443c148e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plates = folders[\"unique_id\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9a9b7c-d71d-49dd-b9dd-66faba5561ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "folders2 = all_folders[all_folders[\"medium\"] == \"'0Myr'\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cd70c5-1aba-4594-89b2-1682693c001c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plates = folders2[folders2[\"Plate\"].isin(plates_num)][\"unique_id\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f8ed18-6555-4802-b9c6-a7e7ac1a72ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "plates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360ef580-4b38-48f6-bfe6-ad131a701bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plates_num = [\"31\", \"33\", \"34\", \"35\", \"61\", \"62\", \"63\", \"64\", \"67\", \"68\", \"69\", \"72\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05366d34-eef6-44c4-8512-51946d4b5bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plates[6:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42804c1-aed9-460d-967d-e63147c3275f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a5e5f0-c91e-4d5b-ad62-e7e329d144c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "results = {}\n",
    "for plate in plates[0:]:\n",
    "    folders = all_folders.loc[all_folders[\"unique_id\"] == plate].copy()\n",
    "    folders = folders.loc[folders[\"/Analysis/nx_graph_pruned_width.p\"] == True]\n",
    "    folders = folders.sort_values(by=\"datetime\")\n",
    "    folders = folders.reset_index()\n",
    "    folders[\"days_after_crossing\"] = [\n",
    "        (\n",
    "            row[\"datetime\"]\n",
    "            - datetime.datetime(\n",
    "                int(row[\"CrossDate\"][:4]),\n",
    "                int(row[\"CrossDate\"][4:6]),\n",
    "                int(row[\"CrossDate\"][6:]),\n",
    "            )\n",
    "        )\n",
    "        for index, row in folders.iterrows()\n",
    "    ]\n",
    "    abs_diff_from_14 = (folders[\"days_after_crossing\"].dt.days - 15).abs()\n",
    "\n",
    "    # Find the index of the row with the smallest difference\n",
    "    closest_index = abs_diff_from_14.idxmin()\n",
    "    exp = Experiment(directory_targ)\n",
    "    i = closest_index\n",
    "    i = len(folders) - 1\n",
    "    # i=0\n",
    "    exp.load(folders.loc[i:i], suffix=\"\")\n",
    "    for t in range(exp.ts):\n",
    "        exp.load_tile_information(t)\n",
    "    G = exp.nx_graph[t]\n",
    "    components = nx.connected_components(G)\n",
    "\n",
    "    # Find the largest connected component\n",
    "    largest_component = max(components, key=len)\n",
    "\n",
    "    # Create a new graph representing the largest connected component\n",
    "    largest_component_graph = G.subgraph(largest_component)\n",
    "    exp.nx_graph[t] = largest_component_graph\n",
    "    # if abs_diff_from_14.iloc[0]<=2:\n",
    "    print(get_length_tot(exp, 0)[1], abs_diff_from_14)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af94b13-6009-470f-bded-5e9648fe8699",
   "metadata": {},
   "outputs": [],
   "source": [
    "vmax = 10\n",
    "vmin = 0\n",
    "downsizing = 10\n",
    "width = 10\n",
    "height = 7\n",
    "region = [[0, 0], [4000 * 5, 10000 * 5]]\n",
    "nodes = get_all_nodes(exp, t)\n",
    "\n",
    "fig, ax = plot_paper(\n",
    "    exp,\n",
    "    t,\n",
    "    lambda edge: 5,\n",
    "    # region=region,\n",
    "    # nodes = nodes,\n",
    "    cmap=cm.get_cmap(\"viridis\", 100),\n",
    "    v_min=vmin,\n",
    "    v_max=vmax,\n",
    "    plot_cmap=False,\n",
    "    show_background=True,\n",
    "    dilation=5,\n",
    "    figsize=(width, height),\n",
    "    alpha=0.5,\n",
    "    downsizing=downsizing,\n",
    ")\n",
    "rect = mpatches.Rectangle((100, 100), 1000 * 1.725 / downsizing, 50, color=\"black\")\n",
    "\n",
    "# Add the rectangle to the plot\n",
    "ax.add_patch(rect)\n",
    "# time = int(\n",
    "#     (\n",
    "#         folders.iloc[i : i + 1][\"datetime\"].iloc[0] - folders.iloc[0][\"datetime\"]\n",
    "#     ).total_seconds()\n",
    "#     / 3600\n",
    "# )\n",
    "# # plt.savefig(os.path.join(\"figures\",f\"{folders.iloc[i:i+1]['datetime'].iloc[0]}_{plate}.pdf\"), transparent=True, bbox_inches='tight')\n",
    "# ax.text(3500, 400, f\"t = {time}h\", size=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f0ca8c-3c63-4039-b516-f187ef6ebf68",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from amftrack.pipeline.functions.post_processing.time_plate import *\n",
    "\n",
    "data = {}\n",
    "for plate in plates:\n",
    "    folders = all_folders.loc[all_folders[\"unique_id\"] == plate].copy()\n",
    "    folders = folders.loc[folders[\"/Analysis/nx_graph_pruned_width.p\"] == True]\n",
    "    folders = folders.sort_values(by=\"datetime\")\n",
    "    folders = folders.reset_index()\n",
    "    folders[\"days_after_crossing\"] = [\n",
    "        (\n",
    "            row[\"datetime\"]\n",
    "            - datetime.datetime(\n",
    "                int(row[\"CrossDate\"][:4]),\n",
    "                int(row[\"CrossDate\"][4:6]),\n",
    "                int(row[\"CrossDate\"][6:]),\n",
    "            )\n",
    "        )\n",
    "        for index, row in folders.iterrows()\n",
    "    ]\n",
    "    if len(folders) > 0:\n",
    "        abs_diff_from_14 = (folders[\"days_after_crossing\"].dt.days - 14).abs()\n",
    "\n",
    "        # Find the index of the row with the smallest difference\n",
    "        closest_index = abs_diff_from_14.idxmin()\n",
    "        exp = Experiment(directory_targ)\n",
    "        i = closest_index\n",
    "        exp.load(folders.loc[i:i], suffix=\"_width\")\n",
    "        for t in range(exp.ts):\n",
    "            exp.load_tile_information(t)\n",
    "        G = exp.nx_graph[t]\n",
    "        try:\n",
    "\n",
    "            components = nx.connected_components(G)\n",
    "\n",
    "            # Find the largest connected component\n",
    "            largest_component = max(components, key=len)\n",
    "\n",
    "            # Create a new graph representing the largest connected component\n",
    "            largest_component_graph = G.subgraph(largest_component)\n",
    "            exp.nx_graph[t] = largest_component_graph\n",
    "            area, length = get_area(exp, 0)[1], get_length_tot(exp, 0)[1]\n",
    "            strain = folders[\"strain\"].iloc[0]\n",
    "            unique_id = folders[\"unique_id\"].iloc[0]\n",
    "            medium = folders[\"medium\"].iloc[0]\n",
    "            data[unique_id] = {\n",
    "                \"strain\": strain,\n",
    "                \"density\": length / area,\n",
    "                \"medium\": medium,\n",
    "            }\n",
    "        except:\n",
    "            print(plate)\n",
    "        print(length / area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426c18bb-6b40-4736-a114-41966a67a635",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data).transpose().to_csv(\"control.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98231ac-f34f-4877-9033-03d5ec72c8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data).transpose()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
