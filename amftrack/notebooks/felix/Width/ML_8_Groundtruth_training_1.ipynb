{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a88eb95",
   "metadata": {},
   "source": [
    "# Groundtruth training on focused edges (training 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46b5b487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "$('<div id=\"toc\"></div>').css({position: 'fixed', top: '120px', left: 0}).appendTo(document.body);\n",
       "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js');\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "$('<div id=\"toc\"></div>').css({position: 'fixed', top: '120px', left: 0}).appendTo(document.body);\n",
    "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa80930",
   "metadata": {},
   "source": [
    "## Presentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90444c84",
   "metadata": {},
   "source": [
    "For each different training we proceed as follow:\n",
    "\n",
    "Step 1: random search or bayesian search over a lot of models and parameters\\\n",
    "Step 2: evaluate the 3 best models with cross validation and chose the best out of the 3\n",
    "\n",
    "For the seed, we always take the same seed: 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870525d5",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "060f5678",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-18 09:59:14.315899: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/opt/gurobi951/linux64/lib\n",
      "2022-08-18 09:59:14.315943: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "/home/felix/Wks/AMFtrack/amftrack/util/dbx.py:3: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n",
      "2022-08-18 09:59:16.178753: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/cv2/../../lib64::/opt/gurobi951/linux64/lib\n",
      "2022-08-18 09:59:16.178777: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-08-18 09:59:16.178797: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (felix-XPS-13-9360): /proc/driver/nvidia/version does not exist\n",
      "2022-08-18 09:59:16.178967: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "import imageio\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import regularizers\n",
    "import keras_tuner as kt\n",
    "\n",
    "from amftrack.ml.width.models import hyper_model_builder_simple, build_model_dense, build_model_conv\n",
    "from amftrack.util.sys import storage_path\n",
    "from amftrack.ml.width.data_augmentation import data_augmentation, data_preparation\n",
    "from keras.utils.layer_utils import count_params  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485285ad",
   "metadata": {},
   "source": [
    "### Fetch data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b305e51e",
   "metadata": {},
   "source": [
    "Repository with all possible datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9c884c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = os.path.join(storage_path, \"datasets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b9bdd8",
   "metadata": {},
   "source": [
    "Two datasets that I have choosen to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82126ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "focused_dataset_path = os.path.join(dataset_path, \"focused_with_varying_lum_train\") # dataset with varying lumination but consistent focus\n",
    "extended_dataset_path = os.path.join(dataset_path, \"varying_lum_and_focus_train\") # dataset with varying lumination but consistent focus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2653ccf5",
   "metadata": {},
   "source": [
    "For now: using the focused dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9f1d2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = focused_dataset_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e5d9e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_path = os.path.join(path, \"slices.png\")\n",
    "label_path = os.path.join(path, \"labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cab14b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(527, 120)\n"
     ]
    }
   ],
   "source": [
    "im = imageio.imread(im_path)\n",
    "print(im.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c26d17c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(527,)\n"
     ]
    }
   ],
   "source": [
    "with open(label_path, 'rb') as f:\n",
    "    label = np.load(f)\n",
    "print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c568feb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = np.expand_dims(label, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d530f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(527, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4d5dd1",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37844b7",
   "metadata": {},
   "source": [
    "For seperating the test set (not used for now as the test is done in another notebookÂ²)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e76a7826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "377\n",
      "150\n"
     ]
    }
   ],
   "source": [
    "seed = 11\n",
    "np.random.seed(11)\n",
    "p = np.random.permutation(len(label))\n",
    "training = p[:-150]\n",
    "valid = p[-150:]\n",
    "print(len(training))\n",
    "print(len(valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a513000",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature = im[training, :]\n",
    "train_label = label[training,:]\n",
    "valid_feature = im[valid, :]\n",
    "valid_label = label[valid, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fdb088",
   "metadata": {},
   "source": [
    "Instead we just take it all"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d9f95f1c",
   "metadata": {},
   "source": [
    "train_feature = im\n",
    "train_label = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aeb87d01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(377, 120)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feature.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26c2475",
   "metadata": {},
   "source": [
    "### Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a8a0447",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "197fd5be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff9e0388040>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(im[i,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a27e66af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.54463004])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label[i,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e69aa32",
   "metadata": {},
   "source": [
    "## Mean predicting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8bbb1b88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(377, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07f41a64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.982430809438182"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.var(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4546373c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2321359298748322"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13ef7529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean is: 5.279759580329631, Mean squarred error is: 4.982430809438182\n"
     ]
    }
   ],
   "source": [
    "mean = np.mean(train_label)\n",
    "pred = np.full(train_label.shape, mean)\n",
    "res = np.mean((train_label - pred)**2)\n",
    "print(f\"Mean is: {mean}, Mean squarred error is: {res}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ddd21728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean is: 5.279759580329631, Mean absolute error is: 1.5887181524020357\n"
     ]
    }
   ],
   "source": [
    "mean = np.mean(train_label)\n",
    "pred = np.full(train_label.shape, mean)\n",
    "res = np.mean(abs(train_label - pred))\n",
    "print(f\"Mean is: {mean}, Mean absolute error is: {res}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3fa786",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3a0b4c",
   "metadata": {},
   "source": [
    "### Train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3a80fc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from amftrack.ml.width.data_augmentation import data_preparation, data_augmentation, random_crop, random_mirror, random_invert, random_brightness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff749531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(377, 120)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feature.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc203714",
   "metadata": {},
   "source": [
    "PROPRE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c413fa9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature_ds = np.expand_dims(train_feature, axis = -1)\n",
    "train_feature_ds = np.expand_dims(train_feature_ds, axis = -3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b465374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(377, 1, 120, 1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feature_ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a678f245",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = tf.data.Dataset.from_tensor_slices(train_feature_ds)\n",
    "d2 = tf.data.Dataset.from_tensor_slices(train_label)\n",
    "train_ds = tf.data.Dataset.zip((d1, d2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2ee85d00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset element_spec=TensorSpec(shape=(1, 120, 1), dtype=tf.uint8, name=None)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST\n",
    "d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8b2bc3b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset element_spec=TensorSpec(shape=(1,), dtype=tf.float64, name=None)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST\n",
    "d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9e138b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(377, 1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST\n",
    "train_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4a1d117d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 100, 1), dtype=float32, numpy=\n",
       "array([[[255.],\n",
       "        [255.],\n",
       "        [255.],\n",
       "        [255.],\n",
       "        [255.],\n",
       "        [255.],\n",
       "        [255.],\n",
       "        [255.],\n",
       "        [255.],\n",
       "        [255.],\n",
       "        [255.],\n",
       "        [255.],\n",
       "        [255.],\n",
       "        [255.],\n",
       "        [255.],\n",
       "        [255.],\n",
       "        [255.],\n",
       "        [255.],\n",
       "        [255.],\n",
       "        [255.],\n",
       "        [255.],\n",
       "        [255.],\n",
       "        [255.],\n",
       "        [255.],\n",
       "        [255.],\n",
       "        [255.],\n",
       "        [255.],\n",
       "        [255.],\n",
       "        [255.],\n",
       "        [255.],\n",
       "        [255.],\n",
       "        [255.],\n",
       "        [255.],\n",
       "        [255.],\n",
       "        [255.],\n",
       "        [255.],\n",
       "        [255.],\n",
       "        [255.],\n",
       "        [255.],\n",
       "        [255.],\n",
       "        [255.],\n",
       "        [255.],\n",
       "        [255.],\n",
       "        [255.],\n",
       "        [255.],\n",
       "        [255.],\n",
       "        [255.],\n",
       "        [255.],\n",
       "        [255.],\n",
       "        [255.],\n",
       "        [255.],\n",
       "        [255.],\n",
       "        [255.],\n",
       "        [255.],\n",
       "        [255.],\n",
       "        [255.],\n",
       "        [253.],\n",
       "        [250.],\n",
       "        [245.],\n",
       "        [239.],\n",
       "        [232.],\n",
       "        [231.],\n",
       "        [212.],\n",
       "        [201.],\n",
       "        [183.],\n",
       "        [151.],\n",
       "        [151.],\n",
       "        [169.],\n",
       "        [173.],\n",
       "        [162.],\n",
       "        [144.],\n",
       "        [135.],\n",
       "        [143.],\n",
       "        [158.],\n",
       "        [174.],\n",
       "        [185.],\n",
       "        [187.],\n",
       "        [191.],\n",
       "        [197.],\n",
       "        [200.],\n",
       "        [206.],\n",
       "        [212.],\n",
       "        [217.],\n",
       "        [222.],\n",
       "        [228.],\n",
       "        [227.],\n",
       "        [236.],\n",
       "        [237.],\n",
       "        [238.],\n",
       "        [242.],\n",
       "        [243.],\n",
       "        [248.],\n",
       "        [251.],\n",
       "        [253.],\n",
       "        [253.],\n",
       "        [255.],\n",
       "        [255.],\n",
       "        [254.],\n",
       "        [255.],\n",
       "        [255.]]], dtype=float32)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST\n",
    "for e in train_ds:\n",
    "    break\n",
    "data_augmentation(e[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "57e84709",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = (\n",
    "    train_ds.map(lambda x, y: (data_augmentation(x, training=True), y))\n",
    "    #.unbatch()\n",
    "    .batch(16)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "801ef0f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(TensorSpec(shape=(None, None, None, 1), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e8282e",
   "metadata": {},
   "source": [
    "TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f584bf12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for e in train_ds:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e92a6148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 1, 100, 1)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(e[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cfe9aa3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff9e0079ca0>]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.array(e[0][0, 0,:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3d1daa37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff9d97e5580>]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.array(e[0][0, 0,:,0]))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "200903d9",
   "metadata": {},
   "source": [
    "plt.plot(np.array(e[0][0,:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "48588d12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff9e0133f70>]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.array(e[0][0, 0,:,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0af29fc",
   "metadata": {},
   "source": [
    "### Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b161e2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_feature_ds = np.expand_dims(valid_feature, axis = -1)\n",
    "valid_feature_ds = np.expand_dims(valid_feature_ds, axis = -3)\n",
    "d1 = tf.data.Dataset.from_tensor_slices(valid_feature_ds)\n",
    "d2 = tf.data.Dataset.from_tensor_slices(valid_label)\n",
    "valid_ds = tf.data.Dataset.zip((d1, d2))\n",
    "valid_ds = (\n",
    "    valid_ds.map(lambda x, y: (data_preparation(x, training=True), y))\n",
    "    .unbatch()\n",
    "    .batch(16)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8eb49638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(16, 100, 1), dtype=float32, numpy=\n",
      "array([[[140.],\n",
      "        [138.],\n",
      "        [142.],\n",
      "        ...,\n",
      "        [132.],\n",
      "        [134.],\n",
      "        [132.]],\n",
      "\n",
      "       [[185.],\n",
      "        [185.],\n",
      "        [189.],\n",
      "        ...,\n",
      "        [175.],\n",
      "        [175.],\n",
      "        [173.]],\n",
      "\n",
      "       [[165.],\n",
      "        [164.],\n",
      "        [164.],\n",
      "        ...,\n",
      "        [166.],\n",
      "        [168.],\n",
      "        [167.]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[224.],\n",
      "        [224.],\n",
      "        [223.],\n",
      "        ...,\n",
      "        [216.],\n",
      "        [220.],\n",
      "        [217.]],\n",
      "\n",
      "       [[255.],\n",
      "        [254.],\n",
      "        [255.],\n",
      "        ...,\n",
      "        [255.],\n",
      "        [255.],\n",
      "        [255.]],\n",
      "\n",
      "       [[150.],\n",
      "        [150.],\n",
      "        [148.],\n",
      "        ...,\n",
      "        [144.],\n",
      "        [144.],\n",
      "        [145.]]], dtype=float32)>, <tf.Tensor: shape=(16,), dtype=float64, numpy=\n",
      "array([5.24173503, 4.34090199, 3.71157107, 8.97995119, 5.29939395,\n",
      "       5.29939395, 5.4984222 , 2.85702873, 5.35827466, 4.18356936,\n",
      "       4.34090199, 3.06895321, 4.45399496, 4.67930649, 4.88385177,\n",
      "       4.51179147])>)\n"
     ]
    }
   ],
   "source": [
    "for e in valid_ds:\n",
    "    print(e)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b62d96f",
   "metadata": {},
   "source": [
    "## Training a dense model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8363a6e",
   "metadata": {},
   "source": [
    "### 1/ Run hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "616586d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp = kt.HyperParameters()\n",
    "hp.Fixed('input_size', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "99c9f9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.RandomSearch(\n",
    "    build_model_dense,\n",
    "    objective='val_mean_absolute_error',\n",
    "    max_trials=2,\n",
    "    seed=seed,\n",
    "    hyperparameters=hp,\n",
    "    tune_new_entries=True,\n",
    "    allow_new_entries=True,\n",
    "    overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66a17c5",
   "metadata": {},
   "source": [
    "Other tuner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "df3d65b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.BayesianOptimization(\n",
    "    hypermodel = build_model_dense,\n",
    "    objective='val_mean_absolute_error',\n",
    "    max_trials=50,\n",
    "    num_initial_points=None,\n",
    "    alpha=0.0001,\n",
    "    beta=2.6, # explorative factor\n",
    "    seed=seed,\n",
    "    hyperparameters=hp,\n",
    "    allow_new_entries=True,\n",
    "    tune_new_entries=True,\n",
    "    overwrite = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a381007e",
   "metadata": {},
   "source": [
    "Without augmentation:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1419fe70",
   "metadata": {},
   "source": [
    "tuner.search(train_feature,\n",
    "             train_label,\n",
    "             validation_split=0.2,\n",
    "             epochs=50,\n",
    "             callbacks=[tf.keras.callbacks.EarlyStopping(patience=8)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9596a0ac",
   "metadata": {},
   "source": [
    "Actual search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "904cbdd2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 50 Complete [00h 00m 15s]\n",
      "val_mean_absolute_error: 0.8479289412498474\n",
      "\n",
      "Best val_mean_absolute_error So Far: 0.8294814825057983\n",
      "Total elapsed time: 00h 07m 37s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "2022-08-18 10:18:56,386-[INFO]- tensorflow:1 -> Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(train_ds,\n",
    "             validation_data= valid_ds,\n",
    "             epochs=100,\n",
    "             callbacks=[tf.keras.callbacks.EarlyStopping(patience=8)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bafe37f",
   "metadata": {},
   "source": [
    "### 2/ Analyse hyperparameter search results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c594e72",
   "metadata": {},
   "source": [
    "#### Search space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7b8a5e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 6\n",
      "input_size (Fixed)\n",
      "{'conditions': [], 'value': 100}\n",
      "hidden_size (Int)\n",
      "{'default': 32, 'conditions': [], 'min_value': 10, 'max_value': 100, 'step': 32, 'sampling': None}\n",
      "regul (Float)\n",
      "{'default': 0.0001, 'conditions': [], 'min_value': 1e-05, 'max_value': 0.1, 'step': None, 'sampling': 'log'}\n",
      "dense_blocks (Int)\n",
      "{'default': 3, 'conditions': [], 'min_value': 1, 'max_value': 10, 'step': 1, 'sampling': None}\n",
      "dropout (Float)\n",
      "{'default': 0.5, 'conditions': [], 'min_value': 0.0, 'max_value': 0.5, 'step': 0.1, 'sampling': None}\n",
      "learning_rate (Float)\n",
      "{'default': 0.001, 'conditions': [], 'min_value': 1e-05, 'max_value': 0.1, 'step': None, 'sampling': 'log'}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2734bd6",
   "metadata": {},
   "source": [
    "#### Best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "00be1ffa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in ./untitled_project\n",
      "Showing 10 best trials\n",
      "<keras_tuner.engine.objective.Objective object at 0x7ff9d951c9d0>\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "input_size: 100\n",
      "hidden_size: 74\n",
      "regul: 0.0005677953653291085\n",
      "dense_blocks: 10\n",
      "dropout: 0.0\n",
      "learning_rate: 0.0004614331680175835\n",
      "Score: 0.8294814825057983\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "input_size: 100\n",
      "hidden_size: 42\n",
      "regul: 0.0036787999149105136\n",
      "dense_blocks: 9\n",
      "dropout: 0.0\n",
      "learning_rate: 0.0003168240557749865\n",
      "Score: 0.8479289412498474\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "input_size: 100\n",
      "hidden_size: 74\n",
      "regul: 1e-05\n",
      "dense_blocks: 2\n",
      "dropout: 0.0\n",
      "learning_rate: 0.0008055913640444876\n",
      "Score: 0.8586128950119019\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "input_size: 100\n",
      "hidden_size: 74\n",
      "regul: 8.406197928657229e-05\n",
      "dense_blocks: 9\n",
      "dropout: 0.0\n",
      "learning_rate: 0.000283869492481734\n",
      "Score: 0.8602651953697205\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "input_size: 100\n",
      "hidden_size: 74\n",
      "regul: 1e-05\n",
      "dense_blocks: 3\n",
      "dropout: 0.0\n",
      "learning_rate: 0.00029603943000279195\n",
      "Score: 0.8655903339385986\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "input_size: 100\n",
      "hidden_size: 42\n",
      "regul: 0.005345868140133228\n",
      "dense_blocks: 7\n",
      "dropout: 0.1\n",
      "learning_rate: 0.0006830096465894109\n",
      "Score: 0.870337724685669\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "input_size: 100\n",
      "hidden_size: 74\n",
      "regul: 1e-05\n",
      "dense_blocks: 2\n",
      "dropout: 0.1\n",
      "learning_rate: 0.003717423458509542\n",
      "Score: 0.8713451027870178\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "input_size: 100\n",
      "hidden_size: 74\n",
      "regul: 1.1197291634395498e-05\n",
      "dense_blocks: 2\n",
      "dropout: 0.30000000000000004\n",
      "learning_rate: 0.0013053937581869813\n",
      "Score: 0.8732981085777283\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "input_size: 100\n",
      "hidden_size: 74\n",
      "regul: 1e-05\n",
      "dense_blocks: 3\n",
      "dropout: 0.2\n",
      "learning_rate: 0.0013951195813092865\n",
      "Score: 0.8802753686904907\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "input_size: 100\n",
      "hidden_size: 74\n",
      "regul: 0.00012517252348905926\n",
      "dense_blocks: 4\n",
      "dropout: 0.1\n",
      "learning_rate: 0.00036940599565187904\n",
      "Score: 0.8826348781585693\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "74f9ea97",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models = tuner.get_best_models(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1db17612",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hyperparameters = tuner.get_best_hyperparameters(10)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d80e7329",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "dir(tuner)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c874a3",
   "metadata": {},
   "source": [
    "#### Best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "96694849",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = best_models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f48c513c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 100, 1)]          0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 100)               0         \n",
      "                                                                 \n",
      " rescaling (Rescaling)       (None, 100)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 74)                7474      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 74)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 74)                5550      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 74)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 74)                5550      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 74)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 74)                5550      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 74)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 74)                5550      \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 74)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 74)                5550      \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 74)                0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 74)                5550      \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 74)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 74)                5550      \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 74)                0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 74)                5550      \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 74)                0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 74)                5550      \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 74)                0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 1)                 75        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 57,499\n",
      "Trainable params: 57,499\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "18f92423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_size': 100,\n",
       " 'hidden_size': 74,\n",
       " 'regul': 0.0005677953653291085,\n",
       " 'dense_blocks': 10,\n",
       " 'dropout': 0.0,\n",
       " 'learning_rate': 0.0004614331680175835}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hyperparameters[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1a7d28e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0\n",
      "57499\n",
      "\n",
      "Model 1\n",
      "18733\n",
      "\n",
      "Model 2\n",
      "13099\n",
      "\n",
      "Model 3\n",
      "51949\n",
      "\n",
      "Model 4\n",
      "18649\n",
      "\n",
      "Model 5\n",
      "15121\n",
      "\n",
      "Model 6\n",
      "13099\n",
      "\n",
      "Model 7\n",
      "13099\n",
      "\n",
      "Model 8\n",
      "18649\n",
      "\n",
      "Model 9\n",
      "24199\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(f\"Model {i}\")\n",
    "    print(count_params(best_models[i].trainable_weights))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9252386",
   "metadata": {},
   "source": [
    "#### Visualize prediction on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1d696ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_against(model, test_feature, test_label):\n",
    "    predicted = model.predict(test_feature)\n",
    "    plt.scatter(test_label, predicted, marker='o')\n",
    "    plt.plot([0,12],[0,12])\n",
    "    plt.xlim(2, 16)\n",
    "    plt.ylim(2, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4f177b4f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_against(best_model, data_preparation(valid_feature), valid_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6c96324b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 2.6193 - mean_absolute_error: 0.8295\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.6193456649780273, 0.8294814825057983]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.evaluate(data_preparation(valid_feature), valid_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4971c3b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 120)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_feature.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a083a2",
   "metadata": {},
   "source": [
    "### 3/ Retrain the best models with cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c604bb08",
   "metadata": {},
   "source": [
    "valid_e is the validation set for early stopping\\\n",
    "valid is the validation set to evaluate a split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9532cd0b",
   "metadata": {},
   "source": [
    "**Model hyperparameter**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b6d4d9",
   "metadata": {},
   "source": [
    "**a. From a saved dictionnary**"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0154ac08",
   "metadata": {},
   "source": [
    "best_config = {'input_size': 100,\n",
    " 'hidden_size': 42,\n",
    " 'regul': 0.0035557261842639634,\n",
    " 'dense_blocks': 3,\n",
    " 'dropout': 0.0,\n",
    " 'learning_rate': 0.0016003804865801434}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a61237f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_fixed_hp_from_dict(d):\n",
    "    Ä¥p = kt.HyperParameters()\n",
    "    for key in d.keys():\n",
    "        hp.Fixed(key, d[key])\n",
    "    return hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6566b3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = make_fixed_hp_from_dict(best_config)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d879f45a",
   "metadata": {},
   "source": [
    "# Equivalent to doing:\n",
    "hp = kt.HyperParameters()\n",
    "hp.Fixed('input_size', 100)\n",
    "hp.Fixed('hidden_size', 42)\n",
    "hp.Fixed('regul', 0.0035)\n",
    "hp.Fixed('dense_blocks', 3)\n",
    "hp.Fixed('dropout', 0.0)\n",
    "hp.Fixed('learning_rate', 0.0016)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a14fd80",
   "metadata": {},
   "source": [
    "**b. From a hyperparameter instance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "7c28171c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = best_hyperparameters[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31deaa9",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "0b72e66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = build_model_dense(hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "086ab7c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 100, 1)]          0         \n",
      "                                                                 \n",
      " reshape_4 (Reshape)         (None, 100)               0         \n",
      "                                                                 \n",
      " rescaling_4 (Rescaling)     (None, 100)               0         \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 74)                7474      \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 74)                0         \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 74)                5550      \n",
      "                                                                 \n",
      " dropout_26 (Dropout)        (None, 74)                0         \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 74)                5550      \n",
      "                                                                 \n",
      " dropout_27 (Dropout)        (None, 74)                0         \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 74)                5550      \n",
      "                                                                 \n",
      " dropout_28 (Dropout)        (None, 74)                0         \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 74)                5550      \n",
      "                                                                 \n",
      " dropout_29 (Dropout)        (None, 74)                0         \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 74)                5550      \n",
      "                                                                 \n",
      " dropout_30 (Dropout)        (None, 74)                0         \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 74)                5550      \n",
      "                                                                 \n",
      " dropout_31 (Dropout)        (None, 74)                0         \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 74)                5550      \n",
      "                                                                 \n",
      " dropout_32 (Dropout)        (None, 74)                0         \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 74)                5550      \n",
      "                                                                 \n",
      " dropout_33 (Dropout)        (None, 74)                0         \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 74)                5550      \n",
      "                                                                 \n",
      " dropout_34 (Dropout)        (None, 74)                0         \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 1)                 75        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 57,499\n",
      "Trainable params: 57,499\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950b860e",
   "metadata": {},
   "source": [
    "**Cross validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "8f10a6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature_ds = np.expand_dims(train_feature, axis = -1)\n",
    "train_feature_ds = np.expand_dims(train_feature_ds, axis = -3)\n",
    "d1 = tf.data.Dataset.from_tensor_slices(train_feature_ds)\n",
    "d2 = tf.data.Dataset.from_tensor_slices(train_label)\n",
    "train_ds = tf.data.Dataset.zip((d1, d2))\n",
    "train_ds = (\n",
    "    train_ds.map(lambda x, y: (data_augmentation(x, training=True), y))\n",
    "    .unbatch()\n",
    "    .batch(16)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "f9e412fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_feature_ds = np.expand_dims(valid_feature, axis = -1)\n",
    "valid_feature_ds = np.expand_dims(valid_feature_ds, axis = -3)\n",
    "d1 = tf.data.Dataset.from_tensor_slices(valid_feature_ds)\n",
    "d2 = tf.data.Dataset.from_tensor_slices(valid_label)\n",
    "valid_ds = tf.data.Dataset.zip((d1, d2))\n",
    "valid_ds = (\n",
    "    valid_ds.map(lambda x, y: (data_preparation(x, training=True), y))\n",
    "    .unbatch()\n",
    "    .batch(16)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7c6dee36",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "valid_ds"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dd786e46",
   "metadata": {},
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a1a90082",
   "metadata": {},
   "source": [
    "new_model.fit(train_ds,\n",
    "             validation_data= valid_ds,\n",
    "             epochs=10,\n",
    "             callbacks=[tf.keras.callbacks.EarlyStopping(patience=8)])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "405c2151",
   "metadata": {},
   "source": [
    "new_model.fit(train_ds,\n",
    "             #validation_data= valid_ds,\n",
    "             epochs=10)\n",
    "             #callbacks=[tf.keras.callbacks.EarlyStopping(patience=8)])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a4220391",
   "metadata": {},
   "source": [
    "new_model.fit(train_ds,\n",
    "             validation_data= valid_ds,\n",
    "             epochs=100,\n",
    "             callbacks=[tf.keras.callbacks.EarlyStopping(patience=8)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018f4969",
   "metadata": {},
   "source": [
    "**Creating datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "03dbeabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy_to_ds(feature, label):\n",
    "    feature_ds = np.expand_dims(feature, axis = -1)\n",
    "    feature_ds = np.expand_dims(feature_ds, axis = -3)\n",
    "    d1 = tf.data.Dataset.from_tensor_slices(feature_ds)\n",
    "    d2 = tf.data.Dataset.from_tensor_slices(label)\n",
    "    ds = tf.data.Dataset.zip((d1, d2))\n",
    "    ds = (\n",
    "    ds.map(lambda x, y: (data_augmentation(x, training=True), y))\n",
    "    .unbatch()\n",
    "    .batch(16)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    "    )\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "fe16408d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy_to_ds_preparation(feature, label):\n",
    "    feature_ds = np.expand_dims(feature, axis = -1)\n",
    "    feature_ds = np.expand_dims(feature_ds, axis = -3)\n",
    "    d1 = tf.data.Dataset.from_tensor_slices(feature_ds)\n",
    "    d2 = tf.data.Dataset.from_tensor_slices(label)\n",
    "    ds = tf.data.Dataset.zip((d1, d2))\n",
    "    ds = (\n",
    "    ds.map(lambda x, y: (data_preparation(x, training=True), y))\n",
    "    .unbatch()\n",
    "    .batch(16)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    "    )\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "raw",
   "id": "971b4f60",
   "metadata": {},
   "source": [
    "for train, valid in KFold(4).split(training):\n",
    "    train, valid_e = next(KFold(4).split(train))\n",
    "    train_feature = im[train, :]\n",
    "    train_label = label[train,:]\n",
    "    #train_label = np.expand_dims(train_label, axis = 1)\n",
    "    valid_e_feature = im[valid_e, :]\n",
    "    valid_e_label = label[valid_e,:]\n",
    "    #valid_e_label = np.expand_dims(valid_e_label, axis = 1)\n",
    "    valid_feature = im[valid, :]\n",
    "    valid_label = label[valid, :]\n",
    "    train_ds = numpy_to_ds(train_feature, train_label)\n",
    "    valid_e_ds = numpy_to_ds_preparation(valid_e_feature, valid_e_label)\n",
    "    break"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b62792e2",
   "metadata": {},
   "source": [
    "feature_ds = np.expand_dims(train_feature, axis = -1)\n",
    "feature_ds = np.expand_dims(feature_ds, axis = -3)\n",
    "d1 = tf.data.Dataset.from_tensor_slices(feature_ds)\n",
    "d2 = tf.data.Dataset.from_tensor_slices(train_label)\n",
    "ds = tf.data.Dataset.zip((d1, d2))\n",
    "ds = (\n",
    "train_ds.map(lambda x, y: (data_preparation(x, training=True), y))\n",
    "#.unbatch()\n",
    "#.batch(16)\n",
    "#.prefetch(tf.data.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8a168d51",
   "metadata": {},
   "source": [
    "d1"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d1420486",
   "metadata": {},
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "raw",
   "id": "565a9d57",
   "metadata": {},
   "source": [
    "d2"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5e794ad2",
   "metadata": {},
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a0b245e3",
   "metadata": {},
   "source": [
    "train_label.shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a8b4b886",
   "metadata": {},
   "source": [
    "valid_e_feature.shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3dd41975",
   "metadata": {},
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "raw",
   "id": "34b68a1d",
   "metadata": {},
   "source": [
    "for e in train_ds:\n",
    "    break"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6ff56a52",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "train_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "e0ab4cc9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def generalisation_estimator(model, n_split=4):\n",
    "    evaluations = []\n",
    "    history = []\n",
    "    for train_g, valid in KFold(n_split).split(training):\n",
    "        train, valid_e = next(KFold(n_split).split(train_g))\n",
    "        train_feature = im[train, :]\n",
    "        train_label = label[train,:]\n",
    "        valid_e_feature = im[valid_e, :]\n",
    "        valid_e_label = label[valid_e,:]\n",
    "        valid_feature = im[valid, :]\n",
    "        valid_label = label[valid, :]\n",
    "        \n",
    "        train_ds = numpy_to_ds(train_feature, train_label)\n",
    "        valid_e_ds = numpy_to_ds_preparation(valid_e_feature, valid_e_label)\n",
    "        #valid_ds = numpy_to_ds_preparation(valid_feature, valid_label)\n",
    "        \n",
    "        model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "        loss=keras.losses.MeanSquaredError(name=\"mean_squared_error\"),\n",
    "        metrics=[tf.keras.metrics.mean_absolute_error])\n",
    "\n",
    "        print(valid_e)\n",
    "        \n",
    "        history.append(model.fit(\n",
    "        train_ds,\n",
    "        validation_data = valid_e_ds,\n",
    "        #batch_size=16,\n",
    "        epochs=100,\n",
    "        callbacks=[tf.keras.callbacks.EarlyStopping(patience=8)]\n",
    "        #validation_data = (data_preparation(valid_e_feature), valid_e_label),\n",
    "        ))\n",
    "        evaluations.append(model.evaluate(data_preparation(valid_feature), valid_label))\n",
    "        \n",
    "    return model, history, evaluations"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ec39599a",
   "metadata": {},
   "source": [
    "# TEST\n",
    "for train_g, valid in KFold(4).split(training):\n",
    "    train, valid_e = next(KFold(4).split(train_g))\n",
    "    print(train)\n",
    "    print(valid_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "2e589e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO(FK): problÃ¨me with valid_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "fd19cd1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 29.3141 - mean_absolute_error: 4.9518 - val_loss: 30.4052 - val_mean_absolute_error: 5.1042\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 27.6299 - mean_absolute_error: 4.7993 - val_loss: 29.7732 - val_mean_absolute_error: 5.0515\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 25.9773 - mean_absolute_error: 4.6378 - val_loss: 29.1224 - val_mean_absolute_error: 4.9963\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 24.3805 - mean_absolute_error: 4.4722 - val_loss: 28.4567 - val_mean_absolute_error: 4.9386\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 22.7718 - mean_absolute_error: 4.2944 - val_loss: 27.7764 - val_mean_absolute_error: 4.8783\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 21.2290 - mean_absolute_error: 4.1025 - val_loss: 27.0744 - val_mean_absolute_error: 4.8152\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 19.7182 - mean_absolute_error: 3.9016 - val_loss: 26.3396 - val_mean_absolute_error: 4.7473\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 18.3013 - mean_absolute_error: 3.6792 - val_loss: 25.6149 - val_mean_absolute_error: 4.6780\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 17.1227 - mean_absolute_error: 3.4774 - val_loss: 24.8908 - val_mean_absolute_error: 4.6066\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 15.8787 - mean_absolute_error: 3.3020 - val_loss: 24.1981 - val_mean_absolute_error: 4.5361\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 15.1539 - mean_absolute_error: 3.1976 - val_loss: 23.5746 - val_mean_absolute_error: 4.4711\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 14.5519 - mean_absolute_error: 3.1152 - val_loss: 23.0278 - val_mean_absolute_error: 4.4130\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 14.0841 - mean_absolute_error: 3.0545 - val_loss: 22.5450 - val_mean_absolute_error: 4.3614\n",
      "Epoch 14/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 13.7337 - mean_absolute_error: 3.0116 - val_loss: 22.1476 - val_mean_absolute_error: 4.3187\n",
      "Epoch 15/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 13.5396 - mean_absolute_error: 2.9707 - val_loss: 21.8365 - val_mean_absolute_error: 4.2851\n",
      "Epoch 16/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 13.3118 - mean_absolute_error: 2.9544 - val_loss: 21.5710 - val_mean_absolute_error: 4.2564\n",
      "Epoch 17/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 13.0169 - mean_absolute_error: 2.9025 - val_loss: 21.3270 - val_mean_absolute_error: 4.2305\n",
      "Epoch 18/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 12.9389 - mean_absolute_error: 2.8902 - val_loss: 21.0941 - val_mean_absolute_error: 4.2065\n",
      "Epoch 19/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 12.7254 - mean_absolute_error: 2.8773 - val_loss: 20.8618 - val_mean_absolute_error: 4.1823\n",
      "Epoch 20/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 12.6488 - mean_absolute_error: 2.8682 - val_loss: 20.6032 - val_mean_absolute_error: 4.1556\n",
      "Epoch 21/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 12.4349 - mean_absolute_error: 2.8408 - val_loss: 20.3392 - val_mean_absolute_error: 4.1283\n",
      "Epoch 22/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 12.4295 - mean_absolute_error: 2.8355 - val_loss: 20.0943 - val_mean_absolute_error: 4.1025\n",
      "Epoch 23/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 12.2875 - mean_absolute_error: 2.8170 - val_loss: 19.8547 - val_mean_absolute_error: 4.0770\n",
      "Epoch 24/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 12.1806 - mean_absolute_error: 2.8078 - val_loss: 19.6177 - val_mean_absolute_error: 4.0518\n",
      "Epoch 25/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 11.8514 - mean_absolute_error: 2.7589 - val_loss: 19.3247 - val_mean_absolute_error: 4.0203\n",
      "Epoch 26/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 11.7938 - mean_absolute_error: 2.7515 - val_loss: 19.0048 - val_mean_absolute_error: 3.9854\n",
      "Epoch 27/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 11.6823 - mean_absolute_error: 2.7254 - val_loss: 18.7153 - val_mean_absolute_error: 3.9543\n",
      "Epoch 28/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 11.4027 - mean_absolute_error: 2.7100 - val_loss: 18.4576 - val_mean_absolute_error: 3.9268\n",
      "Epoch 29/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 11.1281 - mean_absolute_error: 2.6593 - val_loss: 18.1914 - val_mean_absolute_error: 3.8978\n",
      "Epoch 30/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 10.8740 - mean_absolute_error: 2.6345 - val_loss: 17.9210 - val_mean_absolute_error: 3.8675\n",
      "Epoch 31/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 10.9959 - mean_absolute_error: 2.6540 - val_loss: 17.5886 - val_mean_absolute_error: 3.8305\n",
      "Epoch 32/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 10.8137 - mean_absolute_error: 2.6086 - val_loss: 17.2546 - val_mean_absolute_error: 3.7928\n",
      "Epoch 33/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 10.3865 - mean_absolute_error: 2.5642 - val_loss: 16.9112 - val_mean_absolute_error: 3.7537\n",
      "Epoch 34/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 10.4478 - mean_absolute_error: 2.5708 - val_loss: 16.5825 - val_mean_absolute_error: 3.7159\n",
      "Epoch 35/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 10.0927 - mean_absolute_error: 2.5352 - val_loss: 16.2733 - val_mean_absolute_error: 3.6799\n",
      "Epoch 36/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 9.9921 - mean_absolute_error: 2.5149 - val_loss: 15.9368 - val_mean_absolute_error: 3.6403\n",
      "Epoch 37/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 9.7032 - mean_absolute_error: 2.4666 - val_loss: 15.6005 - val_mean_absolute_error: 3.6007\n",
      "Epoch 38/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 9.5399 - mean_absolute_error: 2.4607 - val_loss: 15.2692 - val_mean_absolute_error: 3.5615\n",
      "Epoch 39/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 9.6572 - mean_absolute_error: 2.4679 - val_loss: 14.9368 - val_mean_absolute_error: 3.5217\n",
      "Epoch 40/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 9.3332 - mean_absolute_error: 2.4230 - val_loss: 14.6276 - val_mean_absolute_error: 3.4844\n",
      "Epoch 41/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 9.1041 - mean_absolute_error: 2.3844 - val_loss: 14.2682 - val_mean_absolute_error: 3.4403\n",
      "Epoch 42/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 8.8935 - mean_absolute_error: 2.3698 - val_loss: 13.8708 - val_mean_absolute_error: 3.3900\n",
      "Epoch 43/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 8.8530 - mean_absolute_error: 2.3419 - val_loss: 13.5295 - val_mean_absolute_error: 3.3463\n",
      "Epoch 44/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 8.4965 - mean_absolute_error: 2.3156 - val_loss: 13.2029 - val_mean_absolute_error: 3.3043\n",
      "Epoch 45/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 8.3766 - mean_absolute_error: 2.2979 - val_loss: 12.8716 - val_mean_absolute_error: 3.2612\n",
      "Epoch 46/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 8.2802 - mean_absolute_error: 2.2572 - val_loss: 12.5228 - val_mean_absolute_error: 3.2139\n",
      "Epoch 47/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 7.9322 - mean_absolute_error: 2.2328 - val_loss: 12.1998 - val_mean_absolute_error: 3.1702\n",
      "Epoch 48/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 7.7277 - mean_absolute_error: 2.1977 - val_loss: 11.7748 - val_mean_absolute_error: 3.1097\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 4ms/step - loss: 7.3152 - mean_absolute_error: 2.1262 - val_loss: 11.3776 - val_mean_absolute_error: 3.0534\n",
      "Epoch 50/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 7.2367 - mean_absolute_error: 2.1289 - val_loss: 10.9782 - val_mean_absolute_error: 2.9951\n",
      "Epoch 51/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 7.2908 - mean_absolute_error: 2.0858 - val_loss: 10.5924 - val_mean_absolute_error: 2.9369\n",
      "Epoch 52/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 6.8715 - mean_absolute_error: 2.0403 - val_loss: 10.2225 - val_mean_absolute_error: 2.8805\n",
      "Epoch 53/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 6.8562 - mean_absolute_error: 2.0366 - val_loss: 9.8817 - val_mean_absolute_error: 2.8279\n",
      "Epoch 54/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 6.6583 - mean_absolute_error: 1.9920 - val_loss: 9.5255 - val_mean_absolute_error: 2.7711\n",
      "Epoch 55/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 6.2262 - mean_absolute_error: 1.9363 - val_loss: 9.1648 - val_mean_absolute_error: 2.7140\n",
      "Epoch 56/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 6.1332 - mean_absolute_error: 1.9254 - val_loss: 8.8447 - val_mean_absolute_error: 2.6645\n",
      "Epoch 57/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 6.1127 - mean_absolute_error: 1.9148 - val_loss: 8.5351 - val_mean_absolute_error: 2.6141\n",
      "Epoch 58/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 5.7073 - mean_absolute_error: 1.8416 - val_loss: 8.2062 - val_mean_absolute_error: 2.5590\n",
      "Epoch 59/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 5.7037 - mean_absolute_error: 1.8283 - val_loss: 7.8785 - val_mean_absolute_error: 2.5024\n",
      "Epoch 60/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 5.3408 - mean_absolute_error: 1.7662 - val_loss: 7.5524 - val_mean_absolute_error: 2.4447\n",
      "Epoch 61/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 5.1364 - mean_absolute_error: 1.7424 - val_loss: 7.2118 - val_mean_absolute_error: 2.3828\n",
      "Epoch 62/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 5.1165 - mean_absolute_error: 1.7252 - val_loss: 6.9035 - val_mean_absolute_error: 2.3228\n",
      "Epoch 63/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 4.8017 - mean_absolute_error: 1.6689 - val_loss: 6.6208 - val_mean_absolute_error: 2.2690\n",
      "Epoch 64/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 4.9215 - mean_absolute_error: 1.6723 - val_loss: 6.3192 - val_mean_absolute_error: 2.2066\n",
      "Epoch 65/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 4.7358 - mean_absolute_error: 1.6274 - val_loss: 6.0489 - val_mean_absolute_error: 2.1512\n",
      "Epoch 66/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 4.6823 - mean_absolute_error: 1.5872 - val_loss: 5.8226 - val_mean_absolute_error: 2.1034\n",
      "Epoch 67/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 4.2062 - mean_absolute_error: 1.5433 - val_loss: 5.5838 - val_mean_absolute_error: 2.0523\n",
      "Epoch 68/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 3.9377 - mean_absolute_error: 1.5389 - val_loss: 5.3476 - val_mean_absolute_error: 1.9999\n",
      "Epoch 69/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 4.0651 - mean_absolute_error: 1.4828 - val_loss: 5.1085 - val_mean_absolute_error: 1.9434\n",
      "Epoch 70/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 3.7226 - mean_absolute_error: 1.4546 - val_loss: 4.8770 - val_mean_absolute_error: 1.8860\n",
      "Epoch 71/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 3.5666 - mean_absolute_error: 1.4293 - val_loss: 4.6496 - val_mean_absolute_error: 1.8324\n",
      "Epoch 72/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 3.6413 - mean_absolute_error: 1.4181 - val_loss: 4.4497 - val_mean_absolute_error: 1.7854\n",
      "Epoch 73/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 3.2557 - mean_absolute_error: 1.3647 - val_loss: 4.2593 - val_mean_absolute_error: 1.7384\n",
      "Epoch 74/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 3.0200 - mean_absolute_error: 1.3145 - val_loss: 4.0932 - val_mean_absolute_error: 1.6993\n",
      "Epoch 75/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 3.3039 - mean_absolute_error: 1.3587 - val_loss: 3.9172 - val_mean_absolute_error: 1.6547\n",
      "Epoch 76/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 3.2173 - mean_absolute_error: 1.3291 - val_loss: 3.7173 - val_mean_absolute_error: 1.6017\n",
      "Epoch 77/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 2.9557 - mean_absolute_error: 1.2638 - val_loss: 3.5439 - val_mean_absolute_error: 1.5561\n",
      "Epoch 78/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 2.9531 - mean_absolute_error: 1.2564 - val_loss: 3.3784 - val_mean_absolute_error: 1.5099\n",
      "Epoch 79/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 2.7934 - mean_absolute_error: 1.2521 - val_loss: 3.2094 - val_mean_absolute_error: 1.4594\n",
      "Epoch 80/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 2.8417 - mean_absolute_error: 1.2320 - val_loss: 3.0610 - val_mean_absolute_error: 1.4150\n",
      "Epoch 81/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 2.3751 - mean_absolute_error: 1.1732 - val_loss: 2.9166 - val_mean_absolute_error: 1.3744\n",
      "Epoch 82/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 2.4416 - mean_absolute_error: 1.1613 - val_loss: 2.7915 - val_mean_absolute_error: 1.3363\n",
      "Epoch 83/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 2.4690 - mean_absolute_error: 1.1767 - val_loss: 2.6819 - val_mean_absolute_error: 1.2999\n",
      "Epoch 84/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 2.3695 - mean_absolute_error: 1.1190 - val_loss: 2.5841 - val_mean_absolute_error: 1.2713\n",
      "Epoch 85/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 2.2005 - mean_absolute_error: 1.1345 - val_loss: 2.4780 - val_mean_absolute_error: 1.2368\n",
      "Epoch 86/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 2.1915 - mean_absolute_error: 1.0896 - val_loss: 2.4025 - val_mean_absolute_error: 1.2129\n",
      "Epoch 87/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 2.1242 - mean_absolute_error: 1.0917 - val_loss: 2.3143 - val_mean_absolute_error: 1.1850\n",
      "Epoch 88/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 2.3237 - mean_absolute_error: 1.0659 - val_loss: 2.2404 - val_mean_absolute_error: 1.1608\n",
      "Epoch 89/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.9817 - mean_absolute_error: 1.0488 - val_loss: 2.1601 - val_mean_absolute_error: 1.1322\n",
      "Epoch 90/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.9795 - mean_absolute_error: 1.0624 - val_loss: 2.0865 - val_mean_absolute_error: 1.1057\n",
      "Epoch 91/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 2.0277 - mean_absolute_error: 1.0596 - val_loss: 2.0334 - val_mean_absolute_error: 1.0872\n",
      "Epoch 92/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.8693 - mean_absolute_error: 1.0236 - val_loss: 1.9727 - val_mean_absolute_error: 1.0655\n",
      "Epoch 93/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.6982 - mean_absolute_error: 1.0040 - val_loss: 1.9113 - val_mean_absolute_error: 1.0425\n",
      "Epoch 94/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.9854 - mean_absolute_error: 1.0357 - val_loss: 1.8735 - val_mean_absolute_error: 1.0273\n",
      "Epoch 95/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.5844 - mean_absolute_error: 0.9795 - val_loss: 1.8280 - val_mean_absolute_error: 1.0094\n",
      "Epoch 96/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1.9188 - mean_absolute_error: 1.0298 - val_loss: 1.7928 - val_mean_absolute_error: 0.9968\n",
      "Epoch 97/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.8980 - mean_absolute_error: 1.0159 - val_loss: 1.7605 - val_mean_absolute_error: 0.9851\n",
      "Epoch 98/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.5786 - mean_absolute_error: 0.9628 - val_loss: 1.7305 - val_mean_absolute_error: 0.9743\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 5ms/step - loss: 1.6562 - mean_absolute_error: 0.9832 - val_loss: 1.6994 - val_mean_absolute_error: 0.9643\n",
      "Epoch 100/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.5560 - mean_absolute_error: 0.9515 - val_loss: 1.6827 - val_mean_absolute_error: 0.9580\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.6890 - mean_absolute_error: 0.9763\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.5246 - mean_absolute_error: 0.9521 - val_loss: 1.6042 - val_mean_absolute_error: 0.9266\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1.5743 - mean_absolute_error: 0.9585 - val_loss: 1.5880 - val_mean_absolute_error: 0.9245\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.4602 - mean_absolute_error: 0.9168 - val_loss: 1.5617 - val_mean_absolute_error: 0.9128\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.6305 - mean_absolute_error: 0.9672 - val_loss: 1.5427 - val_mean_absolute_error: 0.9038\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.4713 - mean_absolute_error: 0.9234 - val_loss: 1.5321 - val_mean_absolute_error: 0.9007\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.6360 - mean_absolute_error: 0.9843 - val_loss: 1.5223 - val_mean_absolute_error: 0.8948\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.4309 - mean_absolute_error: 0.9293 - val_loss: 1.5095 - val_mean_absolute_error: 0.8890\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.4150 - mean_absolute_error: 0.9142 - val_loss: 1.4972 - val_mean_absolute_error: 0.8850\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.4180 - mean_absolute_error: 0.8865 - val_loss: 1.4805 - val_mean_absolute_error: 0.8787\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.3506 - mean_absolute_error: 0.8829 - val_loss: 1.4757 - val_mean_absolute_error: 0.8772\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.3518 - mean_absolute_error: 0.8767 - val_loss: 1.4706 - val_mean_absolute_error: 0.8737\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.3005 - mean_absolute_error: 0.8668 - val_loss: 1.4605 - val_mean_absolute_error: 0.8708\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.5201 - mean_absolute_error: 0.9426 - val_loss: 1.4567 - val_mean_absolute_error: 0.8681\n",
      "Epoch 14/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.3873 - mean_absolute_error: 0.8741 - val_loss: 1.4587 - val_mean_absolute_error: 0.8691\n",
      "Epoch 15/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.2932 - mean_absolute_error: 0.8620 - val_loss: 1.4681 - val_mean_absolute_error: 0.8740\n",
      "Epoch 16/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1.3179 - mean_absolute_error: 0.8804 - val_loss: 1.4720 - val_mean_absolute_error: 0.8722\n",
      "Epoch 17/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1.4260 - mean_absolute_error: 0.9009 - val_loss: 1.4651 - val_mean_absolute_error: 0.8720\n",
      "Epoch 18/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.2098 - mean_absolute_error: 0.8615 - val_loss: 1.4620 - val_mean_absolute_error: 0.8725\n",
      "Epoch 19/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1.3422 - mean_absolute_error: 0.8896 - val_loss: 1.4602 - val_mean_absolute_error: 0.8678\n",
      "Epoch 20/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.2158 - mean_absolute_error: 0.8406 - val_loss: 1.4567 - val_mean_absolute_error: 0.8674\n",
      "Epoch 21/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1.3817 - mean_absolute_error: 0.8966 - val_loss: 1.4543 - val_mean_absolute_error: 0.8679\n",
      "Epoch 22/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.3619 - mean_absolute_error: 0.8788 - val_loss: 1.4577 - val_mean_absolute_error: 0.8695\n",
      "Epoch 23/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.2043 - mean_absolute_error: 0.8408 - val_loss: 1.4531 - val_mean_absolute_error: 0.8669\n",
      "Epoch 24/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.3020 - mean_absolute_error: 0.8739 - val_loss: 1.4523 - val_mean_absolute_error: 0.8676\n",
      "Epoch 25/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1.2677 - mean_absolute_error: 0.8884 - val_loss: 1.4442 - val_mean_absolute_error: 0.8648\n",
      "Epoch 26/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.3337 - mean_absolute_error: 0.8882 - val_loss: 1.4362 - val_mean_absolute_error: 0.8600\n",
      "Epoch 27/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.2427 - mean_absolute_error: 0.8737 - val_loss: 1.4366 - val_mean_absolute_error: 0.8617\n",
      "Epoch 28/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.1016 - mean_absolute_error: 0.8059 - val_loss: 1.4394 - val_mean_absolute_error: 0.8639\n",
      "Epoch 29/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.3039 - mean_absolute_error: 0.8621 - val_loss: 1.4444 - val_mean_absolute_error: 0.8626\n",
      "Epoch 30/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.3212 - mean_absolute_error: 0.8451 - val_loss: 1.4396 - val_mean_absolute_error: 0.8625\n",
      "Epoch 31/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.1919 - mean_absolute_error: 0.8599 - val_loss: 1.4364 - val_mean_absolute_error: 0.8634\n",
      "Epoch 32/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.3073 - mean_absolute_error: 0.8691 - val_loss: 1.4314 - val_mean_absolute_error: 0.8624\n",
      "Epoch 33/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1.2267 - mean_absolute_error: 0.8432 - val_loss: 1.4294 - val_mean_absolute_error: 0.8646\n",
      "Epoch 34/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1.1706 - mean_absolute_error: 0.8355 - val_loss: 1.4325 - val_mean_absolute_error: 0.8648\n",
      "Epoch 35/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1.1233 - mean_absolute_error: 0.8250 - val_loss: 1.4246 - val_mean_absolute_error: 0.8633\n",
      "Epoch 36/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.1870 - mean_absolute_error: 0.8441 - val_loss: 1.4223 - val_mean_absolute_error: 0.8618\n",
      "Epoch 37/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1.1254 - mean_absolute_error: 0.8235 - val_loss: 1.4218 - val_mean_absolute_error: 0.8613\n",
      "Epoch 38/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.2131 - mean_absolute_error: 0.8560 - val_loss: 1.4187 - val_mean_absolute_error: 0.8627\n",
      "Epoch 39/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.2440 - mean_absolute_error: 0.8578 - val_loss: 1.4203 - val_mean_absolute_error: 0.8602\n",
      "Epoch 40/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.1643 - mean_absolute_error: 0.8328 - val_loss: 1.4124 - val_mean_absolute_error: 0.8575\n",
      "Epoch 41/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.2728 - mean_absolute_error: 0.8496 - val_loss: 1.4046 - val_mean_absolute_error: 0.8570\n",
      "Epoch 42/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.0958 - mean_absolute_error: 0.8112 - val_loss: 1.4038 - val_mean_absolute_error: 0.8576\n",
      "Epoch 43/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.1420 - mean_absolute_error: 0.8293 - val_loss: 1.4053 - val_mean_absolute_error: 0.8565\n",
      "Epoch 44/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.0966 - mean_absolute_error: 0.7957 - val_loss: 1.4020 - val_mean_absolute_error: 0.8560\n",
      "Epoch 45/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.1683 - mean_absolute_error: 0.8444 - val_loss: 1.4025 - val_mean_absolute_error: 0.8581\n",
      "Epoch 46/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.0918 - mean_absolute_error: 0.8128 - val_loss: 1.4054 - val_mean_absolute_error: 0.8581\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 4ms/step - loss: 1.1896 - mean_absolute_error: 0.7991 - val_loss: 1.3990 - val_mean_absolute_error: 0.8562\n",
      "Epoch 48/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.1266 - mean_absolute_error: 0.8128 - val_loss: 1.3983 - val_mean_absolute_error: 0.8560\n",
      "Epoch 49/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.2005 - mean_absolute_error: 0.8481 - val_loss: 1.3994 - val_mean_absolute_error: 0.8580\n",
      "Epoch 50/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.0988 - mean_absolute_error: 0.8061 - val_loss: 1.4112 - val_mean_absolute_error: 0.8635\n",
      "Epoch 51/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.1581 - mean_absolute_error: 0.8430 - val_loss: 1.4103 - val_mean_absolute_error: 0.8626\n",
      "Epoch 52/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.3589 - mean_absolute_error: 0.8877 - val_loss: 1.4078 - val_mean_absolute_error: 0.8601\n",
      "Epoch 53/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1.1458 - mean_absolute_error: 0.8431 - val_loss: 1.4082 - val_mean_absolute_error: 0.8571\n",
      "Epoch 54/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1.1451 - mean_absolute_error: 0.8252 - val_loss: 1.4148 - val_mean_absolute_error: 0.8584\n",
      "Epoch 55/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.2499 - mean_absolute_error: 0.8618 - val_loss: 1.4159 - val_mean_absolute_error: 0.8620\n",
      "Epoch 56/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1.1502 - mean_absolute_error: 0.8253 - val_loss: 1.4148 - val_mean_absolute_error: 0.8609\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1783 - mean_absolute_error: 0.8132\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 1s 12ms/step - loss: 1.1223 - mean_absolute_error: 0.8333 - val_loss: 1.4109 - val_mean_absolute_error: 0.8576\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.1086 - mean_absolute_error: 0.7881 - val_loss: 1.4102 - val_mean_absolute_error: 0.8592\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.0901 - mean_absolute_error: 0.8143 - val_loss: 1.3991 - val_mean_absolute_error: 0.8552\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.0183 - mean_absolute_error: 0.7943 - val_loss: 1.3925 - val_mean_absolute_error: 0.8550\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.1490 - mean_absolute_error: 0.8182 - val_loss: 1.3860 - val_mean_absolute_error: 0.8560\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.2580 - mean_absolute_error: 0.8405 - val_loss: 1.3790 - val_mean_absolute_error: 0.8561\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.2300 - mean_absolute_error: 0.8373 - val_loss: 1.3837 - val_mean_absolute_error: 0.8560\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.1517 - mean_absolute_error: 0.8310 - val_loss: 1.3887 - val_mean_absolute_error: 0.8578\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.0638 - mean_absolute_error: 0.8064 - val_loss: 1.4051 - val_mean_absolute_error: 0.8634\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.1653 - mean_absolute_error: 0.8347 - val_loss: 1.3916 - val_mean_absolute_error: 0.8582\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.0527 - mean_absolute_error: 0.8015 - val_loss: 1.3823 - val_mean_absolute_error: 0.8532\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.1804 - mean_absolute_error: 0.8355 - val_loss: 1.3718 - val_mean_absolute_error: 0.8512\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.1982 - mean_absolute_error: 0.8247 - val_loss: 1.3728 - val_mean_absolute_error: 0.8514\n",
      "Epoch 14/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.0987 - mean_absolute_error: 0.8061 - val_loss: 1.3741 - val_mean_absolute_error: 0.8537\n",
      "Epoch 15/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.2571 - mean_absolute_error: 0.8599 - val_loss: 1.3688 - val_mean_absolute_error: 0.8534\n",
      "Epoch 16/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.1360 - mean_absolute_error: 0.8180 - val_loss: 1.3574 - val_mean_absolute_error: 0.8487\n",
      "Epoch 17/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.1630 - mean_absolute_error: 0.8226 - val_loss: 1.3542 - val_mean_absolute_error: 0.8479\n",
      "Epoch 18/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.0689 - mean_absolute_error: 0.7943 - val_loss: 1.3506 - val_mean_absolute_error: 0.8480\n",
      "Epoch 19/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.1371 - mean_absolute_error: 0.8380 - val_loss: 1.3405 - val_mean_absolute_error: 0.8456\n",
      "Epoch 20/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.1844 - mean_absolute_error: 0.8217 - val_loss: 1.3419 - val_mean_absolute_error: 0.8458\n",
      "Epoch 21/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.1404 - mean_absolute_error: 0.8303 - val_loss: 1.3500 - val_mean_absolute_error: 0.8472\n",
      "Epoch 22/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.0882 - mean_absolute_error: 0.8104 - val_loss: 1.3623 - val_mean_absolute_error: 0.8474\n",
      "Epoch 23/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.0213 - mean_absolute_error: 0.7766 - val_loss: 1.3627 - val_mean_absolute_error: 0.8496\n",
      "Epoch 24/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.1419 - mean_absolute_error: 0.8069 - val_loss: 1.3651 - val_mean_absolute_error: 0.8502\n",
      "Epoch 25/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.0702 - mean_absolute_error: 0.7894 - val_loss: 1.3573 - val_mean_absolute_error: 0.8471\n",
      "Epoch 26/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.0597 - mean_absolute_error: 0.7867 - val_loss: 1.3532 - val_mean_absolute_error: 0.8480\n",
      "Epoch 27/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.1010 - mean_absolute_error: 0.8066 - val_loss: 1.3388 - val_mean_absolute_error: 0.8457\n",
      "Epoch 28/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.0501 - mean_absolute_error: 0.8046 - val_loss: 1.3305 - val_mean_absolute_error: 0.8446\n",
      "Epoch 29/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.0764 - mean_absolute_error: 0.8046 - val_loss: 1.3338 - val_mean_absolute_error: 0.8447\n",
      "Epoch 30/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.1130 - mean_absolute_error: 0.8103 - val_loss: 1.3338 - val_mean_absolute_error: 0.8429\n",
      "Epoch 31/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.1145 - mean_absolute_error: 0.8305 - val_loss: 1.3163 - val_mean_absolute_error: 0.8382\n",
      "Epoch 32/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.0498 - mean_absolute_error: 0.7819 - val_loss: 1.3172 - val_mean_absolute_error: 0.8390\n",
      "Epoch 33/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.0356 - mean_absolute_error: 0.7666 - val_loss: 1.3258 - val_mean_absolute_error: 0.8416\n",
      "Epoch 34/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.0775 - mean_absolute_error: 0.7898 - val_loss: 1.3259 - val_mean_absolute_error: 0.8407\n",
      "Epoch 35/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.1099 - mean_absolute_error: 0.8235 - val_loss: 1.3232 - val_mean_absolute_error: 0.8350\n",
      "Epoch 36/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.0316 - mean_absolute_error: 0.8029 - val_loss: 1.3143 - val_mean_absolute_error: 0.8314\n",
      "Epoch 37/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.1243 - mean_absolute_error: 0.8268 - val_loss: 1.3096 - val_mean_absolute_error: 0.8331\n",
      "Epoch 38/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.0508 - mean_absolute_error: 0.7836 - val_loss: 1.3081 - val_mean_absolute_error: 0.8336\n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 4ms/step - loss: 1.0805 - mean_absolute_error: 0.7948 - val_loss: 1.3007 - val_mean_absolute_error: 0.8328\n",
      "Epoch 40/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.0571 - mean_absolute_error: 0.7899 - val_loss: 1.2769 - val_mean_absolute_error: 0.8268\n",
      "Epoch 41/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.0798 - mean_absolute_error: 0.8185 - val_loss: 1.2794 - val_mean_absolute_error: 0.8285\n",
      "Epoch 42/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.0023 - mean_absolute_error: 0.7744 - val_loss: 1.2899 - val_mean_absolute_error: 0.8346\n",
      "Epoch 43/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.1047 - mean_absolute_error: 0.8281 - val_loss: 1.2953 - val_mean_absolute_error: 0.8357\n",
      "Epoch 44/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.0629 - mean_absolute_error: 0.7924 - val_loss: 1.2922 - val_mean_absolute_error: 0.8347\n",
      "Epoch 45/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.9299 - mean_absolute_error: 0.7490 - val_loss: 1.2883 - val_mean_absolute_error: 0.8371\n",
      "Epoch 46/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.1484 - mean_absolute_error: 0.8118 - val_loss: 1.2932 - val_mean_absolute_error: 0.8388\n",
      "Epoch 47/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.0082 - mean_absolute_error: 0.7750 - val_loss: 1.2870 - val_mean_absolute_error: 0.8353\n",
      "Epoch 48/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.0726 - mean_absolute_error: 0.7920 - val_loss: 1.2921 - val_mean_absolute_error: 0.8344\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.8649 - mean_absolute_error: 0.7123\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70]\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 1.0715 - mean_absolute_error: 0.8023 - val_loss: 1.2882 - val_mean_absolute_error: 0.8339\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.0369 - mean_absolute_error: 0.7894 - val_loss: 1.2909 - val_mean_absolute_error: 0.8348\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 1.0614 - mean_absolute_error: 0.7915 - val_loss: 1.2723 - val_mean_absolute_error: 0.8290\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.0538 - mean_absolute_error: 0.7963 - val_loss: 1.2543 - val_mean_absolute_error: 0.8233\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 1.0967 - mean_absolute_error: 0.8318 - val_loss: 1.2489 - val_mean_absolute_error: 0.8204\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.0946 - mean_absolute_error: 0.8135 - val_loss: 1.2457 - val_mean_absolute_error: 0.8168\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 1.0489 - mean_absolute_error: 0.7798 - val_loss: 1.2489 - val_mean_absolute_error: 0.8186\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.1213 - mean_absolute_error: 0.8409 - val_loss: 1.2579 - val_mean_absolute_error: 0.8225\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.1546 - mean_absolute_error: 0.8242 - val_loss: 1.2696 - val_mean_absolute_error: 0.8251\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.0318 - mean_absolute_error: 0.7922 - val_loss: 1.2811 - val_mean_absolute_error: 0.8287\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.0206 - mean_absolute_error: 0.7799 - val_loss: 1.2890 - val_mean_absolute_error: 0.8312\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.1065 - mean_absolute_error: 0.8193 - val_loss: 1.2807 - val_mean_absolute_error: 0.8311\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.0852 - mean_absolute_error: 0.7963 - val_loss: 1.2859 - val_mean_absolute_error: 0.8322\n",
      "Epoch 14/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 1.0178 - mean_absolute_error: 0.7680 - val_loss: 1.2803 - val_mean_absolute_error: 0.8307\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.1207 - mean_absolute_error: 0.8251\n"
     ]
    }
   ],
   "source": [
    "model, history, evaluations = generalisation_estimator(new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "219f7d86",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.8317078948020935 Std: 0.09428310291551761\n"
     ]
    }
   ],
   "source": [
    "acc = [e[1] for e in evaluations]\n",
    "mean = np.mean(acc)\n",
    "std_dev = np.std(acc)\n",
    "print(f\"Mean: {mean} Std: {std_dev}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "1f53d9a0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'mean_absolute_error', 'val_loss', 'val_mean_absolute_error'])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history[0].history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "95087fe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff990d05cd0>]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history[0].history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "1c42fbfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_size': 100,\n",
       " 'hidden_size': 74,\n",
       " 'regul': 1e-05,\n",
       " 'dense_blocks': 2,\n",
       " 'dropout': 0.0,\n",
       " 'learning_rate': 0.0008055913640444876}"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hyperparameters[2].values"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2fa6e0b7",
   "metadata": {},
   "source": [
    "Result for model 1:\n",
    "Mean: 0.7618974298238754 Std: 0.05709931374324902\n",
    "{'input_size': 100,\n",
    " 'hidden_size': 74,\n",
    " 'regul': 0.0005677953653291085,\n",
    " 'dense_blocks': 10,\n",
    " 'dropout': 0.0,\n",
    " 'learning_rate': 0.0004614331680175835}\n",
    " \n",
    "Result for model 2:\n",
    "Mean: 0.8102992177009583 Std: 0.09478390787437432\n",
    "{'input_size': 100,\n",
    " 'hidden_size': 42,\n",
    " 'regul': 0.0036787999149105136,\n",
    " 'dense_blocks': 9,\n",
    " 'dropout': 0.0,\n",
    " 'learning_rate': 0.0003168240557749865}\n",
    " \n",
    "Result for model 3:\n",
    "Mean: 0.8317078948020935 Std: 0.09428310291551761\n",
    "{'input_size': 100,\n",
    " 'hidden_size': 74,\n",
    " 'regul': 1e-05,\n",
    " 'dense_blocks': 2,\n",
    " 'dropout': 0.0,\n",
    " 'learning_rate': 0.0008055913640444876}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f36a38",
   "metadata": {},
   "source": [
    "### 4/ Retrain the best model on all the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7fcafb",
   "metadata": {},
   "source": [
    "#### Intel on the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "1802afc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = best_hyperparameters[0]\n",
    "model = build_model_dense(hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "141b89f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"dense_01_focused_edge\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "e1ec555e",
   "metadata": {},
   "outputs": [],
   "source": [
    "info = f\"\"\"\n",
    "Trained on focused slices with illumination variation:\n",
    "{path}\n",
    "\n",
    "Hyperparameters:\n",
    "{str(hp.values)}\n",
    " \n",
    "Cross validation results:\n",
    "Mean: 0.7618974298238754 Std: 0.05709931374324902\n",
    "\n",
    "Size: {count_params(model.trainable_weights)}\n",
    "\n",
    "Training on {len(training)} points and {len(im) - len(training)} used for early stopping validation.\n",
    "\n",
    "Input size: 100\n",
    "\n",
    "Data augmentation: random_crop + random_mirror\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "258c3128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trained on focused slices with illumination variation:\n",
      "/media/felix/AMFtopology02/storage/datasets/focused_with_varying_lum_train\n",
      "\n",
      "Hyperparameters:\n",
      "{'input_size': 100, 'hidden_size': 74, 'regul': 0.0005677953653291085, 'dense_blocks': 10, 'dropout': 0.0, 'learning_rate': 0.0004614331680175835}\n",
      " \n",
      "Cross validation results:\n",
      "Mean: 0.7618974298238754 Std: 0.05709931374324902\n",
      "\n",
      "Size: 57499\n",
      "\n",
      "Training on 377 points and 150 used for early stopping validation.\n",
      "\n",
      "Input size: 100\n",
      "\n",
      "Data augmentation: random_crop + random_mirror\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfbc351",
   "metadata": {},
   "source": [
    "#### Saving location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "c34e66ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(storage_path, \"models\", name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "d4671ae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/felix/AMFtopology02/storage/models/dense_01_focused_edge'"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8ea3dc14",
   "metadata": {},
   "source": [
    "os.mkdir(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "46d1a474",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(model_path, 'info_general.txt'), 'w') as f:\n",
    "    f.write(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cd2c94",
   "metadata": {},
   "source": [
    "#### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "14204f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from amftrack.ml.callbacks import SavePlots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "33787b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_path = os.path.join(os.path.dirname(model_path), \"tensorboard\")\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(tensorboard_path, update_freq=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "281d4c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=8,\n",
    "    verbose=0,\n",
    "    restore_best_weights=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "ea70e81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr_callback = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor=\"val_loss\",\n",
    "        factor=0.5,\n",
    "        patience=6,\n",
    "        verbose=0,\n",
    "        min_delta=0.001,\n",
    "        cooldown=0,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "9859408d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_callback = SavePlots(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "fad8dcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_logger = tf.keras.callbacks.CSVLogger(os.path.join(model_path, \"training.log\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "c0a413d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    csv_logger,\n",
    "    #reduce_lr_callback,\n",
    "    early_stopping_callback,\n",
    "    tb_callback,\n",
    "    plot_callback,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e3ab5e",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc34cc1a",
   "metadata": {},
   "source": [
    "Full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "96bf3598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      " 1/24 [>.............................] - ETA: 17s - loss: 35.8398 - mean_absolute_error: 5.0591WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0022s vs `on_train_batch_end` time: 0.0031s). Check your callbacks.\n",
      "2022-08-18 11:37:13,809-[WARNING]- tensorflow:339 -> Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0022s vs `on_train_batch_end` time: 0.0031s). Check your callbacks.\n",
      "24/24 [==============================] - 1s 10ms/step - loss: 27.3931 - mean_absolute_error: 4.3292 - val_loss: 17.1029 - val_mean_absolute_error: 3.1056\n",
      "Epoch 2/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 15.6985 - mean_absolute_error: 2.8266 - val_loss: 11.9574 - val_mean_absolute_error: 2.4868\n",
      "Epoch 3/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 11.4524 - mean_absolute_error: 2.3153 - val_loss: 7.5569 - val_mean_absolute_error: 1.7228\n",
      "Epoch 4/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 5.8979 - mean_absolute_error: 1.3388 - val_loss: 4.9974 - val_mean_absolute_error: 1.1885\n",
      "Epoch 5/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4.4835 - mean_absolute_error: 1.0658 - val_loss: 4.3487 - val_mean_absolute_error: 1.0392\n",
      "Epoch 6/200\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 4.1198 - mean_absolute_error: 0.9994 - val_loss: 4.1278 - val_mean_absolute_error: 1.0022\n",
      "Epoch 7/200\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3.9096 - mean_absolute_error: 0.9450 - val_loss: 4.0210 - val_mean_absolute_error: 1.0331\n",
      "Epoch 8/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3.8070 - mean_absolute_error: 0.9462 - val_loss: 3.7624 - val_mean_absolute_error: 0.9497\n",
      "Epoch 9/200\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3.5046 - mean_absolute_error: 0.8753 - val_loss: 3.7489 - val_mean_absolute_error: 0.9851\n",
      "Epoch 10/200\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3.5495 - mean_absolute_error: 0.9219 - val_loss: 3.6100 - val_mean_absolute_error: 0.9807\n",
      "Epoch 11/200\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3.3954 - mean_absolute_error: 0.9005 - val_loss: 3.6024 - val_mean_absolute_error: 0.9700\n",
      "Epoch 12/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3.3264 - mean_absolute_error: 0.9090 - val_loss: 3.3446 - val_mean_absolute_error: 0.9021\n",
      "Epoch 13/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3.1826 - mean_absolute_error: 0.8822 - val_loss: 3.3669 - val_mean_absolute_error: 0.9404\n",
      "Epoch 14/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3.0908 - mean_absolute_error: 0.8562 - val_loss: 3.2429 - val_mean_absolute_error: 0.9087\n",
      "Epoch 15/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3.0972 - mean_absolute_error: 0.8739 - val_loss: 3.2495 - val_mean_absolute_error: 0.9152\n",
      "Epoch 16/200\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3.0071 - mean_absolute_error: 0.8428 - val_loss: 3.2015 - val_mean_absolute_error: 0.9150\n",
      "Epoch 17/200\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2.9154 - mean_absolute_error: 0.8388 - val_loss: 3.1440 - val_mean_absolute_error: 0.9129\n",
      "Epoch 18/200\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 2.9685 - mean_absolute_error: 0.8580 - val_loss: 3.2755 - val_mean_absolute_error: 0.9681\n",
      "Epoch 19/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2.9826 - mean_absolute_error: 0.8707 - val_loss: 3.1369 - val_mean_absolute_error: 0.8994\n",
      "Epoch 20/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2.9663 - mean_absolute_error: 0.8764 - val_loss: 3.1169 - val_mean_absolute_error: 0.9002\n",
      "Epoch 21/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3.0536 - mean_absolute_error: 0.9025 - val_loss: 3.0352 - val_mean_absolute_error: 0.8521\n",
      "Epoch 22/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2.9194 - mean_absolute_error: 0.8661 - val_loss: 3.0544 - val_mean_absolute_error: 0.8845\n",
      "Epoch 23/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2.8980 - mean_absolute_error: 0.8590 - val_loss: 3.0128 - val_mean_absolute_error: 0.8751\n",
      "Epoch 24/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2.8476 - mean_absolute_error: 0.8422 - val_loss: 3.0184 - val_mean_absolute_error: 0.9173\n",
      "Epoch 25/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2.8298 - mean_absolute_error: 0.8591 - val_loss: 2.9935 - val_mean_absolute_error: 0.8826\n",
      "Epoch 26/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2.8057 - mean_absolute_error: 0.8296 - val_loss: 2.9648 - val_mean_absolute_error: 0.8798\n",
      "Epoch 27/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2.7681 - mean_absolute_error: 0.8254 - val_loss: 3.0572 - val_mean_absolute_error: 0.9276\n",
      "Epoch 28/200\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2.7945 - mean_absolute_error: 0.8323 - val_loss: 2.9153 - val_mean_absolute_error: 0.8609\n",
      "Epoch 29/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2.8054 - mean_absolute_error: 0.8395 - val_loss: 2.9402 - val_mean_absolute_error: 0.8727\n",
      "Epoch 30/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2.8098 - mean_absolute_error: 0.8569 - val_loss: 2.9624 - val_mean_absolute_error: 0.8735\n",
      "Epoch 31/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2.7460 - mean_absolute_error: 0.8395 - val_loss: 2.9841 - val_mean_absolute_error: 0.8885\n",
      "Epoch 32/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2.7735 - mean_absolute_error: 0.8435 - val_loss: 2.9294 - val_mean_absolute_error: 0.8717\n",
      "Epoch 33/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2.7342 - mean_absolute_error: 0.8238 - val_loss: 2.9031 - val_mean_absolute_error: 0.8555\n",
      "Epoch 34/200\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2.7911 - mean_absolute_error: 0.8443 - val_loss: 3.0205 - val_mean_absolute_error: 0.9265\n",
      "Epoch 35/200\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2.7351 - mean_absolute_error: 0.8274 - val_loss: 2.8811 - val_mean_absolute_error: 0.8822\n",
      "Epoch 36/200\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2.7039 - mean_absolute_error: 0.8376 - val_loss: 2.9450 - val_mean_absolute_error: 0.8804\n",
      "Epoch 37/200\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2.6854 - mean_absolute_error: 0.8272 - val_loss: 2.9208 - val_mean_absolute_error: 0.8759\n",
      "Epoch 38/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2.6307 - mean_absolute_error: 0.8081 - val_loss: 2.8141 - val_mean_absolute_error: 0.8594\n",
      "Epoch 39/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2.6708 - mean_absolute_error: 0.8304 - val_loss: 2.9310 - val_mean_absolute_error: 0.8962\n",
      "Epoch 40/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2.6365 - mean_absolute_error: 0.8156 - val_loss: 2.8942 - val_mean_absolute_error: 0.8853\n",
      "Epoch 41/200\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2.5687 - mean_absolute_error: 0.7800 - val_loss: 3.1672 - val_mean_absolute_error: 0.9493\n",
      "Epoch 42/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2.6827 - mean_absolute_error: 0.8217 - val_loss: 3.0228 - val_mean_absolute_error: 0.9096\n",
      "Epoch 43/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2.7355 - mean_absolute_error: 0.8577 - val_loss: 2.8433 - val_mean_absolute_error: 0.8537\n",
      "Epoch 44/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 2.6292 - mean_absolute_error: 0.8205 - val_loss: 2.8338 - val_mean_absolute_error: 0.8699\n",
      "Epoch 45/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2.6299 - mean_absolute_error: 0.8221 - val_loss: 2.8765 - val_mean_absolute_error: 0.8867\n",
      "Epoch 46/200\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2.6738 - mean_absolute_error: 0.8374 - val_loss: 2.8333 - val_mean_absolute_error: 0.8637\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff9d8d0dfa0>"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds,\n",
    "    validation_data = valid_ds,\n",
    "    epochs=200,\n",
    "    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34e1025",
   "metadata": {},
   "source": [
    "**Saving model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "18375338",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join(model_path, \"saved_model_retrained.h5\"))\n",
    "\n",
    "with open(os.path.join(model_path, \"model_summary.txt\"), \"w\") as fh:\n",
    "    model.summary(print_fn=lambda x: fh.write(x + \"\\n\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e68878",
   "metadata": {},
   "source": [
    "**Saving the model obtained during bayesian search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "2701a589",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models[0].save(os.path.join(model_path, \"saved_model_from_search.h5\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30e4301",
   "metadata": {},
   "source": [
    "## Random search with conv model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bd2ea9",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d1148ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.RandomSearch(\n",
    "    build_model_conv,\n",
    "    objective='val_mean_absolute_error',\n",
    "    max_trials=50,\n",
    "    seed=seed,\n",
    "    hyperparameters=None,\n",
    "    tune_new_entries=True,\n",
    "    allow_new_entries=True,\n",
    "    overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b8ff0b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 50 Complete [00h 02m 13s]\n",
      "val_mean_absolute_error: 0.8619729280471802\n",
      "\n",
      "Best val_mean_absolute_error So Far: 0.702015221118927\n",
      "Total elapsed time: 01h 30m 12s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "2022-08-12 15:44:42,115-[INFO]- tensorflow:1 -> Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(data_preparation(im),\n",
    "             label,\n",
    "             validation_split=0.2,\n",
    "             epochs=200,\n",
    "             callbacks=[tf.keras.callbacks.EarlyStopping(patience=8, restore_best_weights = True)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492ab450",
   "metadata": {},
   "source": [
    "### Analyse results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c9d257f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in ./untitled_project\n",
      "Showing 10 best trials\n",
      "<keras_tuner.engine.objective.Objective object at 0x7f75c4753eb0>\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "input_size: 80\n",
      "regul: 0.0002707623734125964\n",
      "batch_normalization: True\n",
      "conv_blocks: 3\n",
      "filters_0: 224\n",
      "kernel_size0: 19\n",
      "filters_1: 160\n",
      "kernel_size1: 20\n",
      "pooling_1: avg\n",
      "hidden_size: 10\n",
      "dense_blocks: 3\n",
      "dropout: 0.1\n",
      "learning_rate: 0.020272548846591663\n",
      "pooling_0: avg\n",
      "filters_2: 256\n",
      "kernel_size2: 17\n",
      "pooling_2: none\n",
      "Score: 0.702015221118927\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "input_size: 80\n",
      "regul: 0.00010991863288278036\n",
      "batch_normalization: False\n",
      "conv_blocks: 2\n",
      "filters_0: 64\n",
      "kernel_size0: 14\n",
      "filters_1: 160\n",
      "kernel_size1: 18\n",
      "pooling_1: avg\n",
      "hidden_size: 42\n",
      "dense_blocks: 3\n",
      "dropout: 0.5\n",
      "learning_rate: 0.00638224910178181\n",
      "pooling_0: max\n",
      "filters_2: 192\n",
      "kernel_size2: 15\n",
      "pooling_2: max\n",
      "Score: 0.704502284526825\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "input_size: 80\n",
      "regul: 0.00032199506051567314\n",
      "batch_normalization: True\n",
      "conv_blocks: 2\n",
      "filters_0: 64\n",
      "kernel_size0: 13\n",
      "filters_1: 160\n",
      "kernel_size1: 5\n",
      "pooling_1: avg\n",
      "hidden_size: 74\n",
      "dense_blocks: 2\n",
      "dropout: 0.30000000000000004\n",
      "learning_rate: 0.00020644391295639603\n",
      "pooling_0: none\n",
      "Score: 0.7146832942962646\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "input_size: 80\n",
      "regul: 6.908837503318941e-05\n",
      "batch_normalization: False\n",
      "conv_blocks: 2\n",
      "filters_0: 160\n",
      "kernel_size0: 6\n",
      "filters_1: 128\n",
      "kernel_size1: 9\n",
      "pooling_1: avg\n",
      "hidden_size: 42\n",
      "dense_blocks: 2\n",
      "dropout: 0.0\n",
      "learning_rate: 0.0009775664203574934\n",
      "pooling_0: avg\n",
      "Score: 0.7626064419746399\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "input_size: 80\n",
      "regul: 0.0010562376768930327\n",
      "batch_normalization: True\n",
      "conv_blocks: 2\n",
      "filters_0: 192\n",
      "kernel_size0: 8\n",
      "filters_1: 224\n",
      "kernel_size1: 7\n",
      "pooling_1: max\n",
      "hidden_size: 10\n",
      "dense_blocks: 1\n",
      "dropout: 0.0\n",
      "learning_rate: 0.0004832573378556583\n",
      "pooling_0: max\n",
      "Score: 0.7866157293319702\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "input_size: 80\n",
      "regul: 1.619773895005048e-05\n",
      "batch_normalization: False\n",
      "conv_blocks: 3\n",
      "filters_0: 160\n",
      "kernel_size0: 6\n",
      "filters_1: 256\n",
      "kernel_size1: 14\n",
      "pooling_1: none\n",
      "hidden_size: 42\n",
      "dense_blocks: 2\n",
      "dropout: 0.2\n",
      "learning_rate: 0.0008639229762234833\n",
      "pooling_0: none\n",
      "filters_2: 160\n",
      "kernel_size2: 6\n",
      "pooling_2: avg\n",
      "Score: 0.7882844805717468\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "input_size: 80\n",
      "regul: 0.00050472731221573\n",
      "batch_normalization: False\n",
      "conv_blocks: 1\n",
      "filters_0: 224\n",
      "kernel_size0: 8\n",
      "filters_1: 160\n",
      "kernel_size1: 8\n",
      "pooling_1: max\n",
      "hidden_size: 74\n",
      "dense_blocks: 2\n",
      "dropout: 0.1\n",
      "learning_rate: 0.0004956405624619392\n",
      "pooling_0: max\n",
      "filters_2: 64\n",
      "kernel_size2: 16\n",
      "pooling_2: max\n",
      "Score: 0.8011331558227539\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "input_size: 80\n",
      "regul: 0.0097400166982067\n",
      "batch_normalization: True\n",
      "conv_blocks: 1\n",
      "filters_0: 224\n",
      "kernel_size0: 17\n",
      "filters_1: 160\n",
      "kernel_size1: 5\n",
      "pooling_1: avg\n",
      "hidden_size: 74\n",
      "dense_blocks: 2\n",
      "dropout: 0.30000000000000004\n",
      "learning_rate: 0.0001465777550436778\n",
      "pooling_0: max\n",
      "filters_2: 192\n",
      "kernel_size2: 13\n",
      "pooling_2: avg\n",
      "Score: 0.8049061298370361\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "input_size: 80\n",
      "regul: 1.5061420490559164e-05\n",
      "batch_normalization: True\n",
      "conv_blocks: 2\n",
      "filters_0: 64\n",
      "kernel_size0: 12\n",
      "filters_1: 160\n",
      "kernel_size1: 16\n",
      "pooling_1: avg\n",
      "hidden_size: 42\n",
      "dense_blocks: 2\n",
      "dropout: 0.30000000000000004\n",
      "learning_rate: 0.0008758408573224307\n",
      "pooling_0: avg\n",
      "filters_2: 160\n",
      "kernel_size2: 19\n",
      "pooling_2: none\n",
      "Score: 0.807873547077179\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "input_size: 80\n",
      "regul: 0.00030389246930894354\n",
      "batch_normalization: True\n",
      "conv_blocks: 1\n",
      "filters_0: 256\n",
      "kernel_size0: 6\n",
      "filters_1: 96\n",
      "kernel_size1: 12\n",
      "pooling_1: max\n",
      "hidden_size: 42\n",
      "dense_blocks: 1\n",
      "dropout: 0.0\n",
      "learning_rate: 0.0004831323790896749\n",
      "pooling_0: none\n",
      "filters_2: 224\n",
      "kernel_size2: 17\n",
      "pooling_2: avg\n",
      "Score: 0.8135343194007874\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1a04d770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "2022-08-12 15:46:06,331-[WARNING]- tensorflow:185 -> Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "2022-08-12 15:46:06,332-[WARNING]- tensorflow:194 -> Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
      "2022-08-12 15:46:06,332-[WARNING]- tensorflow:194 -> Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
      "2022-08-12 15:46:06,333-[WARNING]- tensorflow:194 -> Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "2022-08-12 15:46:06,333-[WARNING]- tensorflow:194 -> Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
      "2022-08-12 15:46:06,334-[WARNING]- tensorflow:194 -> Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n"
     ]
    }
   ],
   "source": [
    "best_model = tuner.get_best_models(2)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "17fe4590",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hyperparameters = tuner.get_best_hyperparameters(1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "899c8b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 80, 1)]           0         \n",
      "                                                                 \n",
      " rescaling (Rescaling)       (None, 80, 1)             0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 71, 64)            704       \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 71, 64)            0         \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 62, 160)           102560    \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 62, 160)           0         \n",
      "                                                                 \n",
      " average_pooling1d (AverageP  (None, 31, 160)          0         \n",
      " ooling1D)                                                       \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4960)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 42)                208362    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 42)                1806      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 42)                1806      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 42)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 43        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 315,281\n",
      "Trainable params: 315,281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "802d0f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 17\n",
      "input_size (Fixed)\n",
      "{'conditions': [], 'value': 80}\n",
      "regul (Float)\n",
      "{'default': 0.0001, 'conditions': [], 'min_value': 1e-05, 'max_value': 0.1, 'step': None, 'sampling': 'log'}\n",
      "batch_normalization (Boolean)\n",
      "{'default': False, 'conditions': []}\n",
      "conv_blocks (Int)\n",
      "{'default': 2, 'conditions': [], 'min_value': 1, 'max_value': 3, 'step': 1, 'sampling': None}\n",
      "filters_0 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 256, 'step': 32, 'sampling': None}\n",
      "kernel_size0 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 5, 'max_value': 20, 'step': 1, 'sampling': None}\n",
      "filters_1 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 256, 'step': 32, 'sampling': None}\n",
      "kernel_size1 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 5, 'max_value': 20, 'step': 1, 'sampling': None}\n",
      "pooling_1 (Choice)\n",
      "{'default': 'avg', 'conditions': [], 'values': ['avg', 'max', 'none'], 'ordered': False}\n",
      "hidden_size (Int)\n",
      "{'default': 32, 'conditions': [], 'min_value': 10, 'max_value': 100, 'step': 32, 'sampling': None}\n",
      "dense_blocks (Int)\n",
      "{'default': 1, 'conditions': [], 'min_value': 1, 'max_value': 3, 'step': 1, 'sampling': None}\n",
      "dropout (Float)\n",
      "{'default': 0.5, 'conditions': [], 'min_value': 0.0, 'max_value': 0.5, 'step': 0.1, 'sampling': None}\n",
      "learning_rate (Float)\n",
      "{'default': 0.001, 'conditions': [], 'min_value': 1e-05, 'max_value': 0.1, 'step': None, 'sampling': 'log'}\n",
      "pooling_0 (Choice)\n",
      "{'default': 'avg', 'conditions': [], 'values': ['avg', 'max', 'none'], 'ordered': False}\n",
      "filters_2 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 256, 'step': 32, 'sampling': None}\n",
      "kernel_size2 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 5, 'max_value': 20, 'step': 1, 'sampling': None}\n",
      "pooling_2 (Choice)\n",
      "{'default': 'avg', 'conditions': [], 'values': ['avg', 'max', 'none'], 'ordered': False}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "504d343e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_against(model, test_feature, test_label):\n",
    "    predicted = model.predict(test_feature)\n",
    "    plt.scatter(test_label, predicted, marker='o')\n",
    "    plt.plot([0,12],[0,12])\n",
    "    plt.xlim(2, 16)\n",
    "    plt.ylim(2, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7c343ab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[179, 178, 179, ..., 166, 169, 169],\n",
       "       [188, 185, 185, ..., 191, 193, 192],\n",
       "       [184, 186, 184, ..., 183, 182, 180],\n",
       "       ...,\n",
       "       [191, 189, 191, ..., 195, 193, 195],\n",
       "       [187, 187, 188, ..., 189, 190, 190],\n",
       "       [187, 185, 186, ..., 163, 162, 166]], dtype=uint8)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7a2d0c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(storage_path, \"test_final\")\n",
    "im_path_test = os.path.join(path, \"slices.png\")\n",
    "label_path_test = os.path.join(path, \"labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d0e19521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(810, 120)\n"
     ]
    }
   ],
   "source": [
    "im_test = imageio.imread(im_path_test)\n",
    "print(im_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e2dcfdd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(810,)\n"
     ]
    }
   ],
   "source": [
    "with open(label_path, 'rb') as f:\n",
    "    label_test = np.load(f)\n",
    "print(label_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a3055d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_test = np.expand_dims(label_test, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8218f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "13b40dc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a42bf64ae3144808defd36fa7e1c212",
       "version_major": 2,
       "version_minor": 0
      },
      "image/png": "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",
      "text/html": [
       "\n",
       "            <div style=\"display: inline-block;\">\n",
       "                <div class=\"jupyter-widgets widget-label\" style=\"text-align: center;\">\n",
       "                    Figure\n",
       "                </div>\n",
       "                <img src='data:image/png;base64,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' width=640.0/>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "plot_against(best_model, data_preparation(im_test), label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a5100144",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-12 16:34:00.585513: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /media/kahane/AMFtopology02/storage/models/model_vendredi/assets\n",
      "2022-08-12 16:34:02,605-[INFO]- tensorflow:779 -> Assets written to: /media/kahane/AMFtopology02/storage/models/model_vendredi/assets\n"
     ]
    }
   ],
   "source": [
    "save_path = os.path.join(storage_path, \"models\", \"model_vendredi\")\n",
    "best_model.save(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4f889166",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 6ms/step - loss: 2.2786 - mean_absolute_error: 1.0133\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.278571844100952, 1.0132561922073364]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.evaluate(test_feature, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "80d3a718",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 120, 1)]          0         \n",
      "                                                                 \n",
      " rescaling (Rescaling)       (None, 120, 1)            0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 111, 160)          1760      \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 111, 160)          0         \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 102, 128)          204928    \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 102, 128)          0         \n",
      "                                                                 \n",
      " average_pooling1d (AverageP  (None, 51, 128)          0         \n",
      " ooling1D)                                                       \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6528)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 42)                274218    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 42)                1806      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 42)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 43        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 482,755\n",
      "Trainable params: 482,755\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bbe87426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "2022-06-07 15:53:58,773-[WARNING]- tensorflow:185 -> Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "2022-06-07 15:53:58,774-[WARNING]- tensorflow:194 -> Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
      "2022-06-07 15:53:58,775-[WARNING]- tensorflow:194 -> Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
      "2022-06-07 15:53:58,777-[WARNING]- tensorflow:194 -> Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "2022-06-07 15:53:58,778-[WARNING]- tensorflow:194 -> Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
      "2022-06-07 15:53:58,779-[WARNING]- tensorflow:194 -> Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<keras.engine.functional.Functional at 0x7fcbc5fc2460>,\n",
       " <keras.engine.functional.Functional at 0x7fcbc5fd1040>,\n",
       " <keras.engine.functional.Functional at 0x7fcbc5ff2370>,\n",
       " <keras.engine.functional.Functional at 0x7fcbe442f370>,\n",
       " <keras.engine.functional.Functional at 0x7fcbe460e8e0>]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner.get_best_models(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7656f24e",
   "metadata": {},
   "source": [
    "### Evaluate with data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "91028823",
   "metadata": {},
   "outputs": [],
   "source": [
    "from amftrack.ml.width.data_augmentation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32aabccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.Input(shape=(120, 1)),\n",
    "        random_crop(120),\n",
    "        # random_invert(p=0.5),  # TODO(FK): keep?\n",
    "        random_mirror(p=0.5),\n",
    "        random_brightness(20),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "81f531c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7fcbf42ec700>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f08d1d37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[199, 198, 197, ..., 203, 204, 207],\n",
       "       [175, 177, 176, ..., 167, 166, 166],\n",
       "       [194, 194, 194, ..., 146, 134, 120],\n",
       "       ...,\n",
       "       [186, 186, 186, ..., 179, 177, 179],\n",
       "       [204, 206, 206, ..., 205, 206, 206],\n",
       "       [188, 189, 188, ..., 174, 177, 179]], dtype=uint8)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f8ea1200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74, 1)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "61098b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feature_ = data_augmentation(test_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2bea5a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 80, 1])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f80240",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.evaluate(test_feature, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5d366d12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7fcbf74f6b20>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc39908",
   "metadata": {},
   "source": [
    "## BROUILLON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "7d0564cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(32, 80, 1), dtype=float32, numpy=\n",
       " array([[[130.],\n",
       "         [130.],\n",
       "         [130.],\n",
       "         ...,\n",
       "         [127.],\n",
       "         [128.],\n",
       "         [129.]],\n",
       " \n",
       "        [[113.],\n",
       "         [111.],\n",
       "         [109.],\n",
       "         ...,\n",
       "         [129.],\n",
       "         [128.],\n",
       "         [125.]],\n",
       " \n",
       "        [[119.],\n",
       "         [120.],\n",
       "         [120.],\n",
       "         ...,\n",
       "         [122.],\n",
       "         [123.],\n",
       "         [122.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[146.],\n",
       "         [144.],\n",
       "         [141.],\n",
       "         ...,\n",
       "         [148.],\n",
       "         [147.],\n",
       "         [147.]],\n",
       " \n",
       "        [[110.],\n",
       "         [107.],\n",
       "         [106.],\n",
       "         ...,\n",
       "         [116.],\n",
       "         [115.],\n",
       "         [114.]],\n",
       " \n",
       "        [[124.],\n",
       "         [124.],\n",
       "         [124.],\n",
       "         ...,\n",
       "         [124.],\n",
       "         [123.],\n",
       "         [123.]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(32,), dtype=float64, numpy=\n",
       " array([7.26221294, 5.93755418, 5.5774322 , 4.19787153, 3.7441611 ,\n",
       "        5.20109506, 4.87914297, 0.        , 8.52101685, 8.73503977,\n",
       "        4.59109883, 4.34090199, 4.35067225, 4.18356936, 5.923182  ,\n",
       "        8.89809448, 4.7800506 , 5.29939395, 5.08347615, 8.36581426,\n",
       "        8.89809448, 4.7800506 , 5.29939395, 5.08347615, 5.923182  ,\n",
       "        4.59109883, 4.34090199, 8.52101685, 8.73503977, 4.18356936,\n",
       "        4.35067225, 0.        ])>)"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2df246",
   "metadata": {},
   "source": [
    "TEST 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fb73a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "9e486f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([527, 80, 1])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_augmentation(train_feature).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbe79fc",
   "metadata": {},
   "source": [
    "TEST 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "a19a6ab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3, 1), dtype=float32, numpy=\n",
       "array([[[131.],\n",
       "        [130.],\n",
       "        [129.]],\n",
       "\n",
       "       [[130.],\n",
       "        [130.],\n",
       "        [128.]],\n",
       "\n",
       "       [[130.],\n",
       "        [131.],\n",
       "        [131.]]], dtype=float32)>"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_augmentation(train_feature)[:3,:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c10f7a",
   "metadata": {},
   "source": [
    "TEST 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "55c8d9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method search in module keras_tuner.engine.base_tuner:\n",
      "\n",
      "search(*fit_args, **fit_kwargs) method of keras_tuner.tuners.randomsearch.RandomSearch instance\n",
      "    Performs a search for best hyperparameter configuations.\n",
      "    \n",
      "    Args:\n",
      "        *fit_args: Positional arguments that should be passed to\n",
      "          `run_trial`, for example the training and validation data.\n",
      "        **fit_kwargs: Keyword arguments that should be passed to\n",
      "          `run_trial`, for example the training and validation data.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tuner.search)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d874adb",
   "metadata": {},
   "source": [
    "TEST 4: making an augmented dataset from the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b625707",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "a1ffe145",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class DatasetV2 in module tensorflow.python.data.ops.dataset_ops:\n",
      "\n",
      "class DatasetV2(collections.abc.Iterable, tensorflow.python.training.tracking.base.Trackable, tensorflow.python.framework.composite_tensor.CompositeTensor)\n",
      " |  DatasetV2(variant_tensor)\n",
      " |  \n",
      " |  Represents a potentially large set of elements.\n",
      " |  \n",
      " |  The `tf.data.Dataset` API supports writing descriptive and efficient input\n",
      " |  pipelines. `Dataset` usage follows a common pattern:\n",
      " |  \n",
      " |  1. Create a source dataset from your input data.\n",
      " |  2. Apply dataset transformations to preprocess the data.\n",
      " |  3. Iterate over the dataset and process the elements.\n",
      " |  \n",
      " |  Iteration happens in a streaming fashion, so the full dataset does not need to\n",
      " |  fit into memory.\n",
      " |  \n",
      " |  Source Datasets:\n",
      " |  \n",
      " |  The simplest way to create a dataset is to create it from a python `list`:\n",
      " |  \n",
      " |  >>> dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
      " |  >>> for element in dataset:\n",
      " |  ...   print(element)\n",
      " |  tf.Tensor(1, shape=(), dtype=int32)\n",
      " |  tf.Tensor(2, shape=(), dtype=int32)\n",
      " |  tf.Tensor(3, shape=(), dtype=int32)\n",
      " |  \n",
      " |  To process lines from files, use `tf.data.TextLineDataset`:\n",
      " |  \n",
      " |  >>> dataset = tf.data.TextLineDataset([\"file1.txt\", \"file2.txt\"])\n",
      " |  \n",
      " |  To process records written in the `TFRecord` format, use `TFRecordDataset`:\n",
      " |  \n",
      " |  >>> dataset = tf.data.TFRecordDataset([\"file1.tfrecords\", \"file2.tfrecords\"])\n",
      " |  \n",
      " |  To create a dataset of all files matching a pattern, use\n",
      " |  `tf.data.Dataset.list_files`:\n",
      " |  \n",
      " |  ```python\n",
      " |  dataset = tf.data.Dataset.list_files(\"/path/*.txt\")\n",
      " |  ```\n",
      " |  \n",
      " |  See `tf.data.FixedLengthRecordDataset` and `tf.data.Dataset.from_generator`\n",
      " |  for more ways to create datasets.\n",
      " |  \n",
      " |  Transformations:\n",
      " |  \n",
      " |  Once you have a dataset, you can apply transformations to prepare the data for\n",
      " |  your model:\n",
      " |  \n",
      " |  >>> dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
      " |  >>> dataset = dataset.map(lambda x: x*2)\n",
      " |  >>> list(dataset.as_numpy_iterator())\n",
      " |  [2, 4, 6]\n",
      " |  \n",
      " |  Common Terms:\n",
      " |  \n",
      " |  **Element**: A single output from calling `next()` on a dataset iterator.\n",
      " |    Elements may be nested structures containing multiple components. For\n",
      " |    example, the element `(1, (3, \"apple\"))` has one tuple nested in another\n",
      " |    tuple. The components are `1`, `3`, and `\"apple\"`.\n",
      " |  \n",
      " |  **Component**: The leaf in the nested structure of an element.\n",
      " |  \n",
      " |  Supported types:\n",
      " |  \n",
      " |  Elements can be nested structures of tuples, named tuples, and dictionaries.\n",
      " |  Note that Python lists are *not* treated as nested structures of components.\n",
      " |  Instead, lists are converted to tensors and treated as components. For\n",
      " |  example, the element `(1, [1, 2, 3])` has only two components; the tensor `1`\n",
      " |  and the tensor `[1, 2, 3]`. Element components can be of any type\n",
      " |  representable by `tf.TypeSpec`, including `tf.Tensor`, `tf.data.Dataset`,\n",
      " |  `tf.sparse.SparseTensor`, `tf.RaggedTensor`, and `tf.TensorArray`.\n",
      " |  \n",
      " |  ```python\n",
      " |  a = 1 # Integer element\n",
      " |  b = 2.0 # Float element\n",
      " |  c = (1, 2) # Tuple element with 2 components\n",
      " |  d = {\"a\": (2, 2), \"b\": 3} # Dict element with 3 components\n",
      " |  Point = collections.namedtuple(\"Point\", [\"x\", \"y\"])\n",
      " |  e = Point(1, 2) # Named tuple\n",
      " |  f = tf.data.Dataset.range(10) # Dataset element\n",
      " |  ```\n",
      " |  \n",
      " |  For more information,\n",
      " |  read [this guide](https://www.tensorflow.org/guide/data).\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      DatasetV2\n",
      " |      collections.abc.Iterable\n",
      " |      tensorflow.python.training.tracking.base.Trackable\n",
      " |      tensorflow.python.framework.composite_tensor.CompositeTensor\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __bool__(self)\n",
      " |  \n",
      " |  __debug_string__(self)\n",
      " |      Returns a string showing the type of the dataset and its inputs.\n",
      " |      \n",
      " |      This string is intended only for debugging purposes, and may change without\n",
      " |      warning.\n",
      " |  \n",
      " |  __init__(self, variant_tensor)\n",
      " |      Creates a DatasetV2 object.\n",
      " |      \n",
      " |      This is a difference between DatasetV1 and DatasetV2. DatasetV1 does not\n",
      " |      take anything in its constructor whereas in the DatasetV2, we expect\n",
      " |      subclasses to create a variant_tensor and pass it in to the super() call.\n",
      " |      \n",
      " |      Args:\n",
      " |        variant_tensor: A DT_VARIANT tensor that represents the dataset.\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |      Creates an iterator for elements of this dataset.\n",
      " |      \n",
      " |      The returned iterator implements the Python Iterator protocol.\n",
      " |      \n",
      " |      Returns:\n",
      " |        An `tf.data.Iterator` for the elements of this dataset.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If not inside of tf.function and not executing eagerly.\n",
      " |  \n",
      " |  __len__(self)\n",
      " |      Returns the length of the dataset if it is known and finite.\n",
      " |      \n",
      " |      This method requires that you are running in eager mode, and that the\n",
      " |      length of the dataset is known and non-infinite. When the length may be\n",
      " |      unknown or infinite, or if you are running in graph mode, use\n",
      " |      `tf.data.Dataset.cardinality` instead.\n",
      " |      \n",
      " |      Returns:\n",
      " |        An integer representing the length of the dataset.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If the dataset length is unknown or infinite, or if eager\n",
      " |          execution is not enabled.\n",
      " |  \n",
      " |  __nonzero__ = __bool__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  apply(self, transformation_func)\n",
      " |      Applies a transformation function to this dataset.\n",
      " |      \n",
      " |      `apply` enables chaining of custom `Dataset` transformations, which are\n",
      " |      represented as functions that take one `Dataset` argument and return a\n",
      " |      transformed `Dataset`.\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.range(100)\n",
      " |      >>> def dataset_fn(ds):\n",
      " |      ...   return ds.filter(lambda x: x < 5)\n",
      " |      >>> dataset = dataset.apply(dataset_fn)\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [0, 1, 2, 3, 4]\n",
      " |      \n",
      " |      Args:\n",
      " |        transformation_func: A function that takes one `Dataset` argument and\n",
      " |          returns a `Dataset`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: The `Dataset` returned by applying `transformation_func` to this\n",
      " |            dataset.\n",
      " |  \n",
      " |  as_numpy_iterator(self)\n",
      " |      Returns an iterator which converts all elements of the dataset to numpy.\n",
      " |      \n",
      " |      Use `as_numpy_iterator` to inspect the content of your dataset. To see\n",
      " |      element shapes and types, print dataset elements directly instead of using\n",
      " |      `as_numpy_iterator`.\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
      " |      >>> for element in dataset:\n",
      " |      ...   print(element)\n",
      " |      tf.Tensor(1, shape=(), dtype=int32)\n",
      " |      tf.Tensor(2, shape=(), dtype=int32)\n",
      " |      tf.Tensor(3, shape=(), dtype=int32)\n",
      " |      \n",
      " |      This method requires that you are running in eager mode and the dataset's\n",
      " |      element_spec contains only `TensorSpec` components.\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
      " |      >>> for element in dataset.as_numpy_iterator():\n",
      " |      ...   print(element)\n",
      " |      1\n",
      " |      2\n",
      " |      3\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
      " |      >>> print(list(dataset.as_numpy_iterator()))\n",
      " |      [1, 2, 3]\n",
      " |      \n",
      " |      `as_numpy_iterator()` will preserve the nested structure of dataset\n",
      " |      elements.\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.from_tensor_slices({'a': ([1, 2], [3, 4]),\n",
      " |      ...                                               'b': [5, 6]})\n",
      " |      >>> list(dataset.as_numpy_iterator()) == [{'a': (1, 3), 'b': 5},\n",
      " |      ...                                       {'a': (2, 4), 'b': 6}]\n",
      " |      True\n",
      " |      \n",
      " |      Returns:\n",
      " |        An iterable over the elements of the dataset, with their tensors converted\n",
      " |        to numpy arrays.\n",
      " |      \n",
      " |      Raises:\n",
      " |        TypeError: if an element contains a non-`Tensor` value.\n",
      " |        RuntimeError: if eager execution is not enabled.\n",
      " |  \n",
      " |  batch(self, batch_size, drop_remainder=False, num_parallel_calls=None, deterministic=None, name=None)\n",
      " |      Combines consecutive elements of this dataset into batches.\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.range(8)\n",
      " |      >>> dataset = dataset.batch(3)\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [array([0, 1, 2]), array([3, 4, 5]), array([6, 7])]\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.range(8)\n",
      " |      >>> dataset = dataset.batch(3, drop_remainder=True)\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [array([0, 1, 2]), array([3, 4, 5])]\n",
      " |      \n",
      " |      The components of the resulting element will have an additional outer\n",
      " |      dimension, which will be `batch_size` (or `N % batch_size` for the last\n",
      " |      element if `batch_size` does not divide the number of input elements `N`\n",
      " |      evenly and `drop_remainder` is `False`). If your program depends on the\n",
      " |      batches having the same outer dimension, you should set the `drop_remainder`\n",
      " |      argument to `True` to prevent the smaller batch from being produced.\n",
      " |      \n",
      " |      Note: If your program requires data to have a statically known shape (e.g.,\n",
      " |      when using XLA), you should use `drop_remainder=True`. Without\n",
      " |      `drop_remainder=True` the shape of the output dataset will have an unknown\n",
      " |      leading dimension due to the possibility of a smaller final batch.\n",
      " |      \n",
      " |      Args:\n",
      " |        batch_size: A `tf.int64` scalar `tf.Tensor`, representing the number of\n",
      " |          consecutive elements of this dataset to combine in a single batch.\n",
      " |        drop_remainder: (Optional.) A `tf.bool` scalar `tf.Tensor`, representing\n",
      " |          whether the last batch should be dropped in the case it has fewer than\n",
      " |          `batch_size` elements; the default behavior is not to drop the smaller\n",
      " |          batch.\n",
      " |        num_parallel_calls: (Optional.) A `tf.int64` scalar `tf.Tensor`,\n",
      " |          representing the number of batches to compute asynchronously in\n",
      " |          parallel.\n",
      " |          If not specified, batches will be computed sequentially. If the value\n",
      " |          `tf.data.AUTOTUNE` is used, then the number of parallel\n",
      " |          calls is set dynamically based on available resources.\n",
      " |        deterministic: (Optional.) When `num_parallel_calls` is specified, if this\n",
      " |          boolean is specified (`True` or `False`), it controls the order in which\n",
      " |          the transformation produces elements. If set to `False`, the\n",
      " |          transformation is allowed to yield elements out of order to trade\n",
      " |          determinism for performance. If not specified, the\n",
      " |          `tf.data.Options.deterministic` option (`True` by default) controls the\n",
      " |          behavior.\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset`.\n",
      " |  \n",
      " |  bucket_by_sequence_length(self, element_length_func, bucket_boundaries, bucket_batch_sizes, padded_shapes=None, padding_values=None, pad_to_bucket_boundary=False, no_padding=False, drop_remainder=False, name=None)\n",
      " |      A transformation that buckets elements in a `Dataset` by length.\n",
      " |      \n",
      " |      Elements of the `Dataset` are grouped together by length and then are padded\n",
      " |      and batched.\n",
      " |      \n",
      " |      This is useful for sequence tasks in which the elements have variable\n",
      " |      length. Grouping together elements that have similar lengths reduces the\n",
      " |      total fraction of padding in a batch which increases training step\n",
      " |      efficiency.\n",
      " |      \n",
      " |      Below is an example to bucketize the input data to the 3 buckets\n",
      " |      \"[0, 3), [3, 5), [5, inf)\" based on sequence length, with batch size 2.\n",
      " |      \n",
      " |      >>> elements = [\n",
      " |      ...   [0], [1, 2, 3, 4], [5, 6, 7],\n",
      " |      ...   [7, 8, 9, 10, 11], [13, 14, 15, 16, 19, 20], [21, 22]]\n",
      " |      >>> dataset = tf.data.Dataset.from_generator(\n",
      " |      ...     lambda: elements, tf.int64, output_shapes=[None])\n",
      " |      >>> dataset = dataset.bucket_by_sequence_length(\n",
      " |      ...         element_length_func=lambda elem: tf.shape(elem)[0],\n",
      " |      ...         bucket_boundaries=[3, 5],\n",
      " |      ...         bucket_batch_sizes=[2, 2, 2])\n",
      " |      >>> for elem in dataset.as_numpy_iterator():\n",
      " |      ...   print(elem)\n",
      " |      [[1 2 3 4]\n",
      " |      [5 6 7 0]]\n",
      " |      [[ 7  8  9 10 11  0]\n",
      " |      [13 14 15 16 19 20]]\n",
      " |      [[ 0  0]\n",
      " |      [21 22]]\n",
      " |      \n",
      " |      Args:\n",
      " |        element_length_func: function from element in `Dataset` to `tf.int32`,\n",
      " |          determines the length of the element, which will determine the bucket it\n",
      " |          goes into.\n",
      " |        bucket_boundaries: `list<int>`, upper length boundaries of the buckets.\n",
      " |        bucket_batch_sizes: `list<int>`, batch size per bucket. Length should be\n",
      " |          `len(bucket_boundaries) + 1`.\n",
      " |        padded_shapes: Nested structure of `tf.TensorShape` to pass to\n",
      " |          `tf.data.Dataset.padded_batch`. If not provided, will use\n",
      " |          `dataset.output_shapes`, which will result in variable length dimensions\n",
      " |          being padded out to the maximum length in each batch.\n",
      " |        padding_values: Values to pad with, passed to\n",
      " |          `tf.data.Dataset.padded_batch`. Defaults to padding with 0.\n",
      " |        pad_to_bucket_boundary: bool, if `False`, will pad dimensions with unknown\n",
      " |          size to maximum length in batch. If `True`, will pad dimensions with\n",
      " |          unknown size to bucket boundary minus 1 (i.e., the maximum length in\n",
      " |          each bucket), and caller must ensure that the source `Dataset` does not\n",
      " |          contain any elements with length longer than `max(bucket_boundaries)`.\n",
      " |        no_padding: `bool`, indicates whether to pad the batch features (features\n",
      " |          need to be either of type `tf.sparse.SparseTensor` or of same shape).\n",
      " |        drop_remainder: (Optional.) A `tf.bool` scalar `tf.Tensor`, representing\n",
      " |          whether the last batch should be dropped in the case it has fewer than\n",
      " |          `batch_size` elements; the default behavior is not to drop the smaller\n",
      " |          batch.\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `Dataset`.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: if `len(bucket_batch_sizes) != len(bucket_boundaries) + 1`.\n",
      " |  \n",
      " |  cache(self, filename='', name=None)\n",
      " |      Caches the elements in this dataset.\n",
      " |      \n",
      " |      The first time the dataset is iterated over, its elements will be cached\n",
      " |      either in the specified file or in memory. Subsequent iterations will\n",
      " |      use the cached data.\n",
      " |      \n",
      " |      Note: For the cache to be finalized, the input dataset must be iterated\n",
      " |      through in its entirety. Otherwise, subsequent iterations will not use\n",
      " |      cached data.\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.range(5)\n",
      " |      >>> dataset = dataset.map(lambda x: x**2)\n",
      " |      >>> dataset = dataset.cache()\n",
      " |      >>> # The first time reading through the data will generate the data using\n",
      " |      >>> # `range` and `map`.\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [0, 1, 4, 9, 16]\n",
      " |      >>> # Subsequent iterations read from the cache.\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [0, 1, 4, 9, 16]\n",
      " |      \n",
      " |      When caching to a file, the cached data will persist across runs. Even the\n",
      " |      first iteration through the data will read from the cache file. Changing\n",
      " |      the input pipeline before the call to `.cache()` will have no effect until\n",
      " |      the cache file is removed or the filename is changed.\n",
      " |      \n",
      " |      ```python\n",
      " |      dataset = tf.data.Dataset.range(5)\n",
      " |      dataset = dataset.cache(\"/path/to/file\")\n",
      " |      list(dataset.as_numpy_iterator())\n",
      " |      # [0, 1, 2, 3, 4]\n",
      " |      dataset = tf.data.Dataset.range(10)\n",
      " |      dataset = dataset.cache(\"/path/to/file\")  # Same file!\n",
      " |      list(dataset.as_numpy_iterator())\n",
      " |      # [0, 1, 2, 3, 4]\n",
      " |      ```\n",
      " |      \n",
      " |      Note: `cache` will produce exactly the same elements during each iteration\n",
      " |      through the dataset. If you wish to randomize the iteration order, make sure\n",
      " |      to call `shuffle` *after* calling `cache`.\n",
      " |      \n",
      " |      Args:\n",
      " |        filename: A `tf.string` scalar `tf.Tensor`, representing the name of a\n",
      " |          directory on the filesystem to use for caching elements in this Dataset.\n",
      " |          If a filename is not provided, the dataset will be cached in memory.\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset`.\n",
      " |  \n",
      " |  cardinality(self)\n",
      " |      Returns the cardinality of the dataset, if known.\n",
      " |      \n",
      " |      `cardinality` may return `tf.data.INFINITE_CARDINALITY` if the dataset\n",
      " |      contains an infinite number of elements or `tf.data.UNKNOWN_CARDINALITY` if\n",
      " |      the analysis fails to determine the number of elements in the dataset\n",
      " |      (e.g. when the dataset source is a file).\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.range(42)\n",
      " |      >>> print(dataset.cardinality().numpy())\n",
      " |      42\n",
      " |      >>> dataset = dataset.repeat()\n",
      " |      >>> cardinality = dataset.cardinality()\n",
      " |      >>> print((cardinality == tf.data.INFINITE_CARDINALITY).numpy())\n",
      " |      True\n",
      " |      >>> dataset = dataset.filter(lambda x: True)\n",
      " |      >>> cardinality = dataset.cardinality()\n",
      " |      >>> print((cardinality == tf.data.UNKNOWN_CARDINALITY).numpy())\n",
      " |      True\n",
      " |      \n",
      " |      Returns:\n",
      " |        A scalar `tf.int64` `Tensor` representing the cardinality of the dataset.\n",
      " |        If the cardinality is infinite or unknown, `cardinality` returns the\n",
      " |        named constants `tf.data.INFINITE_CARDINALITY` and\n",
      " |        `tf.data.UNKNOWN_CARDINALITY` respectively.\n",
      " |  \n",
      " |  concatenate(self, dataset, name=None)\n",
      " |      Creates a `Dataset` by concatenating the given dataset with this dataset.\n",
      " |      \n",
      " |      >>> a = tf.data.Dataset.range(1, 4)  # ==> [ 1, 2, 3 ]\n",
      " |      >>> b = tf.data.Dataset.range(4, 8)  # ==> [ 4, 5, 6, 7 ]\n",
      " |      >>> ds = a.concatenate(b)\n",
      " |      >>> list(ds.as_numpy_iterator())\n",
      " |      [1, 2, 3, 4, 5, 6, 7]\n",
      " |      >>> # The input dataset and dataset to be concatenated should have\n",
      " |      >>> # compatible element specs.\n",
      " |      >>> c = tf.data.Dataset.zip((a, b))\n",
      " |      >>> a.concatenate(c)\n",
      " |      Traceback (most recent call last):\n",
      " |      TypeError: Two datasets to concatenate have different types\n",
      " |      <dtype: 'int64'> and (tf.int64, tf.int64)\n",
      " |      >>> d = tf.data.Dataset.from_tensor_slices([\"a\", \"b\", \"c\"])\n",
      " |      >>> a.concatenate(d)\n",
      " |      Traceback (most recent call last):\n",
      " |      TypeError: Two datasets to concatenate have different types\n",
      " |      <dtype: 'int64'> and <dtype: 'string'>\n",
      " |      \n",
      " |      Args:\n",
      " |        dataset: `Dataset` to be concatenated.\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset`.\n",
      " |  \n",
      " |  enumerate(self, start=0, name=None)\n",
      " |      Enumerates the elements of this dataset.\n",
      " |      \n",
      " |      It is similar to python's `enumerate`.\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
      " |      >>> dataset = dataset.enumerate(start=5)\n",
      " |      >>> for element in dataset.as_numpy_iterator():\n",
      " |      ...   print(element)\n",
      " |      (5, 1)\n",
      " |      (6, 2)\n",
      " |      (7, 3)\n",
      " |      \n",
      " |      >>> # The (nested) structure of the input dataset determines the\n",
      " |      >>> # structure of elements in the resulting dataset.\n",
      " |      >>> dataset = tf.data.Dataset.from_tensor_slices([(7, 8), (9, 10)])\n",
      " |      >>> dataset = dataset.enumerate()\n",
      " |      >>> for element in dataset.as_numpy_iterator():\n",
      " |      ...   print(element)\n",
      " |      (0, array([7, 8], dtype=int32))\n",
      " |      (1, array([ 9, 10], dtype=int32))\n",
      " |      \n",
      " |      Args:\n",
      " |        start: A `tf.int64` scalar `tf.Tensor`, representing the start value for\n",
      " |          enumeration.\n",
      " |        name: Optional. A name for the tf.data operations used by `enumerate`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset`.\n",
      " |  \n",
      " |  filter(self, predicate, name=None)\n",
      " |      Filters this dataset according to `predicate`.\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
      " |      >>> dataset = dataset.filter(lambda x: x < 3)\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [1, 2]\n",
      " |      >>> # `tf.math.equal(x, y)` is required for equality comparison\n",
      " |      >>> def filter_fn(x):\n",
      " |      ...   return tf.math.equal(x, 1)\n",
      " |      >>> dataset = dataset.filter(filter_fn)\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [1]\n",
      " |      \n",
      " |      Args:\n",
      " |        predicate: A function mapping a dataset element to a boolean.\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: The `Dataset` containing the elements of this dataset for which\n",
      " |            `predicate` is `True`.\n",
      " |  \n",
      " |  flat_map(self, map_func, name=None)\n",
      " |      Maps `map_func` across this dataset and flattens the result.\n",
      " |      \n",
      " |      The type signature is:\n",
      " |      \n",
      " |      ```\n",
      " |      def flat_map(\n",
      " |        self: Dataset[T],\n",
      " |        map_func: Callable[[T], Dataset[S]]\n",
      " |      ) -> Dataset[S]\n",
      " |      ```\n",
      " |      \n",
      " |      Use `flat_map` if you want to make sure that the order of your dataset\n",
      " |      stays the same. For example, to flatten a dataset of batches into a\n",
      " |      dataset of their elements:\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.from_tensor_slices(\n",
      " |      ...     [[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
      " |      >>> dataset = dataset.flat_map(\n",
      " |      ...     lambda x: tf.data.Dataset.from_tensor_slices(x))\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      " |      \n",
      " |      `tf.data.Dataset.interleave()` is a generalization of `flat_map`, since\n",
      " |      `flat_map` produces the same output as\n",
      " |      `tf.data.Dataset.interleave(cycle_length=1)`\n",
      " |      \n",
      " |      Args:\n",
      " |        map_func: A function mapping a dataset element to a dataset.\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset`.\n",
      " |  \n",
      " |  get_single_element(self, name=None)\n",
      " |      Returns the single element of the `dataset`.\n",
      " |      \n",
      " |      The function enables you to use a `tf.data.Dataset` in a stateless\n",
      " |      \"tensor-in tensor-out\" expression, without creating an iterator.\n",
      " |      This facilitates the ease of data transformation on tensors using the\n",
      " |      optimized `tf.data.Dataset` abstraction on top of them.\n",
      " |      \n",
      " |      For example, lets consider a `preprocessing_fn` which would take as an\n",
      " |      input the raw features and returns the processed feature along with\n",
      " |      it's label.\n",
      " |      \n",
      " |      ```python\n",
      " |      def preprocessing_fn(raw_feature):\n",
      " |        # ... the raw_feature is preprocessed as per the use-case\n",
      " |        return feature\n",
      " |      \n",
      " |      raw_features = ...  # input batch of BATCH_SIZE elements.\n",
      " |      dataset = (tf.data.Dataset.from_tensor_slices(raw_features)\n",
      " |                .map(preprocessing_fn, num_parallel_calls=BATCH_SIZE)\n",
      " |                .batch(BATCH_SIZE))\n",
      " |      \n",
      " |      processed_features = dataset.get_single_element()\n",
      " |      ```\n",
      " |      \n",
      " |      In the above example, the `raw_features` tensor of length=BATCH_SIZE\n",
      " |      was converted to a `tf.data.Dataset`. Next, each of the `raw_feature` was\n",
      " |      mapped using the `preprocessing_fn` and the processed features were\n",
      " |      grouped into a single batch. The final `dataset` contains only one element\n",
      " |      which is a batch of all the processed features.\n",
      " |      \n",
      " |      NOTE: The `dataset` should contain only one element.\n",
      " |      \n",
      " |      Now, instead of creating an iterator for the `dataset` and retrieving the\n",
      " |      batch of features, the `tf.data.get_single_element()` function is used\n",
      " |      to skip the iterator creation process and directly output the batch of\n",
      " |      features.\n",
      " |      \n",
      " |      This can be particularly useful when your tensor transformations are\n",
      " |      expressed as `tf.data.Dataset` operations, and you want to use those\n",
      " |      transformations while serving your model.\n",
      " |      \n",
      " |      #### Keras\n",
      " |      \n",
      " |      ```python\n",
      " |      \n",
      " |      model = ... # A pre-built or custom model\n",
      " |      \n",
      " |      class PreprocessingModel(tf.keras.Model):\n",
      " |        def __init__(self, model):\n",
      " |          super().__init__(self)\n",
      " |          self.model = model\n",
      " |      \n",
      " |        @tf.function(input_signature=[...])\n",
      " |        def serving_fn(self, data):\n",
      " |          ds = tf.data.Dataset.from_tensor_slices(data)\n",
      " |          ds = ds.map(preprocessing_fn, num_parallel_calls=BATCH_SIZE)\n",
      " |          ds = ds.batch(batch_size=BATCH_SIZE)\n",
      " |          return tf.argmax(self.model(ds.get_single_element()), axis=-1)\n",
      " |      \n",
      " |      preprocessing_model = PreprocessingModel(model)\n",
      " |      your_exported_model_dir = ... # save the model to this path.\n",
      " |      tf.saved_model.save(preprocessing_model, your_exported_model_dir,\n",
      " |                    signatures={'serving_default': preprocessing_model.serving_fn}\n",
      " |                    )\n",
      " |      ```\n",
      " |      \n",
      " |      #### Estimator\n",
      " |      \n",
      " |      In the case of estimators, you need to generally define a `serving_input_fn`\n",
      " |      which would require the features to be processed by the model while\n",
      " |      inferencing.\n",
      " |      \n",
      " |      ```python\n",
      " |      def serving_input_fn():\n",
      " |      \n",
      " |        raw_feature_spec = ... # Spec for the raw_features\n",
      " |        input_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(\n",
      " |            raw_feature_spec, default_batch_size=None)\n",
      " |        )\n",
      " |        serving_input_receiver = input_fn()\n",
      " |        raw_features = serving_input_receiver.features\n",
      " |      \n",
      " |        def preprocessing_fn(raw_feature):\n",
      " |          # ... the raw_feature is preprocessed as per the use-case\n",
      " |          return feature\n",
      " |      \n",
      " |        dataset = (tf.data.Dataset.from_tensor_slices(raw_features)\n",
      " |                  .map(preprocessing_fn, num_parallel_calls=BATCH_SIZE)\n",
      " |                  .batch(BATCH_SIZE))\n",
      " |      \n",
      " |        processed_features = dataset.get_single_element()\n",
      " |      \n",
      " |        # Please note that the value of `BATCH_SIZE` should be equal to\n",
      " |        # the size of the leading dimension of `raw_features`. This ensures\n",
      " |        # that `dataset` has only element, which is a pre-requisite for\n",
      " |        # using `dataset.get_single_element()`.\n",
      " |      \n",
      " |        return tf.estimator.export.ServingInputReceiver(\n",
      " |            processed_features, serving_input_receiver.receiver_tensors)\n",
      " |      \n",
      " |      estimator = ... # A pre-built or custom estimator\n",
      " |      estimator.export_saved_model(your_exported_model_dir, serving_input_fn)\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A nested structure of `tf.Tensor` objects, corresponding to the single\n",
      " |        element of `dataset`.\n",
      " |      \n",
      " |      Raises:\n",
      " |        InvalidArgumentError: (at runtime) if `dataset` does not contain exactly\n",
      " |          one element.\n",
      " |  \n",
      " |  group_by_window(self, key_func, reduce_func, window_size=None, window_size_func=None, name=None)\n",
      " |      Groups windows of elements by key and reduces them.\n",
      " |      \n",
      " |      This transformation maps each consecutive element in a dataset to a key\n",
      " |      using `key_func` and groups the elements by key. It then applies\n",
      " |      `reduce_func` to at most `window_size_func(key)` elements matching the same\n",
      " |      key. All except the final window for each key will contain\n",
      " |      `window_size_func(key)` elements; the final window may be smaller.\n",
      " |      \n",
      " |      You may provide either a constant `window_size` or a window size determined\n",
      " |      by the key through `window_size_func`.\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.range(10)\n",
      " |      >>> window_size = 5\n",
      " |      >>> key_func = lambda x: x%2\n",
      " |      >>> reduce_func = lambda key, dataset: dataset.batch(window_size)\n",
      " |      >>> dataset = dataset.group_by_window(\n",
      " |      ...           key_func=key_func,\n",
      " |      ...           reduce_func=reduce_func,\n",
      " |      ...           window_size=window_size)\n",
      " |      >>> for elem in dataset.as_numpy_iterator():\n",
      " |      ...   print(elem)\n",
      " |      [0 2 4 6 8]\n",
      " |      [1 3 5 7 9]\n",
      " |      \n",
      " |      Args:\n",
      " |        key_func: A function mapping a nested structure of tensors (having shapes\n",
      " |          and types defined by `self.output_shapes` and `self.output_types`) to a\n",
      " |          scalar `tf.int64` tensor.\n",
      " |        reduce_func: A function mapping a key and a dataset of up to `window_size`\n",
      " |          consecutive elements matching that key to another dataset.\n",
      " |        window_size: A `tf.int64` scalar `tf.Tensor`, representing the number of\n",
      " |          consecutive elements matching the same key to combine in a single batch,\n",
      " |          which will be passed to `reduce_func`. Mutually exclusive with\n",
      " |          `window_size_func`.\n",
      " |        window_size_func: A function mapping a key to a `tf.int64` scalar\n",
      " |          `tf.Tensor`, representing the number of consecutive elements matching\n",
      " |          the same key to combine in a single batch, which will be passed to\n",
      " |          `reduce_func`. Mutually exclusive with `window_size`.\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `Dataset`.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: if neither or both of {`window_size`, `window_size_func`} are\n",
      " |          passed.\n",
      " |  \n",
      " |  interleave(self, map_func, cycle_length=None, block_length=None, num_parallel_calls=None, deterministic=None, name=None)\n",
      " |      Maps `map_func` across this dataset, and interleaves the results.\n",
      " |      \n",
      " |      The type signature is:\n",
      " |      \n",
      " |      ```\n",
      " |      def interleave(\n",
      " |        self: Dataset[T],\n",
      " |        map_func: Callable[[T], Dataset[S]]\n",
      " |      ) -> Dataset[S]\n",
      " |      ```\n",
      " |      \n",
      " |      For example, you can use `Dataset.interleave()` to process many input files\n",
      " |      concurrently:\n",
      " |      \n",
      " |      >>> # Preprocess 4 files concurrently, and interleave blocks of 16 records\n",
      " |      >>> # from each file.\n",
      " |      >>> filenames = [\"/var/data/file1.txt\", \"/var/data/file2.txt\",\n",
      " |      ...              \"/var/data/file3.txt\", \"/var/data/file4.txt\"]\n",
      " |      >>> dataset = tf.data.Dataset.from_tensor_slices(filenames)\n",
      " |      >>> def parse_fn(filename):\n",
      " |      ...   return tf.data.Dataset.range(10)\n",
      " |      >>> dataset = dataset.interleave(lambda x:\n",
      " |      ...     tf.data.TextLineDataset(x).map(parse_fn, num_parallel_calls=1),\n",
      " |      ...     cycle_length=4, block_length=16)\n",
      " |      \n",
      " |      The `cycle_length` and `block_length` arguments control the order in which\n",
      " |      elements are produced. `cycle_length` controls the number of input elements\n",
      " |      that are processed concurrently. If you set `cycle_length` to 1, this\n",
      " |      transformation will handle one input element at a time, and will produce\n",
      " |      identical results to `tf.data.Dataset.flat_map`. In general,\n",
      " |      this transformation will apply `map_func` to `cycle_length` input elements,\n",
      " |      open iterators on the returned `Dataset` objects, and cycle through them\n",
      " |      producing `block_length` consecutive elements from each iterator, and\n",
      " |      consuming the next input element each time it reaches the end of an\n",
      " |      iterator.\n",
      " |      \n",
      " |      For example:\n",
      " |      \n",
      " |      >>> dataset = Dataset.range(1, 6)  # ==> [ 1, 2, 3, 4, 5 ]\n",
      " |      >>> # NOTE: New lines indicate \"block\" boundaries.\n",
      " |      >>> dataset = dataset.interleave(\n",
      " |      ...     lambda x: Dataset.from_tensors(x).repeat(6),\n",
      " |      ...     cycle_length=2, block_length=4)\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [1, 1, 1, 1,\n",
      " |       2, 2, 2, 2,\n",
      " |       1, 1,\n",
      " |       2, 2,\n",
      " |       3, 3, 3, 3,\n",
      " |       4, 4, 4, 4,\n",
      " |       3, 3,\n",
      " |       4, 4,\n",
      " |       5, 5, 5, 5,\n",
      " |       5, 5]\n",
      " |      \n",
      " |      Note: The order of elements yielded by this transformation is\n",
      " |      deterministic, as long as `map_func` is a pure function and\n",
      " |      `deterministic=True`. If `map_func` contains any stateful operations, the\n",
      " |      order in which that state is accessed is undefined.\n",
      " |      \n",
      " |      Performance can often be improved by setting `num_parallel_calls` so that\n",
      " |      `interleave` will use multiple threads to fetch elements. If determinism\n",
      " |      isn't required, it can also improve performance to set\n",
      " |      `deterministic=False`.\n",
      " |      \n",
      " |      >>> filenames = [\"/var/data/file1.txt\", \"/var/data/file2.txt\",\n",
      " |      ...              \"/var/data/file3.txt\", \"/var/data/file4.txt\"]\n",
      " |      >>> dataset = tf.data.Dataset.from_tensor_slices(filenames)\n",
      " |      >>> dataset = dataset.interleave(lambda x: tf.data.TFRecordDataset(x),\n",
      " |      ...     cycle_length=4, num_parallel_calls=tf.data.AUTOTUNE,\n",
      " |      ...     deterministic=False)\n",
      " |      \n",
      " |      Args:\n",
      " |        map_func: A function that takes a dataset element and returns a\n",
      " |          `tf.data.Dataset`.\n",
      " |        cycle_length: (Optional.) The number of input elements that will be\n",
      " |          processed concurrently. If not set, the tf.data runtime decides what it\n",
      " |          should be based on available CPU. If `num_parallel_calls` is set to\n",
      " |          `tf.data.AUTOTUNE`, the `cycle_length` argument identifies\n",
      " |          the maximum degree of parallelism.\n",
      " |        block_length: (Optional.) The number of consecutive elements to produce\n",
      " |          from each input element before cycling to another input element. If not\n",
      " |          set, defaults to 1.\n",
      " |        num_parallel_calls: (Optional.) If specified, the implementation creates a\n",
      " |          threadpool, which is used to fetch inputs from cycle elements\n",
      " |          asynchronously and in parallel. The default behavior is to fetch inputs\n",
      " |          from cycle elements synchronously with no parallelism. If the value\n",
      " |          `tf.data.AUTOTUNE` is used, then the number of parallel\n",
      " |          calls is set dynamically based on available CPU.\n",
      " |        deterministic: (Optional.) When `num_parallel_calls` is specified, if this\n",
      " |          boolean is specified (`True` or `False`), it controls the order in which\n",
      " |          the transformation produces elements. If set to `False`, the\n",
      " |          transformation is allowed to yield elements out of order to trade\n",
      " |          determinism for performance. If not specified, the\n",
      " |          `tf.data.Options.deterministic` option (`True` by default) controls the\n",
      " |          behavior.\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset`.\n",
      " |  \n",
      " |  map(self, map_func, num_parallel_calls=None, deterministic=None, name=None)\n",
      " |      Maps `map_func` across the elements of this dataset.\n",
      " |      \n",
      " |      This transformation applies `map_func` to each element of this dataset, and\n",
      " |      returns a new dataset containing the transformed elements, in the same\n",
      " |      order as they appeared in the input. `map_func` can be used to change both\n",
      " |      the values and the structure of a dataset's elements. Supported structure\n",
      " |      constructs are documented\n",
      " |      [here](https://www.tensorflow.org/guide/data#dataset_structure).\n",
      " |      \n",
      " |      For example, `map` can be used for adding 1 to each element, or projecting a\n",
      " |      subset of element components.\n",
      " |      \n",
      " |      >>> dataset = Dataset.range(1, 6)  # ==> [ 1, 2, 3, 4, 5 ]\n",
      " |      >>> dataset = dataset.map(lambda x: x + 1)\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [2, 3, 4, 5, 6]\n",
      " |      \n",
      " |      The input signature of `map_func` is determined by the structure of each\n",
      " |      element in this dataset.\n",
      " |      \n",
      " |      >>> dataset = Dataset.range(5)\n",
      " |      >>> # `map_func` takes a single argument of type `tf.Tensor` with the same\n",
      " |      >>> # shape and dtype.\n",
      " |      >>> result = dataset.map(lambda x: x + 1)\n",
      " |      \n",
      " |      >>> # Each element is a tuple containing two `tf.Tensor` objects.\n",
      " |      >>> elements = [(1, \"foo\"), (2, \"bar\"), (3, \"baz\")]\n",
      " |      >>> dataset = tf.data.Dataset.from_generator(\n",
      " |      ...     lambda: elements, (tf.int32, tf.string))\n",
      " |      >>> # `map_func` takes two arguments of type `tf.Tensor`. This function\n",
      " |      >>> # projects out just the first component.\n",
      " |      >>> result = dataset.map(lambda x_int, y_str: x_int)\n",
      " |      >>> list(result.as_numpy_iterator())\n",
      " |      [1, 2, 3]\n",
      " |      \n",
      " |      >>> # Each element is a dictionary mapping strings to `tf.Tensor` objects.\n",
      " |      >>> elements =  ([{\"a\": 1, \"b\": \"foo\"},\n",
      " |      ...               {\"a\": 2, \"b\": \"bar\"},\n",
      " |      ...               {\"a\": 3, \"b\": \"baz\"}])\n",
      " |      >>> dataset = tf.data.Dataset.from_generator(\n",
      " |      ...     lambda: elements, {\"a\": tf.int32, \"b\": tf.string})\n",
      " |      >>> # `map_func` takes a single argument of type `dict` with the same keys\n",
      " |      >>> # as the elements.\n",
      " |      >>> result = dataset.map(lambda d: str(d[\"a\"]) + d[\"b\"])\n",
      " |      \n",
      " |      The value or values returned by `map_func` determine the structure of each\n",
      " |      element in the returned dataset.\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.range(3)\n",
      " |      >>> # `map_func` returns two `tf.Tensor` objects.\n",
      " |      >>> def g(x):\n",
      " |      ...   return tf.constant(37.0), tf.constant([\"Foo\", \"Bar\", \"Baz\"])\n",
      " |      >>> result = dataset.map(g)\n",
      " |      >>> result.element_spec\n",
      " |      (TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(3,), dtype=tf.string, name=None))\n",
      " |      >>> # Python primitives, lists, and NumPy arrays are implicitly converted to\n",
      " |      >>> # `tf.Tensor`.\n",
      " |      >>> def h(x):\n",
      " |      ...   return 37.0, [\"Foo\", \"Bar\"], np.array([1.0, 2.0], dtype=np.float64)\n",
      " |      >>> result = dataset.map(h)\n",
      " |      >>> result.element_spec\n",
      " |      (TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(2,), dtype=tf.string, name=None), TensorSpec(shape=(2,), dtype=tf.float64, name=None))\n",
      " |      >>> # `map_func` can return nested structures.\n",
      " |      >>> def i(x):\n",
      " |      ...   return (37.0, [42, 16]), \"foo\"\n",
      " |      >>> result = dataset.map(i)\n",
      " |      >>> result.element_spec\n",
      " |      ((TensorSpec(shape=(), dtype=tf.float32, name=None),\n",
      " |        TensorSpec(shape=(2,), dtype=tf.int32, name=None)),\n",
      " |       TensorSpec(shape=(), dtype=tf.string, name=None))\n",
      " |      \n",
      " |      `map_func` can accept as arguments and return any type of dataset element.\n",
      " |      \n",
      " |      Note that irrespective of the context in which `map_func` is defined (eager\n",
      " |      vs. graph), tf.data traces the function and executes it as a graph. To use\n",
      " |      Python code inside of the function you have a few options:\n",
      " |      \n",
      " |      1) Rely on AutoGraph to convert Python code into an equivalent graph\n",
      " |      computation. The downside of this approach is that AutoGraph can convert\n",
      " |      some but not all Python code.\n",
      " |      \n",
      " |      2) Use `tf.py_function`, which allows you to write arbitrary Python code but\n",
      " |      will generally result in worse performance than 1). For example:\n",
      " |      \n",
      " |      >>> d = tf.data.Dataset.from_tensor_slices(['hello', 'world'])\n",
      " |      >>> # transform a string tensor to upper case string using a Python function\n",
      " |      >>> def upper_case_fn(t: tf.Tensor):\n",
      " |      ...   return t.numpy().decode('utf-8').upper()\n",
      " |      >>> d = d.map(lambda x: tf.py_function(func=upper_case_fn,\n",
      " |      ...           inp=[x], Tout=tf.string))\n",
      " |      >>> list(d.as_numpy_iterator())\n",
      " |      [b'HELLO', b'WORLD']\n",
      " |      \n",
      " |      3) Use `tf.numpy_function`, which also allows you to write arbitrary\n",
      " |      Python code. Note that `tf.py_function` accepts `tf.Tensor` whereas\n",
      " |      `tf.numpy_function` accepts numpy arrays and returns only numpy arrays.\n",
      " |      For example:\n",
      " |      \n",
      " |      >>> d = tf.data.Dataset.from_tensor_slices(['hello', 'world'])\n",
      " |      >>> def upper_case_fn(t: np.ndarray):\n",
      " |      ...   return t.decode('utf-8').upper()\n",
      " |      >>> d = d.map(lambda x: tf.numpy_function(func=upper_case_fn,\n",
      " |      ...           inp=[x], Tout=tf.string))\n",
      " |      >>> list(d.as_numpy_iterator())\n",
      " |      [b'HELLO', b'WORLD']\n",
      " |      \n",
      " |      Note that the use of `tf.numpy_function` and `tf.py_function`\n",
      " |      in general precludes the possibility of executing user-defined\n",
      " |      transformations in parallel (because of Python GIL).\n",
      " |      \n",
      " |      Performance can often be improved by setting `num_parallel_calls` so that\n",
      " |      `map` will use multiple threads to process elements. If deterministic order\n",
      " |      isn't required, it can also improve performance to set\n",
      " |      `deterministic=False`.\n",
      " |      \n",
      " |      >>> dataset = Dataset.range(1, 6)  # ==> [ 1, 2, 3, 4, 5 ]\n",
      " |      >>> dataset = dataset.map(lambda x: x + 1,\n",
      " |      ...     num_parallel_calls=tf.data.AUTOTUNE,\n",
      " |      ...     deterministic=False)\n",
      " |      \n",
      " |      The order of elements yielded by this transformation is deterministic if\n",
      " |      `deterministic=True`. If `map_func` contains stateful operations and\n",
      " |      `num_parallel_calls > 1`, the order in which that state is accessed is\n",
      " |      undefined, so the values of output elements may not be deterministic\n",
      " |      regardless of the `deterministic` flag value.\n",
      " |      \n",
      " |      Args:\n",
      " |        map_func: A function mapping a dataset element to another dataset element.\n",
      " |        num_parallel_calls: (Optional.) A `tf.int64` scalar `tf.Tensor`,\n",
      " |          representing the number elements to process asynchronously in parallel.\n",
      " |          If not specified, elements will be processed sequentially. If the value\n",
      " |          `tf.data.AUTOTUNE` is used, then the number of parallel\n",
      " |          calls is set dynamically based on available CPU.\n",
      " |        deterministic: (Optional.) When `num_parallel_calls` is specified, if this\n",
      " |          boolean is specified (`True` or `False`), it controls the order in which\n",
      " |          the transformation produces elements. If set to `False`, the\n",
      " |          transformation is allowed to yield elements out of order to trade\n",
      " |          determinism for performance. If not specified, the\n",
      " |          `tf.data.Options.deterministic` option (`True` by default) controls the\n",
      " |          behavior.\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset`.\n",
      " |  \n",
      " |  options(self)\n",
      " |      Returns the options for this dataset and its inputs.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `tf.data.Options` object representing the dataset options.\n",
      " |  \n",
      " |  padded_batch(self, batch_size, padded_shapes=None, padding_values=None, drop_remainder=False, name=None)\n",
      " |      Combines consecutive elements of this dataset into padded batches.\n",
      " |      \n",
      " |      This transformation combines multiple consecutive elements of the input\n",
      " |      dataset into a single element.\n",
      " |      \n",
      " |      Like `tf.data.Dataset.batch`, the components of the resulting element will\n",
      " |      have an additional outer dimension, which will be `batch_size` (or\n",
      " |      `N % batch_size` for the last element if `batch_size` does not divide the\n",
      " |      number of input elements `N` evenly and `drop_remainder` is `False`). If\n",
      " |      your program depends on the batches having the same outer dimension, you\n",
      " |      should set the `drop_remainder` argument to `True` to prevent the smaller\n",
      " |      batch from being produced.\n",
      " |      \n",
      " |      Unlike `tf.data.Dataset.batch`, the input elements to be batched may have\n",
      " |      different shapes, and this transformation will pad each component to the\n",
      " |      respective shape in `padded_shapes`. The `padded_shapes` argument\n",
      " |      determines the resulting shape for each dimension of each component in an\n",
      " |      output element:\n",
      " |      \n",
      " |      * If the dimension is a constant, the component will be padded out to that\n",
      " |        length in that dimension.\n",
      " |      * If the dimension is unknown, the component will be padded out to the\n",
      " |        maximum length of all elements in that dimension.\n",
      " |      \n",
      " |      >>> A = (tf.data.Dataset\n",
      " |      ...      .range(1, 5, output_type=tf.int32)\n",
      " |      ...      .map(lambda x: tf.fill([x], x)))\n",
      " |      >>> # Pad to the smallest per-batch size that fits all elements.\n",
      " |      >>> B = A.padded_batch(2)\n",
      " |      >>> for element in B.as_numpy_iterator():\n",
      " |      ...   print(element)\n",
      " |      [[1 0]\n",
      " |       [2 2]]\n",
      " |      [[3 3 3 0]\n",
      " |       [4 4 4 4]]\n",
      " |      >>> # Pad to a fixed size.\n",
      " |      >>> C = A.padded_batch(2, padded_shapes=5)\n",
      " |      >>> for element in C.as_numpy_iterator():\n",
      " |      ...   print(element)\n",
      " |      [[1 0 0 0 0]\n",
      " |       [2 2 0 0 0]]\n",
      " |      [[3 3 3 0 0]\n",
      " |       [4 4 4 4 0]]\n",
      " |      >>> # Pad with a custom value.\n",
      " |      >>> D = A.padded_batch(2, padded_shapes=5, padding_values=-1)\n",
      " |      >>> for element in D.as_numpy_iterator():\n",
      " |      ...   print(element)\n",
      " |      [[ 1 -1 -1 -1 -1]\n",
      " |       [ 2  2 -1 -1 -1]]\n",
      " |      [[ 3  3  3 -1 -1]\n",
      " |       [ 4  4  4  4 -1]]\n",
      " |      >>> # Components of nested elements can be padded independently.\n",
      " |      >>> elements = [([1, 2, 3], [10]),\n",
      " |      ...             ([4, 5], [11, 12])]\n",
      " |      >>> dataset = tf.data.Dataset.from_generator(\n",
      " |      ...     lambda: iter(elements), (tf.int32, tf.int32))\n",
      " |      >>> # Pad the first component of the tuple to length 4, and the second\n",
      " |      >>> # component to the smallest size that fits.\n",
      " |      >>> dataset = dataset.padded_batch(2,\n",
      " |      ...     padded_shapes=([4], [None]),\n",
      " |      ...     padding_values=(-1, 100))\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [(array([[ 1,  2,  3, -1], [ 4,  5, -1, -1]], dtype=int32),\n",
      " |        array([[ 10, 100], [ 11,  12]], dtype=int32))]\n",
      " |      >>> # Pad with a single value and multiple components.\n",
      " |      >>> E = tf.data.Dataset.zip((A, A)).padded_batch(2, padding_values=-1)\n",
      " |      >>> for element in E.as_numpy_iterator():\n",
      " |      ...   print(element)\n",
      " |      (array([[ 1, -1],\n",
      " |             [ 2,  2]], dtype=int32), array([[ 1, -1],\n",
      " |             [ 2,  2]], dtype=int32))\n",
      " |      (array([[ 3,  3,  3, -1],\n",
      " |             [ 4,  4,  4,  4]], dtype=int32), array([[ 3,  3,  3, -1],\n",
      " |             [ 4,  4,  4,  4]], dtype=int32))\n",
      " |      \n",
      " |      See also `tf.data.experimental.dense_to_sparse_batch`, which combines\n",
      " |      elements that may have different shapes into a `tf.sparse.SparseTensor`.\n",
      " |      \n",
      " |      Args:\n",
      " |        batch_size: A `tf.int64` scalar `tf.Tensor`, representing the number of\n",
      " |          consecutive elements of this dataset to combine in a single batch.\n",
      " |        padded_shapes: (Optional.) A (nested) structure of `tf.TensorShape` or\n",
      " |          `tf.int64` vector tensor-like objects representing the shape to which\n",
      " |          the respective component of each input element should be padded prior\n",
      " |          to batching. Any unknown dimensions will be padded to the maximum size\n",
      " |          of that dimension in each batch. If unset, all dimensions of all\n",
      " |          components are padded to the maximum size in the batch. `padded_shapes`\n",
      " |          must be set if any component has an unknown rank.\n",
      " |        padding_values: (Optional.) A (nested) structure of scalar-shaped\n",
      " |          `tf.Tensor`, representing the padding values to use for the respective\n",
      " |          components. None represents that the (nested) structure should be padded\n",
      " |          with default values.  Defaults are `0` for numeric types and the empty\n",
      " |          string for string types. The `padding_values` should have the same\n",
      " |          (nested) structure as the input dataset. If `padding_values` is a single\n",
      " |          element and the input dataset has multiple components, then the same\n",
      " |          `padding_values` will be used to pad every component of the dataset.\n",
      " |          If `padding_values` is a scalar, then its value will be broadcasted\n",
      " |          to match the shape of each component.\n",
      " |        drop_remainder: (Optional.) A `tf.bool` scalar `tf.Tensor`, representing\n",
      " |          whether the last batch should be dropped in the case it has fewer than\n",
      " |          `batch_size` elements; the default behavior is not to drop the smaller\n",
      " |          batch.\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset`.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: If a component has an unknown rank, and the `padded_shapes`\n",
      " |          argument is not set.\n",
      " |        TypeError: If a component is of an unsupported type. The list of supported\n",
      " |          types is documented in\n",
      " |          https://www.tensorflow.org/guide/data#dataset_structure.\n",
      " |  \n",
      " |  prefetch(self, buffer_size, name=None)\n",
      " |      Creates a `Dataset` that prefetches elements from this dataset.\n",
      " |      \n",
      " |      Most dataset input pipelines should end with a call to `prefetch`. This\n",
      " |      allows later elements to be prepared while the current element is being\n",
      " |      processed. This often improves latency and throughput, at the cost of\n",
      " |      using additional memory to store prefetched elements.\n",
      " |      \n",
      " |      Note: Like other `Dataset` methods, prefetch operates on the\n",
      " |      elements of the input dataset. It has no concept of examples vs. batches.\n",
      " |      `examples.prefetch(2)` will prefetch two elements (2 examples),\n",
      " |      while `examples.batch(20).prefetch(2)` will prefetch 2 elements\n",
      " |      (2 batches, of 20 examples each).\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.range(3)\n",
      " |      >>> dataset = dataset.prefetch(2)\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [0, 1, 2]\n",
      " |      \n",
      " |      Args:\n",
      " |        buffer_size: A `tf.int64` scalar `tf.Tensor`, representing the maximum\n",
      " |          number of elements that will be buffered when prefetching. If the value\n",
      " |          `tf.data.AUTOTUNE` is used, then the buffer size is dynamically tuned.\n",
      " |        name: Optional. A name for the tf.data transformation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset`.\n",
      " |  \n",
      " |  reduce(self, initial_state, reduce_func, name=None)\n",
      " |      Reduces the input dataset to a single element.\n",
      " |      \n",
      " |      The transformation calls `reduce_func` successively on every element of\n",
      " |      the input dataset until the dataset is exhausted, aggregating information in\n",
      " |      its internal state. The `initial_state` argument is used for the initial\n",
      " |      state and the final state is returned as the result.\n",
      " |      \n",
      " |      >>> tf.data.Dataset.range(5).reduce(np.int64(0), lambda x, _: x + 1).numpy()\n",
      " |      5\n",
      " |      >>> tf.data.Dataset.range(5).reduce(np.int64(0), lambda x, y: x + y).numpy()\n",
      " |      10\n",
      " |      \n",
      " |      Args:\n",
      " |        initial_state: An element representing the initial state of the\n",
      " |          transformation.\n",
      " |        reduce_func: A function that maps `(old_state, input_element)` to\n",
      " |          `new_state`. It must take two arguments and return a new element\n",
      " |          The structure of `new_state` must match the structure of\n",
      " |          `initial_state`.\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A dataset element corresponding to the final state of the transformation.\n",
      " |  \n",
      " |  rejection_resample(self, class_func, target_dist, initial_dist=None, seed=None, name=None)\n",
      " |      A transformation that resamples a dataset to a target distribution.\n",
      " |      \n",
      " |      Lets consider the following example where a dataset with an initial data\n",
      " |      distribution of `init_dist` needs to be resampled into a dataset with\n",
      " |      `target_dist` distribution.\n",
      " |      \n",
      " |      >>> import collections\n",
      " |      >>> initial_dist = [0.5, 0.5]\n",
      " |      >>> target_dist = [0.6, 0.4]\n",
      " |      >>> num_classes = len(initial_dist)\n",
      " |      >>> num_samples = 100000\n",
      " |      >>> data_np = np.random.choice(num_classes, num_samples, p=initial_dist)\n",
      " |      >>> dataset = tf.data.Dataset.from_tensor_slices(data_np)\n",
      " |      >>> x = collections.defaultdict(int)\n",
      " |      >>> for i in dataset:\n",
      " |      ...   x[i.numpy()] += 1\n",
      " |      \n",
      " |      The value of `x` will be close to `{0: 50000, 1: 50000}` as per the\n",
      " |      `initial_dist` distribution.\n",
      " |      \n",
      " |      >>> dataset = dataset.rejection_resample(\n",
      " |      ...    class_func=lambda x: x % 2,\n",
      " |      ...    target_dist=target_dist,\n",
      " |      ...    initial_dist=initial_dist)\n",
      " |      \n",
      " |      >>> y = collections.defaultdict(int)\n",
      " |      >>> for i in dataset:\n",
      " |      ...   cls, _ = i\n",
      " |      ...   y[cls.numpy()] += 1\n",
      " |      \n",
      " |      The value of `y` will be now be close to `{0: 75000, 1: 50000}` thus\n",
      " |      satisfying the `target_dist` distribution.\n",
      " |      \n",
      " |      Args:\n",
      " |        class_func: A function mapping an element of the input dataset to a scalar\n",
      " |          `tf.int32` tensor. Values should be in `[0, num_classes)`.\n",
      " |        target_dist: A floating point type tensor, shaped `[num_classes]`.\n",
      " |        initial_dist: (Optional.)  A floating point type tensor, shaped\n",
      " |          `[num_classes]`.  If not provided, the true class distribution is\n",
      " |          estimated live in a streaming fashion.\n",
      " |        seed: (Optional.) Python integer seed for the resampler.\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `Dataset`\n",
      " |  \n",
      " |  repeat(self, count=None, name=None)\n",
      " |      Repeats this dataset so each original value is seen `count` times.\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
      " |      >>> dataset = dataset.repeat(3)\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [1, 2, 3, 1, 2, 3, 1, 2, 3]\n",
      " |      \n",
      " |      Note: If this dataset is a function of global state (e.g. a random number\n",
      " |      generator), then different repetitions may produce different elements.\n",
      " |      \n",
      " |      Args:\n",
      " |        count: (Optional.) A `tf.int64` scalar `tf.Tensor`, representing the\n",
      " |          number of times the dataset should be repeated. The default behavior (if\n",
      " |          `count` is `None` or `-1`) is for the dataset be repeated indefinitely.\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset`.\n",
      " |  \n",
      " |  scan(self, initial_state, scan_func, name=None)\n",
      " |      A transformation that scans a function across an input dataset.\n",
      " |      \n",
      " |      This transformation is a stateful relative of `tf.data.Dataset.map`.\n",
      " |      In addition to mapping `scan_func` across the elements of the input dataset,\n",
      " |      `scan()` accumulates one or more state tensors, whose initial values are\n",
      " |      `initial_state`.\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.range(10)\n",
      " |      >>> initial_state = tf.constant(0, dtype=tf.int64)\n",
      " |      >>> scan_func = lambda state, i: (state + i, state + i)\n",
      " |      >>> dataset = dataset.scan(initial_state=initial_state, scan_func=scan_func)\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [0, 1, 3, 6, 10, 15, 21, 28, 36, 45]\n",
      " |      \n",
      " |      Args:\n",
      " |        initial_state: A nested structure of tensors, representing the initial\n",
      " |          state of the accumulator.\n",
      " |        scan_func: A function that maps `(old_state, input_element)` to\n",
      " |          `(new_state, output_element)`. It must take two arguments and return a\n",
      " |          pair of nested structures of tensors. The `new_state` must match the\n",
      " |          structure of `initial_state`.\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `Dataset`.\n",
      " |  \n",
      " |  shard(self, num_shards, index, name=None)\n",
      " |      Creates a `Dataset` that includes only 1/`num_shards` of this dataset.\n",
      " |      \n",
      " |      `shard` is deterministic. The Dataset produced by `A.shard(n, i)` will\n",
      " |      contain all elements of A whose index mod n = i.\n",
      " |      \n",
      " |      >>> A = tf.data.Dataset.range(10)\n",
      " |      >>> B = A.shard(num_shards=3, index=0)\n",
      " |      >>> list(B.as_numpy_iterator())\n",
      " |      [0, 3, 6, 9]\n",
      " |      >>> C = A.shard(num_shards=3, index=1)\n",
      " |      >>> list(C.as_numpy_iterator())\n",
      " |      [1, 4, 7]\n",
      " |      >>> D = A.shard(num_shards=3, index=2)\n",
      " |      >>> list(D.as_numpy_iterator())\n",
      " |      [2, 5, 8]\n",
      " |      \n",
      " |      This dataset operator is very useful when running distributed training, as\n",
      " |      it allows each worker to read a unique subset.\n",
      " |      \n",
      " |      When reading a single input file, you can shard elements as follows:\n",
      " |      \n",
      " |      ```python\n",
      " |      d = tf.data.TFRecordDataset(input_file)\n",
      " |      d = d.shard(num_workers, worker_index)\n",
      " |      d = d.repeat(num_epochs)\n",
      " |      d = d.shuffle(shuffle_buffer_size)\n",
      " |      d = d.map(parser_fn, num_parallel_calls=num_map_threads)\n",
      " |      ```\n",
      " |      \n",
      " |      Important caveats:\n",
      " |      \n",
      " |      - Be sure to shard before you use any randomizing operator (such as\n",
      " |        shuffle).\n",
      " |      - Generally it is best if the shard operator is used early in the dataset\n",
      " |        pipeline. For example, when reading from a set of TFRecord files, shard\n",
      " |        before converting the dataset to input samples. This avoids reading every\n",
      " |        file on every worker. The following is an example of an efficient\n",
      " |        sharding strategy within a complete pipeline:\n",
      " |      \n",
      " |      ```python\n",
      " |      d = Dataset.list_files(pattern)\n",
      " |      d = d.shard(num_workers, worker_index)\n",
      " |      d = d.repeat(num_epochs)\n",
      " |      d = d.shuffle(shuffle_buffer_size)\n",
      " |      d = d.interleave(tf.data.TFRecordDataset,\n",
      " |                       cycle_length=num_readers, block_length=1)\n",
      " |      d = d.map(parser_fn, num_parallel_calls=num_map_threads)\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        num_shards: A `tf.int64` scalar `tf.Tensor`, representing the number of\n",
      " |          shards operating in parallel.\n",
      " |        index: A `tf.int64` scalar `tf.Tensor`, representing the worker index.\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset`.\n",
      " |      \n",
      " |      Raises:\n",
      " |        InvalidArgumentError: if `num_shards` or `index` are illegal values.\n",
      " |      \n",
      " |          Note: error checking is done on a best-effort basis, and errors aren't\n",
      " |          guaranteed to be caught upon dataset creation. (e.g. providing in a\n",
      " |          placeholder tensor bypasses the early checking, and will instead result\n",
      " |          in an error during a session.run call.)\n",
      " |  \n",
      " |  shuffle(self, buffer_size, seed=None, reshuffle_each_iteration=None, name=None)\n",
      " |      Randomly shuffles the elements of this dataset.\n",
      " |      \n",
      " |      This dataset fills a buffer with `buffer_size` elements, then randomly\n",
      " |      samples elements from this buffer, replacing the selected elements with new\n",
      " |      elements. For perfect shuffling, a buffer size greater than or equal to the\n",
      " |      full size of the dataset is required.\n",
      " |      \n",
      " |      For instance, if your dataset contains 10,000 elements but `buffer_size` is\n",
      " |      set to 1,000, then `shuffle` will initially select a random element from\n",
      " |      only the first 1,000 elements in the buffer. Once an element is selected,\n",
      " |      its space in the buffer is replaced by the next (i.e. 1,001-st) element,\n",
      " |      maintaining the 1,000 element buffer.\n",
      " |      \n",
      " |      `reshuffle_each_iteration` controls whether the shuffle order should be\n",
      " |      different for each epoch. In TF 1.X, the idiomatic way to create epochs\n",
      " |      was through the `repeat` transformation:\n",
      " |      \n",
      " |      ```python\n",
      " |      dataset = tf.data.Dataset.range(3)\n",
      " |      dataset = dataset.shuffle(3, reshuffle_each_iteration=True)\n",
      " |      dataset = dataset.repeat(2)\n",
      " |      # [1, 0, 2, 1, 2, 0]\n",
      " |      \n",
      " |      dataset = tf.data.Dataset.range(3)\n",
      " |      dataset = dataset.shuffle(3, reshuffle_each_iteration=False)\n",
      " |      dataset = dataset.repeat(2)\n",
      " |      # [1, 0, 2, 1, 0, 2]\n",
      " |      ```\n",
      " |      \n",
      " |      In TF 2.0, `tf.data.Dataset` objects are Python iterables which makes it\n",
      " |      possible to also create epochs through Python iteration:\n",
      " |      \n",
      " |      ```python\n",
      " |      dataset = tf.data.Dataset.range(3)\n",
      " |      dataset = dataset.shuffle(3, reshuffle_each_iteration=True)\n",
      " |      list(dataset.as_numpy_iterator())\n",
      " |      # [1, 0, 2]\n",
      " |      list(dataset.as_numpy_iterator())\n",
      " |      # [1, 2, 0]\n",
      " |      ```\n",
      " |      \n",
      " |      ```python\n",
      " |      dataset = tf.data.Dataset.range(3)\n",
      " |      dataset = dataset.shuffle(3, reshuffle_each_iteration=False)\n",
      " |      list(dataset.as_numpy_iterator())\n",
      " |      # [1, 0, 2]\n",
      " |      list(dataset.as_numpy_iterator())\n",
      " |      # [1, 0, 2]\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        buffer_size: A `tf.int64` scalar `tf.Tensor`, representing the number of\n",
      " |          elements from this dataset from which the new dataset will sample.\n",
      " |        seed: (Optional.) A `tf.int64` scalar `tf.Tensor`, representing the random\n",
      " |          seed that will be used to create the distribution. See\n",
      " |          `tf.random.set_seed` for behavior.\n",
      " |        reshuffle_each_iteration: (Optional.) A boolean, which if true indicates\n",
      " |          that the dataset should be pseudorandomly reshuffled each time it is\n",
      " |          iterated over. (Defaults to `True`.)\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset`.\n",
      " |  \n",
      " |  skip(self, count, name=None)\n",
      " |      Creates a `Dataset` that skips `count` elements from this dataset.\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.range(10)\n",
      " |      >>> dataset = dataset.skip(7)\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [7, 8, 9]\n",
      " |      \n",
      " |      Args:\n",
      " |        count: A `tf.int64` scalar `tf.Tensor`, representing the number of\n",
      " |          elements of this dataset that should be skipped to form the new dataset.\n",
      " |          If `count` is greater than the size of this dataset, the new dataset\n",
      " |          will contain no elements.  If `count` is -1, skips the entire dataset.\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset`.\n",
      " |  \n",
      " |  snapshot(self, path, compression='AUTO', reader_func=None, shard_func=None, name=None)\n",
      " |      API to persist the output of the input dataset.\n",
      " |      \n",
      " |      The snapshot API allows users to transparently persist the output of their\n",
      " |      preprocessing pipeline to disk, and materialize the pre-processed data on a\n",
      " |      different training run.\n",
      " |      \n",
      " |      This API enables repeated preprocessing steps to be consolidated, and allows\n",
      " |      re-use of already processed data, trading off disk storage and network\n",
      " |      bandwidth for freeing up more valuable CPU resources and accelerator compute\n",
      " |      time.\n",
      " |      \n",
      " |      https://github.com/tensorflow/community/blob/master/rfcs/20200107-tf-data-snapshot.md\n",
      " |      has detailed design documentation of this feature.\n",
      " |      \n",
      " |      Users can specify various options to control the behavior of snapshot,\n",
      " |      including how snapshots are read from and written to by passing in\n",
      " |      user-defined functions to the `reader_func` and `shard_func` parameters.\n",
      " |      \n",
      " |      `shard_func` is a user specified function that maps input elements to\n",
      " |      snapshot shards.\n",
      " |      \n",
      " |      Users may want to specify this function to control how snapshot files should\n",
      " |      be written to disk. Below is an example of how a potential `shard_func`\n",
      " |      could be written.\n",
      " |      \n",
      " |      ```python\n",
      " |      dataset = ...\n",
      " |      dataset = dataset.enumerate()\n",
      " |      dataset = dataset.snapshot(\"/path/to/snapshot/dir\",\n",
      " |          shard_func=lambda x, y: x % NUM_SHARDS, ...)\n",
      " |      dataset = dataset.map(lambda x, y: y)\n",
      " |      ```\n",
      " |      \n",
      " |      `reader_func` is a user specified function that accepts a single argument:\n",
      " |      (1) a Dataset of Datasets, each representing a \"split\" of elements of the\n",
      " |      original dataset. The cardinality of the input dataset matches the\n",
      " |      number of the shards specified in the `shard_func` (see above). The function\n",
      " |      should return a Dataset of elements of the original dataset.\n",
      " |      \n",
      " |      Users may want specify this function to control how snapshot files should be\n",
      " |      read from disk, including the amount of shuffling and parallelism.\n",
      " |      \n",
      " |      Here is an example of a standard reader function a user can define. This\n",
      " |      function enables both dataset shuffling and parallel reading of datasets:\n",
      " |      \n",
      " |      ```python\n",
      " |      def user_reader_func(datasets):\n",
      " |        # shuffle the datasets splits\n",
      " |        datasets = datasets.shuffle(NUM_CORES)\n",
      " |        # read datasets in parallel and interleave their elements\n",
      " |        return datasets.interleave(lambda x: x, num_parallel_calls=AUTOTUNE)\n",
      " |      \n",
      " |      dataset = dataset.snapshot(\"/path/to/snapshot/dir\",\n",
      " |          reader_func=user_reader_func)\n",
      " |      ```\n",
      " |      \n",
      " |      By default, snapshot parallelizes reads by the number of cores available on\n",
      " |      the system, but will not attempt to shuffle the data.\n",
      " |      \n",
      " |      Args:\n",
      " |        path: Required. A directory to use for storing / loading the snapshot to /\n",
      " |          from.\n",
      " |        compression: Optional. The type of compression to apply to the snapshot\n",
      " |          written to disk. Supported options are `GZIP`, `SNAPPY`, `AUTO` or None.\n",
      " |          Defaults to `AUTO`, which attempts to pick an appropriate compression\n",
      " |          algorithm for the dataset.\n",
      " |        reader_func: Optional. A function to control how to read data from\n",
      " |          snapshot shards.\n",
      " |        shard_func: Optional. A function to control how to shard data when writing\n",
      " |          a snapshot.\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `Dataset`.\n",
      " |  \n",
      " |  take(self, count, name=None)\n",
      " |      Creates a `Dataset` with at most `count` elements from this dataset.\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.range(10)\n",
      " |      >>> dataset = dataset.take(3)\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [0, 1, 2]\n",
      " |      \n",
      " |      Args:\n",
      " |        count: A `tf.int64` scalar `tf.Tensor`, representing the number of\n",
      " |          elements of this dataset that should be taken to form the new dataset.\n",
      " |          If `count` is -1, or if `count` is greater than the size of this\n",
      " |          dataset, the new dataset will contain all elements of this dataset.\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset`.\n",
      " |  \n",
      " |  take_while(self, predicate, name=None)\n",
      " |      A transformation that stops dataset iteration based on a `predicate`.\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.range(10)\n",
      " |      >>> dataset = dataset.take_while(lambda x: x < 5)\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [0, 1, 2, 3, 4]\n",
      " |      \n",
      " |      Args:\n",
      " |        predicate: A function that maps a nested structure of tensors (having\n",
      " |          shapes and types defined by `self.output_shapes` and\n",
      " |          `self.output_types`) to a scalar `tf.bool` tensor.\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `Dataset`.\n",
      " |  \n",
      " |  unbatch(self, name=None)\n",
      " |      Splits elements of a dataset into multiple elements.\n",
      " |      \n",
      " |      For example, if elements of the dataset are shaped `[B, a0, a1, ...]`,\n",
      " |      where `B` may vary for each input element, then for each element in the\n",
      " |      dataset, the unbatched dataset will contain `B` consecutive elements\n",
      " |      of shape `[a0, a1, ...]`.\n",
      " |      \n",
      " |      >>> elements = [ [1, 2, 3], [1, 2], [1, 2, 3, 4] ]\n",
      " |      >>> dataset = tf.data.Dataset.from_generator(lambda: elements, tf.int64)\n",
      " |      >>> dataset = dataset.unbatch()\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [1, 2, 3, 1, 2, 1, 2, 3, 4]\n",
      " |      \n",
      " |      Note: `unbatch` requires a data copy to slice up the batched tensor into\n",
      " |      smaller, unbatched tensors. When optimizing performance, try to avoid\n",
      " |      unnecessary usage of `unbatch`.\n",
      " |      \n",
      " |      Args:\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `Dataset`.\n",
      " |  \n",
      " |  unique(self, name=None)\n",
      " |      A transformation that discards duplicate elements of a `Dataset`.\n",
      " |      \n",
      " |      Use this transformation to produce a dataset that contains one instance of\n",
      " |      each unique element in the input. For example:\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.from_tensor_slices([1, 37, 2, 37, 2, 1])\n",
      " |      >>> dataset = dataset.unique()\n",
      " |      >>> sorted(list(dataset.as_numpy_iterator()))\n",
      " |      [1, 2, 37]\n",
      " |      \n",
      " |      Note: This transformation only supports datasets which fit into memory\n",
      " |      and have elements of either `tf.int32`, `tf.int64` or `tf.string` type.\n",
      " |      \n",
      " |      Args:\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `Dataset`.\n",
      " |  \n",
      " |  window(self, size, shift=None, stride=1, drop_remainder=False, name=None)\n",
      " |      Returns a dataset of \"windows\".\n",
      " |      \n",
      " |      Each \"window\" is a dataset that contains a subset of elements of the\n",
      " |      input dataset. These are finite datasets of size `size` (or possibly fewer\n",
      " |      if there are not enough input elements to fill the window and\n",
      " |      `drop_remainder` evaluates to `False`).\n",
      " |      \n",
      " |      For example:\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.range(7).window(3)\n",
      " |      >>> for window in dataset:\n",
      " |      ...   print(window)\n",
      " |      <...Dataset element_spec=TensorSpec(shape=(), dtype=tf.int64, name=None)>\n",
      " |      <...Dataset element_spec=TensorSpec(shape=(), dtype=tf.int64, name=None)>\n",
      " |      <...Dataset element_spec=TensorSpec(shape=(), dtype=tf.int64, name=None)>\n",
      " |      \n",
      " |      Since windows are datasets, they can be iterated over:\n",
      " |      \n",
      " |      >>> for window in dataset:\n",
      " |      ...   print([item.numpy() for item in window])\n",
      " |      [0, 1, 2]\n",
      " |      [3, 4, 5]\n",
      " |      [6]\n",
      " |      \n",
      " |      #### Shift\n",
      " |      \n",
      " |      The `shift` argument determines the number of input elements to shift\n",
      " |      between the start of each window. If windows and elements are both numbered\n",
      " |      starting at 0, the first element in window `k` will be element `k * shift`\n",
      " |      of the input dataset. In particular, the first element of the first window\n",
      " |      will always be the first element of the input dataset.\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.range(7).window(3, shift=1,\n",
      " |      ...                                           drop_remainder=True)\n",
      " |      >>> for window in dataset:\n",
      " |      ...   print(list(window.as_numpy_iterator()))\n",
      " |      [0, 1, 2]\n",
      " |      [1, 2, 3]\n",
      " |      [2, 3, 4]\n",
      " |      [3, 4, 5]\n",
      " |      [4, 5, 6]\n",
      " |      \n",
      " |      #### Stride\n",
      " |      \n",
      " |      The `stride` argument determines the stride between input elements within a\n",
      " |      window.\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.range(7).window(3, shift=1, stride=2,\n",
      " |      ...                                           drop_remainder=True)\n",
      " |      >>> for window in dataset:\n",
      " |      ...   print(list(window.as_numpy_iterator()))\n",
      " |      [0, 2, 4]\n",
      " |      [1, 3, 5]\n",
      " |      [2, 4, 6]\n",
      " |      \n",
      " |      #### Nested elements\n",
      " |      \n",
      " |      When the `window` transformation is applied to a dataset whos elements are\n",
      " |      nested structures, it produces a dataset where the elements have the same\n",
      " |      nested structure but each leaf is replaced by a window. In other words,\n",
      " |      the nesting is applied outside of the windows as opposed inside of them.\n",
      " |      \n",
      " |      The type signature is:\n",
      " |      \n",
      " |      ```\n",
      " |      def window(\n",
      " |          self: Dataset[Nest[T]], ...\n",
      " |      ) -> Dataset[Nest[Dataset[T]]]\n",
      " |      ```\n",
      " |      \n",
      " |      Applying `window` to a `Dataset` of tuples gives a tuple of windows:\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.from_tensor_slices(([1, 2, 3, 4, 5],\n",
      " |      ...                                               [6, 7, 8, 9, 10]))\n",
      " |      >>> dataset = dataset.window(2)\n",
      " |      >>> windows = next(iter(dataset))\n",
      " |      >>> windows\n",
      " |      (<...Dataset element_spec=TensorSpec(shape=(), dtype=tf.int32, name=None)>,\n",
      " |       <...Dataset element_spec=TensorSpec(shape=(), dtype=tf.int32, name=None)>)\n",
      " |      \n",
      " |      >>> def to_numpy(ds):\n",
      " |      ...   return list(ds.as_numpy_iterator())\n",
      " |      >>>\n",
      " |      >>> for windows in dataset:\n",
      " |      ...   print(to_numpy(windows[0]), to_numpy(windows[1]))\n",
      " |      [1, 2] [6, 7]\n",
      " |      [3, 4] [8, 9]\n",
      " |      [5] [10]\n",
      " |      \n",
      " |      Applying `window` to a `Dataset` of dictionaries gives a dictionary of\n",
      " |      `Datasets`:\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.from_tensor_slices({'a': [1, 2, 3],\n",
      " |      ...                                               'b': [4, 5, 6],\n",
      " |      ...                                               'c': [7, 8, 9]})\n",
      " |      >>> dataset = dataset.window(2)\n",
      " |      >>> def to_numpy(ds):\n",
      " |      ...   return list(ds.as_numpy_iterator())\n",
      " |      >>>\n",
      " |      >>> for windows in dataset:\n",
      " |      ...   print(tf.nest.map_structure(to_numpy, windows))\n",
      " |      {'a': [1, 2], 'b': [4, 5], 'c': [7, 8]}\n",
      " |      {'a': [3], 'b': [6], 'c': [9]}\n",
      " |      \n",
      " |      #### Flatten a dataset of windows\n",
      " |      \n",
      " |      The `Dataset.flat_map` and `Dataset.interleave` methods can be used to\n",
      " |      flatten a dataset of windows into a single dataset.\n",
      " |      \n",
      " |      The argument to `flat_map` is a function that takes an element from the\n",
      " |      dataset and returns a `Dataset`. `flat_map` chains together the resulting\n",
      " |      datasets sequentially.\n",
      " |      \n",
      " |      For example, to turn each window into a dense tensor:\n",
      " |      \n",
      " |      >>> size = 3\n",
      " |      >>> dataset = tf.data.Dataset.range(7).window(size, shift=1,\n",
      " |      ...                                           drop_remainder=True)\n",
      " |      >>> batched = dataset.flat_map(lambda x:x.batch(3))\n",
      " |      >>> for batch in batched:\n",
      " |      ...   print(batch.numpy())\n",
      " |      [0 1 2]\n",
      " |      [1 2 3]\n",
      " |      [2 3 4]\n",
      " |      [3 4 5]\n",
      " |      [4 5 6]\n",
      " |      \n",
      " |      Args:\n",
      " |        size: A `tf.int64` scalar `tf.Tensor`, representing the number of elements\n",
      " |          of the input dataset to combine into a window. Must be positive.\n",
      " |        shift: (Optional.) A `tf.int64` scalar `tf.Tensor`, representing the\n",
      " |          number of input elements by which the window moves in each iteration.\n",
      " |          Defaults to `size`. Must be positive.\n",
      " |        stride: (Optional.) A `tf.int64` scalar `tf.Tensor`, representing the\n",
      " |          stride of the input elements in the sliding window. Must be positive.\n",
      " |          The default value of 1 means \"retain every input element\".\n",
      " |        drop_remainder: (Optional.) A `tf.bool` scalar `tf.Tensor`, representing\n",
      " |          whether the last windows should be dropped if their size is smaller than\n",
      " |          `size`.\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset` of (nests of) windows. Each window is a finite\n",
      " |          datasets of flat elements.\n",
      " |  \n",
      " |  with_options(self, options, name=None)\n",
      " |      Returns a new `tf.data.Dataset` with the given options set.\n",
      " |      \n",
      " |      The options are \"global\" in the sense they apply to the entire dataset.\n",
      " |      If options are set multiple times, they are merged as long as different\n",
      " |      options do not use different non-default values.\n",
      " |      \n",
      " |      >>> ds = tf.data.Dataset.range(5)\n",
      " |      >>> ds = ds.interleave(lambda x: tf.data.Dataset.range(5),\n",
      " |      ...                    cycle_length=3,\n",
      " |      ...                    num_parallel_calls=3)\n",
      " |      >>> options = tf.data.Options()\n",
      " |      >>> # This will make the interleave order non-deterministic.\n",
      " |      >>> options.deterministic = False\n",
      " |      >>> ds = ds.with_options(options)\n",
      " |      \n",
      " |      Args:\n",
      " |        options: A `tf.data.Options` that identifies the options the use.\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset` with the given options.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: when an option is set more than once to a non-default value\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  choose_from_datasets(datasets, choice_dataset, stop_on_empty_dataset=True)\n",
      " |      Creates a dataset that deterministically chooses elements from `datasets`.\n",
      " |      \n",
      " |      For example, given the following datasets:\n",
      " |      \n",
      " |      ```python\n",
      " |      datasets = [tf.data.Dataset.from_tensors(\"foo\").repeat(),\n",
      " |                  tf.data.Dataset.from_tensors(\"bar\").repeat(),\n",
      " |                  tf.data.Dataset.from_tensors(\"baz\").repeat()]\n",
      " |      \n",
      " |      # Define a dataset containing `[0, 1, 2, 0, 1, 2, 0, 1, 2]`.\n",
      " |      choice_dataset = tf.data.Dataset.range(3).repeat(3)\n",
      " |      \n",
      " |      result = tf.data.Dataset.choose_from_datasets(datasets, choice_dataset)\n",
      " |      ```\n",
      " |      \n",
      " |      The elements of `result` will be:\n",
      " |      \n",
      " |      ```\n",
      " |      \"foo\", \"bar\", \"baz\", \"foo\", \"bar\", \"baz\", \"foo\", \"bar\", \"baz\"\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        datasets: A non-empty list of `tf.data.Dataset` objects with compatible\n",
      " |          structure.\n",
      " |        choice_dataset: A `tf.data.Dataset` of scalar `tf.int64` tensors between\n",
      " |          `0` and `len(datasets) - 1`.\n",
      " |        stop_on_empty_dataset: If `True`, selection stops if it encounters an\n",
      " |          empty dataset. If `False`, it skips empty datasets. It is recommended to\n",
      " |          set it to `True`. Otherwise, the selected elements start off as the user\n",
      " |          intends, but may change as input datasets become empty. This can be\n",
      " |          difficult to detect since the dataset starts off looking correct.\n",
      " |          Defaults to `True`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A dataset that interleaves elements from `datasets` according to the\n",
      " |        values of `choice_dataset`.\n",
      " |      \n",
      " |      Raises:\n",
      " |        TypeError: If `datasets` or `choice_dataset` has the wrong type.\n",
      " |        ValueError: If `datasets` is empty.\n",
      " |  \n",
      " |  from_generator(generator, output_types=None, output_shapes=None, args=None, output_signature=None, name=None)\n",
      " |      Creates a `Dataset` whose elements are generated by `generator`. (deprecated arguments)\n",
      " |      \n",
      " |      Warning: SOME ARGUMENTS ARE DEPRECATED: `(output_shapes, output_types)`. They will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      Use output_signature instead\n",
      " |      \n",
      " |      The `generator` argument must be a callable object that returns\n",
      " |      an object that supports the `iter()` protocol (e.g. a generator function).\n",
      " |      \n",
      " |      The elements generated by `generator` must be compatible with either the\n",
      " |      given `output_signature` argument or with the given `output_types` and\n",
      " |      (optionally) `output_shapes` arguments, whichever was specified.\n",
      " |      \n",
      " |      The recommended way to call `from_generator` is to use the\n",
      " |      `output_signature` argument. In this case the output will be assumed to\n",
      " |      consist of objects with the classes, shapes and types defined by\n",
      " |      `tf.TypeSpec` objects from `output_signature` argument:\n",
      " |      \n",
      " |      >>> def gen():\n",
      " |      ...   ragged_tensor = tf.ragged.constant([[1, 2], [3]])\n",
      " |      ...   yield 42, ragged_tensor\n",
      " |      >>>\n",
      " |      >>> dataset = tf.data.Dataset.from_generator(\n",
      " |      ...      gen,\n",
      " |      ...      output_signature=(\n",
      " |      ...          tf.TensorSpec(shape=(), dtype=tf.int32),\n",
      " |      ...          tf.RaggedTensorSpec(shape=(2, None), dtype=tf.int32)))\n",
      " |      >>>\n",
      " |      >>> list(dataset.take(1))\n",
      " |      [(<tf.Tensor: shape=(), dtype=int32, numpy=42>,\n",
      " |      <tf.RaggedTensor [[1, 2], [3]]>)]\n",
      " |      \n",
      " |      There is also a deprecated way to call `from_generator` by either with\n",
      " |      `output_types` argument alone or together with `output_shapes` argument.\n",
      " |      In this case the output of the function will be assumed to consist of\n",
      " |      `tf.Tensor` objects with the types defined by `output_types` and with the\n",
      " |      shapes which are either unknown or defined by `output_shapes`.\n",
      " |      \n",
      " |      Note: The current implementation of `Dataset.from_generator()` uses\n",
      " |      `tf.numpy_function` and inherits the same constraints. In particular, it\n",
      " |      requires the dataset and iterator related operations to be placed\n",
      " |      on a device in the same process as the Python program that called\n",
      " |      `Dataset.from_generator()`. The body of `generator` will not be\n",
      " |      serialized in a `GraphDef`, and you should not use this method if you\n",
      " |      need to serialize your model and restore it in a different environment.\n",
      " |      \n",
      " |      Note: If `generator` depends on mutable global variables or other external\n",
      " |      state, be aware that the runtime may invoke `generator` multiple times\n",
      " |      (in order to support repeating the `Dataset`) and at any time\n",
      " |      between the call to `Dataset.from_generator()` and the production of the\n",
      " |      first element from the generator. Mutating global variables or external\n",
      " |      state can cause undefined behavior, and we recommend that you explicitly\n",
      " |      cache any external state in `generator` before calling\n",
      " |      `Dataset.from_generator()`.\n",
      " |      \n",
      " |      Note: While the `output_signature` parameter makes it possible to yield\n",
      " |      `Dataset` elements, the scope of `Dataset.from_generator()` should be\n",
      " |      limited to logic that cannot be expressed through tf.data operations. Using\n",
      " |      tf.data operations within the generator function is an anti-pattern and may\n",
      " |      result in incremental memory growth.\n",
      " |      \n",
      " |      Args:\n",
      " |        generator: A callable object that returns an object that supports the\n",
      " |          `iter()` protocol. If `args` is not specified, `generator` must take no\n",
      " |          arguments; otherwise it must take as many arguments as there are values\n",
      " |          in `args`.\n",
      " |        output_types: (Optional.) A (nested) structure of `tf.DType` objects\n",
      " |          corresponding to each component of an element yielded by `generator`.\n",
      " |        output_shapes: (Optional.) A (nested) structure of `tf.TensorShape`\n",
      " |          objects corresponding to each component of an element yielded by\n",
      " |          `generator`.\n",
      " |        args: (Optional.) A tuple of `tf.Tensor` objects that will be evaluated\n",
      " |          and passed to `generator` as NumPy-array arguments.\n",
      " |        output_signature: (Optional.) A (nested) structure of `tf.TypeSpec`\n",
      " |          objects corresponding to each component of an element yielded by\n",
      " |          `generator`.\n",
      " |        name: (Optional.) A name for the tf.data operations used by\n",
      " |          `from_generator`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset`.\n",
      " |  \n",
      " |  from_tensor_slices(tensors, name=None)\n",
      " |      Creates a `Dataset` whose elements are slices of the given tensors.\n",
      " |      \n",
      " |      The given tensors are sliced along their first dimension. This operation\n",
      " |      preserves the structure of the input tensors, removing the first dimension\n",
      " |      of each tensor and using it as the dataset dimension. All input tensors\n",
      " |      must have the same size in their first dimensions.\n",
      " |      \n",
      " |      >>> # Slicing a 1D tensor produces scalar tensor elements.\n",
      " |      >>> dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [1, 2, 3]\n",
      " |      \n",
      " |      >>> # Slicing a 2D tensor produces 1D tensor elements.\n",
      " |      >>> dataset = tf.data.Dataset.from_tensor_slices([[1, 2], [3, 4]])\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [array([1, 2], dtype=int32), array([3, 4], dtype=int32)]\n",
      " |      \n",
      " |      >>> # Slicing a tuple of 1D tensors produces tuple elements containing\n",
      " |      >>> # scalar tensors.\n",
      " |      >>> dataset = tf.data.Dataset.from_tensor_slices(([1, 2], [3, 4], [5, 6]))\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [(1, 3, 5), (2, 4, 6)]\n",
      " |      \n",
      " |      >>> # Dictionary structure is also preserved.\n",
      " |      >>> dataset = tf.data.Dataset.from_tensor_slices({\"a\": [1, 2], \"b\": [3, 4]})\n",
      " |      >>> list(dataset.as_numpy_iterator()) == [{'a': 1, 'b': 3},\n",
      " |      ...                                       {'a': 2, 'b': 4}]\n",
      " |      True\n",
      " |      \n",
      " |      >>> # Two tensors can be combined into one Dataset object.\n",
      " |      >>> features = tf.constant([[1, 3], [2, 1], [3, 3]]) # ==> 3x2 tensor\n",
      " |      >>> labels = tf.constant(['A', 'B', 'A']) # ==> 3x1 tensor\n",
      " |      >>> dataset = Dataset.from_tensor_slices((features, labels))\n",
      " |      >>> # Both the features and the labels tensors can be converted\n",
      " |      >>> # to a Dataset object separately and combined after.\n",
      " |      >>> features_dataset = Dataset.from_tensor_slices(features)\n",
      " |      >>> labels_dataset = Dataset.from_tensor_slices(labels)\n",
      " |      >>> dataset = Dataset.zip((features_dataset, labels_dataset))\n",
      " |      >>> # A batched feature and label set can be converted to a Dataset\n",
      " |      >>> # in similar fashion.\n",
      " |      >>> batched_features = tf.constant([[[1, 3], [2, 3]],\n",
      " |      ...                                 [[2, 1], [1, 2]],\n",
      " |      ...                                 [[3, 3], [3, 2]]], shape=(3, 2, 2))\n",
      " |      >>> batched_labels = tf.constant([['A', 'A'],\n",
      " |      ...                               ['B', 'B'],\n",
      " |      ...                               ['A', 'B']], shape=(3, 2, 1))\n",
      " |      >>> dataset = Dataset.from_tensor_slices((batched_features, batched_labels))\n",
      " |      >>> for element in dataset.as_numpy_iterator():\n",
      " |      ...   print(element)\n",
      " |      (array([[1, 3],\n",
      " |             [2, 3]], dtype=int32), array([[b'A'],\n",
      " |             [b'A']], dtype=object))\n",
      " |      (array([[2, 1],\n",
      " |             [1, 2]], dtype=int32), array([[b'B'],\n",
      " |             [b'B']], dtype=object))\n",
      " |      (array([[3, 3],\n",
      " |             [3, 2]], dtype=int32), array([[b'A'],\n",
      " |             [b'B']], dtype=object))\n",
      " |      \n",
      " |      Note that if `tensors` contains a NumPy array, and eager execution is not\n",
      " |      enabled, the values will be embedded in the graph as one or more\n",
      " |      `tf.constant` operations. For large datasets (> 1 GB), this can waste\n",
      " |      memory and run into byte limits of graph serialization. If `tensors`\n",
      " |      contains one or more large NumPy arrays, consider the alternative described\n",
      " |      in [this guide](\n",
      " |      https://tensorflow.org/guide/data#consuming_numpy_arrays).\n",
      " |      \n",
      " |      Args:\n",
      " |        tensors: A dataset element, whose components have the same first\n",
      " |          dimension. Supported values are documented\n",
      " |          [here](https://www.tensorflow.org/guide/data#dataset_structure).\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset`.\n",
      " |  \n",
      " |  from_tensors(tensors, name=None)\n",
      " |      Creates a `Dataset` with a single element, comprising the given tensors.\n",
      " |      \n",
      " |      `from_tensors` produces a dataset containing only a single element. To slice\n",
      " |      the input tensor into multiple elements, use `from_tensor_slices` instead.\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.from_tensors([1, 2, 3])\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [array([1, 2, 3], dtype=int32)]\n",
      " |      >>> dataset = tf.data.Dataset.from_tensors(([1, 2, 3], 'A'))\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [(array([1, 2, 3], dtype=int32), b'A')]\n",
      " |      \n",
      " |      >>> # You can use `from_tensors` to produce a dataset which repeats\n",
      " |      >>> # the same example many times.\n",
      " |      >>> example = tf.constant([1,2,3])\n",
      " |      >>> dataset = tf.data.Dataset.from_tensors(example).repeat(2)\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [array([1, 2, 3], dtype=int32), array([1, 2, 3], dtype=int32)]\n",
      " |      \n",
      " |      Note that if `tensors` contains a NumPy array, and eager execution is not\n",
      " |      enabled, the values will be embedded in the graph as one or more\n",
      " |      `tf.constant` operations. For large datasets (> 1 GB), this can waste\n",
      " |      memory and run into byte limits of graph serialization. If `tensors`\n",
      " |      contains one or more large NumPy arrays, consider the alternative described\n",
      " |      in [this\n",
      " |      guide](https://tensorflow.org/guide/data#consuming_numpy_arrays).\n",
      " |      \n",
      " |      Args:\n",
      " |        tensors: A dataset \"element\". Supported values are documented\n",
      " |          [here](https://www.tensorflow.org/guide/data#dataset_structure).\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset`.\n",
      " |  \n",
      " |  list_files(file_pattern, shuffle=None, seed=None, name=None)\n",
      " |      A dataset of all files matching one or more glob patterns.\n",
      " |      \n",
      " |      The `file_pattern` argument should be a small number of glob patterns.\n",
      " |      If your filenames have already been globbed, use\n",
      " |      `Dataset.from_tensor_slices(filenames)` instead, as re-globbing every\n",
      " |      filename with `list_files` may result in poor performance with remote\n",
      " |      storage systems.\n",
      " |      \n",
      " |      Note: The default behavior of this method is to return filenames in\n",
      " |      a non-deterministic random shuffled order. Pass a `seed` or `shuffle=False`\n",
      " |      to get results in a deterministic order.\n",
      " |      \n",
      " |      Example:\n",
      " |        If we had the following files on our filesystem:\n",
      " |      \n",
      " |          - /path/to/dir/a.txt\n",
      " |          - /path/to/dir/b.py\n",
      " |          - /path/to/dir/c.py\n",
      " |      \n",
      " |        If we pass \"/path/to/dir/*.py\" as the directory, the dataset\n",
      " |        would produce:\n",
      " |      \n",
      " |          - /path/to/dir/b.py\n",
      " |          - /path/to/dir/c.py\n",
      " |      \n",
      " |      Args:\n",
      " |        file_pattern: A string, a list of strings, or a `tf.Tensor` of string type\n",
      " |          (scalar or vector), representing the filename glob (i.e. shell wildcard)\n",
      " |          pattern(s) that will be matched.\n",
      " |        shuffle: (Optional.) If `True`, the file names will be shuffled randomly.\n",
      " |          Defaults to `True`.\n",
      " |        seed: (Optional.) A `tf.int64` scalar `tf.Tensor`, representing the random\n",
      " |          seed that will be used to create the distribution. See\n",
      " |          `tf.random.set_seed` for behavior.\n",
      " |        name: Optional. A name for the tf.data operations used by `list_files`.\n",
      " |      \n",
      " |      Returns:\n",
      " |       Dataset: A `Dataset` of strings corresponding to file names.\n",
      " |  \n",
      " |  random(seed=None, name=None)\n",
      " |      Creates a `Dataset` of pseudorandom values.\n",
      " |      \n",
      " |      The dataset generates a sequence of uniformly distributed integer values.\n",
      " |      \n",
      " |      >>> ds1 = tf.data.Dataset.random(seed=4).take(10)\n",
      " |      >>> ds2 = tf.data.Dataset.random(seed=4).take(10)\n",
      " |      >>> print(list(ds2.as_numpy_iterator())==list(ds2.as_numpy_iterator()))\n",
      " |      True\n",
      " |      \n",
      " |      Args:\n",
      " |        seed: (Optional) If specified, the dataset produces a deterministic\n",
      " |          sequence of values.\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset`.\n",
      " |  \n",
      " |  range(*args, **kwargs)\n",
      " |      Creates a `Dataset` of a step-separated range of values.\n",
      " |      \n",
      " |      >>> list(Dataset.range(5).as_numpy_iterator())\n",
      " |      [0, 1, 2, 3, 4]\n",
      " |      >>> list(Dataset.range(2, 5).as_numpy_iterator())\n",
      " |      [2, 3, 4]\n",
      " |      >>> list(Dataset.range(1, 5, 2).as_numpy_iterator())\n",
      " |      [1, 3]\n",
      " |      >>> list(Dataset.range(1, 5, -2).as_numpy_iterator())\n",
      " |      []\n",
      " |      >>> list(Dataset.range(5, 1).as_numpy_iterator())\n",
      " |      []\n",
      " |      >>> list(Dataset.range(5, 1, -2).as_numpy_iterator())\n",
      " |      [5, 3]\n",
      " |      >>> list(Dataset.range(2, 5, output_type=tf.int32).as_numpy_iterator())\n",
      " |      [2, 3, 4]\n",
      " |      >>> list(Dataset.range(1, 5, 2, output_type=tf.float32).as_numpy_iterator())\n",
      " |      [1.0, 3.0]\n",
      " |      \n",
      " |      Args:\n",
      " |        *args: follows the same semantics as python's range.\n",
      " |          len(args) == 1 -> start = 0, stop = args[0], step = 1.\n",
      " |          len(args) == 2 -> start = args[0], stop = args[1], step = 1.\n",
      " |          len(args) == 3 -> start = args[0], stop = args[1], step = args[2].\n",
      " |        **kwargs:\n",
      " |          - output_type: Its expected dtype. (Optional, default: `tf.int64`).\n",
      " |          - name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `RangeDataset`.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: if len(args) == 0.\n",
      " |  \n",
      " |  sample_from_datasets(datasets, weights=None, seed=None, stop_on_empty_dataset=False)\n",
      " |      Samples elements at random from the datasets in `datasets`.\n",
      " |      \n",
      " |      Creates a dataset by interleaving elements of `datasets` with `weight[i]`\n",
      " |      probability of picking an element from dataset `i`. Sampling is done without\n",
      " |      replacement. For example, suppose we have 2 datasets:\n",
      " |      \n",
      " |      ```python\n",
      " |      dataset1 = tf.data.Dataset.range(0, 3)\n",
      " |      dataset2 = tf.data.Dataset.range(100, 103)\n",
      " |      ```\n",
      " |      \n",
      " |      Suppose that we sample from these 2 datasets with the following weights:\n",
      " |      \n",
      " |      ```python\n",
      " |      sample_dataset = tf.data.Dataset.sample_from_datasets(\n",
      " |          [dataset1, dataset2], weights=[0.5, 0.5])\n",
      " |      ```\n",
      " |      \n",
      " |      One possible outcome of elements in sample_dataset is:\n",
      " |      \n",
      " |      ```\n",
      " |      print(list(sample_dataset.as_numpy_iterator()))\n",
      " |      # [100, 0, 1, 101, 2, 102]\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        datasets: A non-empty list of `tf.data.Dataset` objects with compatible\n",
      " |          structure.\n",
      " |        weights: (Optional.) A list or Tensor of `len(datasets)` floating-point\n",
      " |          values where `weights[i]` represents the probability to sample from\n",
      " |          `datasets[i]`, or a `tf.data.Dataset` object where each element is such\n",
      " |          a list. Defaults to a uniform distribution across `datasets`.\n",
      " |        seed: (Optional.) A `tf.int64` scalar `tf.Tensor`, representing the random\n",
      " |          seed that will be used to create the distribution. See\n",
      " |          `tf.random.set_seed` for behavior.\n",
      " |        stop_on_empty_dataset: If `True`, sampling stops if it encounters an empty\n",
      " |          dataset. If `False`, it skips empty datasets. It is recommended to set\n",
      " |          it to `True`. Otherwise, the distribution of samples starts off as the\n",
      " |          user intends, but may change as input datasets become empty. This can be\n",
      " |          difficult to detect since the dataset starts off looking correct.\n",
      " |          Default to `False` for backward compatibility.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A dataset that interleaves elements from `datasets` at random, according\n",
      " |        to `weights` if provided, otherwise with uniform probability.\n",
      " |      \n",
      " |      Raises:\n",
      " |        TypeError: If the `datasets` or `weights` arguments have the wrong type.\n",
      " |        ValueError:\n",
      " |          - If `datasets` is empty, or\n",
      " |          - If `weights` is specified and does not match the length of `datasets`.\n",
      " |  \n",
      " |  zip(datasets, name=None)\n",
      " |      Creates a `Dataset` by zipping together the given datasets.\n",
      " |      \n",
      " |      This method has similar semantics to the built-in `zip()` function\n",
      " |      in Python, with the main difference being that the `datasets`\n",
      " |      argument can be a (nested) structure of `Dataset` objects. The supported\n",
      " |      nesting mechanisms are documented\n",
      " |      [here] (https://www.tensorflow.org/guide/data#dataset_structure).\n",
      " |      \n",
      " |      >>> # The nested structure of the `datasets` argument determines the\n",
      " |      >>> # structure of elements in the resulting dataset.\n",
      " |      >>> a = tf.data.Dataset.range(1, 4)  # ==> [ 1, 2, 3 ]\n",
      " |      >>> b = tf.data.Dataset.range(4, 7)  # ==> [ 4, 5, 6 ]\n",
      " |      >>> ds = tf.data.Dataset.zip((a, b))\n",
      " |      >>> list(ds.as_numpy_iterator())\n",
      " |      [(1, 4), (2, 5), (3, 6)]\n",
      " |      >>> ds = tf.data.Dataset.zip((b, a))\n",
      " |      >>> list(ds.as_numpy_iterator())\n",
      " |      [(4, 1), (5, 2), (6, 3)]\n",
      " |      >>>\n",
      " |      >>> # The `datasets` argument may contain an arbitrary number of datasets.\n",
      " |      >>> c = tf.data.Dataset.range(7, 13).batch(2)  # ==> [ [7, 8],\n",
      " |      ...                                            #       [9, 10],\n",
      " |      ...                                            #       [11, 12] ]\n",
      " |      >>> ds = tf.data.Dataset.zip((a, b, c))\n",
      " |      >>> for element in ds.as_numpy_iterator():\n",
      " |      ...   print(element)\n",
      " |      (1, 4, array([7, 8]))\n",
      " |      (2, 5, array([ 9, 10]))\n",
      " |      (3, 6, array([11, 12]))\n",
      " |      >>>\n",
      " |      >>> # The number of elements in the resulting dataset is the same as\n",
      " |      >>> # the size of the smallest dataset in `datasets`.\n",
      " |      >>> d = tf.data.Dataset.range(13, 15)  # ==> [ 13, 14 ]\n",
      " |      >>> ds = tf.data.Dataset.zip((a, d))\n",
      " |      >>> list(ds.as_numpy_iterator())\n",
      " |      [(1, 13), (2, 14)]\n",
      " |      \n",
      " |      Args:\n",
      " |        datasets: A (nested) structure of datasets.\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |  \n",
      " |  element_spec\n",
      " |      The type specification of an element of this dataset.\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
      " |      >>> dataset.element_spec\n",
      " |      TensorSpec(shape=(), dtype=tf.int32, name=None)\n",
      " |      \n",
      " |      For more information,\n",
      " |      read [this guide](https://www.tensorflow.org/guide/data#dataset_structure).\n",
      " |      \n",
      " |      Returns:\n",
      " |        A (nested) structure of `tf.TypeSpec` objects matching the structure of an\n",
      " |        element of this dataset and specifying the type of individual components.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset({'_inputs', 'element_spec'})\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from collections.abc.Iterable:\n",
      " |  \n",
      " |  __subclasshook__(C) from abc.ABCMeta\n",
      " |      Abstract classes can override this to customize issubclass().\n",
      " |      \n",
      " |      This is invoked early on by abc.ABCMeta.__subclasscheck__().\n",
      " |      It should return True, False or NotImplemented.  If it returns\n",
      " |      NotImplemented, the normal algorithm is used.  Otherwise, it\n",
      " |      overrides the normal algorithm (and the outcome is cached).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from tensorflow.python.framework.composite_tensor.CompositeTensor:\n",
      " |  \n",
      " |  __tf_tracing_type__(self, context)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.data.Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad30f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "  file_path_features = [data_path_from_slice_path(path) for path in file_paths]\n",
    "\n",
    "    both_path = tf.data.Dataset.from_tensor_slices(\n",
    "        [list(couple) for couple in zip(file_paths, file_path_features)]\n",
    "    )\n",
    "    general_dataset = both_path.interleave(single_slice_dataset, cycle_length=n_readers)\n",
    "    general_dataset = general_dataset.shuffle(shuffle_buffer_size).repeat(repeat)\n",
    "    return general_dataset.batch(1)  # Output shape: (1, 120, 1)\n",
    "    # TODO(FK): remove the batching here and the prefetch  .prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "7a3b5cd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(527, 120)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "6376cd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prov = np.expand_dims(train_feature[4,:], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "a90735e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 120)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prov.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "8d9f8575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 120, 1)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prov = np.expand_dims(train_feature[4,:], axis=-1)\n",
    "prov = np.expand_dims(prov, axis=0)\n",
    "prov.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "62667bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_crop(output_size):\n",
    "    # TODO(FK): add name\n",
    "    # TODO(FK): handle size\n",
    "    size = [74, output_size, 1]\n",
    "    return tf.keras.layers.Lambda(lambda x: tf.image.random_crop(x, size=size))\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def center_crop_slice(x, margin):\n",
    "    return x[..., margin:-margin, :]\n",
    "\n",
    "\n",
    "def center_crop(input_size=120, output_size=80):\n",
    "    return tf.keras.layers.Lambda(\n",
    "        lambda x: center_crop_slice(x, (input_size - output_size) // 2)\n",
    "    )\n",
    "\n",
    "\n",
    "data_augmentation = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.Input(shape=(120, 1)),\n",
    "        random_crop(80),\n",
    "        # random_invert(p=0.5),  # TODO(FK): keep?\n",
    "        #random_mirror(p=0.5),\n",
    "        #random_brightness(10),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "90acfae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from amftrack.ml.width.data_augmentation import *"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bfbb8ffb",
   "metadata": {},
   "source": [
    "data_augmentation = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.Input(shape=(120, 1)),\n",
    "        random_crop(120),\n",
    "        # random_invert(p=0.5),  # TODO(FK): keep?\n",
    "        random_mirror(p=0.5),\n",
    "        random_brightness(20),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8a53a48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.Input(shape=(120, 1)),\n",
    "        random_crop(80),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "1ed5fa01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[199, 198, 197, ..., 203, 204, 207],\n",
       "       [175, 177, 176, ..., 167, 166, 166],\n",
       "       [194, 194, 194, ..., 146, 134, 120],\n",
       "       ...,\n",
       "       [186, 186, 186, ..., 179, 177, 179],\n",
       "       [204, 206, 206, ..., 205, 206, 206],\n",
       "       [188, 189, 188, ..., 174, 177, 179]], dtype=uint8)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "d4ae11b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vector = data_augmentation(test_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "c74b492f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "4a2789df",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(74,), dtype=float32, numpy=\n",
       "array([196., 166., 188., 186., 162., 200., 198., 157., 201., 180., 194.,\n",
       "       188., 184., 189., 183., 180., 165., 155., 202., 171., 171., 203.,\n",
       "       186., 173., 206., 176., 161., 200., 187., 175., 177., 194., 184.,\n",
       "       181., 189., 194., 197., 194., 193., 200., 165., 183., 197., 205.,\n",
       "       191., 155., 167., 168., 182., 178., 185., 192., 198., 158., 196.,\n",
       "       168., 199., 177., 196., 203., 164., 193., 174., 189., 178., 197.,\n",
       "       178., 202., 126., 175., 146., 170., 209., 186.], dtype=float32)>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_vector[:, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "e0a635e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(74,), dtype=float32, numpy=\n",
       "array([196., 166., 188., 186., 162., 200., 198., 157., 201., 180., 194.,\n",
       "       188., 184., 189., 183., 180., 165., 155., 202., 171., 171., 203.,\n",
       "       186., 173., 206., 176., 161., 200., 187., 175., 177., 194., 184.,\n",
       "       181., 189., 194., 197., 194., 193., 200., 165., 183., 197., 205.,\n",
       "       191., 155., 167., 168., 182., 178., 185., 192., 198., 158., 196.,\n",
       "       168., 199., 177., 196., 203., 164., 193., 174., 189., 178., 197.,\n",
       "       178., 202., 126., 175., 146., 170., 209., 186.], dtype=float32)>"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_vector[:, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "2707a279",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 1ms/step - loss: 5.2993 - mean_absolute_error: 1.2498\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5.299310207366943, 1.2498197555541992]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.evaluate(feature_vector, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "5bd83327",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_against(best_model, feature_vector, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "773b7a22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 80, 1), dtype=float32, numpy=\n",
       "array([[[117.],\n",
       "        [115.],\n",
       "        [116.],\n",
       "        [117.],\n",
       "        [118.],\n",
       "        [117.],\n",
       "        [118.],\n",
       "        [119.],\n",
       "        [118.],\n",
       "        [120.],\n",
       "        [123.],\n",
       "        [123.],\n",
       "        [124.],\n",
       "        [125.],\n",
       "        [126.],\n",
       "        [127.],\n",
       "        [131.],\n",
       "        [130.],\n",
       "        [131.],\n",
       "        [136.],\n",
       "        [138.],\n",
       "        [140.],\n",
       "        [145.],\n",
       "        [156.],\n",
       "        [163.],\n",
       "        [160.],\n",
       "        [152.],\n",
       "        [140.],\n",
       "        [132.],\n",
       "        [131.],\n",
       "        [126.],\n",
       "        [124.],\n",
       "        [124.],\n",
       "        [123.],\n",
       "        [122.],\n",
       "        [118.],\n",
       "        [119.],\n",
       "        [121.],\n",
       "        [124.],\n",
       "        [125.],\n",
       "        [121.],\n",
       "        [122.],\n",
       "        [122.],\n",
       "        [121.],\n",
       "        [121.],\n",
       "        [120.],\n",
       "        [118.],\n",
       "        [119.],\n",
       "        [120.],\n",
       "        [119.],\n",
       "        [116.],\n",
       "        [118.],\n",
       "        [118.],\n",
       "        [117.],\n",
       "        [118.],\n",
       "        [119.],\n",
       "        [119.],\n",
       "        [117.],\n",
       "        [115.],\n",
       "        [117.],\n",
       "        [116.],\n",
       "        [117.],\n",
       "        [116.],\n",
       "        [116.],\n",
       "        [118.],\n",
       "        [117.],\n",
       "        [113.],\n",
       "        [116.],\n",
       "        [116.],\n",
       "        [114.],\n",
       "        [116.],\n",
       "        [116.],\n",
       "        [117.],\n",
       "        [118.],\n",
       "        [118.],\n",
       "        [118.],\n",
       "        [116.],\n",
       "        [117.],\n",
       "        [115.],\n",
       "        [115.]]], dtype=float32)>"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_augmentation(prov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "d8517151",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120,)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feature[5,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "21091b50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_label[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "4b6aba28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(np.array(train_feature[6,:]))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "92e1001f",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "list(zip([train_feature[i,:] for i in range(len(train_feature))], train_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "0b33abeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "527"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "baad05d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Can't convert non-rectangular Python sequence to Tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/data/util/structure.py:102\u001b[0m, in \u001b[0;36mnormalize_element\u001b[0;34m(element, element_signature)\u001b[0m\n\u001b[1;32m    101\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 102\u001b[0m     spec \u001b[38;5;241m=\u001b[39m \u001b[43mtype_spec_from_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_fallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    104\u001b[0m   \u001b[38;5;66;03m# TypeError indicates it was not possible to compute a `TypeSpec` for\u001b[39;00m\n\u001b[1;32m    105\u001b[0m   \u001b[38;5;66;03m# the value. As a fallback try converting the value to a tensor.\u001b[39;00m\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/data/util/structure.py:485\u001b[0m, in \u001b[0;36mtype_spec_from_value\u001b[0;34m(element, use_fallback)\u001b[0m\n\u001b[1;32m    482\u001b[0m     logging\u001b[38;5;241m.\u001b[39mvlog(\n\u001b[1;32m    483\u001b[0m         \u001b[38;5;241m3\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to convert \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m to tensor: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mtype\u001b[39m(element)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, e))\n\u001b[0;32m--> 485\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not build a `TypeSpec` for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m with type \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    486\u001b[0m     element,\n\u001b[1;32m    487\u001b[0m     \u001b[38;5;28mtype\u001b[39m(element)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m))\n",
      "\u001b[0;31mTypeError\u001b[0m: Could not build a `TypeSpec` for [[array([129, 129, 130, 130, 128, 130, 130, 128, 130, 128, 129, 131, 129,\n       130, 133, 131, 130, 132, 130, 129, 131, 130, 129, 131, 129, 126,\n       127, 128, 130, 130, 130, 131, 133, 130, 130, 130, 131, 131, 127,\n       131, 128, 128, 126, 125, 129, 127, 126, 125, 121, 116, 107,  92,\n        82,  84,  92, 101, 107, 112, 113, 111, 110, 107, 111, 106, 106,\n       104, 101,  94,  83,  75,  74,  73,  68,  65,  80,  93,  98,  97,\n       101, 106, 107, 107, 110, 112, 112, 108, 107, 108, 109, 111, 114,\n       116, 119, 121, 121, 124, 123, 126, 124, 125, 125, 126, 127, 126,\n       125, 127, 128, 129, 129, 129, 130, 130, 129, 128, 129, 127, 127,\n       126, 125, 126], dtype=uint8), array([7.26221294])], [array([130, 130, 128, 127, 129, 129, 130, 130, 127, 126, 125, 125, 128,\n       129, 129, 130, 130, 132, 131, 130, 130, 130, 128, 126, 128, 128,\n       128, 128, 128, 128, 129, 129, 130, 131, 131, 131, 129, 131, 133,\n       131, 130, 128, 129, 128, 130, 129, 129, 130, 133, 130, 128, 127,\n       129, 133, 130, 133, 134, 134, 134, 134, 134, 135, 136, 137, 138,\n       139, 140, 138, 139, 138, 134, 123, 118, 102,  85,  83,  97, 103,\n       103, 103, 100, 101, 100, 100, 102, 103, 104, 106, 109, 111, 113,\n       115, 117, 119, 118, 119, 120, 125, 124, 126, 127, 127, 128, 131,\n       130, 133, 133, 133, 132, 132, 131, 132, 134, 136, 135, 136, 135,\n       134, 133, 134], dtype=uint8), array([5.93755418])], [array([130, 129, 130, 129, 131, 131, 130, 129, 131, 132, 130, 129, 128,\n       131, 132, 130, 130, 130, 128, 128, 130, 131, 131, 131, 130, 130,\n       129, 130, 132, 130, 130, 132, 131, 134, 133, 131, 131, 133, 132,\n       133, 133, 133, 130, 132, 134, 134, 134, 136, 132, 135, 135, 134,\n       135, 135, 133, 135, 134, 133, 136, 135, 137, 140, 136, 136, 138,\n       139, 139, 140, 139, 139, 134, 125, 116, 104,  91,  91, 105, 105,\n       105, 105, 104, 103, 105, 104, 104, 106, 106, 107, 111, 111, 113,\n       114, 115, 117, 121, 121, 123, 125, 125, 126, 131, 129, 129, 131,\n       132, 129, 133, 132, 132, 135, 136, 138, 136, 133, 135, 135, 136,\n       135, 136, 137], dtype=uint8), array([5.5774322])], [array([140, 139, 138, 137, 136, 137, 138, 138, 137, 135, 138, 137, 137,\n       136, 137, 138, 138, 138, 139, 140, 139, 138, 137, 137, 138, 138,\n       140, 140, 141, 143, 142, 140, 141, 138, 139, 139, 140, 139, 137,\n       140, 139, 140, 139, 140, 139, 136, 135, 135, 135, 136, 136, 135,\n       134, 133, 132, 131, 131, 131, 129, 131, 126, 124, 126, 122, 119,\n       117, 106,  95,  93,  93, 101, 113, 120, 124, 125, 126, 125, 127,\n       129, 128, 130, 133, 132, 132, 134, 136, 137, 135, 134, 133, 134,\n       134, 134, 136, 136, 137, 134, 137, 138, 136, 139, 137, 137, 139,\n       139, 138, 135, 134, 134, 136, 135, 136, 135, 136, 137, 137, 136,\n       135, 135, 139], dtype=uint8), array([4.19787153])], [array([137, 135, 134, 132, 136, 134, 137, 137, 137, 139, 139, 139, 138,\n       139, 141, 141, 139, 140, 140, 138, 139, 137, 137, 137, 138, 139,\n       139, 141, 139, 139, 142, 138, 137, 139, 139, 138, 139, 138, 140,\n       138, 136, 136, 137, 138, 137, 137, 139, 136, 135, 136, 137, 135,\n       134, 134, 133, 133, 134, 130, 131, 134, 136, 137, 133, 132, 131,\n       131, 129, 124, 123, 115, 103,  95,  92,  99, 110, 115, 117, 119,\n       124, 125, 124, 128, 129, 130, 131, 132, 132, 135, 137, 136, 137,\n       138, 137, 138, 139, 140, 138, 138, 140, 141, 141, 141, 141, 141,\n       140, 140, 138, 137, 135, 138, 139, 139, 141, 140, 142, 142, 140,\n       140, 139, 138], dtype=uint8), array([3.7441611])], [array([125, 125, 125, 125, 123, 124, 126, 127, 127, 125, 126, 125, 125,\n       125, 126, 127, 125, 124, 121, 121, 117, 119, 119, 119, 120, 121,\n       121, 124, 123, 125, 125, 126, 127, 125, 124, 126, 127, 126, 125,\n       125, 127, 127, 127, 127, 127, 126, 125, 126, 127, 126, 124, 126,\n       128, 127, 127, 126, 128, 127, 127, 131, 128, 129, 134, 132, 133,\n       132, 133, 134, 135, 131, 128, 120, 105,  89,  82,  92, 104, 106,\n       104, 104, 103, 101, 103, 106, 108, 107, 108, 111, 113, 113, 115,\n       117, 120, 118, 121, 124, 124, 123, 125, 126, 126, 129, 127, 127,\n       128, 130, 127, 128, 129, 126, 127, 129, 128, 128, 127, 126, 129,\n       128, 130, 132], dtype=uint8), array([5.20109506])], [array([119, 118, 116, 117, 118, 117, 116, 116, 117, 118, 119, 120, 121,\n       120, 121, 122, 122, 122, 122, 122, 123, 120, 122, 124, 122, 122,\n       122, 121, 120, 121, 122, 124, 121, 124, 123, 119, 122, 119, 123,\n       123, 122, 123, 120, 123, 122, 123, 121, 122, 120, 121, 122, 124,\n       123, 125, 122, 121, 120, 121, 124, 124, 124, 125, 126, 128, 131,\n       131, 131, 133, 134, 132, 130, 127, 117, 105,  90,  82,  90, 100,\n       103, 103, 101, 100,  99, 100, 100, 100, 100, 102, 104, 103, 108,\n       108, 109, 112, 109, 111, 114, 114, 112, 116, 116, 116, 114, 116,\n       115, 115, 115, 117, 115, 117, 117, 117, 116, 115, 115, 116, 115,\n       114, 115, 113], dtype=uint8), array([4.87914297])], [array([146, 144, 140, 145, 146, 147, 145, 146, 149, 147, 148, 146, 148,\n       145, 145, 145, 145, 145, 147, 150, 148, 147, 147, 146, 146, 149,\n       146, 148, 147, 149, 148, 147, 145, 143, 146, 145, 147, 148, 146,\n       146, 147, 147, 145, 146, 149, 146, 146, 146, 147, 146, 146, 145,\n       145, 144, 143, 145, 145, 147, 146, 147, 147, 146, 144, 147, 146,\n       147, 146, 146, 147, 146, 146, 146, 145, 145, 146, 148, 148, 145,\n       145, 146, 147, 147, 144, 147, 147, 148, 148, 148, 147, 146, 145,\n       146, 147, 145, 145, 147, 148, 146, 146, 147, 147, 145, 147, 146,\n       146, 147, 146, 148, 147, 150, 145, 146, 145, 146, 146, 144, 146,\n       147, 147, 149], dtype=uint8), array([0.])], [array([135, 135, 135, 137, 137, 137, 136, 136, 133, 132, 134, 132, 131,\n       131, 131, 131, 133, 132, 134, 132, 133, 131, 132, 133, 137, 134,\n       133, 136, 133, 133, 136, 133, 135, 134, 137, 138, 136, 136, 137,\n       137, 138, 138, 139, 137, 138, 140, 139, 138, 137, 137, 137, 137,\n       138, 137, 140, 141, 145, 140, 141, 141, 139, 141, 140, 139, 140,\n       139, 133, 125, 110, 108, 112, 116, 111, 100,  93,  94,  95,  92,\n        91,  89,  86,  86,  91,  94,  93,  94,  97,  98,  99,  98, 101,\n       102, 105, 108, 112, 113, 112, 115, 117, 119, 121, 121, 122, 125,\n       126, 128, 131, 132, 135, 132, 132, 134, 137, 139, 137, 137, 136,\n       141, 139, 137], dtype=uint8), array([8.52101685])], [array([134, 131, 130, 132, 135, 132, 132, 133, 133, 133, 132, 134, 134,\n       134, 134, 134, 134, 133, 132, 133, 134, 135, 136, 135, 135, 134,\n       135, 135, 135, 134, 135, 134, 138, 136, 138, 137, 135, 135, 134,\n       137, 133, 135, 139, 136, 136, 136, 137, 141, 143, 140, 138, 138,\n       139, 141, 141, 139, 143, 142, 142, 141, 142, 143, 143, 143, 140,\n       133, 118, 104,  99, 106, 111, 104,  92,  89,  86,  83,  84,  84,\n        84,  86,  88,  91,  88,  87,  89,  91,  95,  97,  98,  98, 101,\n       102, 104, 109, 110, 111, 114, 115, 116, 120, 120, 120, 124, 125,\n       125, 125, 126, 133, 131, 135, 133, 134, 134, 136, 137, 138, 137,\n       137, 138, 140], dtype=uint8), array([8.73503977])], [array([113, 110, 110, 113, 114, 110, 104, 104, 105, 109, 112, 120, 125,\n       126, 128, 133, 135, 137, 135, 135, 137, 137, 135, 135, 134, 135,\n       135, 133, 133, 133, 134, 134, 135, 134, 132, 134, 134, 133, 132,\n       133, 132, 130, 133, 132, 134, 133, 130, 127, 129, 129, 129, 128,\n       127, 129, 127, 125, 124, 124, 123, 124, 121, 121, 122, 120, 120,\n       121, 120, 119, 118, 117, 114, 109, 103, 101,  99, 104, 113, 120,\n       121, 121, 121, 123, 124, 124, 126, 125, 126, 128, 127, 129, 128,\n       129, 129, 129, 131, 129, 128, 131, 132, 131, 130, 129, 129, 131,\n       131, 130, 132, 133, 130, 130, 133, 130, 127, 129, 131, 130, 130,\n       132, 132, 132], dtype=uint8), array([4.59109883])], [array([139, 139, 137, 131, 132, 133, 138, 136, 136, 135, 134, 135, 134,\n       137, 136, 135, 136, 135, 138, 136, 135, 136, 134, 134, 133, 134,\n       133, 132, 133, 133, 133, 133, 131, 131, 131, 131, 129, 131, 128,\n       127, 125, 124, 124, 125, 121, 122, 122, 121, 117, 116, 115, 116,\n       117, 115, 112, 114, 113, 114, 115, 113, 113, 107,  94,  91, 105,\n       115, 123, 130, 134, 134, 135, 135, 134, 135, 134, 134, 133, 135,\n       135, 135, 135, 132, 133, 132, 132, 133, 131, 131, 130, 131, 133,\n       131, 130, 131, 130, 132, 130, 129, 130, 131, 130, 129, 129, 130,\n       126, 125, 127, 125, 126, 127, 125, 125, 127, 124, 122, 124, 127,\n       122, 122, 124], dtype=uint8), array([4.34090199])], [array([132, 132, 131, 131, 132, 132, 132, 132, 131, 132, 132, 131, 132,\n       133, 132, 131, 130, 130, 133, 130, 129, 133, 135, 131, 131, 133,\n       134, 132, 131, 132, 131, 129, 129, 130, 131, 128, 127, 124, 127,\n       126, 126, 125, 123, 123, 121, 119, 119, 121, 119, 117, 116, 117,\n       118, 115, 114, 114, 114, 116, 117, 116, 116, 112, 102, 103, 110,\n       119, 127, 131, 131, 132, 133, 131, 131, 128, 128, 126, 126, 126,\n       124, 123, 124, 125, 125, 125, 126, 125, 126, 124, 128, 127, 126,\n       126, 126, 126, 127, 127, 126, 129, 128, 130, 127, 128, 128, 129,\n       129, 130, 131, 131, 130, 130, 132, 130, 132, 131, 127, 127, 124,\n       123, 126, 126], dtype=uint8), array([4.35067225])], [array([125, 130, 133, 134, 135, 136, 136, 135, 134, 132, 133, 134, 134,\n       134, 133, 131, 131, 130, 132, 133, 134, 133, 134, 134, 132, 132,\n       133, 132, 135, 132, 131, 130, 129, 129, 127, 126, 124, 124, 124,\n       118, 117, 119, 115, 114, 114, 115, 112, 112, 113, 112, 110, 110,\n       113, 114, 113, 113, 112, 114, 113, 105,  93, 101, 111, 122, 129,\n       130, 132, 133, 132, 129, 131, 130, 130, 129, 125, 127, 128, 124,\n       122, 121, 124, 122, 122, 119, 118, 117, 117, 116, 115, 114, 117,\n       114, 104, 102, 108, 121, 125, 130, 131, 130, 130, 128, 125, 122,\n       120, 124, 124, 125, 128, 125, 126, 124, 124, 124, 125, 125, 123,\n       120, 121, 123], dtype=uint8), array([4.18356936])], [array([122, 122, 124, 124, 121, 122, 123, 118, 126, 124, 124, 121, 121,\n       123, 122, 120, 122, 122, 121, 122, 123, 121, 123, 122, 120, 120,\n       122, 120, 121, 121, 122, 123, 123, 122, 121, 123, 123, 121, 121,\n       122, 121, 121, 120, 122, 123, 121, 122, 124, 121, 121, 121, 122,\n       120, 122, 123, 122, 123, 123, 123, 124, 123, 123, 121, 121, 121,\n       123, 123, 121, 121, 120, 121, 115, 106, 100, 100, 101, 103, 108,\n       110, 111, 110, 109, 106, 105, 103, 103, 103, 103, 104, 104, 107,\n       110, 110, 110, 111, 113, 113, 115, 117, 116, 116, 122, 120, 120,\n       120, 121, 121, 122, 122, 122, 123, 125, 124, 122, 122, 125, 124,\n       122, 123, 125], dtype=uint8), array([5.923182])], [array([124, 125, 125, 126, 126, 125, 126, 125, 125, 127, 126, 125, 125,\n       125, 126, 125, 122, 120, 119, 117, 114, 113, 117, 116, 117, 119,\n       119, 121, 124, 123, 118, 114, 109, 102,  99, 103, 110, 116, 118,\n       119, 122, 123, 123, 124, 124, 125, 127, 127, 129, 129, 128, 124,\n       124, 124, 126, 131, 132, 135, 136, 136, 134, 137, 138, 136, 130,\n       122, 114, 116, 116, 102,  87,  77,  74,  71,  70,  72,  73,  75,\n        78,  79,  78,  78,  82,  83,  85,  87,  88,  90,  91,  93,  96,\n        99, 100, 101, 104, 108, 109, 110, 113, 114, 116, 116, 119, 119,\n       121, 122, 123, 124, 125, 124, 126, 127, 124, 128, 125, 126, 128,\n       128, 129, 130], dtype=uint8), array([8.89809448])], [array([122, 122, 122, 122, 124, 123, 123, 123, 122, 119, 119, 117, 118,\n       120, 125, 123, 124, 123, 125, 125, 124, 122, 122, 126, 128, 122,\n       122, 127, 125, 126, 126, 125, 124, 123, 124, 125, 125, 122, 122,\n       126, 124, 123, 124, 124, 121, 123, 125, 125, 124, 123, 121, 122,\n       121, 122, 122, 120, 117, 118, 120, 120, 117, 116, 117, 117, 115,\n       113, 113, 115, 112, 110, 108, 100,  88,  81,  83,  83,  83,  94,\n       105, 111, 111, 110, 113, 114, 114, 115, 114, 116, 119, 122, 122,\n       121, 121, 123, 124, 126, 123, 125, 124, 124, 126, 125, 125, 126,\n       123, 122, 121, 119, 118, 113, 112, 110, 112, 115, 118, 121, 127,\n       124, 124, 122], dtype=uint8), array([4.7800506])], [array([126, 123, 125, 125, 125, 125, 124, 125, 126, 125, 125, 124, 127,\n       125, 123, 124, 125, 124, 125, 125, 123, 124, 125, 124, 123, 125,\n       125, 123, 122, 125, 125, 125, 126, 126, 126, 125, 123, 122, 124,\n       123, 121, 124, 125, 121, 119, 121, 121, 123, 119, 115, 114, 113,\n       114, 114, 113, 111, 109, 109, 108, 108, 108, 107, 106, 105, 106,\n       106, 105, 105, 106, 105, 103,  89,  86,  92,  94,  95, 105, 112,\n       113, 114, 116, 116, 116, 114, 115, 115, 116, 117, 120, 120, 119,\n       118, 122, 122, 120, 121, 122, 122, 120, 121, 123, 122, 122, 122,\n       121, 118, 117, 122, 120, 120, 125, 122, 125, 124, 122, 124, 123,\n       126, 123, 121], dtype=uint8), array([5.29939395])], [array([124, 127, 123, 125, 125, 123, 125, 122, 123, 121, 127, 124, 123,\n       125, 124, 126, 126, 124, 124, 122, 125, 124, 123, 121, 122, 123,\n       119, 124, 123, 122, 122, 123, 119, 124, 125, 122, 120, 123, 123,\n       122, 120, 119, 121, 122, 124, 123, 120, 117, 121, 120, 121, 120,\n       118, 121, 116, 117, 117, 117, 114, 117, 115, 116, 117, 116, 113,\n       114, 115, 114, 113, 112, 112,  98,  96,  91,  95,  94,  98, 107,\n       110, 109, 110, 107, 114, 111, 107, 113, 113, 112, 112, 113, 116,\n       116, 119, 117, 115, 120, 120, 119, 119, 119, 118, 121, 120, 121,\n       120, 123, 118, 122, 120, 124, 123, 119, 123, 120, 122, 125, 120,\n       120, 122, 121], dtype=uint8), array([5.08347615])], [array([153, 153, 154, 154, 155, 153, 153, 155, 153, 156, 155, 153, 153,\n       155, 153, 152, 151, 151, 152, 153, 156, 154, 153, 152, 150, 152,\n       154, 155, 151, 156, 155, 156, 155, 153, 153, 153, 153, 152, 151,\n       153, 150, 150, 150, 151, 149, 147, 145, 144, 142, 140, 130, 106,\n        85,  93, 107,  98,  78,  69,  81,  98, 104, 105, 107, 111, 114,\n       116, 121, 124, 127, 128, 129, 133, 136, 139, 141, 142, 145, 143,\n       149, 146, 150, 149, 149, 151, 149, 148, 152, 149, 152, 151, 152,\n       153, 152, 153, 153, 153, 153, 151, 156, 154, 155, 154, 154, 154,\n       153, 153, 156, 155, 156, 154, 153, 153, 153, 153, 159, 157, 151,\n       153, 153, 152], dtype=uint8), array([8.36581426])], [array([151, 151, 152, 151, 153, 153, 150, 153, 148, 150, 148, 146, 146,\n       148, 148, 144, 144, 140, 139, 137, 139, 137, 129, 121, 121, 123,\n       131, 138, 146, 145, 147, 147, 147, 147, 149, 147, 147, 149, 148,\n       146, 145, 146, 147, 146, 144, 139, 139, 140, 136, 132, 128, 126,\n       125, 121, 118, 117, 112, 110, 107, 110, 114, 116, 112,  99,  83,\n        83, 100, 108,  99,  93, 106, 127, 137, 140, 144, 143, 146, 147,\n       147, 148, 150, 153, 151, 149, 149, 150, 150, 150, 151, 151, 153,\n       153, 151, 153, 151, 153, 153, 153, 153, 153, 150, 154, 149, 154,\n       155, 153, 153, 153, 153, 153, 154, 154, 152, 153, 152, 151, 152,\n       153, 154, 150], dtype=uint8), array([8.89809448])], [array([153, 152, 151, 152, 152, 152, 153, 152, 152, 154, 153, 152, 150,\n       151, 155, 152, 149, 147, 148, 148, 150, 154, 150, 150, 153, 152,\n       152, 151, 151, 147, 153, 151, 151, 152, 149, 152, 154, 150, 151,\n       151, 151, 150, 150, 150, 149, 152, 151, 151, 150, 153, 153, 152,\n       153, 154, 154, 154, 154, 152, 152, 152, 151, 154, 154, 152, 151,\n       148, 150, 150, 148, 144, 132, 118, 111, 107, 104, 116, 127, 133,\n       134, 138, 144, 143, 141, 146, 146, 148, 147, 150, 150, 150, 151,\n       152, 152, 150, 150, 150, 151, 150, 150, 149, 150, 151, 152, 151,\n       150, 150, 150, 151, 152, 154, 153, 152, 152, 150, 148, 151, 153,\n       152, 152, 152], dtype=uint8), array([4.7800506])], [array([153, 153, 152, 153, 155, 152, 155, 153, 153, 154, 153, 151, 151,\n       150, 151, 153, 152, 150, 154, 154, 151, 152, 151, 152, 151, 150,\n       155, 155, 152, 153, 152, 152, 155, 155, 154, 154, 154, 153, 152,\n       151, 151, 151, 152, 152, 155, 149, 152, 153, 154, 149, 155, 153,\n       155, 154, 155, 154, 155, 153, 153, 153, 154, 155, 154, 150, 150,\n       151, 148, 146, 140, 124, 107, 112, 108,  96, 108, 129, 136, 137,\n       139, 141, 139, 142, 144, 143, 145, 147, 147, 148, 151, 149, 147,\n       149, 152, 152, 152, 149, 150, 148, 144, 142, 138, 143, 144, 152,\n       151, 151, 149, 152, 155, 153, 152, 153, 152, 150, 150, 152, 152,\n       152, 154, 155], dtype=uint8), array([5.29939395])], [array([148, 147, 145, 146, 145, 145, 147, 149, 149, 147, 148, 148, 147,\n       148, 149, 148, 148, 148, 150, 150, 149, 150, 150, 149, 148, 150,\n       151, 149, 150, 150, 148, 148, 149, 148, 149, 151, 151, 150, 149,\n       151, 151, 149, 150, 150, 151, 149, 150, 150, 152, 149, 148, 151,\n       153, 152, 149, 150, 152, 152, 150, 152, 150, 150, 152, 150, 150,\n       147, 147, 148, 146, 144, 137, 122, 112, 108, 104, 118, 132, 134,\n       137, 138, 146, 142, 147, 143, 148, 151, 147, 150, 149, 151, 151,\n       151, 152, 152, 154, 152, 155, 155, 155, 154, 153, 152, 151, 152,\n       150, 152, 153, 154, 156, 152, 154, 156, 155, 154, 153, 152, 151,\n       153, 154, 151], dtype=uint8), array([5.08347615])], [array([149, 148, 147, 147, 148, 148, 147, 145, 149, 150, 148, 147, 150,\n       151, 148, 148, 149, 148, 148, 150, 150, 150, 152, 152, 150, 149,\n       149, 149, 150, 151, 150, 149, 149, 150, 150, 152, 152, 151, 150,\n       152, 152, 152, 149, 151, 150, 150, 150, 149, 150, 151, 150, 150,\n       149, 150, 152, 153, 151, 151, 152, 151, 150, 147, 148, 150, 149,\n       148, 146, 145, 143, 136, 123, 114, 114, 115, 120, 132, 135, 136,\n       137, 140, 141, 142, 143, 144, 146, 147, 148, 149, 148, 147, 151,\n       152, 151, 151, 151, 152, 154, 149, 150, 151, 152, 152, 152, 152,\n       153, 153, 152, 152, 152, 150, 149, 153, 153, 152, 150, 150, 152,\n       150, 153, 151], dtype=uint8), array([5.923182])], [array([149, 148, 150, 149, 143, 140, 140, 135, 130, 123, 119, 119, 120,\n       127, 127, 128, 126, 126, 127, 128, 129, 132, 129, 130, 133, 132,\n       133, 135, 135, 137, 137, 138, 140, 140, 142, 142, 141, 144, 144,\n       144, 145, 144, 146, 148, 145, 146, 149, 150, 150, 148, 149, 150,\n       150, 146, 148, 149, 149, 151, 152, 152, 151, 151, 148, 149, 151,\n       151, 151, 150, 147, 139, 130, 122, 114, 112, 118, 125, 126, 127,\n       130, 130, 133, 131, 135, 134, 138, 140, 141, 141, 145, 146, 146,\n       146, 147, 146, 148, 149, 149, 149, 148, 150, 148, 148, 150, 151,\n       152, 151, 149, 152, 151, 150, 151, 152, 149, 149, 152, 149, 151,\n       150, 148, 150], dtype=uint8), array([4.59109883])], [array([145, 144, 146, 148, 148, 149, 147, 147, 149, 151, 147, 150, 152,\n       149, 150, 150, 149, 149, 148, 149, 148, 145, 146, 149, 151, 150,\n       148, 147, 149, 148, 150, 150, 149, 147, 149, 150, 146, 146, 148,\n       147, 148, 147, 147, 148, 148, 151, 150, 147, 150, 150, 149, 149,\n       149, 148, 147, 148, 148, 148, 147, 144, 141, 138, 133, 126, 121,\n       119, 123, 128, 128, 127, 126, 128, 131, 131, 129, 132, 133, 135,\n       138, 134, 138, 139, 141, 142, 142, 141, 143, 143, 144, 146, 146,\n       146, 145, 149, 148, 146, 146, 147, 149, 151, 150, 151, 148, 147,\n       148, 150, 149, 149, 148, 148, 149, 151, 152, 150, 149, 151, 153,\n       150, 151, 150], dtype=uint8), array([4.34090199])], [array([147, 147, 147, 147, 147, 147, 148, 148, 151, 152, 148, 145, 149,\n       149, 146, 148, 147, 147, 148, 146, 148, 148, 151, 149, 147, 148,\n       146, 146, 148, 146, 146, 146, 144, 145, 145, 143, 143, 144, 140,\n       139, 136, 139, 138, 138, 135, 133, 127, 119, 104,  99, 104, 102,\n        90,  72,  75,  89,  99,  99,  99,  99, 101, 101, 105, 106, 109,\n       112, 114, 113, 121, 122, 124, 127, 130, 131, 133, 135, 138, 139,\n       138, 143, 142, 142, 145, 145, 146, 145, 145, 149, 150, 148, 149,\n       148, 149, 150, 148, 149, 148, 148, 150, 148, 149, 146, 147, 148,\n       149, 146, 147, 148, 146, 146, 146, 144, 143, 147, 146, 145, 146,\n       147, 147, 146], dtype=uint8), array([8.52101685])], [array([149, 148, 149, 149, 148, 149, 148, 150, 148, 148, 149, 149, 147,\n       149, 151, 150, 151, 151, 149, 149, 150, 152, 150, 148, 149, 151,\n       150, 147, 148, 148, 149, 149, 151, 151, 151, 148, 147, 148, 146,\n       146, 145, 144, 145, 142, 141, 139, 138, 137, 132, 116, 102, 105,\n       115, 114,  96,  81,  83,  96, 102, 102,  98,  99, 101, 101, 102,\n       105, 107, 109, 112, 117, 119, 120, 125, 126, 126, 126, 131, 133,\n       134, 135, 137, 139, 140, 140, 142, 142, 143, 144, 145, 147, 146,\n       147, 145, 148, 148, 148, 147, 149, 150, 145, 150, 149, 150, 148,\n       149, 147, 150, 148, 148, 148, 149, 147, 147, 149, 148, 148, 149,\n       150, 149, 148], dtype=uint8), array([8.73503977])], [array([148, 148, 147, 147, 147, 148, 148, 148, 146, 149, 148, 147, 148,\n       147, 147, 146, 148, 148, 148, 150, 148, 149, 150, 148, 148, 147,\n       146, 147, 148, 148, 146, 148, 148, 150, 148, 149, 149, 145, 148,\n       147, 147, 149, 150, 149, 147, 148, 149, 148, 146, 147, 148, 148,\n       150, 150, 149, 146, 146, 143, 137, 129, 121, 116, 111, 115, 122,\n       123, 125, 123, 123, 122, 123, 126, 129, 130, 132, 133, 135, 138,\n       140, 138, 141, 144, 146, 146, 146, 146, 146, 145, 146, 150, 148,\n       151, 150, 146, 151, 147, 147, 144, 142, 136, 128, 120, 124, 127,\n       129, 128, 128, 127, 128, 132, 132, 132, 135, 136, 138, 139, 142,\n       145, 140, 142], dtype=uint8), array([4.18356936])], [array([149, 149, 148, 147, 145, 148, 149, 147, 147, 148, 146, 146, 149,\n       151, 149, 148, 147, 147, 148, 148, 148, 151, 151, 149, 149, 149,\n       149, 149, 150, 145, 148, 149, 150, 148, 149, 147, 147, 147, 147,\n       147, 148, 147, 147, 151, 150, 146, 148, 151, 151, 149, 147, 149,\n       150, 150, 150, 148, 150, 150, 149, 149, 146, 144, 139, 132, 123,\n       118, 121, 127, 128, 127, 128, 127, 126, 128, 129, 128, 130, 133,\n       133, 135, 138, 139, 140, 141, 144, 141, 146, 146, 147, 146, 146,\n       146, 146, 147, 147, 150, 151, 149, 149, 149, 150, 148, 147, 149,\n       150, 151, 151, 149, 151, 148, 144, 145, 144, 143, 141, 143, 144,\n       141, 141, 143], dtype=uint8), array([4.35067225])], [array([133, 135, 131, 131, 131, 132, 133, 133, 134, 134, 135, 136, 136,\n       135, 136, 133, 130, 132, 132, 134, 133, 133, 133, 135, 133, 134,\n       133, 134, 135, 135, 134, 134, 135, 134, 134, 136, 136, 134, 134,\n       133, 132, 132, 136, 134, 134, 133, 131, 134, 135, 133, 133, 134,\n       134, 134, 136, 135, 134, 131, 133, 132, 134, 134, 134, 134, 133,\n       133, 132, 132, 134, 132, 129, 130, 133, 133, 131, 127, 128, 131,\n       130, 131, 132, 132, 131, 131, 132, 131, 131, 134, 132, 130, 131,\n       131, 130, 131, 131, 131, 130, 131, 130, 129, 129, 128, 130, 132,\n       131, 129, 131, 131, 130, 132, 132, 130, 131, 131, 128, 130, 128,\n       125, 129, 130], dtype=uint8), array([0.])], [array([140, 143, 142, 140, 141, 141, 142, 139, 140, 140, 140, 140, 142,\n       142, 140, 141, 139, 139, 137, 140, 141, 143, 139, 140, 140, 141,\n       140, 142, 142, 141, 140, 140, 140, 142, 142, 144, 144, 140, 139,\n       138, 141, 139, 141, 140, 138, 139, 137, 138, 140, 141, 137, 139,\n       139, 140, 140, 140, 140, 139, 140, 141, 137, 140, 140, 142, 141,\n       143, 141, 143, 143, 142, 141, 140, 137, 129, 118, 109, 102,  96,\n       100, 110, 116, 118, 119, 118, 117, 117, 117, 118, 116, 119, 120,\n       121, 122, 126, 126, 129, 127, 128, 131, 133, 135, 134, 136, 135,\n       137, 137, 136, 137, 136, 139, 140, 141, 140, 140, 140, 141, 140,\n       142, 140, 141], dtype=uint8), array([4.75818342])], [array([140, 142, 142, 141, 139, 141, 144, 143, 143, 140, 139, 140, 139,\n       139, 139, 141, 140, 140, 140, 141, 141, 139, 138, 139, 139, 138,\n       136, 141, 138, 137, 135, 134, 133, 133, 133, 131, 131, 129, 127,\n       124, 125, 123, 123, 122, 122, 120, 122, 122, 120, 120, 121, 120,\n       121, 123, 123, 121, 120, 116, 113, 119, 127, 134, 138, 142, 141,\n       140, 140, 142, 141, 142, 141, 141, 141, 139, 142, 140, 140, 141,\n       142, 139, 140, 141, 140, 140, 141, 141, 141, 137, 139, 140, 138,\n       138, 139, 138, 137, 136, 136, 135, 134, 134, 136, 136, 136, 137,\n       137, 135, 137, 136, 135, 137, 138, 139, 136, 139, 139, 136, 139,\n       140, 140, 141], dtype=uint8), array([3.84824603])], [array([140, 137, 140, 140, 140, 140, 140, 139, 140, 139, 138, 138, 138,\n       138, 138, 138, 139, 139, 135, 137, 137, 136, 136, 136, 137, 135,\n       137, 136, 136, 138, 134, 133, 135, 135, 134, 134, 135, 135, 135,\n       132, 133, 135, 133, 135, 132, 133, 129, 129, 128, 126, 127, 124,\n       123, 122, 123, 120, 120, 120, 118, 116, 115, 114, 113, 113, 112,\n       112, 115, 111, 105,  95,  91,  94, 101, 106, 115, 125, 131, 132,\n       133, 132, 135, 134, 135, 134, 134, 135, 134, 136, 136, 135, 135,\n       133, 133, 131, 132, 132, 130, 131, 127, 125, 122, 117, 113, 111,\n       109, 110, 113, 120, 124, 126, 130, 133, 132, 134, 131, 133, 135,\n       134, 136, 135], dtype=uint8), array([5.52762087])], [array([138, 140, 139, 139, 140, 138, 137, 139, 141, 142, 140, 138, 142,\n       141, 138, 136, 136, 138, 140, 136, 138, 136, 136, 136, 135, 136,\n       134, 134, 132, 131, 133, 133, 127, 127, 123, 123, 119, 121, 124,\n       118, 115, 114, 113, 115, 111, 107, 108, 108, 107, 108, 111, 113,\n       113, 113, 113, 109, 101,  98, 104, 113, 118, 124, 132, 137, 139,\n       141, 140, 137, 139, 141, 139, 138, 139, 139, 138, 139, 138, 137,\n       137, 138, 137, 134, 135, 135, 137, 137, 136, 135, 134, 135, 134,\n       134, 136, 134, 135, 138, 135, 134, 136, 134, 134, 135, 133, 136,\n       135, 135, 134, 132, 134, 132, 130, 131, 132, 130, 129, 130, 129,\n       128, 128, 127], dtype=uint8), array([5.24173503])], [array([134, 135, 134, 134, 135, 135, 134, 136, 132, 132, 132, 132, 132,\n       132, 131, 133, 132, 130, 130, 132, 130, 129, 126, 128, 127, 126,\n       126, 128, 124, 123, 120, 122, 116, 113, 115, 117, 114, 114, 116,\n       111, 112, 113, 110, 112, 109, 114, 113, 117, 117, 115, 117, 115,\n       116, 114, 110, 107, 109, 118, 125, 132, 135, 135, 133, 134, 134,\n       130, 131, 131, 130, 128, 131, 130, 130, 129, 128, 128, 128, 131,\n       132, 131, 130, 132, 131, 127, 127, 127, 128, 130, 129, 128, 131,\n       131, 128, 128, 127, 128, 128, 127, 129, 129, 130, 129, 127, 127,\n       127, 129, 131, 130, 130, 130, 131, 131, 131, 130, 131, 131, 130,\n       129, 128, 129], dtype=uint8), array([3.48806279])], [array([128, 130, 132, 129, 130, 129, 127, 128, 132, 131, 130, 131, 129,\n       128, 130, 129, 126, 129, 128, 127, 129, 130, 130, 128, 128, 129,\n       128, 129, 129, 131, 129, 127, 129, 131, 128, 131, 131, 130, 128,\n       129, 129, 127, 128, 127, 128, 126, 127, 130, 129, 131, 130, 129,\n       125, 126, 127, 129, 128, 127, 126, 124, 126, 126, 125, 122, 122,\n       123, 124, 123, 121, 122, 121, 122, 119, 117, 115, 107,  98,  95,\n        89,  88,  98, 109, 109, 111, 110, 112, 111, 112, 110, 111, 111,\n       110, 113, 114, 115, 113, 114, 114, 111, 113, 111, 114, 112, 112,\n       111, 110, 111, 111, 112, 111, 112, 109, 111, 111, 111, 110, 110,\n       105,  95,  88], dtype=uint8), array([4.68352392])], [array([131, 129, 129, 128, 130, 129, 128, 128, 129, 129, 130, 131, 129,\n       131, 129, 128, 129, 129, 126, 126, 126, 125, 125, 126, 124, 126,\n       124, 123, 123, 122, 122, 120, 117, 116, 116, 116, 114, 114, 114,\n       110, 100,  91,  89,  92,  94, 100, 109, 115, 115, 115, 117, 118,\n       118, 116, 115, 116, 117, 116, 115, 118, 118, 115, 117, 115, 118,\n       117, 118, 117, 116, 115, 116, 109,  99,  94,  92,  98, 106, 115,\n       122, 123, 123, 124, 126, 125, 127, 129, 131, 129, 129, 132, 130,\n       129, 128, 130, 128, 129, 128, 128, 128, 129, 130, 129, 128, 129,\n       127, 127, 129, 128, 128, 127, 127, 129, 129, 129, 129, 129, 129,\n       130, 129, 129], dtype=uint8), array([4.45399496])], [array([143, 143, 141, 142, 143, 142, 140, 140, 140, 141, 141, 140, 142,\n       141, 141, 144, 142, 141, 144, 144, 142, 143, 143, 141, 142, 139,\n       139, 141, 140, 140, 141, 142, 143, 144, 141, 141, 142, 140, 140,\n       141, 140, 140, 139, 136, 139, 142, 139, 138, 141, 142, 142, 141,\n       139, 139, 139, 142, 140, 138, 140, 140, 139, 137, 140, 138, 141,\n       141, 140, 140, 142, 139, 139, 141, 139, 138, 140, 140, 141, 139,\n       138, 140, 140, 139, 140, 141, 140, 141, 141, 139, 139, 140, 141,\n       139, 137, 139, 141, 141, 138, 136, 137, 139, 141, 139, 139, 140,\n       137, 140, 142, 141, 139, 140, 139, 141, 137, 137, 138, 140, 138,\n       138, 140, 140], dtype=uint8), array([0.])], [array([151, 152, 153, 152, 150, 151, 153, 154, 151, 154, 152, 153, 153,\n       150, 152, 153, 153, 151, 150, 152, 152, 154, 152, 149, 151, 153,\n       150, 152, 153, 152, 154, 152, 150, 153, 152, 149, 148, 151, 152,\n       152, 152, 156, 153, 155, 151, 151, 151, 152, 152, 153, 154, 151,\n       150, 146, 145, 144, 145, 145, 143, 139, 139, 139, 137, 133, 125,\n       113, 102,  98,  99,  97,  87,  82,  87,  98, 106, 108, 108, 113,\n       118, 120, 124, 124, 128, 132, 134, 137, 139, 141, 143, 145, 142,\n       146, 147, 147, 150, 149, 149, 149, 150, 151, 151, 150, 151, 150,\n       151, 153, 152, 151, 153, 152, 151, 150, 152, 150, 151, 153, 153,\n       153, 150, 154], dtype=uint8), array([8.71474618])], [array([152, 153, 153, 151, 154, 152, 151, 155, 153, 154, 159, 153, 153,\n       150, 153, 153, 153, 152, 152, 154, 154, 152, 152, 152, 151, 152,\n       152, 153, 152, 152, 151, 153, 152, 152, 155, 154, 152, 152, 149,\n       152, 152, 150, 147, 149, 150, 150, 151, 152, 149, 152, 150, 147,\n       146, 148, 147, 145, 146, 144, 143, 144, 142, 139, 138, 136, 132,\n       126, 113,  95,  77,  72,  82,  97, 101,  93,  91,  99, 112, 119,\n       120, 123, 125, 127, 128, 130, 136, 136, 138, 140, 142, 141, 142,\n       144, 148, 148, 146, 147, 147, 150, 149, 150, 150, 151, 151, 150,\n       150, 149, 149, 150, 151, 149, 148, 152, 152, 154, 151, 152, 155,\n       152, 151, 152], dtype=uint8), array([9.02551505])], [array([125, 125, 129, 130, 132, 132, 134, 132, 133, 132, 134, 136, 136,\n       139, 138, 141, 142, 140, 140, 140, 141, 143, 143, 146, 145, 145,\n       148, 146, 148, 150, 147, 146, 147, 147, 146, 147, 145, 148, 148,\n       148, 147, 147, 148, 141, 141, 135, 120, 104,  96,  93,  85,  79,\n        83,  93, 100, 104, 104, 108, 112, 115, 119, 122, 126, 128, 130,\n       133, 139, 138, 139, 139, 142, 145, 145, 149, 145, 146, 152, 151,\n       149, 151, 151, 150, 149, 150, 154, 153, 151, 152, 152, 152, 152,\n       150, 153, 153, 151, 151, 152, 150, 150, 147, 153, 152, 151, 151,\n       152, 152, 155, 154, 153, 151, 150, 152, 150, 151, 152, 151, 150,\n       150, 153, 151], dtype=uint8), array([7.32964192])], [array([154, 152, 153, 151, 154, 157, 154, 154, 156, 154, 154, 154, 154,\n       152, 155, 157, 154, 154, 155, 154, 156, 155, 156, 155, 155, 155,\n       152, 156, 152, 153, 154, 155, 154, 153, 150, 150, 148, 142, 143,\n       144, 144, 146, 150, 149, 150, 150, 152, 153, 153, 151, 151, 151,\n       150, 150, 147, 148, 149, 149, 145, 144, 142, 141, 133, 122, 115,\n       112, 109, 112, 121, 126, 128, 133, 133, 138, 140, 140, 141, 144,\n       145, 145, 148, 149, 150, 154, 155, 155, 154, 154, 155, 153, 153,\n       152, 153, 153, 156, 153, 157, 149, 152, 153, 155, 154, 153, 155,\n       155, 154, 155, 155, 158, 155, 154, 153, 154, 151, 153, 155, 155,\n       154, 153, 154], dtype=uint8), array([4.88385177])], [array([152, 151, 150, 151, 150, 153, 150, 150, 153, 150, 152, 151, 151,\n       149, 149, 150, 151, 154, 150, 150, 151, 151, 151, 153, 152, 153,\n       152, 152, 153, 151, 149, 151, 151, 150, 149, 146, 148, 144, 144,\n       138, 135, 137, 139, 142, 147, 149, 149, 148, 148, 144, 146, 146,\n       146, 142, 138, 138, 134, 131, 130, 131, 131, 134, 132, 131, 126,\n       126, 125, 123, 119, 105,  85,  81,  88,  93,  96, 102, 125, 136,\n       138, 139, 141, 144, 144, 146, 148, 149, 149, 146, 146, 151, 149,\n       149, 150, 149, 150, 153, 154, 151, 152, 151, 149, 151, 152, 154,\n       153, 152, 149, 151, 151, 151, 152, 153, 154, 153, 153, 152, 153,\n       153, 153, 153], dtype=uint8), array([6.54541434])], [array([147, 146, 145, 144, 144, 140, 140, 141, 139, 139, 139, 140, 140,\n       135, 133, 133, 130, 127, 123, 115, 110, 105, 106, 111, 121, 129,\n       132, 134, 135, 134, 130, 120, 112, 106, 103, 109, 114, 119, 121,\n       121, 121, 125, 127, 133, 137, 144, 147, 145, 147, 147, 148, 149,\n       148, 148, 149, 149, 147, 147, 148, 145, 144, 144, 141, 141, 140,\n       137, 137, 135, 130, 121, 103,  91,  95,  99,  94,  97, 112, 129,\n       137, 138, 142, 144, 145, 147, 147, 148, 148, 149, 149, 152, 150,\n       154, 153, 154, 153, 151, 153, 151, 153, 155, 157, 154, 153, 155,\n       152, 153, 152, 153, 151, 151, 153, 152, 152, 153, 152, 150, 147,\n       150, 154, 153], dtype=uint8), array([7.03218657])], [array([139, 139, 140, 139, 135, 135, 134, 128, 120, 114, 103, 100, 101,\n       102,  99,  97, 102, 111, 118, 124, 130, 136, 139, 140, 143, 141,\n       142, 142, 142, 145, 142, 146, 145, 145, 146, 148, 150, 149, 149,\n       151, 152, 149, 147, 150, 150, 151, 148, 147, 147, 147, 149, 146,\n       146, 144, 143, 140, 139, 139, 135, 131, 127, 126, 124, 120, 121,\n       120, 119, 115, 105,  91,  90,  95, 100,  95, 103, 121, 134, 140,\n       139, 143, 145, 145, 146, 148, 150, 150, 151, 150, 151, 152, 153,\n       153, 151, 154, 154, 155, 157, 156, 156, 152, 154, 154, 153, 154,\n       154, 153, 152, 153, 152, 153, 154, 153, 154, 153, 154, 151, 150,\n       153, 152, 152], dtype=uint8), array([6.38074043])], [array([146, 141, 143, 146, 145, 143, 146, 146, 145, 145, 145, 146, 144,\n       145, 148, 149, 148, 147, 148, 149, 148, 148, 148, 149, 149, 150,\n       149, 149, 149, 146, 147, 148, 147, 147, 147, 148, 150, 152, 151,\n       150, 152, 152, 149, 148, 147, 148, 147, 146, 151, 150, 150, 147,\n       147, 148, 148, 144, 145, 147, 145, 143, 143, 139, 134, 133, 137,\n       141, 143, 143, 142, 143, 145, 140, 138, 135, 126, 111, 103, 105,\n       108, 114, 125, 138, 147, 146, 151, 149, 150, 149, 146, 150, 149,\n       149, 150, 152, 151, 151, 153, 153, 152, 150, 151, 153, 155, 154,\n       152, 153, 153, 153, 152, 150, 151, 152, 152, 152, 152, 153, 152,\n       152, 152, 152], dtype=uint8), array([5.54238319])], [array([154, 153, 154, 153, 152, 154, 154, 152, 153, 154, 155, 155, 154,\n       157, 156, 154, 152, 154, 155, 155, 152, 153, 153, 154, 152, 151,\n       148, 150, 154, 150, 149, 149, 148, 149, 150, 148, 146, 147, 144,\n       142, 141, 139, 140, 136, 135, 136, 135, 137, 136, 133, 130, 132,\n       135, 140, 143, 148, 146, 143, 145, 146, 147, 148, 149, 148, 146,\n       145, 144, 143, 142, 141, 139, 138, 136, 133, 130, 125, 123, 120,\n       119, 121, 125, 134, 145, 149, 151, 150, 150, 152, 151, 153, 153,\n       153, 149, 150, 151, 149, 146, 148, 144, 143, 145, 146, 141, 143,\n       145, 145, 148, 147, 146, 148, 151, 152, 150, 153, 152, 150, 152,\n       154, 153, 153], dtype=uint8), array([4.58639866])], [array([154, 154, 157, 156, 156, 154, 152, 157, 156, 156, 156, 156, 157,\n       155, 155, 156, 156, 156, 155, 154, 155, 155, 155, 155, 155, 154,\n       155, 155, 154, 155, 154, 154, 152, 154, 155, 155, 155, 154, 154,\n       153, 156, 155, 154, 154, 153, 151, 151, 151, 150, 149, 146, 140,\n       134, 127, 118, 106,  98, 101, 111, 123, 123, 124, 124, 127, 124,\n       128, 132, 136, 138, 140, 141, 144, 149, 149, 149, 151, 150, 150,\n       153, 155, 154, 155, 156, 157, 156, 157, 157, 154, 156, 156, 157,\n       155, 157, 158, 156, 155, 156, 157, 157, 155, 155, 156, 156, 156,\n       157, 158, 158, 158, 156, 156, 155, 156, 155, 155, 155, 157, 152,\n       152, 154, 155], dtype=uint8), array([5.4984222])], [array([143, 142, 140, 136, 141, 138, 135, 125, 110,  99,  89,  85,  79,\n        79,  81,  84,  93, 101, 109, 116, 120, 124, 126, 124, 124, 129,\n       133, 136, 139, 143, 143, 144, 144, 144, 142, 145, 147, 146, 145,\n       145, 145, 147, 144, 147, 150, 145, 146, 147, 148, 148, 148, 148,\n       148, 149, 148, 147, 146, 145, 147, 146, 145, 146, 146, 144, 140,\n       134, 124, 112, 108, 109, 106,  95,  85,  84,  91, 101, 104, 107,\n       108, 112, 114, 117, 121, 123, 127, 130, 133, 135, 139, 141, 141,\n       141, 144, 145, 149, 151, 149, 151, 151, 151, 150, 149, 151, 151,\n       149, 149, 150, 152, 152, 155, 154, 154, 152, 153, 151, 154, 152,\n       151, 152, 151], dtype=uint8), array([8.81468908])], [array([155, 154, 152, 152, 152, 153, 154, 154, 153, 150, 152, 153, 152,\n       153, 152, 152, 152, 153, 152, 152, 153, 154, 151, 151, 153, 153,\n       153, 155, 154, 153, 153, 153, 153, 153, 152, 151, 150, 153, 154,\n       152, 153, 152, 155, 155, 155, 155, 151, 150, 152, 150, 152, 153,\n       150, 152, 152, 151, 152, 148, 149, 150, 148, 149, 148, 148, 145,\n       146, 144, 147, 144, 143, 143, 142, 142, 140, 135, 127, 108,  83,\n        76,  76,  83, 105, 130, 137, 142, 144, 145, 146, 148, 148, 148,\n       149, 150, 150, 154, 152, 150, 152, 152, 151, 154, 152, 153, 153,\n       153, 151, 153, 152, 155, 151, 151, 149, 152, 153, 152, 153, 149,\n       151, 155, 153], dtype=uint8), array([5.09065576])], [array([132, 133, 132, 133, 134, 131, 131, 134, 134, 132, 132, 131, 134,\n       135, 133, 134, 133, 133, 131, 132, 131, 135, 133, 133, 134, 136,\n       136, 135, 133, 133, 134, 133, 132, 132, 134, 134, 132, 135, 134,\n       135, 134, 134, 136, 135, 133, 133, 136, 134, 134, 131, 132, 132,\n       132, 136, 132, 131, 134, 134, 132, 135, 136, 134, 135, 137, 135,\n       136, 136, 135, 135, 139, 136, 136, 138, 137, 137, 138, 137, 136,\n       136, 137, 137, 136, 136, 136, 135, 137, 137, 136, 137, 134, 135,\n       134, 134, 133, 135, 132, 133, 133, 134, 136, 137, 135, 133, 137,\n       137, 135, 134, 135, 135, 135, 135, 135, 135, 136, 136, 136, 137,\n       136, 136, 135], dtype=uint8), array([0.])], [array([148, 149, 149, 149, 149, 148, 149, 149, 149, 149, 150, 150, 148,\n       148, 148, 148, 150, 150, 147, 147, 148, 146, 148, 148, 149, 145,\n       146, 148, 149, 150, 148, 149, 149, 151, 151, 150, 149, 146, 148,\n       148, 152, 149, 146, 146, 147, 147, 148, 150, 150, 152, 151, 150,\n       147, 149, 149, 148, 148, 148, 149, 146, 144, 146, 141, 127, 114,\n       103,  93,  90,  99, 114, 121, 123, 124, 126, 125, 127, 128, 131,\n       133, 135, 136, 136, 137, 139, 141, 143, 144, 143, 144, 144, 146,\n       147, 146, 147, 149, 147, 148, 148, 145, 147, 147, 147, 148, 149,\n       147, 147, 147, 152, 148, 147, 148, 146, 145, 140, 137, 131, 124,\n       115, 114, 122], dtype=uint8), array([4.42544194])], [array([146, 147, 148, 147, 149, 147, 148, 149, 148, 150, 149, 148, 147,\n       149, 149, 148, 148, 149, 148, 148, 148, 150, 150, 148, 146, 149,\n       151, 151, 149, 150, 151, 148, 149, 148, 151, 150, 150, 149, 150,\n       149, 148, 149, 148, 148, 147, 144, 141, 135, 125, 119, 114, 109,\n       111, 120, 130, 132, 134, 137, 140, 141, 144, 143, 144, 147, 146,\n       145, 146, 148, 146, 145, 141, 135, 126, 114, 100,  98, 107, 120,\n       124, 124, 123, 122, 124, 125, 126, 129, 129, 132, 132, 137, 138,\n       138, 142, 143, 145, 146, 145, 143, 144, 144, 150, 147, 146, 146,\n       150, 149, 150, 151, 151, 150, 150, 150, 149, 148, 149, 150, 150,\n       149, 149, 149], dtype=uint8), array([4.45399496])], [array([130, 131, 132, 133, 134, 134, 134, 133, 135, 135, 135, 138, 136,\n       137, 134, 138, 138, 142, 140, 141, 142, 145, 144, 143, 143, 144,\n       144, 142, 143, 143, 145, 145, 145, 146, 146, 147, 149, 147, 150,\n       150, 146, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 148,\n       148, 149, 149, 148, 149, 150, 149, 149, 151, 149, 147, 146, 148,\n       148, 148, 149, 148, 150, 148, 148, 148, 145, 145, 142, 130, 118,\n       108,  95,  92, 107, 120, 123, 125, 130, 131, 131, 132, 134, 137,\n       140, 140, 141, 142, 142, 144, 147, 146, 146, 145, 146, 147, 147,\n       148, 150, 149, 148, 148, 148, 147, 149, 149, 148, 143, 131, 117,\n       106,  96,  87], dtype=uint8), array([4.68352392])], [array([148, 148, 148, 147, 147, 149, 151, 149, 148, 147, 147, 148, 147,\n       147, 146, 147, 148, 149, 148, 148, 148, 145, 143, 147, 147, 147,\n       147, 151, 149, 146, 146, 142, 139, 145, 146, 147, 148, 151, 151,\n       147, 147, 149, 151, 148, 145, 145, 144, 145, 144, 143, 140, 133,\n       122, 113, 111, 116, 127, 134, 135, 134, 133, 133, 135, 136, 136,\n       136, 135, 133, 132, 132, 137, 137, 138, 139, 140, 139, 141, 140,\n       140, 144, 143, 143, 146, 146, 145, 146, 146, 145, 147, 148, 146,\n       147, 145, 146, 145, 148, 150, 150, 146, 150, 150, 149, 150, 149,\n       147, 148, 150, 148, 147, 149, 149, 148, 147, 149, 152, 149, 147,\n       145, 148, 147], dtype=uint8), array([3.48806279])], [array([136, 137, 136, 139, 145, 143, 141, 145, 146, 144, 143, 144, 145,\n       148, 145, 147, 149, 148, 148, 144, 147, 149, 150, 149, 147, 147,\n       149, 149, 148, 148, 146, 146, 147, 147, 151, 147, 149, 147, 147,\n       148, 149, 148, 147, 148, 150, 149, 147, 147, 146, 148, 149, 149,\n       147, 149, 147, 146, 148, 147, 150, 147, 147, 146, 146, 148, 148,\n       146, 148, 147, 151, 148, 146, 146, 140, 129, 114, 106,  94,  89,\n        99, 112, 119, 118, 117, 119, 121, 120, 124, 125, 127, 130, 133,\n       134, 135, 138, 139, 140, 143, 142, 143, 143, 144, 147, 147, 146,\n       147, 148, 147, 150, 146, 148, 149, 151, 149, 147, 147, 144, 150,\n       152, 148, 149], dtype=uint8), array([5.52762087])], [array([147, 145, 144, 146, 146, 146, 146, 148, 148, 148, 147, 146, 147,\n       148, 150, 148, 147, 145, 145, 146, 146, 146, 146, 146, 146, 147,\n       147, 147, 146, 146, 147, 148, 147, 146, 146, 146, 145, 146, 145,\n       139, 130, 122, 117, 122, 131, 138, 141, 142, 144, 146, 147, 144,\n       145, 143, 138, 128, 118, 116, 112, 101,  95, 102, 110, 113, 110,\n       109, 111, 111, 111, 113, 116, 120, 123, 124, 127, 130, 131, 134,\n       136, 138, 137, 137, 140, 142, 143, 145, 144, 145, 146, 146, 145,\n       145, 148, 148, 147, 144, 145, 147, 147, 148, 147, 146, 147, 146,\n       145, 146, 148, 148, 147, 148, 148, 146, 149, 147, 147, 149, 146,\n       146, 147, 147], dtype=uint8), array([5.24173503])], [array([148, 147, 146, 146, 149, 146, 148, 146, 148, 146, 149, 147, 147,\n       145, 145, 142, 147, 147, 147, 147, 143, 144, 144, 141, 143, 143,\n       141, 136, 131, 133, 137, 138, 140, 143, 145, 144, 146, 146, 144,\n       145, 145, 144, 146, 147, 147, 146, 144, 143, 144, 144, 142, 143,\n       146, 144, 141, 140, 139, 142, 137, 134, 136, 133, 130, 129, 127,\n       126, 126, 126, 125, 122, 123, 121, 119, 120, 118, 104,  97,  98,\n       100, 108, 124, 136, 140, 141, 142, 145, 144, 144, 147, 145, 147,\n       145, 143, 146, 144, 147, 146, 145, 145, 148, 146, 144, 144, 147,\n       147, 147, 146, 147, 148, 147, 149, 149, 146, 149, 145, 145, 145,\n       145, 145, 146], dtype=uint8), array([4.75818342])], [array([143, 143, 143, 143, 145, 145, 144, 143, 143, 141, 142, 144, 143,\n       143, 146, 145, 144, 144, 145, 145, 144, 143, 144, 142, 144, 148,\n       145, 147, 145, 145, 144, 147, 146, 146, 144, 140, 141, 143, 142,\n       145, 142, 144, 145, 143, 148, 145, 144, 143, 146, 148, 146, 146,\n       146, 146, 142, 139, 134, 121, 110, 107, 113, 118, 118, 121, 121,\n       122, 122, 121, 120, 122, 124, 125, 126, 129, 132, 134, 135, 136,\n       137, 139, 141, 142, 143, 144, 144, 144, 143, 143, 144, 145, 144,\n       147, 147, 146, 150, 148, 147, 147, 146, 145, 144, 148, 150, 147,\n       145, 145, 144, 144, 148, 147, 145, 139, 139, 139, 137, 136, 135,\n       133, 133, 136], dtype=uint8), array([3.84824603])], [array([139, 141, 141, 140, 140, 142, 140, 139, 139, 138, 136, 138, 137,\n       136, 138, 138, 138, 137, 138, 137, 138, 138, 137, 137, 138, 137,\n       137, 138, 141, 139, 138, 140, 140, 138, 137, 139, 139, 139, 139,\n       141, 138, 140, 141, 139, 142, 142, 140, 143, 141, 143, 141, 142,\n       142, 143, 144, 144, 142, 140, 140, 138, 139, 136, 128, 119, 116,\n       116, 109,  99,  97, 104, 107, 106, 102, 100,  97,  96,  97,  98,\n       102, 103, 106, 109, 111, 115, 116, 115, 118, 122, 124, 126, 127,\n       130, 130, 133, 135, 137, 136, 136, 139, 139, 138, 142, 139, 142,\n       142, 142, 141, 142, 141, 140, 143, 142, 139, 141, 143, 142, 144,\n       143, 145, 144], dtype=uint8), array([6.3266849])], [array([114, 115, 119, 120, 122, 124, 125, 122, 124, 125, 127, 128, 126,\n       127, 131, 129, 129, 130, 131, 132, 133, 135, 134, 137, 136, 138,\n       135, 138, 139, 139, 139, 140, 141, 141, 137, 139, 139, 139, 139,\n       142, 142, 142, 140, 139, 139, 138, 140, 140, 141, 141, 140, 140,\n       138, 137, 137, 137, 137, 134, 126, 119, 115, 116, 118, 125, 130,\n       131, 129, 128, 127, 127, 127, 125, 124, 115, 104,  94,  92,  84,\n        78,  86, 100, 106, 108, 110, 111, 113, 116, 118, 122, 124, 125,\n       129, 128, 131, 130, 133, 135, 137, 136, 137, 139, 140, 140, 139,\n       142, 142, 142, 143, 142, 142, 144, 147, 144, 143, 143, 144, 143,\n       142, 145, 145], dtype=uint8), array([5.48232787])], [array([116, 117, 120, 117, 118, 121, 121, 122, 121, 125, 125, 123, 124,\n       124, 126, 126, 129, 130, 129, 131, 129, 130, 131, 131, 130, 133,\n       134, 130, 132, 133, 132, 138, 137, 135, 137, 134, 134, 129, 132,\n       134, 137, 135, 138, 139, 136, 135, 139, 137, 137, 135, 135, 136,\n       139, 134, 134, 136, 137, 140, 139, 138, 141, 141, 140, 138, 140,\n       137, 143, 141, 141, 143, 142, 140, 143, 140, 136, 128, 117, 106,\n        97,  91, 100, 107, 110, 108, 112, 112, 108, 111, 111, 111, 115,\n       116, 115, 119, 117, 125, 121, 125, 126, 124, 127, 129, 130, 135,\n       133, 138, 138, 137, 139, 136, 136, 139, 138, 140, 140, 142, 138,\n       138, 142, 141], dtype=uint8), array([4.22418291])], [array([148, 148, 151, 151, 149, 148, 151, 151, 149, 148, 150, 149, 148,\n       150, 148, 149, 149, 148, 145, 146, 150, 149, 146, 147, 146, 147,\n       148, 149, 149, 152, 150, 149, 149, 150, 149, 148, 149, 146, 148,\n       149, 150, 148, 147, 148, 148, 149, 149, 150, 148, 148, 149, 148,\n       150, 150, 148, 149, 150, 150, 150, 148, 149, 148, 149, 149, 148,\n       147, 150, 150, 150, 152, 151, 148, 149, 148, 149, 150, 150, 148,\n       149, 148, 151, 151, 149, 152, 149, 146, 150, 150, 150, 150, 151,\n       149, 149, 146, 149, 149, 150, 149, 150, 150, 152, 149, 151, 147,\n       145, 146, 148, 148, 146, 146, 149, 147, 147, 153, 148, 147, 149,\n       148, 149, 148], dtype=uint8), array([0.])], [array([145, 144, 146, 147, 147, 145, 145, 142, 145, 147, 147, 146, 146,\n       145, 146, 146, 146, 145, 145, 145, 146, 146, 145, 147, 148, 146,\n       146, 148, 147, 145, 145, 146, 147, 145, 146, 144, 143, 145, 147,\n       148, 146, 145, 144, 146, 146, 146, 144, 144, 145, 146, 147, 147,\n       147, 148, 148, 147, 146, 148, 144, 146, 146, 146, 145, 145, 143,\n       137, 128, 118, 111, 113, 118, 124, 123, 123, 123, 124, 125, 122,\n       125, 129, 129, 128, 132, 133, 134, 139, 140, 139, 142, 143, 143,\n       143, 143, 143, 145, 148, 145, 144, 146, 152, 148, 146, 146, 148,\n       147, 146, 148, 146, 149, 147, 150, 149, 148, 148, 148, 147, 148,\n       146, 148, 148], dtype=uint8), array([3.71157107])], [array([144, 145, 144, 144, 148, 146, 145, 148, 146, 147, 148, 145, 146,\n       146, 144, 148, 146, 145, 145, 143, 146, 148, 148, 144, 146, 143,\n       146, 147, 145, 144, 145, 145, 146, 148, 146, 144, 145, 144, 145,\n       144, 141, 142, 139, 139, 139, 136, 135, 137, 138, 143, 144, 144,\n       145, 143, 145, 144, 145, 144, 146, 145, 144, 145, 145, 142, 141,\n       144, 140, 138, 141, 139, 137, 131, 126, 113, 101, 102,  97,  98,\n       113, 122, 123, 126, 126, 126, 130, 130, 129, 133, 135, 137, 137,\n       138, 140, 144, 143, 144, 145, 146, 145, 143, 142, 145, 145, 146,\n       145, 144, 144, 146, 148, 147, 147, 149, 147, 148, 149, 149, 147,\n       146, 146, 145], dtype=uint8), array([4.08382213])], [array([150, 149, 148, 147, 147, 149, 147, 149, 148, 144, 145, 147, 146,\n       146, 149, 148, 147, 149, 149, 149, 147, 149, 147, 146, 148, 148,\n       147, 147, 146, 148, 145, 146, 144, 144, 147, 148, 145, 143, 143,\n       145, 143, 138, 137, 136, 135, 131, 127, 112, 102,  99, 106, 123,\n       135, 137, 140, 142, 143, 146, 146, 147, 149, 149, 148, 148, 147,\n       146, 147, 147, 146, 148, 150, 148, 146, 147, 148, 147, 144, 148,\n       144, 148, 149, 149, 150, 151, 149, 148, 147, 147, 148, 150, 149,\n       146, 146, 147, 149, 147, 149, 147, 146, 145, 147, 149, 147, 145,\n       143, 143, 142, 142, 140, 142, 138, 135, 133, 128, 122, 117, 112,\n       111, 112, 117], dtype=uint8), array([3.69767209])], [array([141, 142, 142, 143, 143, 143, 141, 141, 141, 143, 143, 143, 144,\n       141, 143, 143, 142, 142, 141, 134, 125, 121, 118, 118, 123, 127,\n       127, 130, 130, 125, 123, 122, 119, 118, 113, 110, 110, 106, 107,\n       102,  99,  98,  99, 102, 107, 112, 117, 121, 125, 127, 127, 126,\n       128, 130, 130, 129, 130, 129, 132, 134, 136, 134, 136, 135, 134,\n       136, 137, 139, 140, 129, 119, 110,  97,  95, 103, 111, 115, 114,\n       114, 113, 114, 110, 110, 112, 114, 116, 115, 120, 120, 122, 122,\n       126, 126, 127, 128, 130, 134, 133, 136, 137, 137, 140, 140, 139,\n       139, 141, 143, 141, 142, 141, 144, 144, 141, 141, 142, 142, 142,\n       144, 144, 139], dtype=uint8), array([4.18255064])], [array([148, 145, 145, 145, 145, 146, 146, 145, 148, 147, 147, 146, 147,\n       145, 147, 148, 146, 148, 145, 144, 144, 148, 148, 149, 147, 145,\n       144, 144, 146, 147, 146, 145, 148, 146, 145, 146, 144, 145, 145,\n       144, 147, 146, 145, 138, 141, 143, 142, 142, 141, 138, 138, 135,\n       133, 132, 130, 130, 130, 128, 128, 125, 122, 121, 116, 113, 113,\n       112, 110, 111, 108, 103,  84,  71,  73,  79,  76,  74,  90, 113,\n       126, 126, 128, 133, 132, 134, 136, 140, 140, 140, 138, 141, 145,\n       146, 145, 143, 147, 149, 147, 146, 148, 145, 146, 146, 145, 146,\n       146, 144, 146, 144, 145, 144, 144, 145, 145, 145, 144, 144, 146,\n       144, 144, 143], dtype=uint8), array([9.01671984])], [array([115, 117, 124, 124, 126, 127, 126, 127, 128, 127, 127, 127, 127,\n       126, 124, 125, 128, 126, 126, 128, 125, 125, 125, 125, 125, 123,\n       123, 119, 118, 119, 121, 122, 123, 120, 119, 122, 121, 121, 120,\n       120, 119, 117, 114, 112, 107, 102, 102, 101, 107, 111, 115, 118,\n       119, 121, 124, 127, 127, 126, 127, 126, 127, 128, 126, 121, 115,\n       112, 116, 110, 110, 121, 132, 137, 138, 140, 139, 141, 142, 144,\n       141, 143, 142, 142, 144, 145, 143, 146, 143, 141, 142, 141, 141,\n       140, 141, 141, 142, 142, 142, 141, 138, 137, 141, 141, 143, 143,\n       142, 143, 146, 144, 139, 140, 140, 142, 144, 141, 141, 146, 143,\n       141, 142, 140], dtype=uint8), array([6.47364817])], [array([140, 143, 144, 143, 142, 141, 143, 143, 142, 141, 140, 141, 142,\n       143, 140, 141, 140, 142, 144, 142, 142, 143, 141, 139, 141, 141,\n       142, 141, 142, 142, 141, 143, 142, 143, 142, 142, 143, 141, 141,\n       141, 144, 145, 144, 144, 144, 141, 144, 143, 141, 142, 144, 143,\n       143, 142, 141, 142, 144, 144, 144, 145, 144, 143, 143, 145, 145,\n       143, 146, 145, 145, 144, 143, 144, 138, 133, 120, 111, 102, 103,\n       113, 119, 118, 120, 124, 123, 123, 124, 123, 124, 124, 126, 124,\n       126, 128, 129, 129, 134, 133, 133, 136, 136, 136, 137, 138, 138,\n       139, 141, 141, 141, 140, 141, 141, 142, 139, 141, 142, 141, 142,\n       144, 143, 145], dtype=uint8), array([4.51710674])], [array([151, 149, 149, 150, 150, 151, 150, 147, 149, 148, 150, 150, 150,\n       148, 148, 146, 148, 152, 148, 147, 146, 146, 145, 144, 144, 145,\n       147, 148, 148, 147, 147, 148, 146, 146, 148, 148, 149, 148, 150,\n       150, 149, 146, 149, 148, 150, 149, 155, 151, 150, 147, 145, 147,\n       147, 148, 146, 149, 149, 150, 148, 147, 150, 149, 146, 146, 147,\n       149, 149, 148, 148, 148, 148, 148, 147, 146, 145, 142, 136, 131,\n       133, 134, 137, 135, 135, 136, 137, 138, 137, 136, 138, 141, 141,\n       145, 143, 143, 145, 146, 144, 146, 145, 145, 146, 147, 148, 149,\n       147, 149, 150, 149, 148, 147, 149, 148, 146, 148, 150, 148, 145,\n       147, 148, 147], dtype=uint8), array([4.88037655])], [array([145, 146, 147, 148, 149, 149, 148, 149, 150, 147, 147, 148, 147,\n       147, 147, 146, 145, 147, 147, 146, 146, 146, 147, 149, 148, 149,\n       146, 149, 146, 148, 147, 146, 146, 145, 146, 147, 148, 151, 148,\n       148, 147, 146, 149, 147, 147, 146, 147, 147, 148, 146, 146, 145,\n       145, 144, 144, 146, 147, 145, 144, 146, 145, 143, 144, 144, 143,\n       146, 146, 143, 145, 146, 145, 143, 141, 141, 143, 145, 144, 143,\n       143, 145, 146, 145, 144, 144, 144, 143, 143, 142, 140, 139, 140,\n       142, 144, 146, 148, 146, 147, 148, 149, 149, 148, 148, 148, 145,\n       146, 148, 148, 150, 149, 147, 146, 146, 145, 145, 142, 144, 146,\n       146, 147, 146], dtype=uint8), array([4.75318777])], [array([145, 145, 145, 147, 146, 145, 146, 147, 146, 146, 146, 143, 145,\n       147, 144, 143, 143, 143, 142, 142, 142, 141, 140, 138, 136, 137,\n       133, 133, 132, 132, 129, 128, 125, 124, 123, 120, 121, 120, 120,\n       120, 120, 120, 119, 121, 119, 110,  98,  96, 104, 114, 123, 136,\n       142, 143, 143, 141, 143, 145, 143, 146, 141, 144, 149, 147, 145,\n       145, 146, 145, 144, 146, 145, 146, 147, 147, 146, 144, 145, 145,\n       146, 148, 145, 146, 146, 145, 145, 146, 143, 145, 144, 145, 145,\n       146, 145, 145, 148, 147, 145, 144, 145, 144, 144, 148, 145, 143,\n       144, 143, 143, 142, 143, 144, 143, 144, 142, 145, 147, 148, 146,\n       145, 145, 144], dtype=uint8), array([4.67930649])], [array([146, 146, 144, 144, 145, 144, 147, 145, 145, 148, 147, 147, 146,\n       145, 143, 145, 145, 143, 145, 146, 146, 145, 146, 145, 145, 145,\n       147, 147, 146, 148, 143, 144, 144, 144, 143, 144, 143, 142, 141,\n       143, 143, 141, 144, 144, 143, 143, 143, 146, 145, 144, 144, 145,\n       143, 143, 142, 144, 142, 140, 140, 138, 140, 139, 136, 136, 136,\n       133, 133, 125, 120, 118, 119, 126, 129, 132, 130, 134, 134, 134,\n       132, 133, 135, 135, 139, 138, 138, 141, 141, 142, 142, 145, 144,\n       143, 144, 146, 142, 141, 142, 144, 142, 143, 145, 146, 145, 145,\n       145, 145, 147, 150, 147, 144, 144, 145, 144, 145, 144, 146, 144,\n       147, 146, 143], dtype=uint8), array([3.66342182])], [array([129, 130, 129, 133, 130, 131, 129, 128, 130, 130, 130, 130, 129,\n       128, 129, 130, 131, 130, 129, 130, 131, 130, 127, 128, 129, 131,\n       129, 128, 132, 132, 131, 131, 128, 130, 130, 130, 132, 131, 129,\n       130, 131, 129, 128, 126, 130, 131, 128, 128, 130, 128, 129, 130,\n       128, 127, 129, 129, 130, 131, 129, 126, 126, 128, 128, 126, 125,\n       124, 124, 123, 121, 121, 118, 114, 111, 103,  95,  96, 102,  99,\n        83,  66,  65,  71,  67,  65,  68,  72,  78,  78,  80,  81,  82,\n        84,  84,  86,  91,  92,  95,  99, 102, 105, 106, 107, 108, 107,\n       110, 111, 113, 116, 117, 118, 118, 120, 121, 123, 124, 126, 126,\n       125, 127, 127], dtype=uint8), array([11.24816955])], [array([131, 134, 133, 136, 136, 134, 132, 135, 135, 135, 134, 132, 132,\n       134, 134, 131, 131, 131, 130, 130, 126, 125, 124, 122, 123, 123,\n       121, 119, 119, 118, 116, 117, 115, 114, 112, 110, 111, 111, 112,\n       112, 112, 113, 114, 116, 118, 116, 115, 113, 103,  96, 105, 116,\n       122, 129, 139, 138, 140, 141, 138, 138, 138, 137, 136, 137, 135,\n       137, 136, 136, 133, 133, 132, 132, 133, 134, 134, 134, 134, 133,\n       132, 132, 132, 132, 132, 134, 132, 132, 132, 133, 132, 132, 134,\n       131, 131, 130, 129, 130, 131, 131, 133, 134, 133, 136, 132, 131,\n       131, 131, 130, 131, 131, 131, 130, 133, 132, 131, 132, 131, 131,\n       132, 134, 131], dtype=uint8), array([5.29607184])], [array([135, 135, 135, 136, 134, 133, 132, 133, 135, 136, 137, 135, 135,\n       135, 132, 133, 130, 129, 129, 132, 130, 131, 130, 132, 128, 128,\n       124, 123, 125, 124, 121, 118, 118, 118, 117, 115, 112, 110, 109,\n       109, 107, 103, 104, 104, 103, 103, 105, 104, 104, 104, 101,  97,\n        88,  84,  90, 103, 116, 127, 137, 137, 136, 135, 136, 137, 136,\n       138, 138, 136, 136, 135, 136, 138, 135, 133, 134, 134, 135, 134,\n       136, 137, 131, 135, 133, 135, 135, 134, 134, 131, 132, 134, 132,\n       131, 131, 133, 131, 128, 128, 126, 127, 126, 126, 123, 125, 128,\n       127, 126, 127, 125, 128, 129, 131, 131, 131, 132, 133, 131, 132,\n       132, 130, 130], dtype=uint8), array([5.46791157])], [array([135, 133, 134, 135, 134, 133, 133, 132, 135, 135, 134, 133, 135,\n       135, 135, 134, 134, 132, 133, 132, 130, 130, 129, 131, 130, 128,\n       128, 127, 125, 125, 123, 122, 121, 120, 120, 117, 114, 114, 113,\n       113, 112, 110, 109, 108, 107, 107, 105, 104, 105, 108, 108, 109,\n       109, 110, 111, 103,  94,  91,  96, 108, 119, 130, 135, 135, 135,\n       136, 134, 135, 135, 134, 136, 136, 134, 133, 136, 135, 137, 135,\n       135, 135, 134, 135, 135, 133, 134, 134, 134, 134, 136, 134, 133,\n       134, 135, 136, 135, 134, 137, 136, 133, 135, 134, 134, 133, 132,\n       133, 133, 134, 133, 133, 134, 135, 134, 133, 134, 135, 134, 133,\n       131, 130, 125], dtype=uint8), array([5.45620238])], [array([143, 147, 149, 149, 146, 147, 147, 144, 144, 145, 145, 146, 146,\n       144, 145, 144, 144, 145, 144, 144, 145, 146, 146, 148, 150, 148,\n       149, 151, 150, 147, 147, 145, 144, 147, 148, 148, 147, 146, 144,\n       144, 144, 144, 144, 143, 144, 144, 145, 147, 147, 146, 147, 148,\n       147, 147, 148, 148, 147, 150, 150, 148, 150, 148, 148, 150, 148,\n       148, 149, 149, 149, 147, 149, 150, 149, 148, 148, 147, 145, 144,\n       145, 148, 149, 149, 150, 149, 147, 148, 148, 148, 149, 148, 148,\n       148, 149, 148, 147, 147, 148, 147, 147, 147, 148, 148, 148, 148,\n       147, 147, 148, 148, 148, 148, 146, 146, 148, 149, 149, 149, 147,\n       147, 147, 147], dtype=uint8), array([0.])], [array([110, 119, 129, 136, 136, 137, 139, 142, 143, 145, 145, 145, 146,\n       146, 148, 148, 147, 147, 149, 149, 148, 150, 150, 149, 151, 151,\n       149, 150, 151, 148, 150, 149, 150, 152, 150, 150, 148, 151, 152,\n       151, 151, 152, 152, 151, 150, 151, 150, 150, 153, 151, 149, 151,\n       151, 151, 151, 150, 151, 150, 148, 150, 151, 150, 147, 146, 146,\n       147, 147, 146, 144, 143, 139, 122, 101,  85,  82,  78,  68,  54,\n        48,  52,  58,  64,  71,  78,  83,  88,  93,  93,  97, 102, 107,\n       107, 108, 111, 116, 118, 121, 122, 126, 130, 132, 132, 137, 139,\n       139, 138, 142, 143, 142, 145, 147, 146, 144, 146, 147, 148, 147,\n       148, 148, 150], dtype=uint8), array([11.65322989])], [array([149, 149, 148, 149, 148, 148, 152, 148, 152, 150, 148, 151, 149,\n       149, 153, 151, 148, 150, 148, 149, 148, 149, 147, 147, 147, 148,\n       147, 148, 148, 152, 151, 150, 149, 151, 148, 152, 148, 150, 151,\n       150, 148, 147, 148, 145, 148, 146, 148, 149, 147, 150, 149, 150,\n       151, 152, 151, 150, 149, 149, 149, 148, 149, 146, 146, 145, 143,\n       142, 143, 136, 135, 128, 125, 116, 109,  94,  74,  60,  55,  52,\n        48,  56,  67,  80,  93, 100, 102, 103, 107, 114, 115, 118, 121,\n       124, 125, 127, 129, 129, 132, 133, 138, 139, 140, 139, 143, 146,\n       146, 147, 150, 148, 147, 149, 147, 148, 147, 148, 150, 150, 150,\n       149, 151, 151], dtype=uint8), array([11.24816955])], [array([150, 151, 149, 150, 149, 148, 149, 151, 149, 151, 152, 148, 146,\n       149, 146, 147, 149, 150, 153, 152, 150, 149, 151, 148, 148, 149,\n       149, 149, 148, 149, 149, 150, 149, 149, 148, 148, 149, 148, 148,\n       148, 150, 148, 148, 149, 148, 146, 147, 149, 146, 146, 144, 142,\n       143, 142, 138, 139, 136, 135, 132, 131, 123, 110,  99, 100, 103,\n       106, 110, 105,  91,  85, 101, 110, 123, 135, 141, 141, 144, 144,\n       149, 147, 146, 146, 148, 148, 145, 145, 143, 149, 147, 147, 149,\n       149, 147, 148, 147, 151, 148, 148, 149, 148, 149, 148, 148, 148,\n       149, 149, 149, 150, 149, 149, 146, 147, 148, 148, 148, 147, 146,\n       146, 148, 146], dtype=uint8), array([5.29607184])], [array([152, 155, 155, 154, 151, 151, 150, 152, 150, 149, 149, 150, 150,\n       152, 151, 151, 152, 151, 150, 152, 152, 151, 152, 151, 153, 153,\n       151, 150, 149, 151, 153, 155, 154, 152, 153, 150, 154, 152, 152,\n       152, 150, 150, 153, 150, 150, 153, 148, 147, 147, 143, 133, 113,\n       103,  90,  85, 100, 114, 119, 122, 122, 123, 126, 129, 131, 135,\n       138, 139, 140, 142, 144, 145, 147, 148, 148, 149, 152, 153, 147,\n       150, 152, 151, 154, 152, 150, 148, 152, 149, 151, 151, 152, 153,\n       150, 149, 148, 147, 149, 150, 149, 147, 148, 148, 147, 148, 149,\n       147, 148, 150, 150, 150, 151, 151, 152, 150, 150, 149, 151, 154,\n       153, 156, 152], dtype=uint8), array([5.46791157])], [array([150, 149, 148, 149, 149, 149, 151, 151, 151, 152, 150, 151, 150,\n       150, 150, 151, 152, 152, 152, 150, 150, 150, 149, 148, 148, 149,\n       147, 148, 149, 149, 144, 145, 146, 143, 146, 147, 149, 150, 150,\n       151, 153, 152, 150, 151, 151, 151, 151, 150, 150, 150, 148, 147,\n       145, 139, 125, 111,  98,  86,  78,  93, 109, 111, 115, 119, 121,\n       123, 128, 130, 128, 132, 132, 136, 139, 142, 141, 145, 145, 147,\n       148, 151, 149, 149, 148, 151, 150, 148, 148, 151, 152, 149, 147,\n       145, 149, 151, 150, 151, 150, 151, 153, 152, 152, 151, 150, 149,\n       152, 151, 152, 151, 150, 153, 149, 153, 150, 151, 150, 148, 149,\n       151, 152, 150], dtype=uint8), array([5.45620238])], [array([153, 153, 152, 152, 153, 151, 151, 151, 154, 154, 153, 151, 151,\n       152, 153, 155, 152, 152, 152, 152, 153, 152, 152, 153, 153, 153,\n       151, 153, 152, 152, 151, 152, 151, 150, 149, 151, 150, 150, 153,\n       152, 148, 149, 148, 152, 153, 148, 151, 152, 154, 150, 153, 150,\n       157, 153, 154, 151, 150, 150, 154, 154, 153, 150, 152, 150, 150,\n       150, 150, 147, 149, 153, 153, 152, 152, 154, 151, 148, 146, 146,\n       145, 147, 148, 148, 149, 150, 150, 152, 151, 150, 150, 153, 153,\n       154, 153, 150, 150, 150, 153, 153, 152, 154, 154, 154, 153, 149,\n       152, 151, 152, 153, 154, 151, 158, 154, 153, 155, 153, 150, 152,\n       152, 153, 151], dtype=uint8), array([3.54463004])], [array([135, 135, 136, 134, 136, 137, 136, 136, 135, 136, 137, 137, 136,\n       136, 137, 137, 139, 140, 138, 137, 138, 139, 140, 140, 137, 138,\n       136, 138, 138, 139, 138, 138, 138, 141, 137, 139, 137, 136, 137,\n       139, 136, 139, 140, 140, 139, 138, 139, 138, 138, 136, 136, 136,\n       139, 138, 134, 132, 132, 133, 130, 127, 125, 125, 123, 122, 120,\n       117, 115, 112, 110, 109, 107, 105, 103, 104, 102, 102, 100,  87,\n        78,  92, 111, 123, 135, 140, 139, 142, 142, 138, 140, 142, 142,\n       139, 136, 136, 137, 135, 135, 136, 135, 136, 136, 135, 135, 134,\n       132, 131, 132, 132, 133, 132, 131, 130, 130, 129, 129, 128, 126,\n       129, 127, 127], dtype=uint8), array([4.51179147])], [array([146, 148, 147, 149, 147, 146, 148, 150, 146, 146, 148, 147, 149,\n       148, 146, 146, 147, 147, 145, 147, 144, 148, 146, 146, 146, 147,\n       145, 147, 145, 144, 144, 143, 141, 144, 143, 141, 140, 138, 140,\n       139, 135, 134, 135, 136, 135, 134, 136, 136, 131, 131, 130, 131,\n       130, 131, 130, 126, 126, 126, 126, 123, 116, 110, 107, 107, 120,\n       128, 138, 146, 146, 145, 148, 149, 148, 146, 145, 144, 140, 141,\n       143, 142, 140, 141, 140, 139, 139, 139, 139, 141, 143, 141, 141,\n       138, 136, 138, 139, 137, 138, 137, 136, 136, 136, 137, 137, 137,\n       136, 134, 136, 135, 135, 137, 136, 137, 135, 136, 139, 137, 138,\n       139, 138, 137], dtype=uint8), array([4.37560143])], [array([146, 149, 149, 146, 146, 144, 144, 146, 146, 146, 144, 143, 141,\n       143, 141, 140, 142, 141, 140, 142, 142, 143, 143, 143, 144, 145,\n       143, 142, 140, 143, 142, 142, 142, 143, 143, 142, 141, 142, 143,\n       140, 141, 138, 139, 141, 142, 139, 139, 138, 137, 138, 140, 137,\n       137, 137, 135, 135, 134, 131, 132, 130, 129, 130, 125, 124, 125,\n       124, 121, 121, 118, 113, 110, 112, 116, 118, 113, 111, 105,  90,\n        84,  91, 106, 122, 134, 140, 139, 141, 140, 139, 136, 141, 139,\n       138, 139, 137, 137, 135, 135, 134, 133, 132, 135, 133, 129, 133,\n       131, 129, 133, 134, 134, 132, 132, 134, 131, 132, 133, 135, 137,\n       132, 135, 135], dtype=uint8), array([3.95002995])], [array([139, 139, 139, 137, 133, 137, 139, 139, 137, 135, 136, 136, 136,\n       138, 137, 138, 136, 135, 136, 136, 135, 136, 134, 134, 138, 134,\n       139, 136, 135, 135, 134, 137, 137, 134, 136, 137, 134, 135, 137,\n       135, 135, 136, 135, 135, 135, 136, 137, 138, 134, 135, 135, 135,\n       135, 131, 133, 132, 131, 130, 130, 127, 124, 123, 120, 118, 117,\n       116, 119, 119, 116, 113, 110, 111, 111, 110, 106,  98,  93, 100,\n       114, 128, 134, 139, 141, 141, 138, 137, 137, 135, 134, 137, 127,\n       131, 129, 125, 126, 126, 123, 121, 119, 118, 116, 117, 118, 120,\n       121, 123, 126, 129, 130, 128, 126, 128, 130, 128, 127, 126, 122,\n       122, 123, 125], dtype=uint8), array([3.53048839])], [array([119, 119, 120, 119, 119, 116, 117, 114, 115, 114, 112, 112, 113,\n       110, 109, 110, 112, 112, 111, 111, 111, 110, 108, 109, 106, 107,\n       106, 108, 105, 104, 106, 105, 103, 104, 105, 107, 110, 114, 113,\n       117, 119, 120, 120, 118, 116, 113, 115, 114, 115, 115, 117, 117,\n       120, 121, 122, 123, 123, 123, 121, 119, 116, 112, 107, 106, 112,\n       120, 129, 136, 137, 140, 139, 141, 142, 140, 140, 139, 142, 140,\n       139, 142, 140, 141, 138, 139, 136, 136, 136, 137, 138, 136, 135,\n       140, 140, 138, 139, 135, 130, 132, 133, 134, 133, 135, 136, 137,\n       138, 137, 135, 138, 133, 134, 129, 124, 122, 116, 113, 115, 123,\n       129, 132, 133], dtype=uint8), array([3.67640104])], [array([133, 133, 132, 133, 133, 132, 133, 133, 133, 132, 133, 130, 131,\n       133, 131, 130, 131, 132, 133, 132, 132, 132, 131, 132, 133, 132,\n       132, 130, 130, 132, 133, 131, 131, 130, 130, 130, 131, 131, 126,\n       126, 125, 122, 122, 119, 118, 117, 115, 109, 106, 105, 104, 100,\n        99,  95,  97,  97,  92,  89,  85,  84,  81,  76,  72,  69,  66,\n        65,  62,  63,  68,  76,  87, 100, 111, 114, 119, 128, 140, 146,\n       148, 150, 150, 150, 148, 147, 146, 146, 148, 145, 146, 143, 142,\n       142, 140, 137, 138, 136, 134, 138, 134, 132, 133, 131, 129, 130,\n       126, 128, 127, 129, 125, 125, 127, 126, 125, 123, 126, 129, 128,\n       127, 126, 126], dtype=uint8), array([8.97995119])], [array([138, 136, 136, 138, 138, 137, 136, 133, 135, 135, 133, 133, 131,\n       133, 133, 134, 134, 131, 130, 133, 131, 131, 130, 132, 132, 132,\n       132, 130, 130, 128, 126, 129, 128, 130, 131, 127, 125, 130, 129,\n       128, 127, 130, 128, 127, 129, 125, 120, 114, 102,  92,  86,  82,\n        88, 100, 108, 110, 113, 114, 115, 116, 117, 118, 120, 121, 122,\n       123, 122, 127, 128, 128, 127, 127, 127, 128, 128, 127, 129, 130,\n       130, 130, 131, 130, 129, 129, 130, 127, 129, 131, 131, 128, 130,\n       130, 131, 131, 130, 128, 130, 130, 130, 131, 130, 130, 129, 128,\n       129, 129, 130, 128, 130, 129, 129, 130, 131, 129, 130, 132, 130,\n       131, 131, 127], dtype=uint8), array([5.35827466])], [array([133, 133, 132, 134, 132, 137, 135, 136, 136, 136, 139, 138, 137,\n       137, 137, 139, 138, 141, 140, 138, 140, 141, 143, 141, 139, 141,\n       140, 140, 138, 139, 141, 139, 141, 141, 140, 134, 130, 127, 131,\n       133, 134, 134, 135, 136, 137, 137, 137, 137, 140, 141, 142, 141,\n       142, 141, 142, 141, 141, 141, 141, 139, 137, 137, 136, 136, 135,\n       133, 129, 131, 130, 116, 100,  88,  94,  95,  91,  83,  83,  84,\n        86,  89,  90,  92,  91,  93,  95,  96,  97,  99, 101, 101, 102,\n       102, 105, 105, 106, 106, 106, 108, 108, 107, 108, 109, 109, 108,\n       110, 109, 110, 112, 112, 110, 110, 111, 111, 112, 112, 113, 113,\n       112, 112, 114], dtype=uint8), array([8.97995119])], [array([110, 111, 109, 112, 115, 113, 115, 115, 116, 116, 117, 119, 118,\n       119, 118, 119, 118, 118, 115, 116, 119, 119, 117, 115, 118, 118,\n       116, 115, 117, 117, 113, 111, 112, 112, 112, 110, 109, 112, 112,\n       112, 110, 109, 110, 111, 111, 111, 105,  91,  86,  95, 104, 113,\n       124, 135, 139, 143, 145, 143, 141, 138, 140, 141, 142, 139, 138,\n       138, 138, 136, 137, 138, 137, 138, 136, 138, 138, 136, 139, 139,\n       138, 139, 139, 136, 135, 136, 138, 138, 137, 138, 137, 136, 136,\n       136, 137, 137, 138, 139, 139, 139, 138, 140, 138, 138, 137, 138,\n       140, 138, 136, 137, 137, 135, 134, 134, 133, 127, 116, 109, 110,\n       114, 125, 134], dtype=uint8), array([5.35827466])], [array([139, 141, 142, 143, 144, 144, 143, 142, 142, 141, 142, 142, 143,\n       140, 144, 144, 142, 142, 142, 140, 141, 141, 140, 141, 141, 139,\n       138, 140, 140, 140, 142, 140, 140, 142, 139, 144, 142, 140, 143,\n       142, 142, 141, 141, 141, 139, 139, 137, 138, 136, 136, 137, 137,\n       137, 138, 138, 136, 136, 135, 135, 134, 132, 134, 132, 131, 133,\n       133, 134, 136, 135, 136, 136, 132, 132, 133, 123, 115, 106,  98,\n        95, 104, 112, 116, 117, 115, 115, 116, 114, 113, 115, 114, 114,\n       114, 111, 111, 114, 113, 111, 111, 111, 111, 109, 110, 110, 109,\n       110, 110, 109, 109, 109, 109, 109, 108, 107, 109, 110, 109, 109,\n       111, 111, 111], dtype=uint8), array([3.76287851])], [array([143, 143, 145, 144, 145, 146, 145, 144, 146, 145, 142, 145, 143,\n       144, 145, 144, 144, 145, 143, 143, 143, 147, 146, 146, 146, 145,\n       143, 142, 137, 136, 138, 139, 141, 140, 138, 138, 139, 138, 136,\n       135, 132, 129, 127, 127, 131, 132, 135, 136, 139, 139, 139, 138,\n       137, 143, 141, 141, 143, 144, 146, 145, 142, 142, 144, 145, 147,\n       143, 146, 148, 148, 146, 145, 146, 147, 142, 137, 135, 134, 136,\n       136, 135, 131, 134, 131, 133, 130, 131, 132, 133, 136, 136, 135,\n       138, 140, 140, 140, 140, 141, 142, 144, 145, 144, 142, 143, 143,\n       144, 144, 143, 145, 142, 144, 143, 145, 145, 145, 145, 147, 147,\n       148, 145, 146], dtype=uint8), array([3.04808728])], [array([139, 142, 142, 144, 146, 146, 144, 145, 142, 147, 147, 147, 144,\n       143, 144, 143, 145, 147, 146, 146, 146, 147, 148, 146, 147, 147,\n       147, 147, 150, 147, 149, 148, 148, 147, 148, 148, 146, 146, 147,\n       147, 144, 146, 147, 148, 145, 146, 147, 148, 149, 147, 148, 148,\n       148, 148, 148, 145, 146, 147, 149, 149, 148, 148, 146, 149, 147,\n       147, 148, 147, 144, 145, 146, 141, 141, 137, 127, 119, 110, 106,\n       115, 121, 125, 123, 126, 127, 127, 128, 128, 128, 132, 131, 129,\n       129, 130, 133, 133, 132, 132, 132, 133, 133, 132, 133, 131, 130,\n       134, 135, 136, 133, 132, 134, 132, 133, 132, 132, 133, 133, 131,\n       130, 129, 127], dtype=uint8), array([3.04562947])], [array([150, 148, 149, 152, 152, 150, 148, 150, 151, 152, 150, 149, 150,\n       150, 148, 148, 149, 149, 148, 150, 150, 152, 151, 152, 151, 151,\n       148, 150, 152, 148, 148, 149, 151, 151, 149, 148, 147, 149, 148,\n       151, 149, 148, 149, 150, 148, 151, 150, 150, 149, 148, 148, 148,\n       147, 146, 150, 150, 150, 150, 150, 148, 147, 148, 150, 149, 146,\n       147, 145, 143, 144, 143, 140, 134, 125, 108,  95,  98, 114, 128,\n       137, 140, 143, 145, 144, 143, 140, 139, 140, 141, 140, 141, 140,\n       139, 138, 136, 136, 135, 133, 133, 132, 130, 131, 132, 131, 132,\n       131, 131, 132, 130, 130, 130, 126, 121, 116, 110, 105, 102,  99,\n        88,  84,  83], dtype=uint8), array([3.06895321])], [array([146, 146, 146, 147, 147, 148, 146, 147, 146, 143, 145, 143, 142,\n       140, 137, 134, 130, 126, 119, 113, 111, 106, 100, 103, 108, 110,\n       106, 105, 108, 108, 118, 123, 124, 126, 128, 132, 133, 134, 134,\n       135, 137, 140, 140, 140, 141, 143, 142, 141, 139, 137, 133, 130,\n       119, 115, 121, 127, 136, 139, 143, 144, 143, 142, 140, 140, 143,\n       145, 143, 141, 143, 147, 147, 147, 145, 147, 144, 144, 151, 147,\n       149, 147, 144, 143, 147, 147, 147, 148, 148, 149, 148, 149, 150,\n       150, 149, 149, 150, 146, 148, 148, 147, 146, 147, 146, 146, 146,\n       146, 144, 146, 146, 144, 143, 142, 140, 139, 137, 137, 138, 134,\n       132, 131, 126], dtype=uint8), array([2.85702873])], [array([130, 129, 130, 130, 133, 133, 132, 131, 131, 130, 132, 133, 133,\n       133, 133, 131, 130, 132, 133, 130, 131, 133, 131, 133, 133, 131,\n       134, 133, 133, 133, 131, 131, 132, 131, 133, 135, 132, 130, 129,\n       132, 132, 133, 131, 133, 132, 134, 130, 133, 133, 133, 130, 130,\n       131, 132, 132, 133, 134, 133, 132, 133, 131, 133, 133, 135, 134,\n       133, 133, 133, 133, 134, 136, 137, 138, 138, 137, 138, 139, 139,\n       138, 133, 126, 114, 103, 100, 105, 110, 111, 113, 112, 112, 112,\n       110, 109, 108, 111, 110, 114, 114, 114, 116, 120, 119, 120, 121,\n       122, 125, 126, 127, 126, 128, 126, 133, 133, 135, 132, 133, 131,\n       131, 131, 135], dtype=uint8), array([4.51179147])], [array([141, 140, 139, 143, 142, 144, 141, 141, 141, 140, 140, 140, 140,\n       139, 138, 135, 132, 134, 137, 138, 133, 132, 130, 127, 126, 122,\n       119, 117, 115, 111, 103,  96,  94,  93,  94,  96,  97,  98, 103,\n       105, 107, 109, 112, 112, 114, 116, 115, 115, 118, 116, 117, 119,\n       118, 120, 118, 119, 116, 118, 115, 104,  95,  93,  92,  93, 101,\n       110, 110, 110, 108, 107, 105, 105, 105, 103, 103, 103, 105, 103,\n       106, 106, 107, 107, 106, 107, 108, 112, 109, 112, 114, 113, 115,\n       115, 117, 118, 117, 118, 118, 119, 123, 124, 122, 124, 125, 124,\n       125, 125, 127, 126, 129, 130, 129, 129, 130, 132, 131, 130, 132,\n       132, 133, 133], dtype=uint8), array([4.37560143])], [array([117, 113, 110, 109, 108, 105, 104, 105, 102, 103, 104, 105, 106,\n       104, 106, 106, 107, 107, 107, 107, 106, 107, 108, 109, 110, 111,\n       112, 113, 113, 113, 113, 114, 116, 115, 113, 115, 118, 117, 115,\n       118, 120, 121, 123, 122, 123, 122, 122, 125, 126, 124, 125, 127,\n       128, 126, 126, 126, 128, 125, 125, 127, 129, 130, 130, 129, 131,\n       132, 132, 134, 133, 133, 135, 135, 134, 138, 140, 140, 138, 138,\n       135, 130, 119, 104,  93,  92, 102, 109, 111, 110, 111, 111, 112,\n       111, 112, 114, 114, 116, 117, 119, 123, 123, 123, 126, 128, 130,\n       127, 131, 132, 134, 135, 134, 133, 135, 135, 137, 138, 134, 135,\n       138, 138, 136], dtype=uint8), array([3.95002995])], [array([127, 127, 129, 128, 130, 132, 133, 133, 134, 133, 136, 136, 136,\n       135, 136, 136, 137, 138, 138, 139, 137, 138, 137, 142, 142, 139,\n       140, 139, 139, 139, 140, 138, 140, 139, 139, 141, 140, 140, 141,\n       142, 142, 142, 141, 142, 142, 141, 141, 144, 142, 142, 140, 140,\n       140, 140, 141, 141, 143, 143, 140, 142, 144, 143, 141, 141, 142,\n       141, 135, 135, 142, 139, 142, 142, 142, 144, 141, 139, 139, 136,\n       132, 126, 118, 119, 123, 127, 128, 128, 127, 125, 127, 125, 126,\n       124, 125, 124, 126, 129, 131, 131, 133, 136, 135, 137, 140, 138,\n       137, 138, 134, 133, 132, 129, 129, 129, 130, 131, 133, 132, 133,\n       135, 132, 129], dtype=uint8), array([3.53048839])], [array([143, 142, 144, 144, 145, 146, 146, 143, 142, 145, 148, 146, 144,\n       143, 145, 146, 144, 143, 144, 143, 143, 143, 142, 143, 142, 143,\n       144, 143, 144, 145, 144, 140, 139, 134, 134, 137, 140, 143, 142,\n       144, 140, 145, 145, 145, 144, 145, 146, 144, 145, 145, 145, 145,\n       145, 147, 147, 142, 140, 141, 140, 138, 134, 126, 117, 112, 108,\n       118, 127, 128, 129, 133, 135, 135, 134, 135, 136, 136, 136, 137,\n       138, 137, 136, 134, 134, 134, 134, 135, 136, 134, 133, 133, 135,\n       136, 135, 134, 132, 128, 123, 125, 127, 130, 132, 133, 136, 137,\n       135, 138, 138, 137, 139, 141, 139, 141, 142, 142, 139, 140, 141,\n       142, 142, 142], dtype=uint8), array([3.67640104])], [array([138, 139, 138, 138, 138, 137, 137, 138, 137, 138, 137, 134, 139,\n       137, 136, 136, 134, 133, 133, 134, 135, 134, 136, 135, 132, 132,\n       133, 130, 135, 134, 135, 133, 133, 133, 132, 133, 133, 133, 132,\n       131, 131, 131, 128, 129, 127, 126, 126, 130, 128, 126, 126, 126,\n       127, 125, 125, 127, 129, 130, 125, 123, 105,  91,  89,  88,  94,\n       110, 118, 120, 122, 125, 124, 124, 126, 128, 128, 130, 132, 133,\n       133, 133, 133, 129, 125, 116, 110, 113, 122, 130, 133, 137, 136,\n       137, 138, 139, 138, 139, 139, 138, 138, 138, 136, 138, 135, 138,\n       139, 139, 140, 140, 143, 143, 141, 142, 139, 140, 141, 143, 140,\n       141, 140, 139], dtype=uint8), array([5.21064103])], [array([145, 146, 147, 146, 145, 146, 147, 148, 147, 149, 147, 149, 148,\n       145, 147, 147, 146, 147, 148, 149, 148, 150, 148, 150, 148, 145,\n       143, 143, 145, 146, 147, 147, 147, 146, 145, 146, 147, 147, 146,\n       145, 146, 146, 142, 143, 144, 144, 141, 139, 139, 135, 131, 128,\n       121, 112, 115, 119, 122, 125, 127, 126, 125, 124, 125, 123, 121,\n       120, 117, 113, 103,  88,  84,  91,  91,  81,  81,  98, 106, 109,\n       111, 116, 119, 122, 124, 125, 124, 122, 121, 119, 118, 121, 128,\n       131, 132, 133, 133, 135, 138, 138, 140, 142, 141, 140, 142, 141,\n       143, 142, 142, 143, 143, 144, 144, 143, 146, 145, 142, 144, 143,\n       145, 141, 143], dtype=uint8), array([7.26221294])], [array([146, 145, 142, 144, 145, 145, 143, 143, 144, 145, 144, 144, 145,\n       146, 146, 149, 147, 146, 147, 147, 146, 146, 146, 148, 144, 146,\n       146, 147, 146, 144, 148, 147, 147, 149, 148, 149, 146, 146, 147,\n       147, 147, 148, 147, 145, 146, 146, 144, 144, 146, 149, 145, 147,\n       146, 150, 148, 148, 149, 149, 150, 152, 152, 153, 156, 156, 158,\n       158, 154, 153, 157, 156, 146, 136, 124, 107,  94,  97, 108, 116,\n       115, 115, 114, 112, 114, 116, 118, 118, 117, 121, 122, 123, 127,\n       129, 130, 133, 135, 136, 138, 142, 144, 144, 145, 146, 149, 149,\n       148, 148, 150, 149, 150, 150, 150, 153, 154, 154, 153, 152, 152,\n       153, 153, 150], dtype=uint8), array([5.93755418])], [array([149, 145, 147, 146, 151, 145, 144, 144, 146, 147, 146, 144, 145,\n       145, 146, 146, 147, 147, 147, 147, 148, 149, 147, 147, 146, 148,\n       148, 148, 147, 147, 147, 148, 149, 148, 147, 149, 150, 150, 148,\n       151, 150, 151, 151, 150, 153, 152, 151, 151, 150, 150, 151, 150,\n       153, 152, 151, 151, 151, 154, 153, 154, 154, 151, 155, 157, 157,\n       157, 159, 159, 159, 155, 148, 137, 128, 113, 105, 112, 123, 122,\n       121, 122, 118, 114, 118, 118, 119, 120, 124, 124, 125, 126, 127,\n       133, 133, 135, 132, 135, 139, 141, 142, 145, 147, 149, 150, 151,\n       151, 148, 150, 151, 152, 153, 154, 153, 152, 153, 152, 152, 153,\n       152, 154, 155], dtype=uint8), array([5.5774322])], [array([155, 157, 157, 159, 158, 156, 155, 154, 154, 155, 156, 155, 156,\n       157, 155, 154, 151, 154, 155, 154, 156, 155, 151, 155, 155, 155,\n       153, 157, 158, 156, 156, 156, 160, 157, 157, 156, 156, 157, 158,\n       154, 156, 157, 157, 157, 156, 155, 158, 155, 153, 151, 154, 151,\n       147, 150, 150, 148, 147, 146, 146, 144, 144, 144, 140, 141, 138,\n       135, 132, 119, 106, 103, 104, 111, 127, 136, 140, 140, 143, 146,\n       145, 147, 146, 147, 148, 152, 149, 149, 149, 151, 153, 154, 153,\n       154, 153, 153, 156, 156, 153, 153, 153, 157, 157, 156, 154, 153,\n       154, 156, 154, 153, 153, 151, 152, 152, 154, 153, 157, 157, 153,\n       155, 152, 152], dtype=uint8), array([4.19787153])], [array([154, 154, 155, 156, 154, 157, 154, 156, 157, 157, 157, 157, 158,\n       154, 159, 159, 157, 156, 156, 156, 156, 156, 157, 156, 157, 157,\n       159, 159, 158, 157, 155, 158, 158, 158, 158, 156, 158, 157, 158,\n       157, 156, 155, 155, 153, 154, 158, 158, 155, 156, 155, 153, 153,\n       152, 152, 150, 149, 148, 147, 146, 148, 147, 150, 153, 155, 152,\n       148, 149, 147, 143, 140, 126, 117, 107, 106, 116, 126, 131, 134,\n       138, 139, 139, 142, 144, 146, 149, 147, 151, 151, 152, 155, 153,\n       154, 156, 158, 159, 156, 154, 158, 160, 158, 157, 159, 159, 157,\n       161, 161, 160, 159, 156, 158, 158, 158, 158, 160, 157, 157, 158,\n       157, 156, 156], dtype=uint8), array([3.7441611])], [array([143, 143, 141, 141, 141, 141, 143, 143, 141, 142, 143, 143, 140,\n       140, 141, 144, 141, 139, 140, 136, 136, 135, 135, 137, 136, 136,\n       136, 139, 141, 143, 142, 141, 142, 143, 144, 144, 144, 144, 141,\n       143, 143, 141, 144, 144, 142, 143, 144, 144, 144, 146, 141, 144,\n       144, 143, 143, 143, 144, 146, 148, 146, 147, 147, 149, 147, 147,\n       151, 152, 152, 152, 148, 142, 132, 117, 101,  97, 108, 118, 121,\n       121, 118, 116, 116, 117, 120, 121, 120, 123, 127, 127, 130, 131,\n       131, 134, 136, 135, 136, 141, 140, 140, 144, 146, 145, 143, 143,\n       142, 145, 143, 143, 145, 141, 142, 145, 145, 145, 144, 145, 145,\n       144, 146, 147], dtype=uint8), array([5.20109506])], [array([135, 133, 133, 135, 133, 132, 134, 135, 134, 135, 136, 137, 136,\n       137, 138, 137, 138, 137, 136, 137, 136, 136, 138, 139, 138, 138,\n       138, 137, 139, 142, 139, 138, 137, 139, 139, 138, 139, 136, 138,\n       138, 135, 138, 137, 137, 134, 139, 139, 139, 139, 137, 137, 138,\n       139, 141, 139, 139, 140, 139, 139, 140, 141, 143, 145, 146, 147,\n       148, 149, 150, 151, 150, 147, 141, 131, 117, 100,  90,  98, 109,\n       114, 115, 112, 111, 110, 109, 111, 112, 115, 116, 116, 117, 121,\n       121, 124, 125, 125, 127, 127, 129, 130, 130, 134, 133, 132, 131,\n       131, 132, 132, 134, 130, 131, 131, 130, 132, 131, 133, 132, 131,\n       131, 130, 130], dtype=uint8), array([4.87914297])], [array([162, 160, 162, 163, 165, 167, 169, 168, 168, 169, 168, 167, 166,\n       164, 164, 163, 161, 161, 162, 163, 163, 165, 167, 169, 164, 164,\n       167, 167, 165, 168, 168, 164, 165, 165, 167, 165, 167, 166, 166,\n       165, 164, 164, 165, 166, 166, 167, 166, 165, 165, 163, 166, 165,\n       166, 165, 167, 163, 163, 165, 168, 167, 164, 165, 162, 163, 166,\n       164, 165, 165, 164, 162, 166, 168, 166, 166, 165, 166, 166, 166,\n       164, 166, 170, 168, 165, 164, 165, 168, 168, 167, 164, 166, 167,\n       169, 164, 164, 164, 165, 165, 166, 166, 166, 168, 166, 167, 165,\n       165, 166, 166, 165, 165, 166, 165, 165, 166, 166, 165, 166, 163,\n       162, 162, 166], dtype=uint8), array([0.])], [array([154, 154, 155, 155, 156, 155, 154, 151, 150, 149, 151, 151, 151,\n       149, 150, 151, 151, 151, 151, 153, 151, 150, 152, 150, 153, 152,\n       152, 151, 152, 152, 155, 151, 155, 154, 155, 156, 157, 154, 154,\n       152, 156, 154, 152, 154, 155, 155, 156, 155, 155, 155, 157, 157,\n       155, 155, 156, 158, 160, 159, 158, 159, 156, 159, 158, 158, 157,\n       157, 154, 145, 133, 118, 115, 118, 113, 101, 100, 102, 104, 103,\n       103, 103, 100,  98, 100, 103, 106, 105, 108, 110, 112, 112, 113,\n       115, 116, 120, 123, 125, 129, 131, 134, 135, 137, 138, 137, 139,\n       140, 143, 144, 146, 149, 151, 149, 152, 153, 154, 155, 156, 157,\n       155, 158, 156], dtype=uint8), array([8.52101685])], [array([149, 151, 149, 151, 149, 151, 149, 150, 149, 150, 152, 151, 152,\n       151, 152, 151, 151, 151, 152, 152, 153, 153, 151, 151, 152, 151,\n       154, 157, 154, 150, 151, 154, 153, 156, 158, 155, 153, 153, 155,\n       156, 154, 157, 156, 155, 155, 154, 155, 157, 157, 158, 156, 153,\n       156, 157, 160, 160, 160, 159, 159, 158, 159, 160, 161, 161, 164,\n       155, 144, 130, 121, 122, 126, 121, 106,  97,  93,  97,  96,  97,\n       100,  99,  99, 100,  99,  99, 103, 101, 105, 109, 108, 112, 117,\n       115, 118, 122, 125, 125, 126, 129, 132, 135, 135, 135, 141, 143,\n       142, 143, 145, 148, 150, 149, 150, 151, 153, 154, 153, 152, 153,\n       156, 156, 155], dtype=uint8), array([8.73503977])], [array([126, 125, 125, 127, 125, 118, 112, 116, 120, 126, 132, 137, 143,\n       143, 149, 151, 151, 153, 155, 151, 151, 153, 152, 151, 152, 152,\n       150, 149, 151, 152, 152, 150, 150, 152, 151, 152, 151, 150, 151,\n       152, 151, 149, 149, 148, 146, 149, 150, 146, 143, 146, 146, 147,\n       146, 146, 142, 142, 141, 140, 140, 139, 138, 138, 137, 136, 135,\n       134, 133, 134, 135, 135, 130, 120, 117, 115, 113, 120, 131, 132,\n       135, 135, 135, 137, 139, 141, 141, 140, 142, 145, 145, 145, 145,\n       147, 145, 147, 147, 146, 147, 150, 146, 148, 147, 149, 150, 153,\n       150, 147, 147, 149, 147, 147, 147, 148, 148, 147, 148, 149, 147,\n       144, 147, 147], dtype=uint8), array([4.59109883])], [array([152, 152, 152, 153, 152, 152, 153, 153, 154, 153, 152, 152, 152,\n       152, 154, 153, 154, 153, 153, 150, 153, 154, 153, 152, 153, 153,\n       152, 152, 150, 149, 150, 151, 149, 147, 148, 148, 147, 148, 145,\n       145, 144, 145, 142, 137, 135, 135, 134, 133, 130, 129, 132, 130,\n       126, 125, 126, 129, 128, 129, 130, 130, 127, 114, 104, 114, 126,\n       136, 144, 150, 152, 155, 153, 151, 148, 152, 153, 152, 152, 150,\n       154, 151, 152, 152, 151, 150, 149, 148, 149, 148, 151, 150, 149,\n       149, 148, 148, 147, 145, 146, 147, 145, 144, 147, 146, 143, 142,\n       143, 143, 139, 142, 142, 142, 141, 142, 144, 142, 140, 137, 138,\n       138, 137, 137], dtype=uint8), array([4.34090199])], [array([150, 152, 151, 150, 151, 150, 150, 148, 151, 148, 148, 148, 148,\n       148, 150, 149, 147, 145, 150, 150, 151, 151, 150, 149, 150, 153,\n       149, 142, 149, 148, 148, 147, 144, 145, 144, 143, 142, 142, 144,\n       141, 144, 143, 140, 137, 135, 134, 134, 133, 131, 132, 133, 130,\n       130, 132, 132, 133, 132, 132, 132, 132, 132, 121, 116, 119, 127,\n       142, 149, 150, 150, 148, 149, 149, 147, 146, 141, 142, 141, 144,\n       143, 143, 143, 142, 139, 140, 142, 143, 141, 144, 144, 143, 142,\n       146, 145, 144, 144, 143, 143, 146, 144, 146, 145, 146, 148, 147,\n       146, 147, 148, 147, 146, 145, 144, 148, 147, 145, 142, 140, 141,\n       138, 141, 143], dtype=uint8), array([4.35067225])], [array([148, 150, 152, 153, 152, 152, 152, 149, 148, 149, 150, 151, 151,\n       151, 150, 149, 149, 151, 152, 152, 151, 149, 150, 150, 150, 148,\n       149, 150, 150, 149, 148, 147, 146, 144, 143, 139, 139, 140, 137,\n       134, 133, 135, 133, 132, 128, 128, 128, 129, 127, 124, 125, 127,\n       129, 128, 128, 129, 128, 127, 123, 112, 111, 119, 132, 141, 147,\n       149, 150, 150, 150, 148, 147, 148, 146, 146, 142, 142, 141, 140,\n       138, 137, 136, 136, 136, 133, 133, 132, 132, 133, 131, 128, 129,\n       121, 114, 119, 137, 140, 144, 147, 147, 147, 148, 143, 139, 137,\n       135, 137, 139, 141, 142, 142, 142, 143, 143, 142, 141, 140, 139,\n       138, 138, 138], dtype=uint8), array([4.18356936])], [array([140, 142, 141, 139, 139, 136, 137, 137, 140, 139, 137, 134, 137,\n       140, 140, 137, 138, 138, 137, 138, 138, 137, 140, 139, 139, 138,\n       135, 137, 138, 137, 137, 138, 136, 137, 136, 135, 137, 137, 137,\n       137, 135, 137, 138, 138, 139, 139, 137, 139, 138, 139, 138, 137,\n       137, 138, 138, 138, 137, 137, 137, 139, 139, 139, 141, 141, 139,\n       136, 138, 138, 138, 137, 136, 132, 122, 117, 115, 115, 116, 121,\n       126, 126, 125, 122, 120, 118, 118, 116, 116, 117, 118, 119, 120,\n       121, 121, 123, 126, 128, 128, 130, 132, 131, 131, 133, 136, 138,\n       133, 136, 135, 136, 139, 138, 138, 139, 140, 139, 136, 138, 138,\n       139, 139, 139], dtype=uint8), array([5.923182])], [array([142, 144, 142, 140, 141, 140, 141, 140, 141, 142, 142, 140, 140,\n       141, 144, 142, 140, 139, 136, 132, 128, 126, 128, 130, 132, 133,\n       135, 139, 141, 137, 138, 133, 127, 119, 114, 117, 121, 128, 132,\n       134, 136, 135, 137, 139, 141, 142, 143, 141, 144, 146, 145, 144,\n       141, 142, 139, 146, 146, 150, 151, 154, 156, 158, 157, 154, 149,\n       142, 130, 127, 126, 117, 104,  91,  86,  86,  85,  83,  85,  85,\n        88,  90,  92,  92,  92,  93,  95,  97,  99, 100, 103, 103, 106,\n       111, 113, 114, 117, 121, 121, 125, 126, 128, 129, 135, 133, 133,\n       134, 136, 136, 138, 143, 141, 141, 143, 144, 145, 145, 143, 143,\n       145, 146, 147], dtype=uint8), array([8.89809448])], [array([138, 139, 140, 137, 139, 139, 141, 138, 139, 139, 133, 133, 137,\n       141, 139, 141, 139, 140, 141, 141, 140, 140, 142, 143, 143, 140,\n       139, 140, 142, 139, 144, 143, 143, 144, 139, 139, 137, 140, 141,\n       141, 141, 142, 139, 141, 139, 139, 140, 140, 140, 142, 139, 138,\n       136, 138, 138, 136, 134, 135, 134, 135, 134, 132, 132, 132, 133,\n       131, 128, 126, 125, 124, 122, 115, 102,  96,  97,  96,  95, 103,\n       116, 124, 126, 127, 128, 127, 128, 132, 133, 132, 133, 134, 136,\n       137, 138, 139, 139, 142, 141, 142, 140, 140, 142, 143, 142, 141,\n       140, 139, 138, 130, 129, 124, 124, 127, 124, 125, 133, 132, 138,\n       142, 141, 142], dtype=uint8), array([4.7800506])], [array([142, 140, 141, 139, 142, 140, 141, 140, 141, 140, 140, 141, 140,\n       141, 144, 142, 140, 139, 140, 141, 141, 140, 139, 140, 141, 141,\n       142, 141, 141, 140, 141, 140, 139, 140, 139, 140, 142, 138, 140,\n       137, 141, 137, 133, 138, 136, 136, 136, 136, 134, 132, 129, 130,\n       131, 127, 126, 126, 126, 124, 122, 121, 121, 120, 119, 118, 119,\n       119, 121, 121, 119, 119, 115, 102,  97, 102, 103, 108, 121, 127,\n       130, 128, 129, 130, 132, 131, 130, 129, 131, 136, 136, 135, 135,\n       135, 135, 135, 137, 137, 138, 138, 136, 137, 138, 139, 138, 138,\n       137, 136, 135, 138, 138, 139, 140, 139, 140, 140, 141, 140, 139,\n       140, 138, 138], dtype=uint8), array([5.29939395])], [array([142, 140, 141, 142, 142, 138, 143, 138, 140, 139, 143, 142, 144,\n       143, 141, 139, 138, 141, 140, 137, 139, 140, 137, 138, 140, 140,\n       135, 136, 138, 140, 142, 139, 138, 136, 140, 138, 135, 138, 141,\n       137, 138, 136, 137, 141, 138, 133, 136, 136, 136, 134, 138, 132,\n       132, 137, 133, 131, 133, 128, 133, 129, 128, 129, 131, 130, 131,\n       128, 129, 128, 127, 122, 122, 114, 106, 101, 106, 102, 116, 121,\n       126, 122, 125, 121, 127, 127, 125, 127, 127, 125, 130, 128, 129,\n       131, 135, 129, 133, 135, 134, 134, 138, 133, 136, 139, 137, 138,\n       136, 138, 133, 138, 139, 135, 139, 138, 139, 135, 137, 139, 139,\n       138, 135, 138], dtype=uint8), array([5.08347615])], [array([172, 173, 173, 173, 171, 174, 174, 173, 174, 173, 174, 169, 173,\n       174, 172, 168, 169, 170, 171, 172, 169, 172, 172, 172, 172, 174,\n       172, 172, 174, 175, 172, 171, 172, 174, 171, 172, 174, 170, 173,\n       170, 169, 171, 169, 165, 166, 165, 161, 160, 159, 147, 124, 107,\n       117, 131, 118,  90,  81,  97, 115, 118, 120, 122, 125, 128, 132,\n       137, 139, 141, 145, 146, 152, 153, 155, 158, 160, 162, 164, 165,\n       165, 167, 168, 169, 169, 167, 168, 168, 167, 171, 170, 171, 171,\n       173, 172, 172, 172, 174, 173, 174, 172, 173, 174, 174, 175, 175,\n       172, 172, 173, 174, 176, 176, 174, 174, 173, 172, 174, 174, 173,\n       172, 173, 172], dtype=uint8), array([8.36581426])], [array([173, 172, 173, 170, 172, 175, 174, 171, 171, 170, 169, 165, 164,\n       165, 165, 163, 162, 162, 158, 157, 157, 156, 151, 145, 138, 136,\n       142, 148, 153, 161, 166, 166, 165, 166, 166, 166, 164, 165, 165,\n       165, 164, 165, 164, 163, 164, 162, 161, 160, 156, 155, 152, 148,\n       142, 138, 135, 134, 130, 126, 123, 125, 129, 131, 132, 128, 111,\n        90,  91, 103, 108, 102,  99, 119, 143, 155, 160, 162, 159, 163,\n       166, 165, 166, 169, 168, 169, 168, 170, 171, 171, 171, 172, 172,\n       171, 178, 172, 170, 172, 175, 177, 175, 175, 172, 174, 169, 169,\n       172, 171, 174, 176, 173, 172, 172, 175, 170, 173, 172, 171, 173,\n       175, 173, 170], dtype=uint8), array([8.89809448])], [array([174, 175, 172, 173, 173, 172, 173, 173, 171, 172, 173, 172, 170,\n       171, 170, 173, 168, 167, 168, 167, 171, 170, 171, 171, 172, 170,\n       170, 172, 174, 170, 169, 170, 170, 172, 170, 170, 169, 171, 172,\n       168, 173, 175, 174, 170, 168, 172, 171, 171, 171, 173, 171, 172,\n       173, 173, 173, 175, 173, 172, 173, 171, 172, 172, 171, 170, 170,\n       169, 168, 166, 166, 162, 155, 141, 127, 121, 118, 123, 140, 150,\n       154, 155, 157, 158, 165, 163, 165, 164, 165, 167, 167, 170, 168,\n       169, 170, 170, 170, 171, 173, 171, 170, 170, 173, 171, 170, 170,\n       171, 172, 171, 172, 172, 171, 171, 171, 171, 170, 168, 170, 170,\n       168, 170, 172], dtype=uint8), array([4.7800506])], [array([173, 171, 171, 173, 173, 175, 172, 173, 173, 173, 172, 170, 170,\n       171, 170, 171, 173, 172, 174, 175, 171, 172, 172, 173, 170, 172,\n       171, 173, 172, 175, 172, 172, 172, 171, 173, 171, 172, 172, 170,\n       172, 172, 173, 173, 170, 171, 171, 170, 172, 170, 170, 173, 175,\n       176, 172, 175, 172, 176, 172, 172, 171, 171, 173, 174, 171, 168,\n       169, 168, 167, 163, 150, 130, 121, 121, 109, 110, 135, 149, 151,\n       152, 157, 158, 159, 162, 162, 161, 165, 166, 168, 169, 169, 169,\n       169, 170, 170, 169, 169, 168, 162, 153, 143, 139, 143, 153, 165,\n       168, 169, 168, 170, 173, 173, 176, 172, 169, 170, 170, 171, 172,\n       173, 174, 176], dtype=uint8), array([5.29939395])], [array([165, 166, 165, 164, 165, 167, 167, 167, 167, 166, 167, 167, 170,\n       172, 169, 168, 169, 169, 168, 168, 167, 169, 170, 170, 170, 171,\n       170, 170, 170, 169, 169, 170, 168, 168, 168, 168, 169, 169, 169,\n       169, 172, 170, 170, 171, 170, 168, 171, 170, 169, 170, 171, 170,\n       168, 170, 168, 168, 171, 171, 168, 170, 171, 171, 170, 170, 170,\n       167, 170, 169, 166, 163, 162, 152, 135, 127, 122, 124, 139, 149,\n       153, 161, 161, 166, 164, 163, 165, 171, 171, 169, 171, 172, 172,\n       171, 171, 173, 171, 171, 174, 173, 171, 173, 173, 171, 174, 172,\n       175, 174, 175, 175, 174, 173, 175, 175, 171, 171, 172, 172, 173,\n       171, 173, 175], dtype=uint8), array([5.08347615])], [array([168, 168, 170, 170, 168, 167, 167, 166, 168, 169, 166, 169, 169,\n       170, 170, 169, 171, 168, 167, 168, 170, 172, 170, 169, 168, 171,\n       170, 169, 174, 169, 170, 168, 169, 172, 172, 169, 170, 171, 168,\n       171, 173, 169, 172, 170, 167, 172, 170, 172, 166, 167, 168, 171,\n       172, 172, 173, 173, 171, 172, 170, 169, 166, 166, 169, 167, 167,\n       168, 168, 165, 163, 159, 149, 137, 129, 128, 131, 140, 148, 152,\n       153, 157, 157, 162, 162, 162, 164, 166, 168, 169, 169, 168, 169,\n       170, 170, 171, 171, 170, 174, 170, 171, 170, 173, 174, 172, 172,\n       173, 172, 168, 170, 173, 173, 173, 171, 172, 170, 168, 169, 169,\n       170, 169, 167], dtype=uint8), array([5.923182])], [array([168, 168, 166, 165, 161, 156, 153, 149, 145, 141, 139, 136, 141,\n       145, 143, 144, 143, 143, 144, 147, 148, 146, 148, 147, 147, 151,\n       154, 154, 154, 157, 158, 156, 157, 158, 160, 160, 164, 162, 166,\n       168, 165, 166, 166, 165, 168, 169, 169, 169, 169, 169, 171, 171,\n       168, 169, 170, 169, 169, 172, 170, 170, 169, 171, 169, 169, 170,\n       169, 167, 166, 167, 157, 146, 134, 127, 122, 129, 140, 144, 145,\n       147, 147, 150, 149, 146, 153, 154, 153, 159, 163, 165, 164, 165,\n       167, 165, 165, 167, 169, 166, 168, 168, 170, 166, 167, 169, 168,\n       169, 170, 169, 171, 173, 172, 170, 169, 171, 172, 172, 169, 169,\n       169, 169, 166], dtype=uint8), array([4.59109883])], [array([162, 163, 165, 165, 166, 167, 167, 165, 172, 169, 168, 169, 169,\n       167, 168, 168, 167, 167, 167, 167, 167, 167, 165, 170, 171, 171,\n       167, 170, 168, 170, 169, 166, 166, 168, 168, 168, 167, 168, 168,\n       168, 167, 168, 166, 169, 166, 170, 170, 170, 170, 168, 168, 169,\n       168, 169, 169, 169, 169, 168, 166, 161, 160, 153, 146, 142, 136,\n       140, 144, 146, 144, 144, 146, 148, 147, 147, 148, 149, 150, 153,\n       150, 156, 154, 156, 157, 159, 161, 160, 159, 161, 165, 165, 163,\n       165, 167, 169, 169, 170, 169, 169, 168, 168, 169, 169, 170, 169,\n       169, 168, 169, 168, 168, 169, 170, 172, 169, 167, 167, 167, 169,\n       166, 168, 167], dtype=uint8), array([4.34090199])], [array([170, 167, 167, 167, 165, 167, 168, 164, 169, 170, 168, 166, 168,\n       166, 169, 166, 166, 169, 167, 169, 167, 166, 166, 168, 166, 163,\n       167, 168, 166, 166, 165, 166, 166, 169, 168, 162, 162, 162, 158,\n       155, 153, 155, 152, 149, 146, 144, 131, 112,  99, 102,  96,  79,\n        70,  82,  99, 112, 110, 110, 111, 113, 114, 117, 119, 125, 125,\n       127, 131, 136, 137, 142, 143, 147, 150, 152, 152, 155, 157, 157,\n       159, 161, 161, 162, 163, 164, 166, 167, 164, 165, 166, 167, 170,\n       167, 168, 168, 169, 169, 167, 170, 167, 166, 167, 169, 167, 167,\n       166, 164, 165, 168, 165, 162, 165, 165, 164, 163, 164, 165, 165,\n       164, 165, 163], dtype=uint8), array([8.52101685])], [array([167, 166, 167, 169, 167, 168, 166, 168, 169, 169, 170, 168, 168,\n       168, 168, 168, 169, 170, 168, 170, 171, 171, 171, 166, 168, 170,\n       170, 169, 168, 169, 173, 169, 168, 169, 167, 166, 166, 168, 168,\n       163, 161, 159, 159, 159, 158, 156, 152, 144, 130, 116, 116, 126,\n       127, 107,  89,  94, 107, 114, 113, 110, 111, 111, 114, 118, 119,\n       121, 125, 129, 132, 133, 137, 138, 138, 142, 144, 149, 149, 151,\n       155, 157, 157, 160, 161, 162, 162, 164, 163, 165, 166, 166, 166,\n       168, 165, 169, 168, 167, 165, 167, 167, 168, 168, 168, 167, 165,\n       166, 166, 165, 169, 165, 167, 168, 168, 167, 169, 166, 166, 166,\n       168, 167, 169], dtype=uint8), array([8.73503977])], [array([167, 167, 167, 166, 167, 168, 170, 168, 170, 167, 165, 164, 167,\n       167, 169, 169, 168, 166, 168, 167, 168, 168, 167, 165, 165, 166,\n       169, 167, 168, 165, 163, 166, 166, 165, 167, 166, 167, 167, 166,\n       167, 168, 168, 165, 167, 169, 167, 167, 170, 169, 167, 166, 167,\n       169, 167, 167, 164, 162, 156, 146, 138, 132, 127, 128, 137, 142,\n       140, 139, 139, 139, 140, 142, 143, 146, 147, 150, 152, 155, 157,\n       157, 159, 161, 162, 163, 165, 165, 166, 167, 167, 167, 167, 166,\n       170, 170, 170, 168, 166, 166, 161, 158, 148, 139, 136, 141, 145,\n       144, 145, 145, 146, 148, 149, 150, 150, 151, 154, 156, 159, 159,\n       163, 160, 161], dtype=uint8), array([4.18356936])], [array([167, 166, 165, 168, 167, 167, 168, 169, 169, 168, 169, 169, 168,\n       168, 170, 169, 169, 168, 166, 166, 168, 165, 165, 164, 165, 166,\n       167, 167, 171, 165, 166, 167, 169, 167, 168, 169, 170, 169, 165,\n       165, 168, 170, 167, 167, 167, 165, 166, 168, 165, 168, 166, 167,\n       168, 168, 169, 167, 169, 172, 167, 167, 166, 160, 153, 145, 137,\n       138, 141, 145, 142, 142, 142, 143, 144, 145, 145, 147, 149, 152,\n       153, 155, 156, 159, 161, 160, 161, 163, 161, 163, 164, 165, 165,\n       167, 167, 166, 166, 169, 170, 167, 171, 172, 168, 169, 168, 166,\n       170, 170, 172, 170, 169, 168, 164, 162, 161, 160, 161, 160, 159,\n       158, 159, 161], dtype=uint8), array([4.35067225])], [array([150, 152, 149, 148, 150, 152, 152, 150, 151, 152, 154, 154, 153,\n       151, 150, 152, 149, 150, 147, 152, 150, 150, 153, 152, 153, 150,\n       151, 151, 151, 151, 153, 154, 153, 152, 154, 151, 153, 152, 150,\n       151, 148, 153, 156, 150, 148, 148, 150, 150, 150, 151, 151, 151,\n       151, 152, 154, 153, 151, 153, 153, 152, 153, 151, 151, 151, 149,\n       149, 150, 150, 150, 148, 148, 147, 149, 148, 149, 148, 148, 147,\n       148, 147, 149, 149, 149, 149, 148, 151, 147, 148, 149, 149, 147,\n       145, 147, 146, 145, 145, 147, 147, 146, 147, 145, 147, 146, 147,\n       145, 145, 148, 147, 146, 149, 151, 147, 147, 149, 146, 146, 146,\n       146, 147, 147], dtype=uint8), array([0.])], [array([159, 158, 160, 160, 159, 159, 162, 160, 160, 158, 158, 156, 159,\n       160, 159, 158, 159, 160, 160, 158, 159, 157, 158, 160, 160, 159,\n       159, 161, 158, 157, 160, 161, 160, 159, 161, 158, 160, 160, 158,\n       157, 158, 157, 157, 157, 156, 161, 158, 157, 156, 156, 155, 159,\n       159, 158, 156, 155, 158, 159, 160, 160, 161, 159, 158, 161, 161,\n       163, 161, 160, 162, 160, 162, 161, 157, 146, 132, 120, 115, 105,\n       106, 124, 132, 133, 134, 136, 135, 135, 133, 133, 135, 135, 138,\n       139, 139, 142, 143, 143, 145, 147, 147, 147, 152, 152, 154, 154,\n       154, 153, 151, 151, 154, 153, 156, 159, 159, 160, 161, 160, 160,\n       159, 160, 159], dtype=uint8), array([4.75818342])], [array([161, 160, 160, 160, 160, 159, 158, 159, 159, 159, 159, 159, 161,\n       159, 158, 158, 158, 160, 159, 159, 159, 160, 157, 158, 157, 155,\n       158, 158, 158, 156, 153, 151, 155, 150, 150, 146, 144, 143, 143,\n       143, 141, 141, 139, 140, 139, 138, 137, 138, 139, 139, 138, 137,\n       138, 139, 139, 140, 139, 132, 126, 129, 138, 148, 156, 160, 159,\n       161, 160, 161, 158, 158, 157, 158, 159, 158, 159, 159, 160, 157,\n       158, 161, 158, 159, 158, 158, 157, 159, 158, 158, 158, 157, 157,\n       155, 156, 157, 156, 155, 154, 153, 153, 152, 151, 153, 154, 154,\n       154, 156, 156, 154, 154, 157, 158, 158, 158, 158, 156, 158, 157,\n       159, 160, 158], dtype=uint8), array([3.84824603])], [array([157, 159, 159, 160, 159, 157, 157, 158, 159, 157, 156, 157, 156,\n       154, 157, 157, 156, 154, 151, 153, 154, 156, 156, 155, 155, 156,\n       153, 152, 156, 157, 155, 155, 153, 153, 154, 152, 150, 153, 152,\n       152, 152, 151, 152, 153, 150, 149, 148, 147, 147, 144, 144, 141,\n       141, 139, 137, 137, 135, 135, 132, 132, 131, 132, 130, 129, 127,\n       128, 128, 128, 128, 116, 104, 106, 114, 121, 126, 136, 144, 147,\n       148, 152, 152, 152, 152, 152, 153, 153, 153, 153, 152, 153, 153,\n       152, 151, 150, 148, 147, 147, 147, 146, 142, 139, 132, 127, 126,\n       126, 124, 128, 133, 139, 142, 146, 147, 149, 147, 150, 152, 153,\n       153, 152, 154], dtype=uint8), array([5.52762087])], [array([156, 160, 162, 158, 157, 158, 157, 156, 156, 156, 157, 157, 159,\n       159, 156, 155, 156, 156, 156, 157, 156, 155, 154, 155, 154, 153,\n       153, 152, 149, 149, 148, 143, 146, 141, 140, 140, 137, 137, 137,\n       135, 134, 131, 129, 125, 126, 123, 121, 119, 122, 125, 126, 125,\n       130, 127, 128, 126, 115, 107, 114, 124, 130, 140, 151, 155, 157,\n       160, 158, 156, 156, 156, 158, 157, 156, 156, 155, 154, 154, 154,\n       153, 154, 157, 157, 154, 153, 153, 154, 152, 151, 153, 154, 153,\n       152, 152, 153, 153, 152, 154, 157, 152, 151, 152, 153, 153, 152,\n       149, 150, 152, 150, 151, 150, 149, 147, 151, 149, 151, 148, 147,\n       147, 146, 146], dtype=uint8), array([5.24173503])], [array([150, 151, 151, 151, 151, 153, 152, 154, 152, 152, 152, 149, 147,\n       146, 150, 150, 150, 151, 149, 146, 147, 150, 145, 144, 147, 145,\n       143, 142, 142, 142, 138, 134, 132, 130, 126, 128, 131, 128, 126,\n       128, 125, 126, 127, 125, 126, 128, 131, 132, 131, 133, 134, 133,\n       133, 131, 126, 118, 119, 132, 140, 151, 149, 150, 150, 151, 151,\n       150, 149, 148, 145, 148, 146, 147, 148, 147, 146, 147, 146, 147,\n       147, 149, 147, 146, 146, 143, 143, 145, 146, 146, 146, 145, 147,\n       147, 145, 144, 145, 143, 142, 145, 146, 146, 146, 146, 147, 146,\n       145, 148, 147, 147, 146, 146, 147, 147, 145, 146, 148, 146, 146,\n       146, 146, 145], dtype=uint8), array([3.48806279])], [array([148, 150, 150, 147, 148, 150, 146, 147, 147, 148, 146, 148, 147,\n       148, 147, 146, 145, 146, 144, 145, 147, 145, 148, 144, 145, 146,\n       147, 145, 146, 146, 145, 145, 145, 149, 147, 145, 147, 148, 147,\n       145, 147, 145, 146, 147, 145, 144, 147, 146, 144, 145, 144, 145,\n       145, 148, 144, 145, 144, 144, 142, 141, 142, 142, 140, 139, 139,\n       141, 140, 142, 139, 141, 138, 139, 138, 135, 134, 126, 114, 109,\n       104, 100, 108, 121, 124, 126, 125, 125, 126, 127, 124, 126, 127,\n       128, 128, 128, 127, 128, 126, 129, 128, 130, 128, 128, 124, 126,\n       126, 125, 126, 127, 126, 125, 126, 124, 125, 126, 123, 123, 125,\n       121, 116, 105], dtype=uint8), array([4.68352392])], [array([146, 148, 146, 147, 147, 147, 145, 144, 146, 144, 144, 146, 149,\n       143, 146, 144, 145, 144, 144, 144, 144, 140, 141, 142, 141, 141,\n       137, 137, 140, 142, 139, 137, 138, 141, 135, 134, 133, 130, 128,\n       127, 120, 107, 104, 105, 107, 110, 122, 127, 130, 129, 130, 130,\n       131, 131, 132, 133, 131, 128, 130, 132, 132, 128, 132, 132, 132,\n       131, 131, 133, 134, 131, 133, 128, 117, 111, 106, 105, 114, 126,\n       135, 137, 138, 140, 142, 143, 144, 145, 143, 144, 144, 144, 146,\n       145, 143, 144, 145, 146, 146, 146, 147, 145, 146, 146, 145, 145,\n       145, 146, 145, 145, 145, 149, 146, 147, 146, 145, 144, 144, 145,\n       144, 143, 146], dtype=uint8), array([4.45399496])], [array([162, 160, 159, 159, 158, 159, 159, 160, 158, 158, 160, 160, 159,\n       157, 157, 159, 160, 160, 163, 163, 161, 161, 160, 156, 155, 156,\n       158, 161, 156, 160, 159, 160, 159, 161, 161, 161, 160, 157, 157,\n       157, 158, 159, 159, 156, 156, 160, 159, 158, 160, 159, 159, 159,\n       160, 159, 158, 159, 161, 156, 160, 160, 161, 158, 160, 155, 156,\n       157, 158, 159, 156, 157, 159, 159, 155, 157, 156, 158, 157, 158,\n       156, 158, 159, 159, 156, 156, 158, 159, 158, 158, 157, 159, 159,\n       157, 158, 158, 157, 157, 157, 158, 156, 156, 157, 159, 158, 158,\n       159, 157, 160, 158, 161, 156, 154, 156, 157, 156, 154, 157, 157,\n       159, 155, 155], dtype=uint8), array([0.])], [array([171, 172, 174, 171, 171, 171, 169, 170, 174, 174, 174, 171, 171,\n       170, 169, 176, 173, 170, 171, 170, 172, 171, 173, 173, 172, 172,\n       173, 169, 171, 172, 172, 172, 171, 169, 170, 171, 170, 169, 171,\n       169, 170, 172, 172, 174, 171, 172, 168, 166, 168, 170, 171, 169,\n       170, 165, 165, 166, 164, 162, 161, 159, 159, 160, 154, 154, 149,\n       134, 111, 104, 109, 107,  90,  82,  95, 111, 120, 122, 126, 126,\n       129, 133, 137, 141, 143, 146, 148, 153, 156, 158, 158, 162, 164,\n       164, 165, 168, 169, 170, 168, 171, 170, 171, 171, 171, 170, 168,\n       168, 170, 169, 171, 171, 170, 171, 169, 170, 171, 171, 172, 172,\n       170, 170, 170], dtype=uint8), array([8.71474618])], [array([174, 175, 173, 173, 170, 172, 174, 170, 172, 173, 173, 171, 173,\n       173, 172, 172, 172, 171, 173, 172, 171, 174, 173, 172, 170, 170,\n       171, 171, 171, 171, 173, 175, 174, 172, 175, 171, 169, 172, 170,\n       171, 170, 165, 169, 169, 170, 169, 170, 173, 175, 170, 170, 170,\n       167, 168, 169, 166, 165, 166, 163, 163, 160, 159, 153, 155, 150,\n       149, 137, 116,  90,  74,  87, 109, 116, 110, 102, 108, 124, 135,\n       136, 137, 139, 142, 146, 149, 149, 153, 153, 157, 158, 159, 158,\n       162, 165, 166, 165, 167, 168, 168, 168, 168, 168, 166, 170, 172,\n       169, 169, 169, 173, 171, 170, 170, 172, 172, 173, 171, 172, 172,\n       172, 172, 170], dtype=uint8), array([9.02551505])], [array([137, 139, 145, 146, 146, 145, 146, 148, 151, 151, 152, 154, 153,\n       154, 157, 156, 157, 159, 161, 159, 158, 159, 161, 163, 162, 163,\n       165, 165, 162, 164, 165, 166, 169, 167, 166, 167, 166, 164, 167,\n       165, 167, 167, 167, 164, 161, 155, 144, 123, 115, 125, 123, 104,\n       101, 109, 116, 117, 120, 121, 124, 130, 133, 137, 140, 142, 145,\n       152, 152, 153, 155, 159, 160, 162, 163, 166, 168, 167, 168, 168,\n       166, 169, 168, 168, 169, 169, 171, 170, 172, 173, 172, 171, 170,\n       172, 169, 171, 170, 171, 172, 171, 169, 170, 171, 170, 172, 170,\n       169, 171, 173, 171, 171, 171, 170, 170, 170, 173, 171, 170, 171,\n       171, 172, 169], dtype=uint8), array([7.32964192])], [array([173, 174, 171, 173, 173, 173, 173, 173, 172, 173, 171, 173, 177,\n       173, 176, 173, 172, 172, 174, 175, 174, 173, 173, 173, 174, 176,\n       175, 172, 175, 174, 172, 170, 173, 171, 169, 170, 167, 164, 159,\n       161, 159, 162, 168, 167, 168, 169, 170, 171, 173, 173, 172, 171,\n       171, 170, 167, 168, 167, 170, 170, 165, 163, 162, 157, 143, 131,\n       126, 118, 120, 131, 140, 144, 144, 149, 153, 158, 161, 161, 163,\n       164, 165, 169, 170, 168, 173, 172, 172, 171, 171, 172, 174, 174,\n       174, 173, 172, 172, 172, 175, 165, 176, 174, 175, 174, 174, 175,\n       174, 173, 174, 174, 175, 176, 173, 173, 172, 174, 173, 172, 172,\n       173, 173, 172], dtype=uint8), array([4.88385177])], [array([168, 169, 171, 171, 172, 170, 170, 170, 172, 171, 170, 171, 171,\n       169, 168, 167, 172, 172, 169, 169, 169, 169, 170, 171, 172, 170,\n       172, 171, 173, 173, 170, 170, 170, 169, 168, 165, 163, 162, 165,\n       159, 156, 155, 158, 163, 165, 166, 167, 168, 166, 165, 167, 167,\n       162, 158, 155, 153, 150, 148, 148, 147, 150, 149, 148, 150, 142,\n       139, 137, 139, 132, 113,  94,  94, 104, 106, 103, 117, 144, 155,\n       158, 161, 161, 165, 165, 166, 168, 169, 169, 164, 167, 165, 171,\n       172, 170, 171, 169, 169, 171, 172, 172, 171, 170, 171, 173, 171,\n       173, 174, 172, 172, 171, 172, 171, 173, 175, 174, 175, 174, 174,\n       171, 172, 173], dtype=uint8), array([6.54541434])], [array([167, 164, 161, 160, 160, 160, 157, 157, 159, 157, 158, 157, 155,\n       154, 151, 150, 148, 147, 137, 127, 120, 119, 124, 132, 141, 148,\n       152, 155, 153, 152, 149, 140, 128, 119, 115, 123, 128, 135, 139,\n       137, 136, 137, 140, 149, 154, 162, 161, 163, 166, 166, 165, 167,\n       169, 167, 168, 166, 168, 168, 168, 165, 161, 162, 159, 155, 156,\n       154, 153, 153, 150, 135, 112, 100, 111, 117, 106, 109, 127, 149,\n       152, 160, 161, 161, 163, 167, 166, 166, 168, 170, 168, 169, 169,\n       173, 175, 171, 171, 172, 174, 174, 172, 174, 174, 173, 174, 173,\n       172, 169, 172, 172, 173, 174, 172, 174, 171, 172, 172, 167, 165,\n       169, 171, 173], dtype=uint8), array([7.03218657])], [array([162, 159, 159, 158, 155, 152, 148, 145, 135, 129, 109, 104, 106,\n       109, 112, 114, 116, 122, 134, 145, 153, 155, 157, 157, 161, 160,\n       157, 160, 161, 163, 163, 163, 164, 164, 166, 168, 165, 170, 172,\n       171, 168, 168, 168, 170, 174, 171, 168, 165, 165, 167, 167, 164,\n       164, 161, 159, 158, 156, 155, 149, 148, 145, 142, 138, 135, 134,\n       136, 134, 128, 115,  99,  97, 109, 110, 107, 118, 139, 153, 157,\n       156, 162, 162, 163, 164, 164, 164, 168, 168, 168, 169, 170, 170,\n       171, 171, 172, 173, 172, 175, 174, 175, 172, 171, 176, 174, 173,\n       174, 175, 174, 175, 174, 173, 172, 171, 171, 172, 171, 170, 170,\n       170, 170, 172], dtype=uint8), array([6.38074043])], [array([165, 162, 163, 163, 164, 162, 160, 161, 163, 163, 163, 166, 165,\n       163, 164, 167, 165, 170, 166, 170, 167, 169, 169, 170, 169, 168,\n       168, 169, 167, 167, 166, 165, 161, 168, 171, 166, 169, 170, 170,\n       168, 169, 169, 168, 168, 166, 167, 168, 168, 166, 165, 168, 163,\n       166, 166, 163, 165, 164, 163, 164, 165, 163, 161, 157, 154, 155,\n       158, 159, 160, 160, 164, 159, 160, 156, 150, 144, 128, 115, 120,\n       127, 129, 136, 153, 163, 164, 169, 167, 170, 170, 168, 169, 169,\n       170, 172, 172, 170, 169, 169, 170, 169, 170, 174, 170, 174, 173,\n       170, 169, 170, 170, 170, 170, 170, 169, 172, 171, 170, 173, 170,\n       173, 176, 174], dtype=uint8), array([5.54238319])], [array([171, 170, 171, 173, 172, 172, 173, 175, 177, 176, 176, 174, 173,\n       173, 170, 174, 173, 173, 173, 173, 174, 176, 174, 172, 169, 172,\n       171, 170, 169, 167, 170, 167, 166, 168, 169, 166, 167, 167, 163,\n       164, 158, 156, 154, 154, 151, 153, 153, 152, 152, 150, 148, 148,\n       154, 160, 160, 163, 164, 163, 164, 167, 168, 167, 166, 165, 165,\n       164, 165, 163, 160, 159, 159, 156, 153, 150, 146, 145, 141, 135,\n       135, 140, 145, 152, 163, 169, 169, 171, 169, 169, 170, 171, 170,\n       170, 172, 170, 169, 171, 173, 172, 167, 163, 165, 167, 162, 162,\n       163, 163, 166, 165, 162, 167, 170, 168, 171, 170, 169, 171, 174,\n       172, 173, 170], dtype=uint8), array([4.58639866])], [array([175, 175, 178, 173, 174, 175, 173, 174, 174, 178, 178, 176, 176,\n       179, 175, 173, 176, 173, 173, 173, 173, 173, 174, 176, 176, 173,\n       171, 172, 173, 173, 174, 172, 172, 173, 176, 175, 175, 175, 175,\n       174, 175, 174, 173, 172, 174, 172, 170, 169, 169, 167, 166, 164,\n       156, 145, 135, 123, 109, 109, 124, 138, 142, 138, 140, 142, 141,\n       142, 147, 149, 155, 158, 159, 162, 164, 168, 169, 169, 169, 170,\n       172, 174, 176, 177, 175, 173, 174, 176, 179, 174, 172, 175, 175,\n       175, 175, 179, 176, 175, 174, 177, 176, 176, 177, 177, 174, 174,\n       177, 176, 174, 175, 177, 175, 173, 175, 177, 177, 176, 174, 173,\n       173, 174, 178], dtype=uint8), array([5.4984222])], [array([163, 161, 158, 157, 160, 157, 152, 145, 136, 122, 109,  99,  96,\n       100, 107, 110, 117, 120, 126, 128, 130, 131, 135, 134, 141, 145,\n       150, 152, 155, 161, 161, 161, 164, 164, 162, 164, 164, 163, 162,\n       164, 167, 166, 163, 166, 168, 167, 167, 165, 166, 167, 167, 168,\n       168, 168, 164, 162, 162, 163, 166, 166, 164, 165, 164, 162, 159,\n       156, 146, 127, 117, 123, 128, 117,  96,  91, 102, 111, 117, 120,\n       122, 125, 128, 132, 135, 138, 141, 145, 146, 153, 157, 158, 161,\n       162, 160, 163, 165, 170, 170, 169, 168, 172, 171, 170, 169, 169,\n       168, 171, 169, 171, 173, 175, 173, 172, 172, 172, 173, 173, 172,\n       172, 173, 175], dtype=uint8), array([8.81468908])], [array([173, 173, 171, 172, 172, 172, 174, 173, 171, 170, 172, 173, 170,\n       169, 171, 171, 168, 169, 172, 173, 172, 172, 171, 169, 172, 173,\n       171, 171, 173, 173, 172, 174, 174, 173, 173, 172, 172, 173, 170,\n       172, 175, 174, 175, 175, 172, 171, 173, 174, 172, 171, 171, 170,\n       170, 173, 172, 169, 172, 168, 167, 164, 167, 168, 166, 166, 163,\n       163, 164, 162, 162, 162, 160, 162, 160, 156, 154, 141, 124,  96,\n        90,  89,  94, 118, 141, 155, 159, 162, 163, 163, 167, 166, 168,\n       170, 167, 168, 172, 174, 167, 170, 172, 173, 171, 173, 175, 174,\n       172, 173, 171, 175, 171, 171, 170, 173, 172, 170, 174, 176, 170,\n       173, 172, 176], dtype=uint8), array([5.09065576])], [array([147, 150, 150, 150, 150, 147, 149, 152, 151, 148, 149, 148, 151,\n       151, 152, 153, 151, 147, 148, 149, 150, 151, 153, 152, 151, 153,\n       153, 152, 150, 151, 152, 153, 151, 151, 150, 152, 151, 152, 151,\n       151, 151, 149, 150, 152, 153, 153, 155, 153, 153, 151, 152, 154,\n       152, 153, 151, 151, 151, 152, 154, 152, 150, 152, 153, 150, 154,\n       154, 154, 155, 153, 152, 157, 158, 157, 155, 156, 155, 154, 154,\n       153, 157, 156, 152, 152, 154, 156, 151, 152, 156, 157, 155, 153,\n       152, 154, 152, 152, 154, 152, 152, 154, 153, 155, 152, 152, 151,\n       153, 154, 151, 150, 152, 154, 154, 154, 151, 151, 153, 153, 153,\n       152, 152, 153], dtype=uint8), array([0.])], [array([171, 170, 168, 167, 171, 170, 167, 167, 168, 169, 169, 170, 168,\n       169, 168, 169, 171, 168, 167, 167, 168, 169, 170, 169, 164, 167,\n       166, 167, 168, 170, 169, 169, 167, 167, 168, 167, 167, 167, 168,\n       166, 168, 167, 166, 167, 167, 168, 170, 170, 168, 170, 171, 172,\n       168, 169, 167, 167, 168, 167, 169, 166, 164, 164, 159, 148, 130,\n       116, 107, 108, 116, 131, 138, 138, 142, 143, 142, 144, 144, 146,\n       148, 151, 153, 154, 157, 159, 161, 161, 162, 162, 161, 159, 164,\n       166, 167, 167, 168, 166, 168, 165, 169, 169, 169, 169, 170, 170,\n       168, 168, 169, 170, 170, 169, 167, 167, 167, 161, 154, 146, 137,\n       129, 131, 139], dtype=uint8), array([4.42544194])], [array([166, 168, 167, 164, 167, 166, 163, 167, 167, 165, 167, 166, 169,\n       167, 167, 169, 166, 167, 169, 168, 166, 167, 171, 169, 168, 170,\n       169, 168, 169, 168, 166, 168, 169, 170, 166, 167, 169, 166, 168,\n       166, 167, 167, 167, 165, 166, 164, 163, 158, 147, 141, 134, 126,\n       122, 126, 139, 142, 151, 153, 156, 160, 162, 161, 164, 165, 164,\n       164, 163, 165, 166, 167, 163, 155, 148, 137, 121, 112, 117, 131,\n       137, 139, 138, 137, 139, 141, 144, 145, 145, 148, 152, 152, 155,\n       157, 161, 160, 162, 162, 163, 163, 164, 165, 166, 166, 166, 166,\n       166, 167, 168, 171, 168, 167, 170, 166, 167, 168, 167, 168, 167,\n       167, 165, 165], dtype=uint8), array([4.45399496])], [array([143, 144, 146, 149, 150, 153, 150, 152, 154, 156, 154, 154, 158,\n       155, 159, 158, 153, 157, 157, 162, 162, 162, 160, 158, 159, 161,\n       163, 165, 165, 162, 163, 165, 164, 166, 166, 163, 165, 165, 167,\n       167, 167, 168, 167, 167, 165, 165, 167, 165, 168, 166, 167, 167,\n       168, 168, 167, 167, 167, 167, 168, 169, 169, 169, 169, 168, 170,\n       170, 168, 169, 168, 168, 167, 166, 165, 165, 165, 164, 158, 146,\n       132, 119, 109, 109, 124, 136, 141, 147, 148, 148, 150, 153, 154,\n       155, 156, 158, 159, 162, 164, 165, 164, 164, 166, 167, 167, 165,\n       166, 169, 168, 167, 167, 169, 171, 171, 171, 168, 163, 153, 141,\n       126, 113, 105], dtype=uint8), array([4.68352392])], [array([166, 170, 170, 167, 166, 167, 167, 167, 169, 168, 166, 165, 166,\n       168, 167, 167, 166, 168, 169, 166, 165, 162, 164, 165, 167, 167,\n       165, 170, 166, 166, 163, 165, 164, 161, 165, 165, 169, 168, 167,\n       169, 167, 166, 167, 165, 167, 165, 162, 160, 160, 154, 148, 138,\n       131, 130, 134, 141, 148, 150, 151, 152, 152, 153, 153, 151, 153,\n       154, 151, 151, 152, 152, 153, 153, 155, 156, 159, 161, 157, 161,\n       161, 163, 161, 161, 164, 165, 164, 164, 164, 165, 168, 163, 162,\n       163, 165, 166, 168, 168, 168, 167, 165, 169, 169, 168, 167, 168,\n       168, 167, 169, 169, 167, 167, 168, 168, 169, 169, 168, 168, 166,\n       169, 169, 165], dtype=uint8), array([3.48806279])], [array([153, 151, 152, 155, 157, 159, 163, 163, 163, 163, 165, 164, 169,\n       165, 163, 165, 166, 165, 164, 167, 166, 168, 166, 165, 165, 166,\n       167, 166, 165, 166, 168, 167, 167, 168, 170, 166, 170, 167, 167,\n       165, 165, 168, 168, 167, 168, 167, 168, 168, 167, 165, 165, 169,\n       167, 167, 166, 165, 167, 168, 165, 169, 168, 168, 167, 168, 168,\n       167, 166, 170, 167, 168, 166, 166, 164, 152, 140, 130, 116, 103,\n       105, 121, 131, 133, 134, 133, 137, 137, 138, 140, 143, 145, 143,\n       148, 151, 154, 156, 157, 159, 159, 159, 161, 162, 164, 164, 163,\n       165, 165, 165, 167, 167, 167, 168, 168, 169, 169, 171, 169, 170,\n       167, 165, 167], dtype=uint8), array([5.52762087])], [array([166, 166, 167, 168, 167, 164, 165, 166, 166, 168, 170, 168, 167,\n       168, 168, 167, 167, 167, 166, 166, 165, 165, 165, 166, 165, 166,\n       167, 168, 167, 166, 167, 166, 166, 165, 166, 166, 165, 165, 162,\n       156, 148, 141, 141, 148, 156, 161, 162, 162, 164, 165, 167, 166,\n       163, 159, 151, 141, 134, 130, 121, 111, 112, 120, 124, 127, 128,\n       125, 123, 124, 126, 129, 132, 136, 139, 142, 146, 147, 149, 151,\n       152, 155, 154, 157, 159, 159, 160, 162, 163, 163, 163, 164, 164,\n       166, 167, 167, 165, 163, 163, 164, 165, 166, 166, 165, 165, 165,\n       165, 167, 167, 167, 167, 167, 166, 166, 166, 165, 166, 166, 165,\n       168, 168, 168], dtype=uint8), array([5.24173503])], [array([164, 164, 166, 166, 168, 166, 165, 164, 167, 164, 163, 165, 165,\n       165, 165, 165, 166, 166, 166, 166, 162, 165, 166, 166, 161, 159,\n       159, 155, 151, 148, 148, 153, 156, 160, 164, 163, 162, 164, 164,\n       163, 164, 167, 165, 164, 166, 166, 163, 164, 164, 164, 168, 163,\n       162, 161, 162, 161, 159, 156, 157, 155, 155, 153, 149, 150, 147,\n       145, 143, 141, 139, 137, 139, 136, 134, 134, 135, 129, 119, 112,\n       114, 117, 125, 141, 152, 157, 159, 160, 162, 163, 165, 163, 162,\n       162, 163, 162, 165, 163, 165, 165, 166, 165, 165, 162, 163, 164,\n       163, 163, 167, 169, 167, 167, 167, 164, 165, 166, 164, 165, 164,\n       166, 164, 166], dtype=uint8), array([4.75818342])], [array([158, 159, 161, 162, 163, 163, 161, 162, 163, 162, 161, 162, 164,\n       163, 163, 163, 162, 161, 162, 163, 162, 160, 161, 165, 164, 166,\n       167, 163, 161, 163, 162, 162, 165, 163, 161, 159, 161, 160, 162,\n       162, 166, 163, 164, 165, 166, 169, 167, 165, 167, 166, 167, 166,\n       166, 164, 161, 155, 143, 131, 124, 127, 134, 136, 138, 141, 141,\n       136, 134, 135, 136, 137, 138, 140, 143, 146, 149, 152, 154, 155,\n       158, 159, 159, 159, 162, 163, 161, 160, 161, 163, 166, 162, 162,\n       164, 164, 164, 168, 168, 166, 167, 164, 167, 161, 165, 168, 164,\n       163, 162, 163, 164, 166, 163, 160, 157, 156, 157, 154, 152, 152,\n       152, 151, 153], dtype=uint8), array([3.84824603])], [array([157, 157, 156, 156, 159, 159, 158, 157, 157, 158, 157, 154, 155,\n       155, 154, 155, 156, 158, 157, 156, 155, 157, 154, 155, 157, 157,\n       156, 156, 157, 157, 156, 156, 159, 158, 158, 159, 160, 160, 158,\n       157, 155, 159, 160, 162, 161, 161, 161, 162, 162, 162, 163, 162,\n       161, 162, 162, 161, 159, 157, 155, 154, 151, 149, 140, 134, 133,\n       126, 116, 109, 113, 118, 121, 120, 113, 108, 108, 109, 110, 112,\n       116, 116, 121, 122, 124, 126, 129, 130, 134, 138, 140, 142, 143,\n       147, 150, 151, 152, 152, 154, 155, 157, 157, 159, 158, 159, 160,\n       159, 158, 158, 160, 157, 159, 159, 159, 159, 159, 158, 160, 162,\n       163, 163, 163], dtype=uint8), array([6.3266849])], [array([129, 130, 132, 134, 134, 133, 137, 140, 141, 139, 138, 140, 143,\n       145, 146, 144, 147, 146, 146, 148, 150, 153, 154, 154, 154, 154,\n       153, 155, 155, 156, 157, 157, 160, 159, 157, 157, 158, 156, 156,\n       157, 158, 161, 157, 160, 158, 159, 161, 160, 159, 158, 158, 158,\n       160, 160, 156, 159, 155, 153, 145, 140, 134, 129, 129, 136, 142,\n       147, 146, 148, 144, 142, 142, 143, 143, 139, 132, 117, 106, 101,\n        93,  90, 100, 111, 119, 122, 127, 130, 129, 131, 135, 138, 139,\n       140, 143, 146, 142, 146, 150, 153, 152, 154, 156, 157, 158, 161,\n       159, 162, 160, 160, 161, 161, 162, 163, 161, 161, 163, 162, 163,\n       161, 161, 163], dtype=uint8), array([5.48232787])], [array([133, 134, 132, 136, 134, 138, 140, 135, 138, 140, 140, 141, 140,\n       141, 143, 147, 143, 146, 146, 148, 149, 144, 150, 150, 153, 151,\n       148, 154, 152, 151, 150, 154, 151, 153, 152, 154, 150, 151, 150,\n       150, 153, 156, 156, 158, 151, 156, 153, 155, 155, 156, 156, 156,\n       158, 154, 156, 157, 155, 154, 157, 154, 157, 156, 158, 157, 159,\n       159, 158, 161, 158, 162, 160, 161, 162, 160, 155, 147, 138, 121,\n       111, 105, 108, 112, 118, 121, 122, 125, 125, 124, 125, 126, 126,\n       131, 130, 131, 135, 134, 137, 140, 137, 139, 145, 146, 150, 151,\n       152, 149, 155, 154, 154, 154, 152, 161, 157, 159, 158, 159, 159,\n       161, 160, 159], dtype=uint8), array([4.22418291])], [array([168, 169, 167, 170, 169, 170, 171, 169, 168, 168, 168, 165, 170,\n       167, 169, 171, 168, 166, 165, 166, 169, 168, 167, 165, 165, 166,\n       166, 167, 169, 169, 168, 169, 168, 169, 170, 168, 166, 167, 166,\n       167, 166, 167, 167, 168, 169, 168, 167, 167, 171, 170, 170, 168,\n       168, 169, 167, 170, 170, 170, 169, 169, 169, 170, 171, 170, 169,\n       167, 168, 168, 169, 168, 167, 168, 167, 165, 167, 169, 167, 169,\n       167, 169, 168, 167, 168, 168, 170, 170, 167, 167, 169, 170, 170,\n       168, 169, 167, 170, 170, 169, 171, 169, 167, 170, 167, 168, 170,\n       167, 168, 168, 168, 165, 165, 169, 167, 165, 168, 166, 165, 168,\n       168, 167, 167], dtype=uint8), array([0.])], [array([163, 162, 165, 164, 165, 162, 162, 163, 163, 164, 165, 164, 164,\n       165, 163, 162, 162, 164, 165, 166, 165, 163, 165, 165, 168, 164,\n       164, 166, 167, 166, 164, 168, 167, 164, 165, 165, 165, 167, 167,\n       167, 165, 165, 166, 165, 166, 166, 165, 166, 168, 166, 167, 167,\n       166, 167, 167, 167, 166, 166, 165, 168, 166, 166, 167, 164, 159,\n       154, 143, 130, 122, 126, 133, 139, 139, 139, 139, 141, 139, 141,\n       144, 146, 149, 149, 152, 150, 153, 154, 159, 158, 158, 159, 163,\n       164, 163, 164, 164, 164, 165, 165, 166, 165, 166, 167, 167, 167,\n       166, 166, 166, 166, 168, 167, 167, 167, 169, 168, 163, 166, 168,\n       165, 166, 166], dtype=uint8), array([3.71157107])], [array([166, 163, 163, 163, 165, 165, 164, 166, 167, 165, 165, 165, 166,\n       166, 167, 166, 166, 167, 165, 163, 165, 166, 165, 165, 165, 164,\n       168, 167, 168, 166, 165, 166, 165, 167, 165, 164, 166, 163, 165,\n       163, 161, 162, 160, 156, 157, 156, 154, 154, 154, 158, 158, 160,\n       162, 163, 162, 163, 164, 164, 167, 167, 167, 167, 161, 163, 162,\n       164, 163, 161, 158, 156, 155, 151, 150, 144, 129, 117, 113, 110,\n       114, 129, 139, 140, 141, 141, 144, 146, 147, 148, 150, 152, 153,\n       154, 156, 159, 162, 164, 162, 164, 163, 162, 165, 167, 166, 167,\n       166, 168, 165, 165, 165, 164, 165, 165, 165, 163, 165, 166, 167,\n       165, 165, 166], dtype=uint8), array([4.08382213])], [array([168, 167, 166, 164, 165, 167, 164, 165, 167, 168, 166, 167, 169,\n       167, 166, 167, 167, 166, 168, 168, 168, 165, 164, 164, 164, 168,\n       166, 165, 167, 167, 166, 166, 164, 166, 168, 164, 165, 164, 161,\n       160, 158, 156, 157, 153, 149, 141, 129, 119, 115, 119, 135, 150,\n       155, 160, 164, 161, 162, 164, 166, 166, 168, 166, 165, 168, 169,\n       163, 167, 165, 165, 167, 170, 165, 168, 168, 168, 165, 166, 166,\n       167, 166, 168, 169, 170, 167, 169, 169, 169, 167, 167, 169, 166,\n       166, 167, 168, 168, 166, 164, 163, 165, 164, 166, 167, 165, 162,\n       161, 160, 160, 160, 156, 153, 150, 148, 145, 137, 128, 126, 126,\n       127, 132, 136], dtype=uint8), array([3.69767209])], [array([158, 159, 158, 160, 161, 161, 159, 156, 161, 161, 162, 161, 161,\n       163, 165, 162, 163, 163, 159, 152, 144, 136, 133, 135, 139, 144,\n       147, 146, 145, 144, 144, 144, 143, 142, 137, 134, 133, 131, 128,\n       126, 123, 118, 117, 114, 114, 117, 127, 133, 137, 140, 142, 143,\n       146, 146, 146, 146, 148, 145, 147, 150, 151, 151, 153, 153, 150,\n       151, 155, 159, 157, 150, 142, 129, 117, 110, 114, 122, 131, 131,\n       132, 131, 130, 127, 125, 126, 128, 128, 132, 133, 135, 137, 140,\n       142, 142, 143, 146, 146, 150, 151, 153, 154, 154, 153, 157, 158,\n       157, 159, 159, 161, 160, 160, 161, 158, 159, 160, 161, 164, 160,\n       159, 161, 159], dtype=uint8), array([4.18255064])], [array([165, 165, 165, 167, 164, 161, 164, 165, 163, 168, 169, 166, 165,\n       163, 164, 167, 167, 165, 165, 163, 165, 166, 165, 166, 166, 164,\n       164, 166, 165, 165, 164, 161, 163, 163, 164, 163, 163, 165, 165,\n       163, 163, 163, 163, 163, 163, 160, 157, 159, 159, 156, 155, 155,\n       152, 149, 147, 146, 146, 144, 143, 140, 140, 136, 132, 129, 130,\n       130, 130, 128, 127, 122, 102,  84,  94, 106,  96,  85,  95, 121,\n       138, 145, 145, 149, 149, 151, 154, 154, 153, 157, 159, 161, 162,\n       163, 165, 163, 163, 165, 163, 164, 167, 164, 164, 167, 166, 164,\n       165, 164, 166, 163, 163, 165, 164, 165, 165, 164, 163, 162, 164,\n       163, 166, 161], dtype=uint8), array([9.01671984])], [array([119, 126, 132, 137, 139, 142, 144, 145, 144, 143, 143, 145, 146,\n       142, 141, 143, 141, 144, 142, 143, 143, 143, 143, 141, 140, 139,\n       139, 135, 135, 136, 139, 139, 140, 141, 143, 137, 135, 131, 132,\n       134, 132, 126, 123, 121, 119, 116, 112, 117, 124, 132, 137, 139,\n       139, 142, 145, 145, 143, 144, 143, 145, 147, 149, 150, 141, 130,\n       126, 133, 127, 127, 135, 147, 155, 155, 155, 158, 160, 163, 162,\n       159, 158, 161, 162, 162, 162, 165, 163, 161, 163, 163, 162, 160,\n       160, 162, 162, 159, 160, 160, 160, 158, 159, 158, 159, 161, 160,\n       161, 161, 160, 159, 159, 161, 159, 162, 163, 161, 159, 160, 161,\n       163, 161, 160], dtype=uint8), array([6.47364817])], [array([165, 162, 161, 161, 162, 159, 160, 159, 161, 163, 159, 157, 159,\n       159, 160, 159, 157, 160, 162, 159, 159, 161, 163, 158, 160, 163,\n       160, 157, 158, 159, 160, 161, 159, 161, 160, 159, 160, 162, 159,\n       160, 161, 159, 159, 160, 160, 163, 161, 159, 160, 158, 162, 164,\n       164, 163, 164, 162, 163, 164, 163, 164, 164, 165, 161, 163, 164,\n       165, 163, 162, 162, 162, 164, 165, 160, 153, 141, 129, 122, 118,\n       121, 136, 135, 136, 137, 137, 139, 140, 140, 142, 142, 140, 141,\n       141, 143, 146, 145, 147, 148, 151, 149, 151, 151, 154, 157, 155,\n       161, 159, 159, 158, 158, 157, 158, 159, 162, 161, 162, 162, 162,\n       162, 161, 161], dtype=uint8), array([4.51710674])], [array([168, 171, 167, 167, 165, 170, 169, 165, 167, 165, 168, 168, 166,\n       168, 167, 167, 166, 168, 167, 167, 166, 164, 163, 164, 163, 165,\n       166, 166, 168, 168, 167, 168, 166, 167, 167, 164, 167, 167, 166,\n       166, 166, 166, 167, 169, 168, 167, 170, 167, 170, 166, 168, 166,\n       169, 167, 166, 167, 169, 169, 168, 166, 164, 168, 169, 165, 166,\n       169, 169, 169, 169, 166, 166, 168, 166, 165, 166, 163, 158, 154,\n       148, 151, 153, 155, 154, 155, 156, 155, 156, 156, 158, 160, 162,\n       162, 159, 159, 160, 163, 162, 166, 165, 161, 165, 167, 165, 167,\n       166, 166, 167, 166, 166, 166, 167, 168, 166, 167, 165, 163, 164,\n       167, 166, 166], dtype=uint8), array([4.88037655])], [array([166, 168, 168, 167, 171, 170, 167, 166, 168, 166, 168, 166, 167,\n       168, 170, 167, 166, 169, 170, 169, 167, 167, 165, 165, 169, 168,\n       167, 167, 168, 167, 165, 165, 165, 165, 165, 165, 166, 168, 166,\n       168, 169, 169, 166, 165, 166, 168, 167, 164, 166, 164, 166, 167,\n       166, 164, 163, 164, 164, 163, 165, 164, 166, 162, 161, 164, 162,\n       163, 162, 165, 164, 161, 160, 158, 157, 159, 160, 160, 162, 166,\n       167, 162, 163, 160, 161, 164, 164, 162, 163, 162, 158, 158, 159,\n       161, 165, 166, 166, 166, 165, 165, 170, 168, 168, 167, 166, 164,\n       166, 165, 165, 165, 165, 167, 168, 165, 164, 162, 162, 163, 164,\n       165, 168, 165], dtype=uint8), array([4.75318777])], [array([164, 167, 165, 164, 165, 166, 167, 162, 163, 164, 163, 165, 166,\n       164, 161, 162, 161, 161, 160, 159, 158, 158, 158, 156, 155, 153,\n       150, 147, 146, 146, 144, 145, 143, 140, 138, 137, 138, 135, 134,\n       136, 133, 134, 134, 133, 133, 122, 109, 113, 123, 136, 151, 159,\n       163, 162, 159, 160, 163, 166, 162, 160, 160, 162, 168, 165, 165,\n       165, 167, 168, 166, 164, 166, 164, 163, 165, 166, 167, 165, 164,\n       166, 161, 163, 164, 166, 166, 164, 164, 164, 164, 164, 162, 165,\n       165, 164, 163, 164, 163, 163, 164, 164, 163, 164, 163, 165, 167,\n       164, 162, 161, 163, 163, 160, 162, 163, 160, 163, 164, 165, 164,\n       165, 163, 160], dtype=uint8), array([4.67930649])], [array([164, 165, 162, 163, 163, 165, 166, 164, 162, 161, 165, 169, 167,\n       165, 160, 164, 167, 162, 164, 165, 164, 164, 165, 163, 165, 168,\n       165, 163, 164, 163, 162, 165, 166, 164, 164, 162, 161, 161, 158,\n       161, 162, 163, 162, 161, 161, 162, 162, 164, 164, 162, 159, 159,\n       160, 161, 160, 162, 160, 158, 157, 154, 153, 156, 154, 152, 152,\n       150, 151, 143, 137, 133, 137, 142, 144, 145, 151, 149, 151, 151,\n       152, 152, 153, 153, 153, 155, 158, 160, 158, 158, 160, 160, 160,\n       161, 162, 161, 163, 159, 161, 162, 163, 164, 165, 166, 165, 164,\n       165, 165, 165, 164, 164, 163, 167, 163, 163, 164, 164, 163, 164,\n       166, 167, 167], dtype=uint8), array([3.66342182])], [array([147, 149, 147, 146, 146, 146, 145, 147, 146, 147, 147, 147, 146,\n       147, 146, 147, 148, 148, 148, 148, 149, 147, 146, 147, 147, 147,\n       147, 148, 147, 148, 149, 147, 149, 150, 146, 147, 148, 144, 146,\n       149, 147, 146, 151, 147, 147, 146, 147, 147, 147, 147, 148, 145,\n       145, 145, 144, 145, 146, 146, 145, 143, 141, 142, 143, 144, 143,\n       145, 146, 139, 138, 137, 137, 134, 131, 120, 107,  97,  98, 104,\n        94,  75,  67,  75,  77,  76,  76,  82,  84,  88,  92,  92,  92,\n        95,  96,  96, 100, 106, 108, 112, 114, 116, 117, 119, 121, 120,\n       124, 126, 126, 129, 131, 132, 133, 135, 136, 138, 139, 141, 145,\n       145, 143, 143], dtype=uint8), array([11.24816955])], [array([153, 152, 152, 151, 152, 152, 151, 153, 153, 150, 150, 150, 149,\n       151, 150, 148, 148, 148, 147, 145, 145, 139, 141, 138, 136, 135,\n       135, 131, 132, 133, 131, 130, 129, 125, 125, 128, 127, 126, 126,\n       126, 126, 129, 130, 132, 131, 131, 131, 123, 111, 112, 124, 136,\n       144, 152, 157, 157, 155, 158, 156, 156, 156, 156, 156, 152, 155,\n       155, 151, 151, 151, 150, 152, 153, 153, 149, 153, 151, 149, 151,\n       149, 148, 147, 148, 148, 151, 151, 149, 148, 149, 149, 149, 147,\n       148, 149, 150, 148, 146, 147, 148, 147, 150, 150, 150, 149, 148,\n       149, 150, 151, 151, 150, 150, 150, 150, 151, 149, 148, 147, 148,\n       150, 149, 148], dtype=uint8), array([5.29607184])], [array([153, 153, 151, 150, 152, 153, 154, 153, 150, 150, 150, 149, 149,\n       149, 149, 146, 149, 148, 147, 147, 146, 150, 147, 146, 144, 143,\n       142, 141, 141, 140, 137, 136, 135, 132, 130, 128, 128, 127, 125,\n       123, 119, 120, 120, 118, 119, 121, 121, 120, 119, 119, 115, 108,\n        97,  94, 109, 125, 135, 146, 156, 157, 156, 154, 155, 156, 156,\n       154, 154, 154, 155, 156, 156, 152, 151, 151, 152, 151, 150, 153,\n       154, 151, 151, 152, 151, 151, 149, 151, 150, 147, 147, 149, 148,\n       149, 149, 148, 146, 145, 143, 142, 142, 142, 139, 142, 142, 142,\n       141, 145, 144, 141, 145, 148, 145, 147, 149, 150, 149, 149, 149,\n       147, 146, 148], dtype=uint8), array([5.46791157])], [array([152, 152, 151, 152, 152, 152, 150, 151, 151, 151, 152, 153, 150,\n       151, 151, 153, 152, 150, 150, 150, 147, 147, 149, 147, 145, 144,\n       142, 142, 140, 138, 139, 138, 136, 134, 131, 131, 131, 128, 127,\n       128, 127, 124, 122, 122, 121, 120, 118, 120, 119, 122, 122, 126,\n       126, 126, 125, 116, 103, 103, 112, 124, 138, 149, 155, 156, 154,\n       155, 152, 148, 151, 155, 153, 153, 153, 151, 152, 152, 154, 153,\n       150, 152, 152, 151, 151, 153, 153, 152, 152, 150, 152, 153, 152,\n       152, 154, 153, 153, 153, 154, 151, 152, 155, 153, 152, 150, 151,\n       151, 150, 151, 151, 152, 150, 152, 151, 152, 152, 152, 151, 149,\n       149, 149, 143], dtype=uint8), array([5.45620238])], [array([167, 165, 166, 162, 161, 164, 163, 164, 166, 166, 164, 164, 165,\n       164, 164, 165, 164, 165, 165, 163, 163, 165, 167, 166, 166, 167,\n       168, 167, 168, 168, 164, 166, 166, 167, 166, 166, 167, 167, 166,\n       163, 162, 163, 161, 162, 163, 163, 163, 164, 167, 166, 167, 169,\n       166, 166, 168, 170, 168, 166, 167, 167, 167, 168, 168, 168, 168,\n       167, 166, 168, 168, 167, 167, 168, 169, 168, 167, 166, 166, 165,\n       164, 167, 169, 169, 166, 165, 166, 166, 165, 165, 165, 166, 166,\n       164, 164, 167, 168, 168, 169, 168, 167, 167, 167, 167, 167, 168,\n       167, 165, 166, 167, 165, 166, 166, 166, 167, 166, 170, 169, 166,\n       165, 165, 167], dtype=uint8), array([0.])], [array([130, 136, 144, 152, 155, 157, 160, 164, 164, 164, 164, 165, 166,\n       167, 168, 166, 167, 167, 168, 166, 169, 166, 166, 168, 168, 170,\n       170, 169, 170, 171, 171, 169, 172, 170, 169, 171, 170, 170, 171,\n       169, 171, 169, 170, 168, 173, 171, 173, 170, 170, 170, 167, 170,\n       169, 171, 170, 171, 173, 169, 169, 171, 170, 168, 169, 167, 165,\n       166, 162, 162, 163, 163, 156, 143, 123, 104,  96,  98,  97,  88,\n        76,  73,  80,  79,  80,  84,  92,  99, 103, 107, 108, 113, 119,\n       121, 124, 124, 127, 131, 135, 140, 142, 145, 148, 150, 153, 152,\n       156, 158, 158, 163, 164, 163, 165, 164, 165, 167, 166, 168, 169,\n       168, 169, 169], dtype=uint8), array([11.65322989])], [array([168, 167, 168, 168, 169, 170, 171, 167, 165, 168, 171, 172, 168,\n       170, 171, 172, 167, 168, 169, 169, 170, 169, 168, 169, 169, 168,\n       168, 167, 170, 172, 169, 168, 170, 171, 168, 172, 172, 170, 168,\n       167, 167, 168, 168, 166, 169, 169, 169, 168, 168, 169, 168, 169,\n       169, 170, 171, 169, 166, 168, 168, 167, 167, 165, 163, 160, 160,\n       160, 159, 153, 151, 145, 145, 141, 129, 114,  98, 100, 108, 108,\n       104,  95,  89,  94, 103, 111, 115, 117, 121, 126, 128, 130, 136,\n       140, 141, 144, 145, 148, 148, 151, 153, 155, 156, 158, 159, 163,\n       165, 164, 163, 163, 166, 165, 166, 168, 168, 167, 168, 169, 171,\n       170, 169, 168], dtype=uint8), array([11.24816955])], [array([168, 170, 169, 169, 172, 169, 167, 170, 169, 170, 169, 170, 170,\n       169, 169, 170, 172, 170, 171, 171, 171, 169, 169, 167, 171, 170,\n       168, 167, 168, 169, 169, 170, 170, 169, 169, 169, 168, 167, 168,\n       167, 169, 169, 166, 165, 166, 166, 165, 165, 164, 165, 163, 163,\n       160, 155, 157, 154, 153, 154, 150, 146, 136, 125, 116, 117, 120,\n       123, 124, 116, 105, 104, 114, 129, 142, 151, 157, 163, 165, 161,\n       159, 163, 166, 165, 165, 167, 167, 167, 165, 165, 167, 166, 167,\n       168, 164, 164, 168, 169, 167, 164, 165, 165, 166, 168, 165, 166,\n       167, 170, 169, 168, 168, 166, 166, 168, 165, 166, 168, 168, 167,\n       167, 164, 168], dtype=uint8), array([5.29607184])], [array([170, 173, 173, 169, 169, 170, 171, 171, 170, 172, 171, 172, 170,\n       169, 170, 169, 169, 172, 173, 172, 170, 170, 173, 174, 170, 169,\n       171, 170, 171, 170, 170, 170, 172, 170, 172, 172, 174, 173, 170,\n       171, 171, 169, 172, 172, 171, 169, 168, 169, 165, 160, 149, 135,\n       118, 105,  98, 108, 124, 133, 135, 137, 141, 145, 146, 149, 149,\n       151, 156, 160, 161, 160, 163, 166, 167, 167, 166, 170, 170, 171,\n       170, 169, 170, 172, 173, 169, 167, 169, 168, 172, 171, 170, 172,\n       172, 170, 169, 172, 170, 170, 169, 167, 166, 165, 165, 167, 167,\n       167, 167, 166, 168, 169, 169, 168, 169, 170, 169, 170, 170, 169,\n       170, 173, 172], dtype=uint8), array([5.46791157])], [array([170, 169, 169, 169, 168, 168, 169, 169, 171, 172, 170, 170, 172,\n       170, 171, 173, 170, 167, 168, 169, 168, 170, 170, 169, 169, 170,\n       170, 166, 163, 164, 161, 160, 162, 164, 165, 166, 169, 171, 167,\n       170, 169, 175, 172, 168, 171, 171, 171, 168, 170, 170, 169, 168,\n       165, 160, 149, 133, 117, 104,  95, 100, 114, 128, 129, 131, 135,\n       139, 142, 144, 144, 146, 149, 150, 157, 159, 160, 159, 163, 167,\n       166, 167, 169, 167, 170, 171, 171, 170, 166, 168, 166, 166, 167,\n       166, 169, 170, 169, 169, 169, 168, 168, 171, 172, 170, 168, 169,\n       172, 171, 168, 172, 169, 170, 173, 171, 171, 172, 171, 170, 167,\n       170, 172, 172], dtype=uint8), array([5.45620238])], [array([175, 171, 171, 172, 173, 172, 172, 173, 172, 172, 172, 172, 170,\n       171, 172, 171, 172, 173, 172, 172, 172, 171, 172, 173, 173, 174,\n       174, 173, 170, 170, 169, 168, 171, 169, 170, 170, 169, 171, 172,\n       172, 171, 172, 170, 173, 174, 172, 171, 170, 171, 170, 175, 173,\n       175, 174, 172, 171, 170, 169, 169, 170, 171, 172, 172, 171, 173,\n       169, 171, 168, 169, 172, 170, 169, 172, 172, 172, 169, 166, 163,\n       166, 168, 168, 169, 168, 167, 170, 169, 167, 170, 170, 170, 171,\n       172, 174, 172, 171, 171, 172, 172, 171, 173, 173, 171, 176, 172,\n       173, 172, 173, 173, 176, 174, 175, 173, 176, 172, 172, 173, 170,\n       171, 175, 170], dtype=uint8), array([3.54463004])], [array([154, 153, 153, 152, 153, 154, 153, 152, 155, 154, 155, 156, 155,\n       155, 157, 156, 156, 156, 156, 157, 155, 154, 156, 157, 157, 156,\n       155, 157, 158, 155, 157, 155, 156, 156, 155, 154, 155, 155, 156,\n       153, 158, 157, 157, 157, 158, 156, 156, 157, 158, 156, 156, 156,\n       154, 155, 155, 153, 153, 152, 150, 149, 147, 144, 144, 143, 142,\n       139, 137, 134, 131, 127, 125, 123, 120, 121, 116, 117, 115, 117,\n       114,  99,  90, 103, 124, 136, 151, 155, 159, 161, 160, 159, 159,\n       159, 158, 157, 156, 156, 157, 156, 155, 154, 153, 152, 153, 152,\n       150, 151, 151, 151, 150, 150, 151, 151, 149, 148, 148, 148, 149,\n       149, 146, 144], dtype=uint8), array([4.51179147])], [array([146, 150, 155, 157, 159, 165, 164, 165, 164, 163, 165, 164, 164,\n       164, 164, 166, 167, 166, 163, 165, 165, 167, 167, 166, 164, 165,\n       166, 166, 164, 164, 165, 165, 161, 163, 162, 161, 161, 160, 162,\n       157, 156, 155, 155, 156, 155, 154, 155, 153, 151, 151, 151, 151,\n       152, 150, 150, 149, 148, 147, 143, 139, 135, 125, 113, 107, 108,\n       120, 140, 155, 163, 168, 168, 166, 166, 166, 164, 163, 158, 159,\n       161, 162, 160, 160, 162, 159, 159, 158, 157, 157, 159, 157, 156,\n       152, 154, 154, 155, 154, 154, 154, 154, 152, 153, 155, 154, 153,\n       154, 154, 153, 157, 157, 155, 156, 156, 155, 155, 155, 154, 157,\n       157, 156, 156], dtype=uint8), array([4.37560143])], [array([166, 168, 166, 168, 165, 169, 165, 163, 164, 164, 163, 162, 162,\n       160, 161, 158, 162, 159, 162, 161, 161, 161, 162, 164, 164, 163,\n       161, 163, 162, 162, 163, 160, 160, 160, 161, 162, 159, 160, 161,\n       161, 159, 160, 160, 158, 157, 156, 156, 160, 159, 157, 158, 159,\n       157, 158, 157, 152, 152, 154, 154, 153, 147, 147, 147, 146, 144,\n       142, 141, 139, 137, 136, 133, 127, 126, 125, 130, 132, 131, 129,\n       119, 102,  94, 105, 123, 140, 152, 158, 158, 159, 162, 159, 161,\n       162, 158, 157, 156, 154, 152, 154, 153, 153, 154, 152, 151, 151,\n       152, 150, 148, 150, 150, 151, 153, 151, 149, 148, 149, 154, 150,\n       152, 151, 148], dtype=uint8), array([3.95002995])], [array([159, 156, 155, 156, 155, 153, 155, 156, 156, 155, 154, 156, 157,\n       155, 154, 156, 157, 154, 153, 152, 153, 154, 154, 153, 153, 152,\n       156, 153, 150, 153, 154, 153, 154, 155, 154, 157, 155, 155, 156,\n       153, 151, 152, 150, 151, 155, 154, 151, 153, 154, 152, 152, 151,\n       151, 151, 152, 150, 150, 149, 145, 147, 146, 143, 141, 140, 137,\n       135, 134, 132, 133, 131, 129, 128, 127, 126, 123, 123, 119, 110,\n       111, 124, 141, 154, 156, 157, 153, 157, 159, 158, 157, 154, 153,\n       148, 149, 147, 147, 144, 143, 143, 139, 135, 131, 134, 136, 136,\n       135, 136, 141, 143, 145, 145, 145, 146, 148, 145, 145, 145, 145,\n       144, 142, 141], dtype=uint8), array([3.53048839])], [array([137, 136, 135, 135, 137, 137, 135, 133, 131, 131, 132, 130, 128,\n       129, 128, 126, 126, 125, 125, 124, 123, 122, 123, 123, 123, 123,\n       123, 122, 122, 123, 124, 120, 116, 114, 116, 121, 125, 126, 127,\n       127, 127, 127, 127, 129, 129, 130, 126, 125, 124, 127, 128, 131,\n       131, 134, 136, 137, 137, 139, 139, 137, 137, 134, 128, 123, 123,\n       130, 142, 150, 154, 158, 159, 157, 156, 155, 154, 156, 157, 155,\n       153, 154, 155, 155, 156, 155, 153, 153, 153, 152, 152, 154, 154,\n       156, 159, 157, 155, 155, 152, 151, 148, 149, 149, 147, 146, 152,\n       154, 157, 157, 156, 156, 155, 151, 152, 151, 147, 141, 141, 144,\n       146, 147, 150], dtype=uint8), array([3.67640104])], [array([151, 151, 150, 151, 151, 148, 147, 151, 151, 149, 149, 149, 149,\n       145, 150, 150, 150, 147, 151, 149, 152, 150, 150, 150, 152, 150,\n       151, 151, 149, 147, 150, 148, 147, 150, 148, 148, 147, 146, 145,\n       145, 146, 145, 140, 138, 136, 133, 133, 129, 128, 125, 122, 118,\n       115, 113, 111, 109, 107, 105, 103, 104,  97,  92,  85,  84,  80,\n        78,  75,  69,  66,  69,  81,  92, 102, 121, 130, 128, 133, 148,\n       162, 165, 165, 168, 168, 167, 167, 167, 167, 164, 165, 163, 162,\n       162, 162, 159, 158, 155, 154, 154, 152, 150, 151, 149, 148, 146,\n       141, 144, 144, 145, 142, 141, 138, 138, 138, 138, 142, 142, 143,\n       144, 142, 141], dtype=uint8), array([8.97995119])], [array([159, 156, 158, 157, 157, 156, 156, 154, 153, 152, 153, 154, 152,\n       149, 152, 155, 150, 150, 152, 151, 149, 150, 148, 149, 150, 148,\n       148, 148, 148, 146, 145, 144, 148, 149, 149, 147, 145, 145, 147,\n       147, 147, 146, 144, 144, 142, 134, 126, 114, 106,  97,  90,  98,\n       116, 122, 127, 129, 130, 130, 131, 130, 134, 138, 137, 136, 137,\n       139, 141, 141, 142, 147, 150, 144, 144, 145, 146, 146, 146, 145,\n       145, 147, 147, 147, 147, 147, 146, 147, 149, 148, 147, 147, 144,\n       147, 145, 146, 147, 147, 147, 147, 149, 148, 147, 147, 146, 146,\n       151, 147, 144, 149, 147, 147, 144, 143, 146, 147, 147, 145, 144,\n       145, 145, 145], dtype=uint8), array([5.35827466])], [array([148, 149, 150, 151, 151, 150, 151, 151, 154, 153, 152, 154, 155,\n       157, 156, 159, 155, 158, 159, 158, 156, 159, 158, 158, 159, 157,\n       160, 158, 156, 156, 158, 160, 160, 158, 155, 155, 150, 144, 147,\n       148, 149, 150, 152, 154, 154, 157, 156, 154, 155, 157, 158, 160,\n       159, 161, 160, 159, 163, 161, 158, 157, 157, 158, 159, 155, 152,\n       152, 152, 150, 144, 137, 125, 113, 121, 127, 123, 111, 101,  98,\n       101, 104, 103, 104, 103, 105, 106, 110, 110, 112, 112, 114, 117,\n       118, 118, 120, 121, 122, 121, 123, 122, 122, 121, 123, 124, 123,\n       124, 124, 126, 128, 128, 127, 129, 127, 129, 127, 126, 128, 129,\n       130, 131, 128], dtype=uint8), array([8.97995119])], [array([123, 122, 125, 125, 125, 128, 127, 128, 132, 132, 131, 134, 133,\n       134, 133, 134, 135, 132, 131, 131, 132, 130, 131, 133, 133, 132,\n       132, 128, 131, 130, 129, 129, 125, 125, 126, 126, 124, 124, 124,\n       123, 124, 123, 124, 124, 126, 127, 120, 108,  99, 106, 116, 128,\n       138, 147, 154, 158, 159, 162, 162, 158, 159, 160, 160, 158, 156,\n       155, 155, 153, 155, 154, 155, 157, 154, 153, 156, 154, 158, 156,\n       156, 156, 156, 157, 155, 156, 155, 154, 156, 157, 155, 153, 155,\n       155, 156, 154, 158, 158, 158, 156, 160, 159, 158, 157, 157, 157,\n       158, 155, 154, 154, 155, 155, 154, 152, 152, 150, 138, 128, 125,\n       132, 140, 147], dtype=uint8), array([5.35827466])], [array([158, 160, 160, 161, 160, 161, 161, 162, 163, 161, 160, 162, 161,\n       159, 163, 162, 160, 162, 162, 162, 160, 161, 160, 160, 159, 158,\n       159, 162, 160, 157, 161, 159, 160, 161, 164, 163, 159, 158, 159,\n       158, 159, 159, 157, 159, 156, 157, 156, 157, 160, 155, 154, 154,\n       156, 160, 155, 154, 155, 153, 153, 151, 150, 153, 150, 148, 149,\n       152, 150, 154, 154, 154, 152, 151, 149, 149, 145, 135, 124, 115,\n       107, 114, 127, 132, 131, 129, 130, 130, 129, 126, 126, 127, 126,\n       128, 127, 128, 127, 123, 125, 125, 124, 126, 128, 128, 126, 125,\n       125, 126, 126, 125, 124, 124, 125, 126, 125, 124, 123, 123, 122,\n       122, 125, 123], dtype=uint8), array([3.76287851])], [array([163, 163, 162, 160, 164, 162, 161, 163, 164, 162, 163, 164, 164,\n       164, 166, 164, 163, 165, 161, 165, 162, 165, 164, 164, 166, 164,\n       162, 161, 158, 159, 157, 158, 158, 159, 159, 157, 156, 155, 154,\n       152, 148, 145, 143, 143, 148, 153, 156, 154, 156, 155, 157, 157,\n       159, 160, 162, 164, 161, 163, 165, 165, 164, 164, 165, 160, 167,\n       166, 166, 165, 166, 166, 164, 165, 166, 161, 156, 153, 153, 152,\n       151, 152, 150, 151, 149, 148, 149, 149, 149, 151, 152, 153, 154,\n       154, 157, 159, 158, 157, 159, 161, 162, 168, 163, 165, 163, 163,\n       165, 163, 163, 163, 163, 163, 163, 163, 161, 164, 165, 162, 163,\n       164, 167, 165], dtype=uint8), array([3.04808728])], [array([161, 162, 162, 163, 163, 164, 164, 163, 162, 164, 164, 165, 161,\n       161, 160, 164, 166, 168, 167, 167, 166, 164, 167, 167, 166, 166,\n       165, 165, 167, 166, 167, 166, 168, 166, 166, 166, 166, 163, 164,\n       165, 163, 166, 165, 165, 165, 165, 165, 168, 169, 167, 166, 165,\n       167, 168, 169, 166, 166, 166, 167, 165, 168, 168, 167, 167, 168,\n       169, 166, 167, 165, 166, 163, 162, 161, 156, 148, 138, 127, 124,\n       125, 134, 141, 142, 143, 144, 145, 144, 146, 148, 145, 143, 145,\n       144, 143, 149, 150, 148, 148, 152, 153, 150, 151, 152, 152, 149,\n       150, 152, 149, 150, 149, 151, 152, 149, 149, 147, 146, 149, 148,\n       147, 147, 144], dtype=uint8), array([3.04562947])], [array([171, 170, 170, 170, 171, 171, 172, 171, 172, 168, 167, 168, 168,\n       169, 169, 170, 168, 167, 169, 169, 167, 171, 170, 168, 168, 168,\n       168, 169, 170, 169, 169, 167, 168, 170, 169, 168, 170, 169, 167,\n       169, 170, 168, 169, 167, 172, 168, 169, 167, 168, 168, 168, 168,\n       168, 166, 167, 170, 171, 169, 168, 166, 169, 170, 170, 168, 166,\n       165, 165, 165, 162, 160, 159, 154, 146, 130, 109, 108, 123, 142,\n       153, 158, 160, 163, 161, 164, 162, 158, 159, 158, 161, 160, 158,\n       157, 156, 154, 153, 154, 153, 152, 150, 149, 150, 149, 149, 150,\n       150, 150, 148, 149, 148, 147, 145, 144, 136, 128, 122, 117, 115,\n       103,  95,  93], dtype=uint8), array([3.06895321])], [array([166, 164, 168, 166, 166, 165, 166, 166, 169, 162, 165, 160, 159,\n       157, 156, 152, 150, 145, 140, 135, 131, 126, 119, 121, 127, 129,\n       127, 126, 123, 128, 135, 139, 136, 142, 144, 146, 149, 151, 149,\n       149, 151, 155, 158, 157, 157, 159, 161, 159, 158, 154, 151, 147,\n       142, 132, 131, 140, 152, 157, 157, 161, 163, 161, 160, 160, 163,\n       164, 163, 161, 160, 160, 161, 167, 166, 165, 165, 165, 166, 167,\n       164, 166, 165, 165, 167, 169, 169, 170, 168, 168, 168, 169, 169,\n       167, 168, 169, 167, 170, 169, 168, 167, 168, 165, 166, 168, 168,\n       165, 164, 164, 163, 163, 163, 159, 158, 157, 158, 156, 153, 153,\n       150, 148, 147], dtype=uint8), array([2.85702873])], [array([147, 148, 146, 146, 148, 150, 147, 149, 148, 149, 150, 150, 148,\n       149, 150, 147, 149, 151, 149, 148, 150, 150, 150, 149, 149, 151,\n       148, 148, 150, 149, 149, 152, 153, 150, 148, 149, 150, 148, 147,\n       150, 152, 150, 150, 149, 149, 148, 150, 151, 151, 150, 150, 148,\n       148, 146, 147, 149, 150, 149, 149, 149, 148, 147, 149, 151, 150,\n       149, 150, 151, 153, 153, 153, 153, 152, 156, 157, 156, 156, 157,\n       157, 151, 146, 132, 119, 115, 118, 125, 128, 128, 126, 127, 126,\n       124, 123, 122, 124, 124, 126, 127, 129, 129, 132, 134, 134, 137,\n       137, 137, 141, 144, 144, 145, 146, 148, 146, 149, 149, 148, 148,\n       148, 153, 150], dtype=uint8), array([4.51179147])], [array([159, 159, 160, 160, 161, 162, 160, 159, 159, 159, 160, 159, 157,\n       157, 157, 153, 150, 151, 152, 153, 151, 150, 149, 147, 146, 143,\n       137, 136, 134, 130, 121, 115, 111, 109, 108, 108, 107, 112, 115,\n       117, 119, 125, 128, 128, 129, 129, 132, 132, 132, 134, 134, 135,\n       137, 137, 135, 136, 133, 133, 132, 122, 108, 103, 103, 103, 110,\n       122, 123, 125, 123, 123, 121, 119, 117, 116, 115, 115, 118, 116,\n       119, 120, 121, 122, 121, 121, 123, 122, 126, 125, 129, 131, 130,\n       133, 135, 134, 133, 133, 136, 135, 137, 139, 139, 140, 140, 141,\n       141, 142, 143, 144, 146, 145, 143, 145, 147, 147, 145, 148, 145,\n       149, 148, 149], dtype=uint8), array([4.37560143])], [array([130, 127, 126, 123, 119, 120, 120, 119, 119, 120, 118, 119, 118,\n       119, 117, 119, 121, 120, 122, 122, 121, 122, 125, 125, 122, 124,\n       126, 127, 127, 126, 127, 127, 129, 128, 132, 131, 134, 132, 133,\n       135, 135, 136, 136, 135, 136, 139, 141, 142, 141, 138, 140, 142,\n       143, 145, 141, 142, 142, 143, 146, 144, 145, 147, 145, 146, 148,\n       148, 149, 151, 153, 152, 153, 154, 153, 154, 156, 157, 156, 154,\n       153, 149, 135, 118, 108, 108, 115, 124, 125, 127, 127, 126, 128,\n       126, 126, 128, 130, 132, 132, 134, 135, 136, 139, 139, 144, 146,\n       147, 147, 149, 153, 154, 152, 152, 153, 154, 156, 157, 156, 155,\n       155, 156, 159], dtype=uint8), array([3.95002995])], [array([140, 143, 146, 145, 147, 150, 150, 150, 150, 149, 153, 152, 151,\n       154, 154, 154, 154, 155, 156, 154, 159, 157, 157, 159, 159, 158,\n       156, 158, 159, 157, 159, 159, 158, 160, 156, 158, 158, 157, 159,\n       161, 160, 160, 159, 159, 160, 159, 158, 160, 160, 161, 159, 159,\n       158, 159, 162, 160, 160, 162, 160, 161, 162, 162, 158, 158, 158,\n       157, 155, 155, 158, 161, 161, 160, 161, 164, 165, 162, 157, 153,\n       148, 138, 134, 136, 140, 146, 142, 144, 145, 144, 143, 142, 142,\n       141, 139, 143, 143, 145, 146, 148, 149, 151, 152, 151, 156, 155,\n       154, 155, 153, 154, 150, 148, 149, 150, 150, 152, 153, 155, 154,\n       154, 152, 152], dtype=uint8), array([3.53048839])], [array([161, 160, 162, 162, 163, 164, 164, 163, 161, 164, 163, 162, 162,\n       164, 163, 162, 165, 166, 161, 165, 165, 164, 162, 159, 163, 161,\n       160, 164, 165, 162, 160, 162, 158, 152, 153, 154, 157, 158, 160,\n       163, 163, 164, 162, 162, 163, 164, 164, 165, 165, 165, 166, 166,\n       166, 166, 164, 164, 164, 163, 157, 155, 151, 145, 139, 132, 125,\n       130, 139, 144, 147, 152, 151, 152, 151, 151, 152, 155, 153, 156,\n       157, 153, 153, 154, 152, 153, 154, 153, 153, 153, 150, 152, 150,\n       151, 151, 152, 151, 146, 143, 140, 145, 150, 151, 151, 151, 152,\n       153, 155, 153, 155, 155, 158, 160, 157, 158, 157, 159, 158, 158,\n       159, 159, 158], dtype=uint8), array([3.67640104])], [array([158, 157, 156, 157, 156, 156, 153, 154, 155, 156, 154, 153, 153,\n       153, 151, 152, 153, 151, 150, 152, 152, 152, 151, 153, 151, 152,\n       150, 152, 152, 152, 152, 151, 150, 150, 150, 150, 149, 150, 151,\n       149, 148, 146, 145, 148, 146, 145, 147, 147, 145, 144, 144, 146,\n       143, 143, 141, 141, 144, 145, 142, 139, 129, 109, 101, 104, 106,\n       116, 133, 137, 136, 139, 142, 144, 143, 144, 144, 146, 146, 147,\n       150, 150, 151, 149, 144, 136, 124, 124, 132, 143, 152, 154, 155,\n       156, 156, 159, 161, 159, 160, 158, 157, 156, 154, 156, 152, 156,\n       155, 157, 156, 159, 157, 158, 159, 160, 159, 159, 159, 157, 159,\n       157, 156, 158], dtype=uint8), array([5.21064103])], [array([178, 180, 180, 181, 180, 181, 183, 179, 181, 185, 182, 182, 181,\n       181, 179, 180, 181, 184, 182, 182, 182, 178, 179, 177, 177, 176,\n       178, 178, 180, 179, 177, 180, 179, 181, 181, 180, 181, 181, 182,\n       179, 179, 178, 176, 175, 173, 173, 171, 170, 167, 160, 142, 125,\n       114, 117, 125, 141, 152, 154, 156, 156, 152, 152, 152, 148, 146,\n       145, 141, 130, 117, 110, 114, 114, 102, 102, 118, 132, 133, 137,\n       142, 146, 149, 153, 155, 155, 156, 152, 150, 150, 151, 158, 159,\n       162, 166, 169, 169, 168, 172, 174, 174, 174, 173, 173, 174, 177,\n       176, 176, 178, 174, 178, 180, 178, 177, 178, 178, 177, 175, 170,\n       173, 173, 176], dtype=uint8), array([7.26221294])], [array([178, 179, 181, 180, 174, 179, 179, 175, 178, 177, 176, 178, 178,\n       178, 178, 179, 178, 180, 182, 179, 179, 181, 182, 177, 179, 178,\n       179, 178, 177, 178, 179, 179, 179, 179, 181, 185, 185, 182, 180,\n       180, 180, 183, 185, 178, 178, 178, 177, 179, 182, 182, 182, 179,\n       180, 181, 181, 182, 182, 183, 182, 187, 193, 189, 190, 191, 192,\n       193, 193, 192, 194, 193, 184, 172, 161, 144, 125, 119, 132, 144,\n       144, 143, 141, 136, 138, 141, 143, 145, 145, 148, 153, 154, 155,\n       159, 163, 163, 163, 164, 166, 170, 172, 176, 179, 179, 179, 180,\n       180, 183, 190, 186, 185, 183, 184, 187, 187, 185, 187, 183, 188,\n       188, 190, 186], dtype=uint8), array([5.93755418])], [array([182, 179, 181, 183, 181, 178, 180, 181, 180, 179, 177, 177, 180,\n       182, 180, 181, 181, 182, 183, 178, 179, 179, 181, 179, 178, 182,\n       182, 182, 182, 182, 183, 186, 183, 183, 185, 185, 186, 183, 184,\n       183, 185, 184, 182, 185, 185, 185, 183, 184, 185, 188, 187, 189,\n       186, 184, 185, 186, 191, 186, 188, 187, 187, 191, 191, 192, 190,\n       192, 191, 192, 191, 191, 186, 173, 158, 142, 130, 130, 146, 147,\n       147, 149, 145, 145, 147, 146, 146, 148, 151, 151, 152, 155, 157,\n       159, 161, 165, 166, 167, 171, 171, 174, 177, 178, 180, 183, 185,\n       185, 185, 185, 186, 186, 182, 185, 185, 187, 186, 186, 187, 186,\n       189, 187, 193], dtype=uint8), array([5.5774322])], [array([193, 192, 192, 189, 191, 193, 191, 191, 189, 189, 191, 191, 188,\n       190, 189, 190, 189, 190, 191, 192, 193, 192, 187, 193, 192, 191,\n       192, 195, 195, 193, 193, 194, 196, 195, 194, 193, 193, 193, 195,\n       192, 194, 193, 189, 191, 190, 190, 189, 189, 189, 191, 188, 187,\n       184, 182, 183, 184, 181, 181, 180, 176, 176, 174, 170, 168, 166,\n       160, 143, 131, 128, 131, 147, 163, 171, 172, 174, 171, 177, 179,\n       180, 181, 182, 182, 182, 185, 188, 190, 186, 187, 187, 188, 187,\n       188, 190, 188, 189, 194, 193, 191, 191, 192, 191, 190, 189, 188,\n       188, 187, 188, 190, 189, 185, 186, 187, 188, 188, 190, 190, 187,\n       192, 192, 187], dtype=uint8), array([4.19787153])], [array([189, 185, 185, 186, 188, 189, 188, 193, 193, 194, 193, 189, 192,\n       191, 192, 194, 193, 192, 191, 192, 194, 191, 191, 191, 193, 193,\n       192, 195, 194, 194, 193, 190, 192, 193, 190, 191, 193, 192, 192,\n       192, 193, 193, 193, 196, 192, 191, 193, 194, 190, 192, 192, 189,\n       188, 186, 186, 186, 185, 185, 186, 188, 186, 188, 188, 185, 186,\n       182, 180, 177, 172, 161, 147, 131, 132, 141, 152, 157, 162, 169,\n       175, 174, 175, 178, 181, 180, 179, 182, 182, 188, 188, 187, 185,\n       188, 194, 193, 193, 197, 195, 194, 197, 196, 197, 196, 193, 197,\n       195, 196, 196, 195, 192, 193, 194, 196, 194, 194, 193, 196, 195,\n       191, 193, 190], dtype=uint8), array([3.7441611])], [array([174, 173, 172, 172, 173, 175, 174, 173, 171, 174, 176, 177, 178,\n       176, 178, 179, 173, 173, 166, 162, 164, 164, 162, 168, 168, 169,\n       171, 169, 171, 174, 174, 177, 177, 175, 175, 174, 176, 176, 176,\n       177, 177, 175, 174, 174, 176, 176, 175, 176, 176, 177, 177, 176,\n       178, 174, 179, 179, 178, 177, 181, 184, 178, 180, 182, 180, 184,\n       184, 186, 184, 184, 182, 176, 165, 147, 130, 119, 131, 145, 148,\n       147, 147, 147, 145, 145, 147, 149, 152, 151, 152, 156, 158, 159,\n       162, 164, 166, 169, 169, 172, 171, 175, 175, 172, 178, 178, 178,\n       181, 178, 180, 178, 177, 175, 177, 178, 177, 177, 177, 175, 176,\n       177, 177, 176], dtype=uint8), array([5.20109506])], [array([166, 163, 163, 164, 164, 163, 162, 161, 163, 162, 163, 168, 169,\n       167, 166, 166, 168, 169, 169, 169, 166, 168, 171, 171, 171, 169,\n       170, 170, 171, 170, 168, 171, 170, 175, 172, 170, 171, 171, 167,\n       169, 168, 167, 172, 171, 169, 167, 168, 171, 171, 169, 170, 171,\n       172, 172, 171, 166, 165, 165, 167, 172, 172, 175, 177, 180, 182,\n       183, 183, 183, 183, 184, 182, 176, 163, 146, 129, 118, 127, 139,\n       144, 143, 142, 138, 137, 137, 138, 140, 140, 140, 141, 143, 147,\n       148, 151, 153, 154, 157, 157, 159, 160, 161, 162, 160, 162, 161,\n       161, 164, 160, 165, 162, 162, 162, 163, 162, 161, 160, 162, 161,\n       159, 157, 158], dtype=uint8), array([4.87914297])], [array([198, 201, 198, 199, 202, 202, 203, 205, 206, 206, 202, 205, 205,\n       203, 205, 204, 202, 199, 200, 203, 202, 204, 205, 205, 204, 204,\n       204, 204, 203, 205, 206, 205, 205, 200, 201, 201, 201, 203, 204,\n       202, 203, 204, 200, 201, 200, 203, 207, 203, 203, 205, 205, 201,\n       200, 202, 204, 203, 202, 201, 205, 206, 203, 203, 204, 204, 201,\n       204, 203, 203, 202, 200, 201, 205, 203, 202, 202, 203, 204, 205,\n       204, 203, 205, 204, 201, 202, 205, 207, 207, 204, 207, 205, 201,\n       200, 205, 202, 203, 204, 205, 202, 203, 205, 204, 202, 202, 203,\n       203, 203, 203, 202, 205, 200, 202, 204, 203, 204, 202, 202, 203,\n       205, 205, 204], dtype=uint8), array([0.])], [array([190, 192, 188, 187, 191, 190, 185, 187, 185, 184, 189, 187, 187,\n       184, 182, 186, 185, 185, 189, 189, 187, 186, 185, 186, 184, 188,\n       189, 190, 186, 187, 189, 189, 189, 190, 191, 192, 189, 191, 193,\n       191, 192, 191, 190, 190, 190, 192, 192, 194, 192, 192, 193, 191,\n       192, 193, 194, 194, 195, 194, 196, 194, 197, 196, 196, 196, 193,\n       193, 189, 175, 160, 157, 165, 168, 154, 136, 128, 131, 132, 132,\n       127, 122, 121, 122, 125, 129, 132, 134, 133, 133, 135, 137, 140,\n       145, 145, 152, 153, 155, 156, 159, 163, 165, 166, 167, 170, 174,\n       177, 177, 178, 182, 184, 183, 184, 186, 187, 189, 189, 192, 192,\n       193, 193, 194], dtype=uint8), array([8.52101685])], [array([184, 186, 186, 185, 187, 185, 186, 185, 185, 187, 191, 186, 187,\n       188, 188, 186, 186, 189, 188, 187, 189, 188, 187, 191, 187, 188,\n       188, 188, 188, 188, 187, 189, 190, 189, 189, 187, 186, 191, 190,\n       190, 189, 189, 192, 189, 191, 192, 194, 192, 192, 192, 192, 191,\n       193, 196, 194, 195, 194, 199, 198, 196, 197, 199, 199, 197, 195,\n       189, 176, 158, 150, 155, 160, 148, 129, 121, 122, 120, 119, 120,\n       120, 120, 123, 124, 124, 123, 126, 126, 129, 134, 137, 137, 141,\n       144, 148, 151, 153, 154, 156, 158, 162, 165, 164, 169, 172, 172,\n       175, 177, 180, 183, 184, 185, 186, 184, 188, 190, 191, 192, 192,\n       188, 191, 191], dtype=uint8), array([8.73503977])], [array([155, 154, 154, 153, 154, 146, 142, 141, 148, 153, 161, 171, 178,\n       180, 185, 185, 189, 188, 190, 187, 187, 188, 186, 187, 188, 185,\n       183, 184, 185, 186, 188, 187, 187, 186, 187, 188, 186, 185, 185,\n       187, 184, 184, 185, 186, 186, 186, 183, 183, 180, 183, 180, 177,\n       176, 178, 177, 176, 173, 171, 171, 173, 171, 168, 168, 168, 167,\n       165, 165, 164, 164, 162, 157, 150, 144, 142, 143, 152, 162, 165,\n       166, 168, 170, 169, 173, 173, 177, 172, 176, 177, 176, 175, 178,\n       181, 178, 178, 180, 182, 181, 183, 186, 182, 181, 179, 182, 184,\n       185, 181, 180, 182, 183, 183, 183, 183, 182, 182, 182, 182, 183,\n       182, 183, 180], dtype=uint8), array([4.59109883])], [array([189, 189, 188, 187, 187, 186, 187, 189, 188, 187, 185, 185, 189,\n       190, 191, 191, 191, 188, 186, 186, 188, 189, 187, 187, 187, 186,\n       187, 185, 184, 183, 186, 184, 182, 183, 182, 183, 179, 178, 181,\n       177, 177, 174, 171, 169, 168, 168, 165, 165, 164, 161, 158, 158,\n       155, 156, 156, 161, 158, 158, 157, 158, 154, 141, 129, 135, 152,\n       163, 174, 183, 188, 188, 190, 189, 189, 187, 187, 190, 188, 185,\n       187, 186, 189, 186, 184, 183, 183, 183, 182, 182, 180, 183, 184,\n       183, 181, 181, 182, 180, 180, 181, 181, 178, 177, 177, 177, 176,\n       176, 174, 177, 175, 175, 173, 172, 173, 171, 174, 173, 171, 169,\n       171, 171, 169], dtype=uint8), array([4.34090199])], [array([184, 185, 186, 180, 184, 182, 183, 185, 183, 184, 184, 183, 183,\n       183, 181, 180, 180, 181, 183, 184, 185, 185, 184, 184, 184, 187,\n       186, 185, 180, 181, 181, 180, 180, 177, 178, 177, 175, 175, 174,\n       175, 176, 173, 171, 169, 166, 166, 164, 160, 163, 165, 162, 161,\n       161, 161, 162, 161, 162, 162, 162, 162, 158, 151, 145, 150, 160,\n       175, 181, 184, 184, 184, 184, 181, 180, 178, 177, 178, 176, 175,\n       175, 173, 175, 174, 171, 173, 176, 175, 175, 176, 180, 178, 177,\n       179, 178, 175, 176, 178, 179, 177, 178, 175, 176, 177, 179, 179,\n       179, 180, 180, 181, 181, 183, 180, 181, 179, 178, 174, 174, 173,\n       173, 175, 175], dtype=uint8), array([4.35067225])], [array([181, 185, 184, 186, 187, 186, 186, 188, 187, 185, 188, 184, 186,\n       188, 184, 184, 182, 186, 186, 185, 186, 186, 186, 183, 183, 183,\n       180, 181, 188, 183, 180, 181, 180, 178, 178, 176, 173, 169, 167,\n       165, 163, 163, 163, 160, 160, 158, 160, 156, 156, 157, 156, 157,\n       159, 158, 157, 158, 157, 156, 152, 141, 137, 146, 163, 171, 180,\n       186, 186, 187, 186, 183, 182, 182, 177, 177, 177, 171, 172, 170,\n       168, 168, 165, 164, 167, 166, 165, 165, 164, 163, 161, 160, 162,\n       153, 143, 148, 162, 171, 178, 180, 180, 180, 181, 177, 172, 169,\n       169, 172, 173, 174, 177, 178, 174, 174, 174, 173, 171, 169, 169,\n       171, 171, 169], dtype=uint8), array([4.18356936])], [array([172, 172, 173, 171, 173, 172, 172, 167, 168, 169, 168, 171, 170,\n       170, 170, 170, 170, 171, 169, 168, 170, 173, 172, 171, 171, 170,\n       170, 172, 169, 169, 169, 170, 170, 168, 168, 168, 170, 170, 172,\n       170, 168, 169, 165, 170, 168, 167, 171, 171, 169, 171, 168, 169,\n       169, 169, 169, 170, 173, 171, 171, 171, 171, 171, 171, 172, 166,\n       171, 170, 170, 170, 170, 167, 160, 149, 142, 141, 141, 145, 153,\n       156, 154, 156, 150, 146, 149, 144, 145, 147, 144, 144, 146, 147,\n       151, 153, 152, 156, 157, 158, 160, 161, 161, 160, 163, 165, 166,\n       169, 171, 169, 170, 169, 171, 172, 171, 171, 172, 169, 168, 172,\n       171, 173, 173], dtype=uint8), array([5.923182])], [array([176, 175, 173, 171, 172, 174, 173, 177, 173, 177, 174, 175, 172,\n       172, 173, 174, 173, 168, 167, 162, 154, 156, 155, 156, 157, 163,\n       163, 168, 172, 170, 167, 160, 155, 143, 140, 143, 154, 163, 165,\n       167, 170, 170, 171, 173, 175, 173, 175, 176, 179, 180, 180, 177,\n       173, 173, 174, 177, 182, 186, 185, 191, 192, 192, 193, 189, 185,\n       175, 162, 163, 170, 156, 135, 117, 110, 104, 102, 102, 105, 108,\n       110, 110, 114, 114, 115, 117, 120, 123, 123, 125, 127, 129, 135,\n       136, 138, 138, 144, 149, 152, 153, 155, 158, 160, 162, 166, 163,\n       166, 169, 169, 170, 172, 174, 177, 176, 178, 178, 175, 177, 178,\n       180, 181, 183], dtype=uint8), array([8.89809448])], [array([170, 172, 170, 170, 171, 172, 171, 170, 168, 165, 166, 166, 170,\n       171, 173, 173, 170, 175, 174, 171, 173, 170, 174, 173, 176, 172,\n       172, 172, 171, 174, 175, 176, 174, 172, 171, 172, 174, 171, 173,\n       176, 173, 175, 172, 172, 171, 170, 169, 172, 174, 173, 171, 172,\n       169, 170, 170, 167, 165, 167, 168, 166, 163, 164, 166, 163, 161,\n       161, 161, 158, 155, 154, 150, 137, 121, 119, 125, 119, 117, 132,\n       147, 153, 152, 153, 158, 159, 160, 161, 161, 163, 165, 168, 171,\n       170, 168, 171, 172, 174, 171, 172, 175, 175, 175, 174, 175, 173,\n       174, 171, 169, 161, 157, 154, 150, 153, 154, 160, 162, 166, 172,\n       176, 174, 176], dtype=uint8), array([4.7800506])], [array([173, 174, 174, 172, 174, 174, 174, 173, 173, 173, 173, 174, 178,\n       175, 176, 175, 174, 172, 173, 174, 174, 174, 173, 172, 174, 172,\n       172, 174, 172, 171, 172, 173, 176, 175, 172, 172, 174, 172, 171,\n       173, 169, 170, 171, 171, 166, 163, 167, 165, 164, 162, 160, 160,\n       159, 157, 156, 155, 151, 149, 151, 150, 151, 149, 147, 147, 146,\n       147, 150, 148, 147, 143, 136, 120, 121, 128, 126, 136, 147, 158,\n       157, 159, 159, 163, 166, 161, 160, 159, 164, 168, 167, 166, 166,\n       167, 167, 165, 166, 168, 169, 170, 166, 166, 169, 168, 169, 172,\n       168, 167, 166, 169, 172, 173, 174, 172, 173, 170, 171, 172, 169,\n       171, 170, 170], dtype=uint8), array([5.29939395])], [array([173, 174, 171, 170, 173, 173, 174, 172, 172, 170, 174, 172, 173,\n       175, 173, 170, 172, 169, 171, 174, 175, 170, 173, 170, 170, 171,\n       168, 175, 169, 171, 171, 172, 167, 170, 174, 169, 172, 168, 169,\n       171, 167, 171, 171, 167, 168, 170, 168, 171, 167, 163, 164, 166,\n       166, 165, 164, 159, 162, 162, 165, 161, 159, 158, 160, 162, 159,\n       156, 160, 157, 153, 157, 151, 133, 128, 126, 124, 126, 140, 150,\n       151, 152, 154, 153, 155, 153, 157, 158, 158, 161, 157, 160, 158,\n       161, 166, 167, 165, 168, 164, 167, 167, 166, 167, 166, 168, 165,\n       166, 166, 167, 167, 171, 167, 172, 165, 169, 168, 169, 169, 169,\n       166, 169, 169], dtype=uint8), array([5.08347615])], [array([216, 216, 214, 213, 213, 214, 211, 214, 213, 214, 213, 213, 212,\n       210, 211, 212, 209, 210, 209, 211, 212, 211, 211, 211, 213, 212,\n       213, 213, 213, 219, 213, 210, 213, 213, 214, 211, 211, 213, 211,\n       212, 211, 210, 206, 203, 204, 204, 200, 198, 195, 188, 159, 129,\n       135, 158, 158, 126, 104, 117, 140, 143, 146, 148, 153, 157, 162,\n       164, 171, 176, 178, 182, 187, 188, 190, 191, 192, 195, 198, 202,\n       203, 206, 207, 208, 206, 205, 205, 207, 204, 208, 207, 211, 209,\n       210, 212, 212, 210, 211, 215, 212, 215, 214, 215, 213, 213, 214,\n       212, 213, 215, 214, 215, 211, 211, 214, 213, 212, 216, 217, 213,\n       215, 214, 211], dtype=uint8), array([8.36581426])], [array([208, 207, 211, 211, 211, 209, 210, 209, 206, 206, 206, 203, 202,\n       203, 203, 200, 197, 198, 192, 192, 192, 189, 178, 168, 168, 176,\n       176, 188, 198, 202, 204, 205, 206, 201, 201, 203, 203, 203, 204,\n       201, 203, 204, 202, 201, 199, 199, 197, 195, 192, 189, 185, 180,\n       179, 171, 166, 166, 161, 158, 152, 153, 158, 162, 160, 154, 136,\n       109, 113, 131, 139, 133, 131, 150, 176, 191, 197, 196, 200, 202,\n       203, 204, 205, 207, 207, 209, 206, 206, 210, 209, 208, 211, 209,\n       210, 211, 208, 211, 211, 212, 213, 214, 215, 210, 207, 209, 213,\n       213, 210, 213, 215, 212, 214, 214, 213, 214, 213, 211, 211, 212,\n       212, 211, 208], dtype=uint8), array([8.89809448])], [array([210, 209, 213, 213, 212, 211, 212, 213, 213, 210, 209, 211, 212,\n       210, 207, 206, 204, 205, 206, 207, 208, 212, 209, 211, 211, 213,\n       211, 207, 213, 207, 209, 211, 209, 209, 209, 213, 207, 208, 209,\n       210, 213, 212, 210, 207, 209, 212, 209, 209, 212, 213, 211, 209,\n       210, 212, 212, 213, 213, 211, 211, 210, 210, 211, 208, 209, 207,\n       209, 208, 205, 203, 195, 177, 159, 160, 154, 150, 173, 181, 184,\n       189, 193, 194, 197, 201, 205, 201, 201, 205, 210, 205, 209, 209,\n       209, 206, 210, 212, 206, 209, 211, 212, 210, 210, 210, 211, 210,\n       209, 210, 208, 209, 211, 211, 211, 210, 210, 208, 207, 209, 212,\n       207, 209, 209], dtype=uint8), array([4.7800506])], [array([208, 214, 211, 210, 212, 213, 210, 211, 210, 209, 211, 212, 214,\n       214, 212, 213, 212, 212, 212, 212, 210, 210, 211, 212, 208, 210,\n       210, 208, 212, 211, 210, 210, 211, 212, 212, 211, 211, 210, 209,\n       212, 212, 210, 210, 208, 211, 214, 213, 210, 213, 211, 211, 211,\n       216, 214, 214, 213, 215, 213, 214, 212, 214, 213, 211, 209, 209,\n       208, 204, 201, 189, 166, 146, 150, 140, 133, 158, 182, 187, 193,\n       192, 194, 197, 201, 199, 198, 201, 203, 204, 205, 208, 208, 207,\n       207, 208, 207, 207, 209, 205, 193, 180, 175, 175, 188, 203, 206,\n       210, 209, 214, 210, 212, 208, 210, 209, 209, 209, 211, 211, 211,\n       212, 215, 213], dtype=uint8), array([5.29939395])], [array([201, 202, 203, 203, 206, 205, 203, 204, 204, 206, 204, 203, 205,\n       208, 207, 208, 209, 207, 208, 207, 206, 208, 207, 205, 206, 207,\n       207, 208, 209, 206, 206, 207, 207, 209, 209, 209, 207, 209, 210,\n       210, 209, 209, 209, 207, 206, 204, 211, 211, 211, 210, 210, 209,\n       209, 208, 210, 208, 206, 208, 208, 208, 208, 212, 211, 209, 207,\n       205, 205, 207, 200, 198, 191, 171, 159, 154, 148, 166, 186, 191,\n       187, 200, 199, 201, 206, 208, 208, 207, 209, 208, 212, 210, 210,\n       213, 209, 211, 210, 212, 210, 211, 211, 213, 210, 208, 213, 212,\n       210, 213, 214, 214, 214, 213, 210, 213, 209, 211, 210, 212, 212,\n       210, 212, 216], dtype=uint8), array([5.08347615])], [array([208, 208, 208, 206, 204, 206, 206, 206, 207, 208, 205, 207, 209,\n       210, 212, 208, 210, 206, 205, 204, 208, 209, 207, 208, 206, 209,\n       210, 206, 212, 208, 207, 208, 204, 208, 210, 211, 210, 210, 210,\n       209, 209, 210, 211, 207, 208, 207, 211, 213, 208, 207, 208, 209,\n       210, 210, 210, 210, 209, 205, 210, 210, 206, 206, 207, 208, 206,\n       207, 204, 202, 199, 193, 177, 160, 156, 161, 166, 179, 185, 189,\n       192, 192, 196, 194, 199, 200, 203, 205, 206, 206, 206, 209, 210,\n       208, 207, 209, 209, 209, 211, 211, 211, 211, 209, 211, 212, 211,\n       210, 211, 209, 209, 209, 210, 209, 208, 211, 210, 208, 208, 208,\n       209, 209, 210], dtype=uint8), array([5.923182])], [array([204, 202, 202, 201, 196, 189, 185, 181, 176, 171, 168, 171, 180,\n       179, 177, 179, 179, 179, 180, 179, 180, 181, 183, 186, 185, 184,\n       188, 190, 192, 194, 191, 193, 196, 196, 197, 199, 201, 202, 200,\n       201, 205, 202, 204, 203, 203, 206, 207, 206, 207, 209, 207, 208,\n       207, 211, 209, 210, 209, 212, 210, 210, 211, 210, 209, 207, 209,\n       211, 209, 205, 199, 184, 172, 162, 154, 160, 175, 179, 178, 178,\n       181, 182, 185, 185, 184, 190, 192, 193, 196, 198, 203, 203, 203,\n       204, 202, 202, 207, 207, 206, 206, 209, 209, 210, 207, 208, 210,\n       210, 209, 212, 212, 210, 211, 210, 209, 210, 210, 208, 206, 209,\n       208, 210, 207], dtype=uint8), array([4.59109883])], [array([202, 203, 203, 201, 203, 200, 204, 204, 209, 203, 206, 206, 208,\n       207, 205, 205, 207, 207, 206, 206, 207, 207, 205, 207, 208, 203,\n       206, 208, 206, 208, 207, 208, 205, 206, 205, 203, 205, 205, 205,\n       202, 204, 204, 203, 206, 206, 207, 205, 207, 210, 207, 207, 208,\n       207, 206, 206, 206, 204, 204, 202, 201, 196, 190, 179, 169, 169,\n       173, 183, 179, 176, 177, 178, 179, 180, 182, 182, 184, 186, 189,\n       189, 194, 190, 194, 195, 198, 196, 196, 197, 200, 202, 200, 203,\n       203, 202, 204, 203, 206, 206, 208, 208, 208, 208, 209, 208, 208,\n       207, 208, 208, 208, 206, 205, 209, 209, 207, 208, 208, 206, 205,\n       202, 206, 207], dtype=uint8), array([4.34090199])], [array([207, 208, 207, 205, 202, 205, 205, 205, 206, 207, 207, 204, 205,\n       204, 204, 205, 207, 209, 207, 206, 204, 204, 203, 204, 204, 205,\n       202, 203, 204, 202, 205, 203, 202, 204, 202, 200, 200, 199, 195,\n       192, 192, 193, 192, 187, 184, 182, 169, 149, 138, 145, 151, 138,\n       114, 105, 118, 135, 140, 136, 135, 139, 143, 144, 147, 149, 152,\n       157, 162, 163, 168, 171, 173, 179, 182, 182, 189, 190, 193, 195,\n       193, 195, 196, 198, 201, 204, 205, 202, 202, 206, 206, 206, 207,\n       205, 204, 208, 207, 206, 205, 207, 205, 205, 206, 206, 205, 203,\n       202, 204, 204, 204, 204, 203, 199, 200, 200, 201, 201, 204, 203,\n       203, 199, 202], dtype=uint8), array([8.52101685])], [array([204, 206, 206, 206, 205, 209, 201, 206, 203, 206, 207, 209, 208,\n       207, 205, 207, 205, 207, 206, 208, 205, 206, 208, 206, 204, 205,\n       207, 208, 208, 207, 206, 208, 207, 207, 206, 207, 207, 204, 205,\n       203, 199, 199, 198, 198, 196, 193, 190, 183, 164, 145, 140, 156,\n       167, 140, 113, 112, 130, 140, 139, 139, 138, 135, 140, 145, 146,\n       149, 153, 158, 158, 162, 166, 171, 172, 174, 180, 181, 185, 188,\n       185, 190, 193, 195, 197, 201, 197, 203, 201, 200, 203, 206, 204,\n       205, 202, 205, 204, 205, 205, 205, 206, 207, 207, 208, 208, 203,\n       203, 205, 206, 205, 201, 206, 204, 206, 205, 205, 206, 209, 207,\n       207, 207, 205], dtype=uint8), array([8.73503977])], [array([203, 201, 205, 205, 208, 203, 203, 205, 206, 205, 203, 206, 207,\n       205, 207, 207, 206, 205, 204, 205, 207, 206, 208, 207, 207, 205,\n       202, 204, 205, 205, 202, 204, 203, 207, 207, 203, 203, 207, 204,\n       205, 207, 208, 205, 206, 209, 206, 208, 208, 207, 209, 208, 207,\n       207, 204, 203, 199, 195, 186, 177, 166, 159, 156, 161, 171, 170,\n       170, 172, 170, 171, 172, 176, 177, 179, 184, 188, 191, 190, 192,\n       193, 194, 199, 202, 203, 204, 204, 205, 209, 205, 204, 209, 208,\n       206, 209, 207, 209, 208, 203, 197, 190, 178, 171, 169, 173, 176,\n       177, 178, 179, 180, 182, 182, 183, 185, 186, 189, 196, 198, 199,\n       198, 198, 200], dtype=uint8), array([4.18356936])], [array([206, 203, 201, 203, 205, 204, 205, 208, 207, 206, 203, 207, 206,\n       207, 205, 204, 204, 206, 206, 207, 206, 205, 206, 209, 206, 207,\n       207, 206, 208, 204, 207, 206, 206, 204, 204, 204, 204, 204, 203,\n       204, 204, 206, 205, 204, 204, 202, 204, 204, 206, 206, 204, 207,\n       208, 209, 206, 208, 209, 207, 209, 202, 198, 194, 184, 172, 166,\n       169, 175, 176, 172, 175, 175, 176, 176, 179, 182, 182, 181, 182,\n       192, 192, 194, 195, 196, 198, 197, 198, 202, 203, 204, 204, 206,\n       206, 206, 207, 208, 207, 206, 205, 207, 206, 206, 205, 204, 205,\n       210, 206, 210, 210, 208, 205, 205, 202, 200, 201, 195, 196, 197,\n       194, 196, 199], dtype=uint8), array([4.35067225])], [array([186, 182, 184, 182, 183, 185, 185, 184, 184, 186, 188, 189, 187,\n       186, 187, 184, 183, 183, 183, 187, 184, 184, 188, 188, 185, 185,\n       185, 185, 186, 186, 187, 189, 187, 187, 189, 187, 190, 185, 187,\n       185, 185, 188, 186, 186, 185, 185, 185, 185, 187, 186, 186, 185,\n       186, 187, 188, 189, 190, 191, 187, 189, 188, 186, 186, 186, 183,\n       183, 185, 184, 183, 182, 182, 186, 185, 184, 184, 179, 182, 182,\n       180, 181, 183, 182, 184, 185, 184, 184, 183, 183, 184, 182, 182,\n       183, 180, 183, 181, 181, 180, 180, 176, 181, 180, 182, 181, 179,\n       180, 182, 182, 180, 180, 182, 184, 181, 180, 180, 178, 177, 181,\n       180, 181, 180], dtype=uint8), array([0.])], [array([195, 196, 198, 198, 196, 196, 195, 194, 195, 196, 194, 194, 193,\n       193, 195, 194, 195, 194, 192, 193, 195, 193, 195, 197, 196, 197,\n       195, 194, 193, 195, 196, 195, 193, 193, 196, 193, 197, 195, 197,\n       196, 196, 195, 195, 193, 192, 194, 193, 193, 194, 194, 194, 193,\n       194, 196, 191, 189, 194, 195, 197, 196, 196, 197, 195, 198, 196,\n       194, 199, 200, 196, 197, 197, 197, 194, 191, 177, 158, 151, 142,\n       131, 133, 153, 161, 162, 164, 163, 162, 163, 163, 161, 162, 167,\n       167, 166, 170, 179, 177, 176, 177, 182, 183, 186, 188, 187, 187,\n       190, 191, 189, 185, 185, 189, 190, 194, 197, 195, 196, 195, 196,\n       196, 196, 197], dtype=uint8), array([4.75818342])], [array([198, 199, 196, 193, 195, 195, 194, 194, 195, 196, 195, 197, 198,\n       194, 193, 196, 196, 197, 198, 200, 195, 194, 196, 193, 193, 193,\n       194, 191, 190, 190, 192, 187, 186, 186, 184, 184, 180, 177, 177,\n       175, 171, 172, 172, 171, 171, 169, 170, 167, 167, 169, 169, 171,\n       173, 174, 173, 171, 168, 164, 162, 166, 173, 184, 192, 198, 196,\n       197, 195, 198, 195, 197, 194, 195, 198, 191, 199, 199, 196, 196,\n       195, 196, 194, 194, 197, 198, 197, 196, 195, 197, 195, 194, 192,\n       192, 195, 193, 191, 191, 190, 189, 185, 186, 187, 186, 188, 189,\n       190, 191, 190, 189, 189, 190, 193, 192, 191, 191, 191, 191, 193,\n       194, 197, 196], dtype=uint8), array([3.84824603])], [array([193, 193, 194, 193, 193, 193, 195, 192, 196, 190, 189, 191, 191,\n       191, 190, 190, 191, 191, 185, 189, 192, 192, 193, 193, 190, 189,\n       188, 189, 190, 189, 188, 191, 189, 188, 191, 191, 187, 190, 189,\n       187, 183, 185, 185, 186, 185, 181, 178, 178, 181, 178, 178, 175,\n       177, 174, 171, 171, 170, 164, 163, 164, 162, 161, 160, 162, 160,\n       158, 158, 159, 158, 146, 134, 130, 135, 143, 156, 164, 174, 180,\n       183, 183, 186, 187, 188, 189, 189, 189, 188, 188, 188, 187, 188,\n       189, 188, 187, 185, 185, 184, 183, 179, 177, 172, 168, 161, 158,\n       154, 148, 147, 154, 162, 169, 176, 180, 184, 184, 185, 186, 188,\n       189, 188, 187], dtype=uint8), array([5.52762087])], [array([192, 194, 194, 193, 194, 193, 193, 190, 194, 195, 194, 194, 194,\n       192, 193, 192, 193, 190, 189, 191, 194, 189, 190, 191, 187, 186,\n       186, 185, 185, 183, 180, 180, 178, 174, 173, 171, 169, 168, 165,\n       165, 162, 155, 154, 156, 154, 153, 151, 150, 151, 155, 157, 157,\n       156, 157, 155, 149, 143, 141, 146, 157, 168, 179, 187, 192, 196,\n       197, 196, 195, 193, 193, 194, 193, 192, 193, 192, 194, 193, 189,\n       188, 191, 191, 191, 189, 190, 190, 189, 190, 188, 187, 187, 190,\n       189, 188, 188, 188, 188, 187, 190, 184, 182, 183, 185, 190, 188,\n       184, 185, 189, 185, 188, 185, 186, 184, 186, 183, 180, 181, 179,\n       180, 180, 178], dtype=uint8), array([5.24173503])], [array([187, 185, 186, 187, 186, 184, 186, 189, 186, 186, 187, 185, 185,\n       183, 184, 183, 184, 182, 183, 181, 178, 181, 180, 176, 178, 174,\n       177, 175, 174, 170, 166, 165, 161, 159, 160, 158, 158, 158, 157,\n       159, 158, 155, 153, 154, 154, 159, 160, 160, 164, 164, 164, 165,\n       161, 154, 147, 145, 152, 164, 178, 184, 190, 187, 187, 186, 186,\n       183, 185, 179, 181, 183, 184, 181, 181, 182, 180, 180, 183, 181,\n       183, 182, 180, 179, 179, 180, 179, 179, 182, 180, 178, 180, 179,\n       178, 178, 178, 177, 181, 181, 179, 178, 177, 178, 177, 177, 177,\n       179, 180, 181, 180, 179, 179, 179, 179, 180, 182, 183, 180, 178,\n       180, 180, 179], dtype=uint8), array([3.48806279])], [array([181, 182, 183, 182, 182, 184, 181, 182, 182, 185, 180, 182, 181,\n       180, 182, 179, 180, 181, 181, 180, 182, 182, 179, 178, 177, 179,\n       180, 180, 179, 179, 178, 177, 180, 178, 180, 179, 181, 181, 181,\n       179, 179, 178, 179, 178, 177, 179, 179, 180, 179, 180, 179, 177,\n       178, 178, 177, 176, 177, 176, 174, 174, 176, 176, 176, 172, 173,\n       171, 173, 171, 170, 169, 169, 168, 170, 170, 169, 164, 155, 144,\n       137, 131, 124, 134, 150, 156, 155, 154, 157, 155, 156, 155, 156,\n       157, 157, 159, 159, 157, 159, 157, 157, 156, 155, 159, 158, 156,\n       156, 155, 156, 155, 155, 154, 153, 152, 155, 151, 155, 153, 153,\n       152, 149, 137], dtype=uint8), array([4.68352392])], [array([181, 183, 180, 179, 180, 181, 180, 179, 178, 178, 181, 181, 181,\n       182, 180, 180, 181, 177, 175, 176, 175, 177, 177, 176, 175, 173,\n       174, 170, 170, 170, 171, 170, 168, 165, 166, 164, 161, 164, 160,\n       157, 155, 147, 135, 131, 132, 132, 139, 152, 158, 159, 159, 159,\n       160, 161, 162, 163, 162, 164, 162, 162, 162, 163, 162, 164, 165,\n       162, 164, 163, 163, 162, 165, 160, 153, 143, 135, 134, 138, 146,\n       160, 167, 171, 172, 172, 172, 175, 177, 178, 179, 179, 177, 181,\n       179, 179, 180, 181, 176, 179, 179, 178, 178, 179, 179, 179, 178,\n       177, 178, 180, 179, 180, 186, 178, 179, 180, 177, 179, 181, 180,\n       178, 179, 180], dtype=uint8), array([4.45399496])], [array([198, 197, 196, 197, 198, 198, 198, 196, 198, 197, 197, 197, 198,\n       195, 197, 194, 197, 197, 199, 199, 197, 200, 195, 196, 193, 196,\n       197, 196, 200, 198, 196, 195, 196, 196, 196, 198, 199, 196, 194,\n       196, 198, 197, 194, 193, 196, 196, 194, 195, 195, 193, 193, 195,\n       195, 193, 193, 193, 191, 194, 194, 197, 195, 192, 192, 190, 196,\n       193, 194, 195, 195, 193, 193, 193, 193, 195, 195, 194, 194, 193,\n       194, 195, 195, 196, 196, 194, 195, 197, 198, 194, 193, 194, 192,\n       190, 192, 196, 195, 193, 194, 190, 192, 194, 193, 193, 196, 192,\n       192, 193, 193, 196, 194, 195, 192, 196, 194, 192, 190, 191, 186,\n       192, 192, 191], dtype=uint8), array([0.])], [array([209, 211, 211, 209, 211, 212, 211, 211, 213, 209, 216, 211, 207,\n       211, 210, 212, 210, 210, 210, 209, 212, 215, 211, 210, 208, 210,\n       210, 211, 213, 212, 211, 212, 210, 212, 210, 209, 210, 206, 204,\n       208, 208, 210, 212, 214, 212, 211, 211, 208, 207, 208, 211, 207,\n       205, 205, 201, 202, 203, 203, 199, 196, 194, 195, 192, 189, 183,\n       171, 147, 133, 129, 129, 121, 111, 112, 126, 140, 148, 152, 153,\n       157, 160, 166, 170, 174, 179, 180, 186, 190, 193, 194, 198, 197,\n       199, 199, 204, 207, 207, 207, 209, 210, 210, 210, 208, 211, 212,\n       210, 211, 209, 210, 209, 208, 211, 208, 209, 208, 206, 208, 210,\n       210, 210, 210], dtype=uint8), array([8.71474618])], [array([212, 215, 213, 210, 210, 211, 212, 212, 212, 213, 215, 212, 213,\n       213, 212, 209, 208, 213, 212, 212, 209, 212, 212, 212, 209, 212,\n       213, 212, 210, 212, 213, 213, 209, 210, 212, 211, 205, 207, 207,\n       208, 210, 206, 209, 207, 206, 208, 208, 208, 207, 210, 208, 207,\n       209, 207, 206, 205, 204, 203, 198, 201, 198, 196, 188, 190, 186,\n       179, 173, 156, 128, 102,  95, 105, 120, 126, 124, 125, 138, 153,\n       165, 170, 174, 173, 176, 182, 185, 187, 188, 192, 193, 193, 195,\n       200, 201, 201, 203, 204, 205, 210, 208, 208, 205, 206, 208, 212,\n       209, 209, 211, 211, 211, 210, 215, 211, 211, 211, 210, 212, 210,\n       210, 209, 210], dtype=uint8), array([9.02551505])], [array([169, 169, 172, 177, 179, 178, 181, 181, 180, 183, 184, 186, 187,\n       189, 192, 190, 193, 193, 194, 193, 191, 196, 195, 199, 201, 201,\n       201, 203, 204, 204, 198, 201, 205, 204, 204, 204, 204, 204, 203,\n       204, 202, 202, 203, 199, 195, 183, 160, 143, 142, 144, 125, 114,\n       125, 137, 142, 146, 148, 152, 157, 162, 169, 172, 176, 179, 181,\n       183, 189, 194, 196, 194, 196, 202, 202, 202, 205, 207, 207, 205,\n       202, 206, 209, 209, 206, 206, 208, 212, 212, 210, 210, 211, 209,\n       208, 208, 213, 212, 209, 208, 208, 208, 207, 210, 210, 211, 205,\n       204, 210, 209, 209, 212, 210, 209, 208, 208, 207, 209, 210, 210,\n       211, 210, 214], dtype=uint8), array([7.32964192])], [array([211, 211, 211, 213, 214, 212, 214, 215, 216, 214, 209, 210, 215,\n       213, 215, 213, 213, 213, 215, 214, 213, 213, 212, 213, 213, 213,\n       213, 209, 209, 213, 209, 212, 211, 210, 210, 209, 206, 202, 200,\n       201, 197, 198, 208, 206, 206, 209, 212, 209, 211, 213, 211, 208,\n       210, 212, 211, 202, 204, 203, 202, 202, 202, 199, 193, 183, 172,\n       159, 152, 155, 163, 171, 174, 172, 175, 178, 185, 191, 199, 202,\n       203, 202, 205, 210, 205, 211, 213, 210, 211, 212, 211, 210, 212,\n       212, 210, 212, 213, 211, 210, 211, 214, 212, 210, 211, 212, 213,\n       213, 215, 216, 215, 215, 214, 215, 214, 213, 213, 215, 213, 210,\n       209, 212, 210], dtype=uint8), array([4.88385177])], [array([212, 208, 210, 208, 208, 206, 205, 207, 208, 211, 210, 210, 207,\n       207, 207, 208, 208, 210, 209, 210, 208, 207, 207, 208, 210, 208,\n       208, 208, 206, 211, 213, 208, 207, 206, 207, 205, 207, 204, 203,\n       198, 195, 196, 195, 199, 202, 204, 205, 206, 204, 202, 201, 200,\n       200, 197, 191, 185, 185, 185, 185, 185, 186, 186, 183, 178, 174,\n       168, 169, 170, 173, 160, 130, 111, 120, 133, 132, 135, 164, 184,\n       193, 196, 198, 198, 199, 200, 202, 202, 204, 207, 205, 207, 208,\n       207, 209, 210, 209, 208, 210, 212, 209, 207, 207, 209, 211, 208,\n       213, 212, 211, 211, 215, 213, 211, 212, 211, 210, 213, 212, 212,\n       209, 209, 211], dtype=uint8), array([6.54541434])], [array([202, 202, 202, 201, 199, 197, 196, 197, 194, 191, 195, 196, 191,\n       188, 185, 185, 181, 177, 172, 159, 151, 151, 153, 160, 170, 182,\n       185, 189, 190, 191, 188, 183, 177, 164, 151, 149, 152, 157, 158,\n       155, 150, 146, 146, 155, 169, 179, 187, 195, 199, 202, 201, 203,\n       205, 207, 208, 206, 202, 203, 203, 203, 199, 199, 197, 195, 195,\n       195, 194, 191, 186, 177, 154, 127, 119, 129, 128, 127, 141, 171,\n       186, 192, 195, 196, 200, 203, 202, 202, 204, 207, 207, 209, 207,\n       210, 208, 210, 210, 211, 213, 211, 212, 211, 213, 214, 214, 214,\n       212, 212, 213, 213, 211, 213, 211, 215, 212, 213, 209, 209, 207,\n       206, 209, 210], dtype=uint8), array([7.03218657])], [array([201, 197, 200, 202, 194, 195, 190, 182, 174, 164, 137, 125, 127,\n       139, 141, 137, 137, 150, 165, 176, 186, 188, 190, 193, 192, 196,\n       198, 199, 200, 201, 202, 204, 204, 204, 206, 206, 206, 205, 211,\n       207, 208, 207, 208, 207, 211, 209, 209, 205, 205, 206, 201, 203,\n       202, 200, 200, 197, 196, 193, 189, 183, 178, 176, 173, 168, 168,\n       166, 166, 167, 155, 130, 115, 125, 138, 126, 131, 158, 183, 191,\n       193, 198, 198, 201, 203, 204, 206, 207, 212, 209, 209, 211, 209,\n       211, 212, 210, 209, 211, 214, 211, 214, 214, 210, 212, 213, 213,\n       213, 215, 213, 214, 211, 213, 213, 212, 209, 211, 208, 213, 210,\n       209, 211, 210], dtype=uint8), array([6.38074043])], [array([199, 199, 197, 203, 200, 199, 197, 198, 201, 201, 200, 201, 203,\n       202, 202, 204, 206, 205, 203, 205, 206, 207, 202, 205, 209, 206,\n       204, 208, 207, 205, 206, 203, 204, 204, 208, 204, 204, 207, 208,\n       209, 207, 208, 206, 206, 206, 205, 206, 206, 208, 206, 204, 203,\n       206, 205, 203, 201, 200, 199, 200, 200, 201, 200, 196, 188, 189,\n       189, 192, 196, 200, 202, 198, 197, 200, 193, 188, 174, 155, 147,\n       148, 151, 159, 171, 188, 198, 206, 201, 212, 207, 207, 208, 209,\n       209, 210, 210, 210, 211, 209, 207, 209, 208, 211, 212, 210, 211,\n       209, 206, 211, 211, 210, 210, 210, 208, 209, 209, 210, 211, 210,\n       209, 208, 211], dtype=uint8), array([5.54238319])], [array([210, 209, 211, 213, 214, 213, 210, 213, 213, 212, 213, 213, 215,\n       217, 213, 210, 208, 209, 210, 211, 211, 214, 215, 214, 210, 212,\n       211, 211, 211, 207, 209, 205, 204, 207, 205, 210, 207, 205, 201,\n       203, 200, 197, 191, 191, 190, 188, 188, 187, 187, 187, 184, 179,\n       183, 190, 196, 200, 199, 198, 200, 202, 204, 203, 204, 206, 202,\n       202, 202, 199, 197, 197, 197, 194, 191, 188, 183, 179, 177, 171,\n       168, 166, 168, 177, 191, 198, 204, 207, 206, 208, 206, 208, 209,\n       210, 209, 209, 207, 207, 207, 205, 201, 203, 201, 198, 203, 203,\n       202, 197, 199, 201, 202, 207, 208, 206, 206, 210, 209, 209, 212,\n       211, 210, 212], dtype=uint8), array([4.58639866])], [array([215, 218, 216, 215, 218, 217, 213, 213, 216, 215, 216, 218, 215,\n       215, 215, 214, 215, 215, 214, 214, 214, 215, 215, 214, 214, 213,\n       211, 211, 212, 211, 212, 213, 212, 214, 213, 211, 218, 217, 216,\n       213, 213, 214, 213, 211, 212, 211, 209, 206, 206, 208, 205, 197,\n       187, 173, 163, 150, 135, 138, 161, 172, 173, 173, 170, 174, 176,\n       179, 182, 186, 190, 196, 197, 201, 206, 206, 207, 209, 211, 211,\n       212, 214, 213, 214, 214, 216, 217, 215, 212, 215, 213, 212, 217,\n       216, 219, 216, 218, 217, 215, 215, 218, 216, 213, 215, 215, 213,\n       213, 216, 216, 215, 216, 213, 213, 213, 215, 217, 215, 214, 212,\n       214, 214, 216], dtype=uint8), array([5.4984222])], [array([200, 198, 197, 199, 201, 195, 194, 191, 186, 173, 162, 148, 143,\n       136, 131, 124, 129, 130, 134, 140, 149, 154, 155, 156, 160, 165,\n       170, 171, 179, 186, 190, 191, 192, 195, 192, 193, 195, 197, 197,\n       202, 199, 199, 196, 196, 202, 200, 201, 202, 203, 203, 203, 204,\n       205, 205, 203, 203, 200, 201, 204, 202, 200, 199, 201, 200, 199,\n       193, 183, 165, 144, 138, 141, 136, 126, 116, 116, 127, 137, 143,\n       147, 152, 154, 160, 162, 166, 171, 177, 181, 183, 187, 192, 193,\n       196, 200, 200, 203, 205, 204, 204, 206, 205, 206, 207, 209, 210,\n       207, 209, 209, 212, 209, 210, 213, 211, 211, 213, 215, 212, 214,\n       210, 210, 213], dtype=uint8), array([8.81468908])], [array([210, 209, 210, 211, 212, 212, 212, 212, 212, 211, 210, 213, 214,\n       210, 210, 209, 210, 210, 211, 211, 213, 212, 210, 208, 210, 210,\n       211, 211, 210, 209, 212, 212, 212, 213, 211, 210, 208, 212, 210,\n       208, 210, 213, 215, 215, 210, 208, 211, 210, 211, 210, 209, 210,\n       206, 208, 210, 208, 209, 207, 205, 207, 207, 205, 203, 204, 204,\n       204, 202, 203, 202, 202, 197, 199, 196, 193, 190, 187, 178, 149,\n       122, 109, 108, 121, 150, 176, 192, 195, 200, 202, 202, 204, 204,\n       206, 208, 211, 212, 209, 207, 209, 210, 210, 210, 211, 211, 210,\n       213, 214, 209, 210, 218, 209, 210, 212, 212, 213, 213, 209, 210,\n       211, 207, 214], dtype=uint8), array([5.09065576])], [array([184, 185, 184, 184, 185, 184, 182, 185, 187, 186, 185, 186, 187,\n       183, 182, 186, 186, 183, 185, 185, 183, 187, 188, 189, 186, 186,\n       188, 186, 187, 186, 186, 188, 186, 185, 187, 186, 185, 185, 183,\n       182, 185, 185, 186, 185, 185, 186, 190, 187, 186, 185, 186, 187,\n       185, 189, 185, 183, 186, 187, 187, 187, 188, 187, 187, 188, 189,\n       187, 188, 189, 187, 188, 189, 189, 188, 193, 191, 190, 189, 190,\n       191, 188, 192, 189, 190, 190, 192, 192, 191, 190, 191, 191, 189,\n       189, 191, 190, 188, 188, 190, 189, 189, 189, 188, 187, 190, 190,\n       190, 188, 188, 187, 188, 190, 187, 186, 186, 188, 190, 192, 188,\n       186, 187, 188], dtype=uint8), array([0.])], [array([207, 207, 203, 204, 205, 207, 205, 206, 208, 209, 206, 206, 208,\n       205, 207, 206, 207, 207, 206, 205, 206, 208, 207, 208, 206, 205,\n       204, 207, 207, 205, 206, 206, 205, 206, 207, 208, 207, 205, 207,\n       205, 206, 207, 204, 203, 204, 206, 209, 208, 208, 207, 208, 207,\n       209, 205, 205, 206, 206, 206, 207, 204, 205, 201, 202, 194, 181,\n       163, 146, 133, 132, 147, 164, 173, 177, 176, 176, 176, 178, 179,\n       180, 181, 184, 190, 190, 192, 194, 196, 196, 199, 198, 199, 202,\n       202, 202, 204, 205, 203, 204, 209, 206, 205, 207, 207, 208, 207,\n       205, 208, 206, 209, 206, 211, 207, 204, 204, 201, 196, 189, 181,\n       172, 168, 170], dtype=uint8), array([4.42544194])], [array([203, 204, 204, 205, 203, 203, 204, 205, 205, 203, 206, 204, 205,\n       205, 206, 204, 204, 205, 205, 207, 206, 207, 205, 205, 204, 204,\n       207, 207, 209, 208, 207, 207, 206, 207, 209, 208, 209, 207, 206,\n       207, 209, 206, 205, 203, 204, 204, 200, 200, 192, 186, 176, 167,\n       159, 156, 159, 166, 177, 184, 187, 190, 194, 195, 197, 202, 201,\n       200, 201, 201, 203, 204, 202, 199, 192, 182, 171, 155, 146, 145,\n       155, 164, 170, 172, 170, 174, 176, 175, 176, 179, 183, 182, 187,\n       190, 197, 197, 195, 201, 197, 197, 199, 201, 201, 203, 204, 205,\n       204, 207, 206, 207, 208, 207, 207, 206, 204, 205, 205, 205, 208,\n       206, 207, 206], dtype=uint8), array([4.45399496])], [array([175, 177, 178, 184, 187, 186, 186, 188, 187, 190, 188, 185, 189,\n       190, 192, 192, 190, 196, 197, 196, 198, 198, 198, 198, 199, 196,\n       196, 198, 200, 201, 200, 203, 201, 204, 201, 202, 204, 203, 204,\n       203, 203, 206, 203, 205, 205, 205, 208, 207, 206, 204, 206, 207,\n       204, 205, 206, 205, 209, 208, 204, 205, 209, 208, 205, 206, 207,\n       206, 205, 208, 206, 205, 206, 205, 203, 202, 204, 201, 197, 191,\n       178, 159, 143, 134, 139, 153, 166, 173, 177, 181, 182, 184, 185,\n       188, 190, 192, 194, 194, 196, 201, 202, 201, 200, 205, 206, 204,\n       205, 207, 205, 205, 205, 204, 203, 205, 208, 208, 206, 202, 192,\n       177, 162, 149], dtype=uint8), array([4.68352392])], [array([204, 206, 206, 205, 206, 208, 206, 205, 206, 204, 204, 204, 206,\n       205, 205, 207, 206, 207, 205, 206, 202, 203, 202, 204, 204, 205,\n       204, 206, 205, 203, 206, 203, 203, 204, 206, 206, 206, 203, 207,\n       205, 206, 206, 205, 205, 204, 201, 200, 195, 197, 190, 180, 170,\n       159, 161, 167, 175, 182, 185, 189, 191, 189, 186, 186, 188, 188,\n       186, 185, 184, 185, 187, 185, 186, 190, 192, 191, 190, 191, 194,\n       198, 198, 198, 198, 199, 200, 196, 200, 203, 203, 205, 199, 201,\n       203, 201, 205, 206, 207, 204, 206, 206, 204, 205, 206, 206, 205,\n       205, 207, 207, 206, 204, 205, 206, 206, 206, 206, 207, 206, 205,\n       204, 204, 204], dtype=uint8), array([3.48806279])], [array([185, 186, 188, 188, 190, 193, 195, 199, 199, 198, 199, 201, 201,\n       202, 202, 204, 203, 202, 204, 203, 205, 203, 205, 205, 205, 204,\n       204, 207, 206, 205, 205, 206, 205, 206, 205, 202, 207, 206, 205,\n       204, 208, 205, 204, 207, 207, 205, 204, 205, 204, 205, 207, 202,\n       205, 202, 201, 205, 206, 207, 206, 204, 202, 202, 203, 205, 206,\n       204, 203, 206, 205, 207, 205, 205, 205, 197, 189, 177, 163, 148,\n       135, 133, 145, 156, 165, 163, 164, 167, 171, 171, 172, 174, 178,\n       181, 182, 185, 186, 191, 196, 196, 195, 195, 196, 199, 201, 202,\n       205, 206, 201, 205, 201, 205, 208, 207, 205, 204, 206, 203, 205,\n       207, 206, 206], dtype=uint8), array([5.52762087])], [array([205, 203, 202, 203, 205, 203, 202, 202, 205, 206, 203, 200, 203,\n       202, 202, 206, 204, 202, 203, 204, 204, 203, 200, 200, 202, 204,\n       206, 205, 203, 202, 204, 204, 201, 201, 204, 203, 204, 205, 202,\n       198, 194, 189, 188, 189, 193, 199, 202, 201, 201, 203, 203, 200,\n       200, 197, 191, 183, 172, 163, 155, 144, 135, 138, 150, 158, 157,\n       154, 155, 155, 154, 158, 162, 166, 168, 171, 175, 181, 184, 185,\n       185, 188, 191, 193, 195, 197, 197, 200, 202, 201, 199, 199, 201,\n       202, 204, 202, 202, 202, 203, 203, 206, 203, 201, 203, 204, 201,\n       202, 204, 207, 205, 203, 204, 206, 205, 205, 206, 203, 206, 203,\n       207, 206, 204], dtype=uint8), array([5.24173503])], [array([203, 206, 205, 203, 204, 204, 203, 202, 203, 203, 200, 201, 200,\n       200, 201, 202, 201, 203, 203, 198, 201, 205, 205, 203, 201, 199,\n       197, 194, 189, 185, 186, 186, 188, 191, 199, 198, 200, 203, 202,\n       199, 201, 199, 201, 203, 202, 203, 201, 202, 201, 201, 201, 196,\n       199, 198, 200, 198, 197, 193, 193, 191, 190, 188, 184, 181, 181,\n       175, 176, 174, 171, 168, 171, 168, 162, 164, 163, 160, 150, 137,\n       136, 141, 152, 169, 184, 193, 195, 196, 197, 201, 202, 201, 201,\n       202, 202, 202, 203, 203, 201, 199, 199, 200, 205, 202, 201, 202,\n       201, 202, 206, 204, 201, 203, 205, 204, 200, 204, 204, 205, 203,\n       203, 201, 202], dtype=uint8), array([4.75818342])], [array([195, 197, 197, 199, 198, 198, 198, 200, 203, 200, 197, 198, 198,\n       198, 200, 200, 198, 200, 202, 200, 202, 202, 201, 203, 201, 202,\n       203, 203, 201, 201, 198, 197, 201, 202, 198, 198, 198, 201, 201,\n       195, 199, 200, 203, 199, 202, 203, 200, 202, 204, 203, 204, 202,\n       204, 201, 200, 194, 182, 166, 159, 157, 161, 166, 169, 169, 168,\n       167, 165, 164, 166, 170, 172, 174, 177, 181, 183, 184, 187, 191,\n       191, 193, 197, 195, 194, 198, 200, 200, 199, 198, 200, 200, 200,\n       204, 202, 204, 205, 206, 200, 204, 203, 202, 200, 207, 205, 199,\n       202, 202, 201, 201, 202, 202, 200, 191, 190, 190, 189, 186, 186,\n       187, 185, 186], dtype=uint8), array([3.84824603])], [array([196, 198, 196, 194, 195, 192, 194, 194, 196, 194, 193, 194, 191,\n       191, 191, 189, 194, 193, 192, 193, 191, 192, 191, 191, 191, 191,\n       192, 190, 189, 188, 192, 191, 193, 194, 194, 194, 194, 196, 193,\n       195, 193, 196, 195, 196, 197, 197, 197, 198, 196, 196, 195, 198,\n       196, 197, 200, 199, 197, 195, 192, 184, 184, 183, 178, 170, 163,\n       159, 154, 144, 138, 136, 146, 151, 146, 138, 134, 133, 134, 137,\n       141, 143, 146, 149, 152, 154, 158, 162, 164, 169, 170, 172, 173,\n       176, 180, 183, 184, 185, 187, 189, 191, 193, 194, 193, 192, 194,\n       195, 196, 195, 196, 197, 196, 196, 195, 197, 196, 198, 197, 198,\n       199, 200, 201], dtype=uint8), array([6.3266849])], [array([157, 158, 158, 162, 162, 163, 167, 168, 169, 168, 172, 172, 174,\n       175, 176, 176, 178, 178, 180, 180, 182, 183, 183, 184, 186, 189,\n       189, 190, 188, 191, 189, 191, 193, 193, 193, 195, 193, 192, 193,\n       197, 195, 195, 196, 197, 197, 196, 195, 195, 193, 193, 194, 195,\n       194, 192, 196, 194, 191, 189, 186, 177, 163, 155, 152, 161, 166,\n       176, 177, 175, 176, 176, 179, 178, 176, 172, 164, 146, 126, 122,\n       116, 108, 111, 124, 138, 147, 152, 155, 159, 161, 168, 168, 169,\n       171, 177, 179, 181, 183, 186, 188, 188, 189, 192, 192, 193, 194,\n       194, 196, 196, 200, 199, 199, 197, 198, 198, 197, 198, 202, 202,\n       198, 200, 200], dtype=uint8), array([5.48232787])], [array([165, 165, 164, 162, 166, 166, 166, 164, 166, 173, 170, 168, 169,\n       172, 177, 177, 175, 181, 177, 179, 175, 180, 184, 181, 179, 182,\n       184, 188, 181, 184, 187, 186, 184, 191, 186, 188, 185, 189, 188,\n       187, 186, 189, 187, 193, 190, 194, 193, 193, 189, 193, 190, 187,\n       192, 191, 188, 192, 191, 192, 192, 187, 195, 193, 192, 192, 192,\n       190, 194, 194, 194, 197, 197, 195, 197, 200, 199, 194, 184, 174,\n       159, 145, 134, 133, 141, 148, 148, 152, 156, 156, 156, 152, 155,\n       160, 158, 162, 164, 163, 165, 170, 174, 171, 179, 178, 180, 182,\n       184, 188, 192, 190, 191, 186, 188, 192, 193, 192, 195, 191, 197,\n       196, 195, 199], dtype=uint8), array([4.22418291])], [array([207, 208, 206, 210, 209, 209, 210, 209, 206, 204, 206, 205, 208,\n       206, 206, 207, 206, 207, 208, 210, 205, 205, 203, 203, 205, 207,\n       207, 205, 208, 211, 207, 206, 204, 204, 206, 204, 205, 207, 207,\n       207, 208, 208, 208, 207, 206, 206, 205, 210, 206, 204, 210, 209,\n       207, 206, 205, 207, 206, 207, 207, 207, 209, 208, 208, 207, 205,\n       204, 205, 204, 205, 205, 206, 208, 209, 206, 205, 208, 204, 205,\n       207, 209, 210, 206, 206, 205, 206, 206, 209, 209, 208, 208, 207,\n       206, 206, 206, 209, 210, 210, 210, 208, 206, 206, 204, 206, 209,\n       206, 205, 206, 206, 202, 201, 207, 204, 203, 208, 208, 208, 208,\n       208, 207, 205], dtype=uint8), array([0.])], [array([203, 202, 203, 203, 203, 200, 201, 202, 202, 202, 202, 203, 202,\n       203, 202, 202, 205, 203, 202, 204, 203, 203, 203, 202, 203, 205,\n       203, 204, 203, 203, 204, 202, 202, 204, 201, 200, 201, 203, 204,\n       204, 203, 202, 201, 202, 202, 203, 204, 206, 206, 204, 206, 201,\n       206, 208, 206, 202, 205, 209, 202, 207, 203, 204, 204, 202, 199,\n       197, 190, 178, 165, 158, 157, 162, 170, 171, 170, 169, 172, 170,\n       172, 177, 179, 183, 183, 185, 186, 188, 191, 194, 194, 196, 198,\n       197, 199, 201, 200, 203, 201, 198, 203, 202, 204, 203, 201, 205,\n       204, 202, 205, 204, 202, 204, 206, 206, 203, 204, 202, 203, 205,\n       203, 205, 205], dtype=uint8), array([3.71157107])], [array([205, 205, 202, 208, 203, 203, 199, 205, 204, 207, 206, 205, 204,\n       202, 201, 204, 201, 204, 204, 203, 204, 205, 199, 203, 203, 206,\n       205, 205, 205, 202, 200, 201, 202, 205, 204, 201, 200, 201, 199,\n       199, 198, 197, 193, 189, 190, 191, 188, 192, 196, 198, 200, 202,\n       202, 201, 198, 202, 202, 202, 199, 203, 202, 203, 202, 198, 200,\n       201, 200, 198, 195, 192, 193, 188, 186, 176, 161, 148, 138, 134,\n       141, 155, 168, 172, 174, 173, 177, 181, 179, 179, 183, 190, 188,\n       193, 193, 193, 198, 199, 196, 197, 201, 200, 200, 204, 202, 204,\n       206, 203, 203, 202, 202, 198, 200, 203, 205, 205, 204, 204, 203,\n       203, 205, 206], dtype=uint8), array([4.08382213])], [array([204, 208, 205, 205, 205, 209, 205, 203, 204, 205, 202, 204, 206,\n       207, 208, 206, 208, 206, 203, 204, 205, 204, 202, 199, 204, 203,\n       203, 204, 205, 205, 205, 204, 201, 201, 203, 203, 199, 198, 198,\n       198, 196, 192, 191, 191, 187, 176, 163, 151, 142, 154, 172, 185,\n       193, 199, 200, 199, 201, 203, 204, 205, 205, 205, 205, 204, 206,\n       204, 206, 203, 204, 206, 207, 204, 202, 205, 207, 206, 202, 206,\n       206, 204, 205, 207, 208, 202, 208, 211, 207, 208, 210, 208, 207,\n       205, 206, 204, 203, 206, 202, 202, 202, 202, 204, 203, 202, 201,\n       198, 196, 194, 195, 192, 190, 186, 179, 173, 161, 152, 151, 152,\n       155, 162, 168], dtype=uint8), array([3.69767209])], [array([196, 197, 198, 195, 195, 198, 195, 195, 199, 198, 200, 199, 198,\n       201, 203, 200, 200, 200, 200, 193, 188, 178, 171, 165, 165, 171,\n       174, 176, 182, 181, 178, 176, 178, 176, 173, 173, 169, 164, 164,\n       161, 155, 152, 148, 148, 146, 145, 146, 150, 162, 166, 169, 172,\n       177, 181, 180, 180, 180, 180, 181, 183, 185, 185, 191, 186, 186,\n       186, 187, 189, 192, 189, 185, 172, 160, 150, 141, 141, 151, 158,\n       158, 161, 160, 156, 157, 156, 156, 156, 162, 159, 162, 164, 170,\n       175, 174, 174, 176, 177, 184, 183, 185, 187, 189, 189, 191, 190,\n       191, 195, 195, 194, 195, 197, 197, 196, 198, 199, 197, 199, 197,\n       199, 200, 198], dtype=uint8), array([4.18255064])], [array([205, 204, 204, 205, 204, 205, 205, 207, 201, 203, 205, 206, 204,\n       204, 204, 202, 205, 204, 203, 204, 204, 205, 205, 202, 201, 200,\n       201, 202, 201, 201, 203, 201, 201, 202, 203, 202, 200, 199, 199,\n       200, 199, 201, 201, 200, 198, 195, 196, 196, 195, 191, 190, 190,\n       186, 184, 180, 178, 181, 178, 174, 171, 169, 166, 164, 163, 161,\n       159, 161, 159, 158, 143, 122, 116, 128, 138, 130, 123, 132, 157,\n       176, 177, 179, 183, 186, 189, 188, 190, 191, 194, 198, 196, 199,\n       198, 202, 199, 201, 203, 203, 202, 202, 204, 205, 202, 201, 204,\n       202, 200, 203, 202, 203, 203, 201, 200, 201, 203, 200, 201, 202,\n       202, 201, 200], dtype=uint8), array([9.01671984])], [array([163, 166, 171, 170, 172, 175, 176, 175, 175, 175, 176, 175, 174,\n       175, 176, 175, 177, 175, 175, 176, 176, 173, 175, 176, 175, 178,\n       172, 172, 167, 167, 170, 171, 170, 170, 170, 170, 163, 163, 165,\n       170, 168, 165, 162, 159, 156, 146, 140, 142, 147, 154, 161, 164,\n       165, 168, 172, 176, 174, 176, 175, 175, 177, 180, 178, 169, 159,\n       156, 158, 152, 154, 164, 180, 188, 191, 191, 196, 197, 198, 199,\n       198, 198, 198, 197, 198, 200, 199, 197, 201, 200, 200, 197, 197,\n       198, 199, 199, 198, 196, 194, 196, 196, 198, 198, 198, 199, 197,\n       198, 195, 199, 199, 198, 198, 197, 198, 197, 196, 198, 198, 197,\n       194, 197, 196], dtype=uint8), array([6.47364817])], [array([199, 199, 199, 199, 197, 195, 197, 195, 198, 198, 198, 195, 194,\n       198, 197, 197, 196, 199, 198, 194, 197, 199, 196, 197, 195, 197,\n       198, 196, 195, 199, 198, 200, 197, 197, 196, 197, 198, 195, 194,\n       192, 198, 198, 200, 200, 199, 198, 201, 201, 197, 200, 201, 201,\n       199, 200, 202, 199, 200, 199, 201, 201, 200, 199, 200, 198, 200,\n       202, 200, 198, 201, 201, 200, 196, 190, 181, 169, 159, 150, 151,\n       159, 162, 168, 167, 170, 171, 172, 170, 172, 175, 174, 174, 175,\n       176, 178, 179, 180, 184, 187, 187, 189, 188, 189, 191, 191, 193,\n       192, 193, 197, 196, 196, 198, 198, 197, 199, 198, 199, 199, 198,\n       196, 198, 198], dtype=uint8), array([4.51710674])], [array([207, 206, 206, 205, 205, 211, 204, 203, 204, 203, 207, 207, 208,\n       207, 206, 205, 203, 204, 205, 206, 204, 202, 203, 203, 201, 202,\n       204, 206, 206, 204, 207, 205, 201, 202, 209, 208, 207, 206, 205,\n       205, 209, 198, 205, 205, 205, 205, 204, 206, 208, 204, 205, 204,\n       202, 204, 205, 208, 204, 208, 208, 205, 206, 207, 203, 203, 206,\n       207, 207, 204, 204, 207, 207, 205, 205, 204, 201, 199, 191, 184,\n       185, 188, 192, 188, 191, 189, 188, 191, 191, 192, 196, 195, 194,\n       201, 200, 200, 198, 199, 200, 206, 204, 202, 203, 206, 204, 204,\n       202, 202, 204, 203, 204, 203, 202, 206, 206, 206, 206, 202, 203,\n       202, 203, 207], dtype=uint8), array([4.88037655])], [array([208, 208, 208, 208, 207, 209, 207, 209, 204, 206, 207, 206, 205,\n       204, 205, 204, 205, 205, 206, 205, 203, 205, 205, 207, 205, 207,\n       203, 203, 203, 203, 203, 202, 202, 204, 204, 202, 205, 208, 205,\n       204, 204, 204, 205, 202, 203, 206, 204, 203, 203, 202, 205, 201,\n       201, 204, 203, 201, 201, 200, 200, 199, 199, 199, 200, 201, 199,\n       199, 203, 203, 202, 202, 202, 198, 196, 198, 200, 198, 199, 198,\n       200, 201, 201, 199, 199, 200, 200, 202, 202, 200, 195, 192, 195,\n       197, 199, 203, 205, 204, 204, 205, 204, 203, 205, 202, 204, 205,\n       203, 204, 204, 203, 205, 205, 203, 203, 202, 199, 198, 200, 204,\n       206, 202, 203], dtype=uint8), array([4.75318777])], [array([202, 204, 203, 202, 204, 205, 204, 203, 203, 202, 205, 202, 201,\n       200, 202, 201, 199, 202, 198, 199, 197, 196, 195, 192, 189, 188,\n       185, 183, 183, 177, 177, 176, 176, 172, 170, 174, 167, 166, 166,\n       165, 163, 164, 166, 166, 165, 158, 146, 138, 143, 160, 174, 188,\n       195, 196, 196, 197, 200, 202, 201, 200, 201, 201, 205, 202, 205,\n       201, 204, 201, 203, 202, 202, 202, 201, 204, 204, 203, 204, 202,\n       203, 201, 200, 201, 203, 201, 202, 205, 204, 202, 202, 202, 203,\n       203, 201, 200, 203, 201, 202, 203, 204, 201, 198, 201, 202, 204,\n       201, 201, 201, 200, 201, 200, 200, 201, 199, 201, 202, 201, 201,\n       201, 199, 196], dtype=uint8), array([4.67930649])], [array([200, 203, 202, 202, 201, 199, 206, 205, 202, 203, 205, 204, 204,\n       202, 198, 203, 203, 200, 199, 200, 201, 201, 203, 208, 205, 203,\n       204, 201, 200, 198, 199, 200, 200, 199, 199, 197, 198, 196, 192,\n       196, 201, 200, 201, 203, 198, 198, 202, 202, 202, 201, 198, 199,\n       198, 198, 197, 196, 194, 193, 192, 192, 191, 188, 189, 186, 188,\n       185, 187, 176, 167, 162, 168, 176, 178, 181, 183, 183, 183, 184,\n       185, 186, 186, 186, 186, 191, 193, 195, 197, 197, 198, 199, 198,\n       200, 200, 200, 199, 200, 198, 201, 203, 203, 200, 202, 204, 200,\n       201, 203, 202, 204, 201, 200, 203, 202, 201, 202, 207, 205, 201,\n       204, 202, 205], dtype=uint8), array([3.66342182])], [array([179, 178, 183, 183, 181, 181, 182, 178, 178, 179, 180, 181, 180,\n       179, 179, 178, 180, 181, 181, 182, 181, 181, 181, 180, 179, 179,\n       180, 180, 183, 183, 183, 180, 183, 180, 181, 177, 182, 183, 182,\n       184, 181, 178, 182, 180, 178, 178, 180, 177, 181, 182, 180, 180,\n       181, 179, 179, 179, 179, 179, 180, 177, 176, 178, 179, 178, 178,\n       176, 171, 171, 172, 169, 166, 161, 154, 140, 123, 112, 112, 110,\n        94,  82,  86,  92,  93,  93,  96,  99, 107, 108, 110, 113, 115,\n       117, 116, 120, 126, 133, 135, 136, 141, 144, 147, 148, 150, 150,\n       155, 158, 158, 160, 163, 166, 168, 168, 167, 171, 174, 173, 174,\n       174, 176, 177], dtype=uint8), array([11.24816955])], [array([188, 185, 187, 189, 186, 186, 187, 186, 185, 185, 187, 190, 185,\n       185, 185, 181, 180, 180, 180, 179, 176, 174, 174, 175, 171, 169,\n       167, 167, 166, 164, 161, 160, 159, 157, 156, 155, 153, 155, 158,\n       154, 157, 157, 159, 161, 164, 164, 158, 154, 146, 136, 140, 156,\n       170, 179, 188, 189, 191, 194, 189, 189, 190, 190, 189, 186, 189,\n       187, 188, 187, 185, 185, 185, 186, 186, 186, 183, 188, 184, 184,\n       183, 183, 186, 185, 182, 187, 185, 184, 182, 183, 185, 183, 182,\n       181, 181, 183, 181, 181, 182, 182, 185, 185, 185, 185, 184, 181,\n       183, 187, 187, 182, 184, 186, 182, 183, 181, 181, 183, 183, 184,\n       182, 185, 184], dtype=uint8), array([5.29607184])], [array([186, 188, 187, 189, 188, 189, 190, 188, 187, 188, 186, 185, 187,\n       187, 184, 183, 183, 182, 182, 181, 182, 182, 180, 182, 180, 179,\n       175, 176, 175, 172, 168, 169, 167, 164, 163, 159, 157, 155, 152,\n       150, 148, 146, 147, 146, 145, 147, 148, 147, 147, 149, 143, 137,\n       125, 119, 127, 145, 162, 175, 183, 191, 194, 192, 192, 193, 190,\n       190, 190, 191, 192, 190, 190, 186, 186, 189, 187, 186, 186, 188,\n       186, 185, 187, 189, 186, 186, 185, 185, 183, 184, 180, 180, 181,\n       183, 183, 181, 178, 178, 177, 174, 179, 178, 175, 175, 174, 177,\n       175, 175, 175, 175, 177, 178, 179, 184, 184, 182, 183, 183, 185,\n       186, 184, 183], dtype=uint8), array([5.46791157])], [array([187, 187, 188, 187, 184, 184, 184, 185, 187, 189, 187, 187, 188,\n       187, 185, 187, 187, 186, 185, 186, 183, 184, 183, 182, 179, 179,\n       177, 174, 173, 173, 170, 170, 166, 165, 168, 163, 162, 159, 158,\n       157, 156, 153, 152, 149, 147, 147, 146, 147, 147, 148, 151, 152,\n       153, 152, 151, 143, 133, 134, 143, 155, 168, 180, 186, 190, 188,\n       189, 187, 187, 186, 188, 187, 189, 188, 189, 188, 185, 188, 187,\n       187, 187, 186, 186, 187, 185, 186, 189, 189, 187, 188, 189, 189,\n       190, 189, 189, 188, 188, 188, 185, 187, 188, 186, 187, 187, 186,\n       187, 188, 188, 187, 187, 185, 187, 187, 187, 185, 187, 187, 186,\n       186, 185, 178], dtype=uint8), array([5.45620238])], [array([205, 206, 205, 202, 203, 205, 206, 207, 203, 202, 202, 202, 203,\n       201, 199, 201, 203, 204, 203, 202, 201, 202, 204, 206, 205, 205,\n       206, 207, 207, 206, 203, 201, 200, 203, 208, 208, 206, 206, 204,\n       202, 201, 200, 201, 200, 200, 201, 203, 205, 205, 206, 207, 207,\n       203, 205, 205, 202, 205, 206, 204, 203, 205, 206, 207, 207, 205,\n       206, 206, 206, 206, 205, 206, 206, 204, 205, 205, 204, 204, 203,\n       201, 203, 205, 209, 208, 205, 206, 206, 207, 208, 205, 205, 207,\n       206, 206, 207, 205, 203, 203, 203, 202, 203, 205, 206, 206, 205,\n       206, 205, 205, 207, 208, 208, 207, 207, 206, 204, 203, 204, 205,\n       204, 205, 206], dtype=uint8), array([0.])], [array([156, 166, 179, 191, 193, 192, 195, 201, 199, 200, 199, 200, 203,\n       203, 204, 206, 206, 202, 205, 208, 208, 208, 208, 206, 209, 210,\n       208, 208, 208, 208, 211, 210, 210, 208, 208, 207, 208, 212, 211,\n       209, 206, 210, 211, 209, 212, 209, 209, 207, 209, 211, 210, 209,\n       208, 212, 211, 208, 210, 207, 208, 207, 207, 205, 204, 206, 204,\n       206, 200, 201, 202, 200, 192, 175, 149, 121, 113, 115, 120, 115,\n        87,  66,  74,  87,  96, 105, 118, 124, 126, 131, 135, 140, 147,\n       150, 152, 152, 157, 163, 166, 172, 175, 179, 180, 186, 187, 191,\n       193, 196, 196, 200, 199, 200, 203, 204, 205, 205, 206, 205, 207,\n       207, 206, 208], dtype=uint8), array([11.65322989])], [array([208, 207, 207, 209, 207, 205, 210, 207, 205, 210, 207, 209, 208,\n       205, 204, 208, 208, 209, 209, 208, 209, 210, 209, 206, 206, 206,\n       207, 207, 207, 207, 204, 205, 208, 211, 209, 209, 209, 207, 208,\n       209, 204, 205, 207, 205, 206, 208, 208, 205, 207, 210, 211, 211,\n       209, 209, 210, 208, 204, 206, 207, 207, 206, 203, 204, 200, 198,\n       198, 194, 187, 187, 177, 172, 168, 157, 136, 113, 109, 116, 114,\n       106, 103, 104, 114, 127, 137, 142, 146, 150, 154, 159, 163, 167,\n       170, 173, 178, 175, 181, 183, 186, 190, 195, 195, 196, 196, 197,\n       202, 202, 200, 201, 203, 202, 201, 203, 204, 206, 208, 207, 208,\n       205, 205, 206], dtype=uint8), array([11.24816955])], [array([207, 208, 209, 207, 207, 205, 206, 207, 206, 208, 211, 208, 206,\n       208, 209, 210, 211, 211, 209, 208, 208, 208, 206, 207, 208, 208,\n       209, 207, 206, 207, 207, 209, 209, 209, 208, 205, 205, 206, 208,\n       203, 207, 207, 204, 204, 203, 200, 203, 204, 200, 200, 198, 198,\n       197, 194, 192, 189, 189, 189, 185, 177, 167, 151, 139, 140, 146,\n       151, 155, 147, 127, 120, 141, 154, 172, 188, 195, 198, 197, 198,\n       205, 203, 201, 203, 205, 204, 200, 202, 202, 203, 204, 204, 206,\n       208, 203, 203, 207, 206, 205, 206, 205, 205, 205, 207, 206, 207,\n       206, 208, 207, 206, 206, 205, 205, 206, 205, 206, 206, 204, 205,\n       204, 209, 199], dtype=uint8), array([5.29607184])], [array([205, 209, 213, 211, 213, 210, 208, 209, 208, 209, 211, 210, 212,\n       209, 207, 208, 209, 211, 210, 210, 210, 213, 214, 212, 211, 211,\n       211, 210, 213, 212, 212, 211, 212, 213, 214, 212, 211, 209, 212,\n       211, 210, 209, 208, 210, 207, 205, 207, 206, 208, 203, 186, 160,\n       147, 129, 118, 138, 161, 167, 168, 170, 173, 175, 179, 181, 184,\n       188, 192, 194, 195, 198, 202, 206, 205, 206, 206, 209, 210, 209,\n       212, 209, 209, 211, 212, 208, 205, 209, 207, 207, 212, 211, 207,\n       208, 208, 207, 206, 206, 205, 207, 205, 202, 201, 203, 204, 203,\n       204, 204, 205, 206, 206, 208, 210, 209, 208, 209, 210, 209, 212,\n       210, 211, 210], dtype=uint8), array([5.46791157])], [array([210, 208, 207, 206, 207, 208, 208, 209, 208, 206, 206, 208, 207,\n       210, 212, 211, 210, 209, 210, 207, 208, 210, 209, 208, 209, 208,\n       206, 206, 201, 202, 201, 199, 201, 203, 206, 206, 204, 207, 210,\n       211, 210, 210, 217, 210, 206, 208, 207, 207, 207, 206, 205, 204,\n       200, 197, 182, 161, 146, 126, 107, 123, 150, 156, 158, 164, 166,\n       171, 175, 175, 176, 180, 185, 189, 189, 197, 196, 198, 203, 204,\n       206, 206, 203, 208, 208, 207, 208, 204, 207, 209, 206, 208, 209,\n       204, 207, 208, 207, 208, 209, 210, 208, 210, 209, 211, 206, 207,\n       206, 210, 210, 212, 211, 208, 210, 209, 210, 212, 211, 211, 206,\n       207, 206, 210], dtype=uint8), array([5.45620238])], [array([211, 211, 212, 211, 211, 211, 209, 210, 210, 211, 211, 210, 211,\n       212, 214, 210, 209, 212, 211, 212, 211, 208, 208, 210, 213, 215,\n       211, 211, 211, 211, 212, 211, 209, 207, 206, 208, 208, 208, 209,\n       209, 208, 207, 205, 212, 210, 211, 209, 208, 211, 212, 212, 211,\n       209, 208, 211, 212, 208, 206, 206, 209, 209, 206, 210, 212, 211,\n       207, 208, 206, 209, 209, 211, 211, 212, 211, 212, 208, 203, 201,\n       201, 204, 206, 210, 208, 207, 208, 206, 208, 212, 209, 208, 210,\n       210, 211, 209, 206, 211, 213, 209, 208, 211, 212, 212, 211, 210,\n       213, 212, 214, 212, 212, 210, 212, 211, 214, 212, 211, 214, 210,\n       209, 213, 210], dtype=uint8), array([3.54463004])], [array([187, 187, 187, 188, 188, 189, 187, 186, 189, 192, 191, 189, 189,\n       190, 191, 190, 192, 192, 191, 191, 191, 190, 195, 193, 190, 192,\n       190, 191, 188, 190, 194, 194, 194, 193, 193, 190, 193, 192, 192,\n       194, 193, 193, 192, 193, 193, 190, 190, 193, 193, 194, 192, 191,\n       188, 187, 186, 185, 185, 183, 182, 178, 175, 175, 172, 168, 166,\n       163, 161, 156, 153, 152, 149, 149, 144, 146, 143, 143, 135, 119,\n       108, 120, 146, 167, 187, 193, 194, 199, 197, 197, 197, 196, 192,\n       188, 190, 191, 192, 187, 187, 189, 190, 188, 186, 186, 188, 187,\n       183, 185, 185, 184, 185, 184, 183, 180, 181, 181, 179, 181, 182,\n       179, 176, 174], dtype=uint8), array([4.51179147])], [array([204, 203, 199, 204, 204, 203, 203, 205, 207, 203, 205, 207, 205,\n       204, 204, 206, 206, 205, 203, 203, 204, 206, 202, 201, 205, 204,\n       204, 203, 203, 203, 198, 198, 196, 198, 197, 195, 194, 192, 192,\n       192, 191, 191, 190, 190, 188, 189, 188, 187, 182, 185, 182, 182,\n       180, 180, 178, 177, 178, 177, 174, 168, 164, 157, 150, 146, 160,\n       171, 189, 200, 202, 205, 205, 203, 205, 205, 202, 199, 195, 196,\n       196, 197, 197, 199, 198, 194, 196, 195, 193, 194, 194, 194, 193,\n       192, 193, 193, 192, 192, 192, 188, 188, 190, 191, 189, 189, 190,\n       190, 188, 186, 189, 192, 192, 189, 191, 191, 193, 191, 192, 191,\n       192, 193, 191], dtype=uint8), array([4.37560143])], [array([206, 205, 207, 205, 201, 201, 200, 199, 199, 201, 197, 196, 196,\n       196, 195, 196, 194, 195, 194, 196, 199, 198, 198, 198, 200, 200,\n       198, 196, 198, 200, 198, 196, 195, 196, 195, 196, 195, 196, 197,\n       194, 194, 195, 192, 193, 198, 193, 194, 193, 194, 192, 192, 191,\n       191, 192, 191, 188, 186, 185, 184, 178, 181, 178, 178, 175, 172,\n       169, 167, 166, 163, 159, 153, 157, 157, 162, 162, 159, 148, 125,\n       116, 129, 150, 168, 187, 195, 196, 198, 196, 192, 195, 197, 198,\n       197, 193, 189, 190, 189, 187, 187, 186, 185, 186, 183, 186, 183,\n       183, 186, 184, 183, 184, 184, 183, 185, 186, 186, 184, 187, 186,\n       184, 188, 187], dtype=uint8), array([3.95002995])], [array([189, 191, 195, 193, 193, 189, 191, 190, 190, 189, 189, 190, 190,\n       192, 189, 187, 193, 191, 187, 185, 188, 188, 189, 188, 190, 188,\n       192, 188, 191, 193, 190, 189, 190, 187, 189, 191, 188, 188, 191,\n       189, 188, 187, 186, 186, 188, 185, 187, 186, 187, 186, 188, 187,\n       187, 188, 187, 187, 184, 181, 176, 177, 175, 171, 170, 166, 163,\n       165, 163, 161, 162, 160, 158, 158, 153, 151, 147, 136, 128, 138,\n       159, 180, 184, 190, 196, 195, 192, 193, 192, 189, 189, 187, 185,\n       181, 181, 180, 178, 173, 170, 168, 165, 163, 164, 166, 166, 163,\n       166, 174, 178, 178, 179, 181, 180, 180, 177, 176, 175, 174, 177,\n       176, 174, 173], dtype=uint8), array([3.53048839])], [array([166, 164, 167, 166, 165, 162, 161, 160, 160, 160, 157, 157, 154,\n       156, 156, 155, 153, 154, 154, 154, 149, 150, 151, 150, 150, 149,\n       147, 146, 147, 148, 147, 148, 145, 144, 145, 147, 150, 156, 159,\n       163, 166, 166, 167, 165, 163, 159, 157, 159, 159, 161, 163, 165,\n       164, 167, 168, 170, 172, 169, 170, 167, 163, 156, 149, 146, 150,\n       166, 181, 191, 195, 194, 193, 194, 194, 192, 193, 194, 194, 195,\n       195, 193, 192, 193, 190, 190, 189, 188, 189, 190, 189, 190, 193,\n       193, 191, 190, 191, 189, 184, 186, 184, 185, 186, 186, 187, 190,\n       192, 191, 190, 188, 183, 185, 181, 176, 170, 161, 155, 161, 169,\n       178, 185, 184], dtype=uint8), array([3.67640104])], [array([184, 185, 187, 186, 183, 184, 186, 183, 183, 185, 183, 183, 183,\n       182, 185, 184, 184, 185, 184, 181, 183, 182, 183, 185, 185, 185,\n       185, 186, 185, 184, 186, 182, 181, 179, 180, 180, 177, 178, 177,\n       175, 175, 175, 171, 164, 164, 161, 161, 156, 150, 149, 145, 139,\n       137, 134, 132, 130, 128, 125, 119, 115, 110, 106, 100,  97,  92,\n        88,  84,  83,  83,  89,  91,  95, 106, 119, 136, 161, 182, 197,\n       204, 204, 206, 208, 205, 204, 203, 204, 202, 200, 199, 196, 195,\n       196, 195, 192, 191, 188, 187, 189, 186, 182, 180, 180, 180, 178,\n       177, 180, 178, 181, 177, 174, 174, 177, 174, 175, 176, 173, 175,\n       179, 177, 176], dtype=uint8), array([8.97995119])], [array([190, 192, 189, 189, 191, 190, 189, 188, 187, 186, 185, 186, 183,\n       183, 183, 187, 184, 182, 185, 186, 184, 182, 183, 183, 184, 181,\n       182, 181, 180, 178, 178, 177, 177, 177, 180, 179, 175, 181, 179,\n       178, 177, 177, 178, 176, 176, 170, 165, 156, 144, 126, 114, 112,\n       119, 134, 148, 155, 158, 156, 159, 161, 164, 167, 168, 167, 169,\n       172, 172, 175, 174, 176, 182, 176, 177, 178, 181, 180, 182, 183,\n       179, 180, 182, 181, 181, 180, 182, 180, 181, 181, 180, 184, 180,\n       179, 181, 180, 179, 179, 182, 182, 180, 181, 182, 182, 181, 178,\n       183, 180, 177, 183, 182, 180, 178, 177, 179, 179, 180, 180, 180,\n       181, 181, 183], dtype=uint8), array([5.35827466])], [array([183, 183, 186, 185, 184, 184, 188, 187, 190, 191, 194, 192, 191,\n       193, 191, 190, 195, 194, 195, 194, 194, 194, 192, 194, 194, 196,\n       195, 194, 191, 194, 196, 195, 195, 195, 192, 189, 184, 181, 183,\n       184, 186, 186, 187, 190, 191, 191, 189, 190, 192, 194, 197, 197,\n       197, 196, 197, 198, 197, 195, 193, 190, 192, 194, 190, 190, 182,\n       183, 183, 177, 174, 160, 144, 133, 135, 137, 132, 121, 115, 117,\n       118, 120, 123, 124, 129, 130, 134, 135, 136, 138, 139, 141, 142,\n       144, 145, 146, 148, 148, 147, 150, 151, 151, 155, 154, 154, 154,\n       154, 154, 154, 157, 157, 158, 155, 156, 157, 156, 158, 159, 158,\n       158, 157, 159], dtype=uint8), array([8.97995119])], [array([153, 152, 155, 156, 158, 158, 160, 159, 163, 164, 163, 162, 164,\n       168, 164, 168, 164, 162, 164, 165, 163, 162, 164, 164, 164, 163,\n       162, 162, 163, 158, 158, 160, 158, 157, 156, 154, 153, 155, 156,\n       155, 153, 151, 153, 153, 153, 158, 149, 130, 121, 129, 142, 154,\n       168, 183, 192, 193, 193, 199, 195, 196, 196, 197, 197, 193, 193,\n       193, 192, 191, 191, 191, 190, 192, 194, 193, 193, 190, 194, 194,\n       194, 193, 194, 194, 193, 190, 188, 191, 187, 186, 190, 191, 192,\n       190, 190, 190, 191, 192, 194, 194, 192, 192, 192, 195, 193, 191,\n       192, 189, 188, 189, 188, 187, 189, 188, 187, 181, 168, 154, 150,\n       158, 170, 181], dtype=uint8), array([5.35827466])], [array([193, 197, 199, 199, 198, 198, 198, 198, 197, 197, 198, 196, 197,\n       198, 200, 197, 197, 197, 197, 200, 199, 195, 197, 197, 195, 194,\n       197, 194, 194, 196, 196, 196, 197, 197, 198, 196, 196, 196, 196,\n       196, 191, 194, 194, 193, 191, 194, 193, 191, 189, 190, 189, 191,\n       192, 196, 194, 192, 186, 189, 188, 187, 187, 192, 189, 189, 188,\n       184, 187, 188, 187, 185, 188, 186, 183, 183, 174, 160, 150, 138,\n       138, 147, 159, 162, 164, 162, 161, 158, 155, 157, 158, 158, 159,\n       157, 155, 155, 156, 156, 155, 155, 156, 154, 154, 154, 156, 155,\n       153, 152, 154, 152, 155, 154, 152, 152, 153, 151, 154, 153, 154,\n       155, 154, 152], dtype=uint8), array([3.76287851])], [array([200, 200, 203, 199, 201, 201, 200, 200, 201, 204, 198, 199, 201,\n       200, 201, 202, 200, 199, 201, 203, 201, 200, 202, 203, 202, 201,\n       198, 195, 192, 191, 194, 193, 195, 195, 193, 192, 192, 191, 190,\n       188, 184, 181, 178, 179, 184, 189, 193, 190, 193, 191, 191, 194,\n       197, 200, 199, 200, 197, 198, 200, 198, 199, 198, 201, 201, 200,\n       202, 203, 206, 204, 202, 202, 202, 199, 198, 190, 188, 187, 188,\n       188, 185, 186, 185, 185, 186, 185, 186, 186, 187, 190, 191, 189,\n       194, 190, 192, 195, 196, 197, 198, 201, 202, 201, 201, 202, 199,\n       200, 202, 203, 200, 200, 200, 198, 202, 203, 203, 202, 201, 202,\n       205, 203, 204], dtype=uint8), array([3.04808728])], [array([198, 199, 198, 200, 203, 205, 205, 202, 198, 200, 202, 204, 201,\n       200, 196, 206, 206, 205, 201, 205, 204, 201, 204, 205, 205, 205,\n       204, 204, 206, 206, 202, 204, 206, 207, 205, 204, 202, 206, 204,\n       202, 205, 204, 204, 204, 204, 207, 206, 205, 206, 206, 205, 204,\n       201, 205, 205, 198, 206, 206, 208, 204, 207, 207, 206, 208, 205,\n       204, 202, 206, 204, 201, 203, 195, 191, 185, 176, 164, 155, 156,\n       161, 168, 174, 176, 178, 177, 179, 175, 177, 177, 180, 182, 181,\n       182, 183, 184, 184, 182, 182, 187, 188, 189, 182, 185, 184, 186,\n       184, 186, 186, 187, 184, 183, 183, 182, 185, 183, 183, 179, 180,\n       180, 176, 177], dtype=uint8), array([3.04562947])], [array([205, 207, 207, 206, 207, 210, 210, 209, 211, 208, 207, 210, 211,\n       207, 206, 207, 203, 205, 204, 205, 206, 208, 207, 208, 207, 207,\n       207, 209, 208, 207, 206, 206, 209, 210, 209, 209, 208, 210, 207,\n       208, 208, 207, 208, 212, 207, 206, 207, 205, 206, 205, 205, 206,\n       206, 203, 207, 209, 208, 206, 206, 206, 204, 205, 206, 203, 202,\n       206, 203, 201, 201, 197, 192, 184, 173, 149, 139, 143, 164, 180,\n       190, 194, 198, 200, 200, 199, 197, 196, 196, 194, 194, 194, 193,\n       192, 191, 190, 186, 188, 188, 186, 186, 186, 185, 183, 183, 185,\n       185, 185, 182, 182, 181, 177, 175, 172, 164, 154, 151, 144, 136,\n       124, 113, 114], dtype=uint8), array([3.06895321])], [array([203, 204, 203, 205, 205, 203, 203, 198, 199, 196, 200, 200, 200,\n       192, 189, 183, 177, 171, 162, 154, 148, 145, 141, 144, 149, 152,\n       150, 148, 149, 153, 161, 168, 172, 176, 180, 181, 186, 188, 188,\n       186, 188, 192, 194, 193, 194, 194, 197, 193, 195, 189, 185, 180,\n       172, 166, 169, 179, 187, 192, 198, 201, 199, 199, 198, 199, 200,\n       201, 198, 197, 199, 200, 201, 204, 202, 203, 201, 202, 206, 203,\n       204, 206, 203, 203, 205, 207, 207, 206, 206, 207, 207, 207, 209,\n       206, 205, 208, 206, 205, 206, 206, 207, 202, 206, 203, 205, 205,\n       204, 202, 200, 201, 199, 198, 198, 196, 193, 194, 193, 190, 186,\n       185, 182, 182], dtype=uint8), array([2.85702873])], [array([182, 182, 183, 184, 185, 185, 182, 182, 182, 183, 184, 185, 184,\n       183, 185, 182, 181, 182, 184, 183, 183, 182, 184, 182, 182, 180,\n       186, 183, 188, 184, 182, 184, 185, 185, 186, 183, 181, 184, 182,\n       183, 184, 183, 187, 184, 185, 184, 184, 185, 184, 182, 181, 181,\n       183, 182, 183, 184, 186, 183, 182, 183, 183, 182, 183, 185, 184,\n       186, 188, 187, 188, 190, 190, 190, 192, 194, 192, 191, 192, 191,\n       190, 185, 169, 153, 145, 141, 146, 153, 155, 156, 157, 155, 154,\n       153, 154, 154, 154, 155, 155, 158, 158, 162, 164, 163, 167, 169,\n       171, 173, 174, 179, 177, 178, 183, 179, 185, 187, 185, 182, 184,\n       184, 182, 187], dtype=uint8), array([4.51179147])], [array([198, 197, 194, 196, 199, 200, 195, 192, 192, 194, 193, 193, 195,\n       192, 188, 186, 181, 182, 184, 184, 179, 178, 178, 173, 171, 168,\n       164, 158, 154, 146, 140, 134, 132, 132, 132, 135, 137, 139, 148,\n       151, 152, 156, 154, 158, 161, 160, 160, 160, 161, 162, 163, 164,\n       166, 168, 170, 166, 165, 163, 160, 147, 132, 127, 127, 128, 139,\n       149, 152, 153, 152, 150, 149, 146, 145, 144, 144, 147, 147, 148,\n       148, 149, 148, 147, 148, 151, 154, 155, 155, 161, 160, 161, 162,\n       165, 166, 164, 162, 165, 171, 171, 172, 172, 173, 173, 173, 175,\n       174, 175, 173, 178, 177, 180, 180, 182, 182, 182, 182, 181, 181,\n       183, 184, 184], dtype=uint8), array([4.37560143])], [array([159, 157, 153, 150, 148, 145, 146, 147, 148, 149, 146, 149, 149,\n       144, 146, 145, 149, 151, 150, 149, 152, 153, 154, 154, 151, 152,\n       154, 154, 155, 157, 158, 159, 160, 159, 160, 161, 163, 163, 164,\n       166, 169, 168, 166, 167, 169, 170, 172, 174, 172, 171, 174, 174,\n       177, 176, 177, 175, 176, 175, 175, 179, 178, 181, 179, 181, 182,\n       183, 185, 185, 185, 189, 190, 187, 188, 192, 193, 192, 192, 190,\n       186, 175, 159, 139, 130, 136, 147, 155, 154, 155, 158, 159, 158,\n       155, 154, 156, 159, 164, 165, 168, 171, 171, 175, 173, 179, 179,\n       180, 183, 185, 189, 189, 190, 189, 190, 188, 191, 192, 190, 191,\n       191, 191, 192], dtype=uint8), array([3.95002995])], [array([175, 177, 177, 178, 180, 184, 184, 184, 184, 186, 188, 189, 190,\n       190, 189, 189, 190, 193, 192, 192, 193, 192, 192, 195, 193, 197,\n       196, 196, 195, 192, 196, 196, 195, 194, 193, 195, 194, 195, 196,\n       198, 197, 195, 196, 196, 198, 196, 194, 196, 198, 196, 194, 196,\n       198, 197, 196, 194, 195, 196, 198, 198, 198, 196, 193, 194, 195,\n       191, 191, 191, 197, 199, 199, 197, 198, 199, 197, 194, 193, 188,\n       180, 168, 163, 167, 173, 178, 177, 176, 176, 176, 173, 172, 174,\n       177, 174, 179, 178, 179, 182, 184, 185, 187, 189, 188, 188, 192,\n       188, 189, 188, 186, 182, 179, 178, 180, 184, 186, 185, 185, 186,\n       186, 183, 180], dtype=uint8), array([3.53048839])], [array([196, 195, 201, 200, 199, 201, 201, 202, 202, 199, 200, 200, 200,\n       201, 200, 204, 203, 197, 202, 201, 198, 195, 194, 194, 197, 197,\n       197, 199, 198, 197, 194, 195, 193, 189, 191, 194, 195, 197, 198,\n       203, 200, 198, 203, 205, 203, 204, 204, 203, 204, 202, 204, 204,\n       206, 204, 200, 201, 197, 199, 195, 191, 186, 179, 171, 160, 152,\n       162, 171, 178, 181, 185, 187, 185, 185, 190, 187, 190, 190, 190,\n       192, 189, 186, 189, 186, 189, 191, 188, 187, 186, 185, 186, 187,\n       188, 189, 188, 185, 177, 172, 173, 177, 180, 185, 186, 188, 188,\n       189, 188, 192, 190, 191, 194, 196, 195, 193, 193, 194, 193, 193,\n       195, 196, 198], dtype=uint8), array([3.67640104])], [array([197, 195, 192, 192, 193, 191, 192, 189, 188, 189, 189, 188, 188,\n       190, 191, 190, 187, 185, 186, 187, 187, 188, 188, 184, 185, 186,\n       185, 185, 188, 188, 184, 186, 185, 186, 186, 185, 184, 183, 182,\n       184, 179, 181, 180, 181, 180, 180, 180, 180, 178, 176, 176, 178,\n       177, 177, 175, 176, 177, 176, 175, 170, 155, 136, 127, 126, 134,\n       149, 162, 165, 169, 173, 173, 173, 176, 179, 180, 179, 181, 182,\n       185, 186, 184, 182, 178, 168, 161, 162, 170, 179, 186, 190, 190,\n       192, 191, 191, 192, 192, 193, 192, 192, 193, 192, 191, 190, 190,\n       194, 192, 194, 194, 196, 196, 194, 194, 195, 196, 199, 195, 195,\n       195, 194, 194], dtype=uint8), array([5.21064103])], [array([196, 195, 196, 197, 197, 197, 197, 197, 199, 202, 199, 198, 200,\n       198, 194, 198, 197, 196, 200, 198, 196, 196, 199, 197, 192, 192,\n       192, 194, 194, 195, 194, 194, 198, 200, 198, 196, 196, 196, 197,\n       195, 193, 195, 195, 195, 192, 192, 189, 186, 184, 180, 165, 142,\n       127, 124, 132, 148, 164, 169, 169, 170, 171, 169, 165, 163, 161,\n       159, 156, 145, 128, 112, 111, 115, 107,  99, 117, 140, 145, 146,\n       151, 159, 163, 164, 171, 167, 170, 167, 166, 163, 165, 171, 176,\n       179, 183, 183, 184, 185, 186, 187, 190, 189, 190, 190, 191, 192,\n       192, 193, 197, 193, 194, 197, 196, 195, 194, 193, 190, 190, 191,\n       190, 189, 194], dtype=uint8), array([7.26221294])], [array([193, 196, 198, 195, 195, 195, 193, 193, 194, 193, 193, 194, 193,\n       196, 198, 199, 196, 196, 198, 197, 196, 198, 201, 195, 195, 195,\n       196, 197, 196, 196, 198, 195, 195, 199, 200, 200, 200, 201, 197,\n       197, 199, 199, 200, 196, 197, 198, 198, 197, 198, 198, 195, 198,\n       197, 200, 199, 200, 198, 200, 200, 205, 205, 206, 204, 209, 208,\n       211, 211, 210, 208, 210, 203, 189, 171, 154, 132, 122, 132, 151,\n       155, 155, 154, 153, 152, 152, 155, 156, 158, 161, 162, 168, 170,\n       171, 174, 178, 180, 183, 187, 187, 189, 191, 194, 195, 196, 198,\n       198, 200, 203, 201, 200, 202, 201, 201, 204, 203, 205, 202, 202,\n       204, 202, 201], dtype=uint8), array([5.93755418])], [array([197, 197, 196, 198, 198, 197, 196, 198, 195, 197, 196, 194, 194,\n       194, 195, 199, 199, 197, 194, 198, 196, 196, 198, 197, 198, 200,\n       202, 198, 200, 199, 199, 200, 202, 202, 200, 201, 204, 201, 200,\n       202, 202, 201, 200, 202, 201, 202, 203, 205, 202, 203, 203, 203,\n       204, 202, 202, 201, 205, 204, 203, 203, 205, 207, 210, 208, 209,\n       211, 211, 214, 211, 212, 206, 195, 182, 168, 147, 135, 155, 162,\n       160, 159, 162, 159, 157, 158, 160, 162, 164, 166, 168, 165, 170,\n       172, 174, 178, 180, 181, 184, 185, 190, 190, 196, 197, 197, 199,\n       201, 200, 201, 201, 201, 208, 205, 204, 206, 203, 205, 204, 202,\n       205, 204, 211], dtype=uint8), array([5.5774322])], [array([210, 210, 213, 210, 211, 212, 209, 207, 208, 208, 211, 208, 210,\n       208, 207, 209, 204, 208, 212, 207, 208, 210, 210, 211, 210, 209,\n       211, 213, 214, 211, 211, 212, 210, 211, 211, 210, 211, 212, 211,\n       209, 212, 213, 208, 210, 210, 206, 207, 204, 204, 206, 204, 204,\n       200, 200, 200, 200, 198, 198, 196, 195, 195, 192, 189, 188, 182,\n       176, 164, 144, 137, 138, 149, 169, 184, 190, 192, 192, 192, 195,\n       197, 199, 201, 201, 200, 203, 204, 205, 205, 206, 202, 203, 204,\n       205, 205, 207, 205, 205, 208, 211, 208, 208, 210, 208, 208, 207,\n       206, 206, 206, 204, 205, 206, 207, 205, 203, 205, 204, 205, 210,\n       209, 209, 206], dtype=uint8), array([4.19787153])], [array([207, 206, 202, 197, 198, 204, 207, 206, 207, 207, 208, 212, 211,\n       208, 213, 210, 210, 210, 210, 210, 211, 209, 212, 211, 209, 210,\n       210, 211, 211, 208, 208, 209, 210, 213, 212, 211, 213, 211, 212,\n       211, 211, 209, 209, 211, 209, 210, 209, 208, 206, 205, 204, 203,\n       202, 203, 205, 203, 204, 201, 201, 203, 204, 206, 206, 207, 203,\n       201, 198, 194, 190, 181, 162, 150, 143, 148, 164, 175, 179, 184,\n       187, 191, 189, 194, 195, 198, 200, 200, 203, 203, 204, 203, 206,\n       211, 211, 212, 210, 213, 212, 212, 213, 212, 212, 213, 214, 212,\n       216, 214, 214, 212, 209, 211, 212, 215, 213, 213, 213, 212, 212,\n       208, 210, 207], dtype=uint8), array([3.7441611])], [array([189, 191, 191, 194, 194, 192, 192, 191, 190, 191, 190, 189, 192,\n       192, 197, 192, 189, 192, 186, 180, 177, 177, 178, 183, 184, 184,\n       184, 185, 188, 192, 193, 191, 190, 191, 192, 192, 192, 192, 191,\n       190, 191, 193, 192, 192, 193, 194, 193, 194, 192, 192, 193, 196,\n       194, 194, 194, 192, 196, 194, 197, 191, 197, 196, 200, 198, 201,\n       202, 202, 204, 201, 199, 195, 183, 167, 146, 128, 133, 152, 162,\n       159, 159, 158, 156, 157, 158, 159, 164, 165, 166, 171, 174, 175,\n       176, 180, 180, 181, 184, 185, 189, 190, 192, 188, 192, 194, 194,\n       196, 195, 194, 192, 194, 193, 195, 194, 194, 196, 195, 195, 196,\n       196, 196, 193], dtype=uint8), array([5.20109506])], [array([181, 179, 178, 177, 177, 178, 179, 180, 180, 179, 180, 181, 183,\n       184, 182, 182, 184, 186, 185, 185, 184, 182, 184, 187, 186, 182,\n       183, 183, 187, 189, 186, 188, 186, 187, 188, 186, 184, 185, 183,\n       186, 183, 185, 185, 182, 185, 184, 186, 185, 185, 185, 184, 184,\n       189, 189, 187, 184, 180, 180, 184, 187, 189, 192, 194, 194, 198,\n       201, 201, 204, 203, 200, 200, 195, 182, 167, 148, 127, 130, 147,\n       156, 154, 153, 150, 149, 149, 150, 152, 154, 153, 156, 157, 162,\n       162, 168, 164, 167, 171, 171, 173, 172, 174, 171, 176, 177, 176,\n       180, 177, 180, 177, 176, 177, 178, 177, 180, 178, 177, 180, 179,\n       173, 172, 174], dtype=uint8), array([4.87914297])], [array([224, 219, 216, 219, 221, 222, 224, 225, 225, 227, 223, 222, 225,\n       223, 221, 221, 222, 223, 222, 220, 220, 221, 226, 223, 223, 222,\n       221, 220, 222, 225, 224, 221, 219, 221, 223, 222, 224, 223, 222,\n       221, 221, 221, 220, 221, 220, 222, 223, 222, 220, 224, 227, 223,\n       220, 218, 219, 222, 223, 223, 220, 221, 221, 220, 221, 219, 220,\n       222, 222, 221, 223, 221, 220, 220, 222, 222, 221, 222, 225, 225,\n       224, 220, 221, 222, 219, 221, 222, 223, 225, 222, 221, 223, 222,\n       222, 224, 222, 222, 221, 221, 221, 220, 220, 222, 222, 227, 222,\n       221, 220, 220, 222, 221, 224, 222, 222, 223, 226, 222, 217, 221,\n       220, 224, 223], dtype=uint8), array([0.])], [array([208, 211, 207, 207, 206, 206, 202, 204, 205, 205, 202, 203, 202,\n       199, 198, 199, 204, 204, 204, 203, 203, 206, 206, 203, 203, 204,\n       204, 212, 203, 206, 205, 207, 206, 208, 209, 208, 205, 208, 208,\n       208, 212, 211, 205, 206, 208, 211, 211, 210, 207, 207, 210, 209,\n       210, 212, 214, 216, 216, 214, 215, 214, 214, 211, 213, 211, 214,\n       209, 198, 177, 160, 162, 172, 166, 148, 137, 138, 144, 143, 140,\n       137, 131, 129, 135, 140, 143, 146, 146, 148, 149, 149, 153, 155,\n       158, 162, 167, 170, 174, 176, 178, 180, 184, 184, 186, 190, 192,\n       194, 194, 199, 202, 204, 203, 203, 207, 210, 208, 207, 209, 211,\n       211, 214, 213], dtype=uint8), array([8.52101685])], [array([202, 204, 202, 200, 206, 205, 204, 203, 201, 202, 204, 205, 207,\n       204, 204, 205, 205, 204, 204, 207, 202, 203, 206, 207, 205, 204,\n       206, 203, 205, 207, 204, 204, 205, 207, 208, 206, 208, 208, 209,\n       207, 205, 206, 208, 208, 209, 209, 209, 209, 214, 210, 209, 207,\n       211, 212, 216, 215, 216, 217, 216, 215, 216, 215, 215, 215, 207,\n       193, 171, 156, 157, 162, 154, 139, 130, 133, 132, 134, 133, 131,\n       131, 132, 134, 136, 136, 138, 138, 140, 144, 149, 152, 153, 158,\n       162, 162, 168, 172, 173, 176, 180, 183, 186, 183, 186, 190, 192,\n       193, 195, 198, 203, 204, 203, 202, 208, 207, 206, 210, 210, 208,\n       209, 211, 213], dtype=uint8), array([8.73503977])], [array([165, 167, 169, 167, 168, 169, 174, 179, 173, 165, 162, 164, 164,\n       167, 178, 187, 195, 201, 204, 203, 205, 207, 206, 206, 205, 204,\n       204, 202, 202, 203, 201, 203, 204, 205, 206, 206, 203, 205, 204,\n       203, 203, 203, 202, 202, 205, 205, 203, 201, 197, 199, 199, 200,\n       196, 197, 193, 193, 190, 190, 190, 192, 191, 187, 187, 186, 186,\n       185, 182, 180, 180, 181, 179, 173, 163, 154, 151, 148, 157, 172,\n       178, 181, 181, 181, 183, 188, 188, 187, 190, 189, 190, 193, 195,\n       198, 196, 194, 196, 198, 197, 200, 197, 198, 199, 199, 201, 203,\n       201, 200, 199, 202, 200, 199, 201, 199, 195, 197, 200, 202, 204,\n       200, 199, 199], dtype=uint8), array([4.59109883])], [array([205, 207, 208, 209, 203, 208, 206, 207, 211, 207, 204, 204, 206,\n       207, 207, 207, 206, 204, 204, 204, 203, 208, 204, 205, 206, 206,\n       205, 204, 208, 201, 203, 203, 201, 201, 202, 198, 201, 197, 196,\n       195, 193, 196, 193, 190, 189, 187, 186, 186, 180, 181, 181, 177,\n       172, 173, 173, 175, 172, 172, 174, 173, 172, 171, 171, 154, 140,\n       146, 164, 180, 191, 201, 207, 205, 205, 204, 204, 205, 205, 203,\n       204, 206, 207, 203, 206, 204, 203, 203, 201, 202, 199, 202, 202,\n       200, 201, 198, 198, 198, 198, 201, 200, 197, 198, 197, 197, 196,\n       193, 195, 190, 194, 193, 191, 192, 190, 189, 190, 190, 188, 189,\n       186, 185, 187], dtype=uint8), array([4.34090199])], [array([202, 202, 201, 201, 202, 201, 202, 204, 201, 201, 200, 201, 200,\n       199, 200, 202, 202, 201, 201, 199, 200, 203, 202, 201, 201, 203,\n       201, 201, 200, 197, 199, 199, 199, 198, 198, 197, 194, 194, 193,\n       192, 193, 190, 192, 192, 188, 185, 185, 183, 180, 181, 179, 176,\n       175, 178, 174, 177, 174, 176, 177, 177, 175, 178, 175, 165, 155,\n       160, 176, 190, 195, 199, 202, 201, 200, 199, 197, 195, 191, 194,\n       194, 190, 190, 193, 194, 191, 191, 190, 189, 190, 190, 187, 192,\n       193, 192, 193, 193, 195, 192, 193, 194, 194, 193, 190, 193, 196,\n       197, 197, 198, 196, 194, 200, 198, 201, 199, 200, 197, 195, 195,\n       191, 192, 192], dtype=uint8), array([4.35067225])], [array([171, 183, 195, 200, 202, 203, 205, 205, 204, 200, 206, 205, 204,\n       203, 201, 204, 203, 201, 202, 202, 201, 199, 199, 202, 203, 201,\n       202, 201, 199, 203, 202, 201, 200, 198, 196, 194, 193, 191, 188,\n       185, 182, 182, 180, 175, 178, 178, 177, 175, 175, 173, 171, 172,\n       170, 169, 170, 172, 172, 174, 174, 173, 169, 151, 149, 159, 174,\n       188, 198, 205, 204, 201, 201, 200, 197, 197, 197, 196, 191, 193,\n       189, 186, 186, 184, 183, 181, 180, 180, 179, 179, 178, 179, 178,\n       179, 172, 165, 160, 162, 172, 186, 195, 199, 197, 197, 197, 196,\n       188, 184, 181, 184, 189, 191, 191, 190, 189, 190, 190, 190, 190,\n       189, 187, 187], dtype=uint8), array([4.18356936])], [array([190, 188, 189, 186, 185, 187, 184, 186, 185, 185, 185, 188, 187,\n       187, 187, 187, 187, 186, 184, 185, 185, 186, 188, 188, 185, 183,\n       184, 188, 188, 185, 184, 187, 187, 186, 187, 187, 185, 188, 190,\n       187, 186, 185, 188, 185, 187, 188, 185, 188, 187, 189, 186, 186,\n       186, 187, 187, 187, 187, 187, 187, 190, 187, 186, 188, 186, 186,\n       186, 187, 184, 187, 184, 184, 180, 169, 159, 154, 154, 152, 156,\n       167, 168, 171, 169, 166, 166, 161, 162, 159, 159, 160, 162, 165,\n       167, 167, 169, 173, 175, 174, 175, 177, 176, 178, 180, 183, 179,\n       184, 185, 186, 183, 187, 185, 186, 187, 186, 186, 186, 186, 187,\n       188, 188, 188], dtype=uint8), array([5.923182])], [array([193, 192, 188, 189, 190, 190, 190, 190, 193, 191, 190, 191, 188,\n       191, 191, 189, 190, 188, 189, 186, 184, 184, 183, 186, 186, 185,\n       186, 188, 191, 188, 179, 168, 157, 145, 145, 157, 170, 181, 182,\n       184, 188, 186, 189, 190, 194, 193, 195, 195, 197, 199, 196, 194,\n       195, 200, 202, 201, 203, 206, 207, 210, 211, 210, 206, 195, 179,\n       167, 167, 159, 140, 122, 114, 112, 107, 105, 107, 112, 114, 117,\n       117, 118, 120, 123, 126, 128, 132, 136, 137, 140, 141, 144, 147,\n       153, 156, 161, 164, 166, 168, 174, 176, 176, 178, 178, 184, 184,\n       185, 187, 188, 189, 188, 189, 194, 191, 196, 195, 194, 194, 196,\n       196, 197, 198], dtype=uint8), array([8.89809448])], [array([186, 187, 187, 186, 188, 185, 187, 183, 182, 184, 181, 180, 180,\n       184, 186, 184, 186, 187, 189, 188, 186, 186, 189, 193, 188, 188,\n       191, 191, 189, 192, 190, 190, 193, 192, 190, 190, 189, 189, 191,\n       190, 189, 186, 186, 187, 187, 188, 187, 189, 189, 188, 185, 184,\n       182, 186, 185, 183, 182, 182, 181, 180, 177, 177, 181, 181, 181,\n       179, 177, 176, 176, 174, 170, 164, 151, 135, 129, 128, 126, 134,\n       152, 166, 171, 169, 171, 174, 173, 173, 176, 177, 179, 180, 182,\n       182, 184, 185, 185, 186, 187, 187, 189, 188, 190, 190, 190, 190,\n       190, 190, 189, 187, 182, 185, 179, 177, 177, 180, 182, 181, 185,\n       187, 190, 192], dtype=uint8), array([4.7800506])], [array([189, 190, 191, 190, 188, 192, 188, 191, 187, 190, 191, 189, 188,\n       189, 192, 191, 192, 188, 187, 188, 188, 190, 191, 193, 190, 189,\n       192, 189, 188, 191, 191, 191, 190, 186, 184, 190, 192, 185, 191,\n       189, 189, 184, 188, 189, 187, 183, 187, 186, 183, 179, 178, 177,\n       179, 175, 173, 173, 171, 169, 169, 167, 166, 166, 166, 163, 160,\n       160, 160, 158, 162, 162, 163, 156, 142, 137, 144, 140, 141, 156,\n       166, 171, 173, 175, 176, 176, 175, 174, 175, 177, 180, 182, 182,\n       183, 183, 182, 182, 182, 184, 188, 185, 180, 185, 184, 186, 188,\n       188, 186, 181, 184, 187, 187, 187, 188, 190, 188, 187, 189, 187,\n       188, 190, 189], dtype=uint8), array([5.29939395])], [array([190, 190, 191, 187, 192, 188, 189, 187, 186, 185, 188, 184, 190,\n       192, 190, 186, 187, 187, 189, 184, 185, 188, 190, 188, 186, 187,\n       182, 187, 185, 187, 184, 186, 183, 188, 187, 186, 188, 185, 188,\n       183, 184, 183, 184, 188, 184, 186, 183, 184, 187, 182, 183, 181,\n       186, 185, 180, 178, 179, 178, 177, 180, 176, 181, 180, 179, 177,\n       177, 176, 174, 174, 170, 172, 169, 161, 150, 148, 143, 146, 153,\n       167, 163, 167, 166, 169, 169, 167, 169, 173, 175, 175, 173, 178,\n       176, 179, 181, 179, 179, 184, 180, 185, 182, 186, 184, 187, 179,\n       183, 186, 187, 184, 187, 187, 190, 184, 188, 183, 187, 187, 187,\n       187, 187, 184], dtype=uint8), array([5.08347615])], [array([237, 232, 230, 234, 234, 233, 232, 232, 232, 235, 229, 236, 230,\n       230, 230, 228, 226, 226, 225, 229, 226, 231, 230, 228, 229, 231,\n       231, 232, 232, 235, 230, 234, 233, 232, 230, 229, 232, 234, 232,\n       232, 228, 230, 229, 226, 223, 222, 220, 217, 217, 210, 205, 175,\n       145, 150, 176, 178, 145, 116, 126, 145, 158, 160, 165, 169, 174,\n       179, 182, 185, 190, 196, 199, 203, 207, 210, 213, 214, 219, 215,\n       221, 226, 225, 226, 227, 226, 224, 229, 229, 230, 231, 230, 230,\n       230, 232, 234, 229, 229, 232, 231, 232, 235, 234, 232, 231, 233,\n       230, 231, 234, 232, 231, 233, 234, 232, 231, 233, 236, 236, 231,\n       231, 232, 232], dtype=uint8), array([8.36581426])], [array([228, 231, 233, 232, 229, 228, 228, 228, 223, 225, 223, 222, 220,\n       222, 223, 219, 218, 214, 211, 209, 208, 205, 199, 184, 179, 182,\n       190, 203, 214, 221, 224, 224, 227, 226, 223, 227, 224, 221, 224,\n       222, 223, 223, 222, 223, 219, 219, 209, 208, 204, 199, 197, 194,\n       189, 182, 180, 173, 169, 166, 170, 179, 183, 180, 164, 138, 115,\n       134, 164, 169, 154, 152, 171, 198, 208, 215, 218, 221, 220, 221,\n       223, 224, 223, 227, 232, 230, 227, 226, 227, 228, 229, 229, 230,\n       229, 231, 229, 226, 228, 232, 233, 235, 234, 228, 229, 229, 230,\n       232, 229, 231, 233, 232, 230, 232, 235, 229, 232, 232, 231, 231,\n       233, 231, 231], dtype=uint8), array([8.89809448])], [array([232, 232, 230, 229, 231, 232, 233, 235, 232, 230, 230, 230, 230,\n       229, 227, 230, 226, 226, 227, 226, 229, 232, 229, 228, 230, 230,\n       229, 226, 232, 230, 229, 231, 229, 231, 227, 231, 231, 229, 230,\n       227, 227, 229, 228, 224, 225, 228, 229, 227, 226, 230, 231, 228,\n       229, 233, 232, 230, 231, 231, 231, 231, 230, 231, 232, 230, 228,\n       229, 229, 227, 226, 221, 216, 202, 177, 166, 164, 154, 173, 196,\n       201, 204, 212, 211, 217, 218, 222, 223, 223, 223, 221, 224, 226,\n       230, 227, 228, 229, 224, 228, 230, 230, 228, 226, 225, 230, 230,\n       230, 231, 230, 231, 229, 230, 230, 229, 228, 228, 226, 226, 226,\n       224, 228, 228], dtype=uint8), array([4.7800506])], [array([228, 230, 230, 230, 230, 230, 233, 232, 232, 232, 232, 232, 232,\n       229, 230, 231, 230, 230, 230, 230, 230, 232, 233, 231, 229, 233,\n       229, 229, 232, 229, 233, 233, 231, 232, 233, 230, 231, 233, 231,\n       229, 229, 229, 230, 228, 230, 232, 231, 232, 230, 227, 232, 232,\n       233, 229, 231, 232, 233, 232, 231, 228, 230, 232, 233, 228, 225,\n       227, 226, 225, 224, 217, 193, 173, 170, 167, 147, 168, 197, 203,\n       202, 213, 213, 214, 218, 216, 217, 221, 222, 223, 225, 227, 227,\n       229, 231, 228, 227, 228, 233, 225, 226, 222, 217, 218, 223, 228,\n       227, 229, 226, 228, 230, 231, 233, 231, 231, 231, 229, 230, 231,\n       231, 232, 232], dtype=uint8), array([5.29939395])], [array([217, 217, 217, 219, 222, 222, 222, 223, 221, 221, 221, 221, 222,\n       222, 223, 225, 224, 222, 222, 222, 221, 223, 224, 224, 223, 223,\n       221, 221, 223, 223, 223, 223, 223, 226, 227, 226, 224, 225, 229,\n       227, 226, 227, 228, 225, 226, 225, 227, 227, 230, 230, 226, 228,\n       230, 228, 226, 226, 229, 228, 227, 225, 230, 228, 225, 226, 227,\n       223, 221, 225, 221, 221, 216, 203, 174, 161, 160, 155, 179, 203,\n       205, 214, 217, 216, 218, 224, 224, 226, 226, 229, 225, 229, 229,\n       231, 226, 231, 229, 232, 234, 234, 232, 233, 230, 227, 230, 229,\n       231, 231, 232, 234, 235, 233, 230, 233, 234, 230, 229, 229, 229,\n       232, 231, 232], dtype=uint8), array([5.08347615])], [array([226, 225, 224, 225, 223, 223, 223, 226, 230, 227, 224, 227, 226,\n       227, 224, 226, 228, 227, 227, 227, 228, 229, 228, 226, 229, 230,\n       230, 229, 231, 227, 231, 227, 225, 229, 230, 229, 228, 226, 228,\n       230, 233, 230, 229, 230, 231, 229, 228, 228, 228, 225, 224, 226,\n       227, 227, 228, 230, 228, 229, 226, 226, 223, 224, 229, 227, 224,\n       223, 220, 220, 217, 212, 201, 182, 169, 170, 170, 183, 199, 203,\n       207, 211, 212, 216, 216, 218, 219, 222, 223, 223, 226, 223, 225,\n       229, 228, 227, 228, 233, 233, 230, 228, 230, 230, 231, 233, 232,\n       233, 230, 228, 227, 229, 230, 224, 228, 229, 228, 226, 226, 226,\n       228, 231, 231], dtype=uint8), array([5.923182])], [array([225, 225, 225, 228, 226, 221, 219, 215, 211, 207, 190, 177, 180,\n       183, 191, 195, 193, 192, 193, 194, 196, 199, 200, 199, 201, 198,\n       202, 205, 203, 204, 206, 209, 212, 212, 213, 216, 219, 216, 217,\n       223, 221, 222, 218, 220, 223, 224, 224, 227, 227, 225, 226, 226,\n       227, 229, 229, 229, 227, 227, 227, 228, 228, 229, 230, 227, 228,\n       228, 227, 228, 230, 224, 213, 198, 186, 175, 170, 179, 191, 195,\n       193, 195, 198, 200, 197, 203, 205, 207, 213, 213, 217, 218, 221,\n       224, 225, 222, 222, 228, 226, 224, 225, 225, 227, 225, 227, 232,\n       230, 228, 231, 232, 228, 228, 230, 228, 225, 226, 229, 227, 228,\n       226, 227, 227], dtype=uint8), array([4.59109883])], [array([220, 220, 219, 220, 223, 222, 221, 219, 225, 224, 222, 226, 227,\n       223, 226, 226, 225, 226, 225, 227, 226, 225, 221, 226, 227, 223,\n       224, 227, 228, 228, 226, 226, 224, 223, 225, 223, 222, 225, 227,\n       223, 223, 224, 223, 223, 223, 225, 223, 225, 224, 225, 226, 229,\n       229, 226, 224, 222, 225, 227, 227, 226, 220, 221, 213, 203, 195,\n       186, 185, 190, 195, 195, 195, 195, 195, 197, 200, 200, 200, 203,\n       204, 206, 208, 211, 212, 215, 218, 218, 216, 215, 214, 218, 218,\n       221, 222, 223, 221, 224, 225, 226, 224, 225, 226, 225, 226, 228,\n       226, 226, 226, 225, 226, 227, 228, 227, 226, 230, 227, 224, 228,\n       223, 226, 229], dtype=uint8), array([4.34090199])], [array([225, 225, 225, 224, 223, 227, 225, 223, 225, 225, 221, 221, 225,\n       226, 224, 224, 224, 226, 224, 227, 226, 223, 221, 221, 221, 220,\n       222, 222, 222, 219, 223, 222, 220, 223, 218, 216, 218, 218, 217,\n       214, 211, 207, 206, 206, 204, 202, 196, 180, 162, 156, 162, 160,\n       136, 113, 119, 136, 146, 149, 148, 150, 150, 153, 160, 164, 165,\n       171, 175, 178, 181, 183, 185, 193, 198, 203, 202, 205, 207, 211,\n       215, 215, 214, 218, 221, 222, 224, 222, 219, 225, 228, 226, 224,\n       223, 224, 228, 227, 220, 221, 225, 228, 225, 224, 224, 226, 224,\n       222, 221, 219, 221, 221, 219, 224, 221, 217, 218, 221, 223, 220,\n       223, 222, 224], dtype=uint8), array([8.52101685])], [array([221, 221, 222, 224, 224, 224, 224, 225, 224, 226, 226, 225, 230,\n       225, 227, 222, 222, 224, 226, 224, 225, 227, 226, 226, 226, 226,\n       226, 230, 224, 224, 226, 226, 225, 226, 229, 227, 225, 223, 223,\n       220, 219, 217, 212, 212, 212, 211, 208, 206, 199, 176, 152, 152,\n       169, 175, 152, 127, 128, 145, 157, 156, 151, 151, 152, 157, 159,\n       161, 165, 169, 170, 178, 180, 184, 186, 191, 191, 191, 198, 200,\n       202, 207, 211, 212, 214, 215, 217, 218, 218, 220, 221, 222, 222,\n       224, 224, 221, 225, 223, 223, 227, 225, 223, 225, 226, 224, 222,\n       221, 225, 225, 226, 225, 226, 226, 225, 224, 227, 226, 229, 221,\n       223, 225, 224], dtype=uint8), array([8.73503977])], [array([225, 223, 224, 224, 222, 223, 223, 225, 227, 223, 223, 225, 222,\n       226, 227, 225, 224, 224, 224, 222, 225, 225, 225, 226, 226, 224,\n       224, 223, 223, 224, 223, 225, 224, 224, 226, 221, 223, 225, 226,\n       224, 226, 224, 225, 224, 225, 225, 224, 226, 226, 226, 227, 226,\n       224, 223, 223, 220, 218, 218, 215, 202, 188, 183, 176, 165, 177,\n       189, 187, 188, 188, 185, 189, 192, 192, 194, 197, 199, 203, 206,\n       209, 212, 213, 216, 217, 219, 219, 224, 232, 223, 225, 226, 224,\n       225, 222, 229, 223, 225, 224, 224, 225, 217, 206, 196, 187, 185,\n       190, 194, 194, 196, 196, 196, 200, 201, 201, 203, 209, 210, 214,\n       216, 217, 213], dtype=uint8), array([4.18356936])], [array([228, 223, 221, 223, 223, 224, 225, 224, 225, 224, 223, 221, 228,\n       224, 224, 224, 226, 225, 224, 223, 228, 229, 227, 227, 222, 219,\n       224, 223, 228, 225, 229, 226, 224, 222, 225, 226, 224, 225, 224,\n       224, 223, 224, 224, 227, 227, 224, 226, 226, 226, 223, 227, 226,\n       225, 224, 226, 227, 225, 226, 225, 227, 228, 226, 218, 210, 198,\n       187, 183, 183, 190, 195, 193, 192, 190, 193, 192, 194, 196, 201,\n       202, 204, 208, 210, 211, 212, 215, 216, 216, 220, 222, 222, 223,\n       225, 224, 224, 225, 228, 227, 227, 226, 228, 227, 227, 224, 226,\n       229, 227, 230, 228, 229, 227, 224, 222, 223, 221, 220, 219, 214,\n       213, 216, 217], dtype=uint8), array([4.35067225])], [array([200, 203, 201, 200, 198, 200, 200, 200, 203, 205, 203, 203, 205,\n       206, 206, 205, 203, 198, 200, 200, 200, 204, 205, 203, 204, 205,\n       204, 201, 202, 203, 205, 208, 206, 204, 208, 203, 203, 206, 206,\n       200, 198, 203, 206, 202, 200, 202, 204, 204, 203, 201, 201, 204,\n       204, 207, 208, 205, 205, 204, 205, 208, 206, 203, 203, 202, 200,\n       203, 205, 204, 202, 201, 202, 199, 199, 200, 201, 197, 199, 198,\n       198, 198, 200, 199, 203, 202, 200, 200, 201, 202, 202, 200, 198,\n       198, 198, 199, 200, 201, 200, 199, 191, 195, 199, 199, 195, 197,\n       198, 198, 196, 196, 198, 201, 201, 197, 199, 199, 197, 196, 195,\n       197, 196, 201], dtype=uint8), array([0.])], [array([213, 214, 218, 214, 213, 214, 216, 214, 211, 211, 210, 208, 214,\n       214, 210, 212, 212, 214, 213, 216, 215, 212, 211, 217, 212, 211,\n       211, 214, 213, 215, 216, 214, 216, 213, 215, 213, 215, 211, 212,\n       213, 212, 208, 212, 210, 210, 211, 212, 213, 213, 211, 208, 213,\n       212, 211, 211, 208, 213, 213, 214, 213, 217, 214, 214, 217, 218,\n       218, 218, 220, 215, 212, 208, 199, 185, 167, 157, 146, 146, 158,\n       173, 177, 180, 179, 179, 177, 178, 180, 179, 178, 180, 183, 186,\n       188, 191, 194, 197, 195, 199, 200, 202, 204, 205, 205, 207, 205,\n       205, 202, 204, 206, 208, 215, 215, 214, 213, 213, 214, 216, 216,\n       216, 214, 214], dtype=uint8), array([4.75818342])], [array([216, 218, 214, 213, 215, 214, 213, 215, 216, 212, 212, 214, 213,\n       211, 213, 212, 213, 213, 214, 216, 212, 211, 216, 214, 214, 208,\n       213, 207, 209, 209, 209, 205, 207, 203, 202, 198, 197, 201, 197,\n       195, 191, 189, 190, 190, 189, 188, 188, 186, 187, 188, 188, 185,\n       184, 184, 188, 191, 189, 185, 178, 173, 172, 180, 192, 200, 207,\n       215, 214, 218, 211, 211, 213, 211, 215, 215, 213, 214, 212, 216,\n       214, 212, 209, 211, 214, 214, 215, 215, 214, 215, 212, 211, 214,\n       213, 213, 212, 210, 209, 209, 208, 205, 205, 207, 203, 205, 205,\n       204, 209, 206, 206, 209, 206, 207, 209, 212, 210, 211, 214, 210,\n       213, 212, 213], dtype=uint8), array([3.84824603])], [array([213, 214, 211, 212, 214, 215, 211, 208, 212, 212, 212, 210, 210,\n       209, 210, 212, 209, 209, 205, 208, 208, 210, 208, 210, 210, 210,\n       209, 209, 208, 203, 209, 209, 206, 204, 203, 209, 205, 203, 202,\n       204, 206, 206, 203, 201, 200, 195, 197, 197, 197, 197, 194, 192,\n       186, 189, 187, 185, 186, 186, 180, 177, 177, 176, 173, 175, 175,\n       173, 174, 174, 171, 162, 151, 147, 151, 157, 169, 180, 189, 197,\n       201, 205, 203, 205, 203, 203, 204, 207, 209, 204, 202, 204, 205,\n       201, 203, 200, 200, 201, 199, 199, 196, 194, 191, 187, 183, 181,\n       181, 182, 182, 188, 191, 196, 198, 201, 202, 202, 202, 203, 205,\n       206, 207, 205], dtype=uint8), array([5.52762087])], [array([211, 212, 211, 210, 210, 210, 212, 212, 212, 212, 212, 212, 213,\n       210, 211, 211, 211, 209, 208, 210, 211, 210, 207, 208, 208, 208,\n       210, 203, 202, 201, 201, 200, 197, 195, 194, 192, 189, 191, 182,\n       182, 180, 179, 176, 182, 172, 169, 170, 167, 164, 166, 166, 167,\n       170, 171, 172, 174, 172, 167, 157, 149, 158, 171, 181, 190, 200,\n       209, 211, 210, 212, 213, 215, 212, 210, 209, 209, 211, 210, 207,\n       208, 209, 213, 213, 209, 209, 207, 210, 208, 204, 206, 206, 204,\n       205, 206, 204, 206, 206, 206, 207, 202, 205, 206, 204, 206, 205,\n       204, 205, 204, 203, 203, 204, 203, 199, 200, 201, 200, 198, 197,\n       198, 198, 195], dtype=uint8), array([5.24173503])], [array([200, 201, 203, 204, 205, 204, 203, 203, 205, 203, 206, 204, 202,\n       201, 201, 199, 198, 199, 199, 197, 199, 199, 196, 193, 193, 192,\n       195, 194, 192, 187, 189, 186, 184, 187, 181, 176, 173, 174, 175,\n       172, 171, 171, 170, 166, 166, 169, 170, 173, 177, 176, 181, 178,\n       182, 179, 175, 175, 170, 165, 165, 175, 192, 200, 203, 205, 204,\n       204, 204, 200, 199, 200, 200, 196, 196, 196, 199, 197, 198, 198,\n       197, 198, 195, 198, 198, 195, 197, 198, 197, 197, 195, 195, 197,\n       195, 195, 196, 193, 195, 196, 195, 195, 194, 196, 194, 194, 193,\n       196, 195, 197, 197, 196, 196, 197, 196, 197, 197, 197, 196, 196,\n       196, 196, 196], dtype=uint8), array([3.48806279])], [array([196, 199, 200, 198, 199, 199, 197, 199, 202, 199, 198, 199, 196,\n       195, 199, 197, 196, 195, 196, 197, 198, 194, 195, 194, 193, 195,\n       198, 198, 198, 199, 194, 194, 196, 197, 199, 199, 197, 196, 198,\n       194, 195, 195, 197, 195, 198, 197, 196, 193, 194, 196, 197, 195,\n       195, 197, 192, 193, 192, 192, 191, 190, 189, 190, 190, 187, 187,\n       187, 188, 187, 190, 187, 187, 186, 186, 177, 166, 154, 144, 140,\n       140, 150, 161, 169, 171, 172, 172, 170, 172, 171, 169, 166, 169,\n       171, 173, 172, 171, 172, 172, 173, 171, 173, 169, 171, 170, 171,\n       172, 170, 168, 169, 169, 170, 167, 169, 165, 167, 167, 164, 166,\n       161, 154, 144], dtype=uint8), array([4.68352392])], [array([197, 195, 198, 196, 197, 199, 197, 196, 194, 197, 200, 198, 196,\n       198, 196, 198, 195, 193, 195, 195, 193, 192, 189, 189, 188, 188,\n       188, 187, 187, 187, 187, 186, 185, 184, 182, 181, 182, 180, 176,\n       169, 157, 149, 143, 142, 147, 154, 164, 173, 176, 175, 174, 175,\n       177, 177, 174, 177, 176, 173, 178, 175, 173, 176, 178, 176, 178,\n       180, 177, 178, 179, 179, 176, 171, 160, 148, 143, 142, 152, 164,\n       176, 186, 189, 188, 192, 193, 192, 192, 194, 196, 197, 197, 198,\n       197, 197, 198, 192, 196, 195, 195, 193, 193, 196, 194, 195, 197,\n       195, 194, 191, 194, 194, 197, 192, 195, 195, 197, 197, 196, 199,\n       200, 193, 193], dtype=uint8), array([4.45399496])], [array([215, 213, 212, 213, 214, 216, 215, 214, 214, 215, 212, 216, 214,\n       217, 219, 215, 213, 212, 214, 217, 219, 216, 217, 216, 212, 215,\n       210, 213, 214, 213, 212, 213, 213, 214, 213, 214, 213, 215, 214,\n       210, 213, 215, 212, 211, 215, 216, 213, 213, 213, 215, 214, 214,\n       215, 210, 210, 211, 212, 210, 211, 212, 214, 214, 212, 211, 213,\n       214, 210, 214, 213, 212, 214, 216, 214, 211, 209, 211, 212, 208,\n       211, 213, 213, 215, 215, 214, 211, 212, 212, 208, 209, 212, 213,\n       213, 211, 212, 212, 211, 215, 214, 211, 212, 213, 212, 211, 209,\n       212, 211, 209, 210, 211, 211, 211, 211, 210, 211, 211, 212, 209,\n       208, 208, 210], dtype=uint8), array([0.])], [array([228, 230, 233, 233, 227, 231, 228, 228, 231, 230, 230, 229, 228,\n       227, 225, 230, 231, 229, 230, 230, 231, 236, 232, 233, 231, 232,\n       229, 228, 228, 232, 231, 230, 231, 230, 229, 228, 227, 229, 228,\n       229, 226, 228, 231, 230, 227, 227, 226, 225, 226, 225, 224, 225,\n       223, 221, 224, 218, 220, 218, 215, 212, 215, 210, 208, 205, 203,\n       187, 167, 151, 145, 141, 132, 125, 124, 140, 154, 167, 172, 175,\n       177, 179, 184, 187, 194, 191, 197, 202, 206, 211, 216, 216, 219,\n       220, 222, 224, 224, 225, 226, 228, 229, 228, 228, 226, 230, 229,\n       229, 230, 224, 228, 229, 230, 233, 230, 230, 229, 228, 228, 229,\n       229, 229, 230], dtype=uint8), array([8.71474618])], [array([232, 232, 230, 229, 231, 229, 227, 230, 232, 229, 229, 230, 231,\n       233, 230, 229, 227, 229, 232, 232, 229, 233, 231, 227, 228, 228,\n       227, 231, 232, 231, 232, 234, 231, 231, 233, 228, 227, 229, 226,\n       226, 226, 224, 227, 227, 227, 232, 229, 227, 230, 227, 226, 226,\n       227, 228, 226, 224, 221, 220, 218, 218, 215, 213, 208, 206, 202,\n       192, 180, 154, 127, 111, 114, 129, 141, 145, 147, 158, 172, 180,\n       186, 187, 192, 191, 194, 197, 200, 205, 209, 209, 214, 212, 215,\n       218, 219, 221, 222, 225, 225, 223, 226, 229, 229, 229, 230, 228,\n       230, 231, 232, 230, 230, 230, 230, 231, 231, 232, 228, 232, 230,\n       230, 230, 230], dtype=uint8), array([9.02551505])], [array([187, 188, 191, 191, 192, 195, 197, 200, 202, 204, 204, 204, 201,\n       205, 209, 208, 208, 211, 214, 212, 210, 215, 218, 218, 216, 220,\n       224, 223, 226, 220, 222, 223, 222, 223, 225, 225, 224, 225, 222,\n       225, 222, 223, 224, 223, 219, 217, 216, 210, 197, 169, 141, 137,\n       137, 128, 125, 136, 152, 156, 157, 163, 168, 173, 177, 185, 190,\n       193, 197, 201, 204, 207, 212, 215, 214, 216, 221, 223, 224, 228,\n       222, 226, 224, 228, 229, 226, 226, 226, 227, 228, 227, 229, 231,\n       228, 225, 230, 230, 230, 230, 226, 230, 230, 231, 229, 225, 228,\n       227, 228, 230, 229, 228, 227, 229, 229, 228, 230, 229, 227, 228,\n       231, 232, 230], dtype=uint8), array([7.32964192])], [array([234, 231, 229, 234, 231, 229, 233, 233, 231, 230, 230, 229, 233,\n       233, 234, 232, 233, 235, 235, 236, 234, 233, 234, 234, 234, 237,\n       231, 232, 236, 231, 233, 232, 233, 231, 229, 232, 231, 226, 225,\n       226, 222, 227, 229, 229, 224, 229, 231, 232, 232, 232, 230, 225,\n       229, 231, 226, 225, 226, 225, 223, 219, 220, 220, 215, 203, 189,\n       175, 164, 165, 170, 177, 188, 194, 199, 204, 205, 211, 215, 216,\n       219, 222, 226, 227, 225, 230, 230, 229, 230, 230, 228, 231, 232,\n       230, 230, 231, 234, 232, 229, 230, 229, 233, 231, 230, 233, 234,\n       232, 233, 235, 232, 232, 231, 233, 235, 231, 234, 233, 231, 229,\n       232, 235, 234], dtype=uint8), array([4.88385177])], [array([228, 229, 227, 227, 226, 226, 226, 225, 229, 230, 229, 233, 229,\n       228, 227, 225, 227, 229, 225, 229, 230, 226, 230, 227, 229, 225,\n       227, 226, 228, 229, 226, 226, 224, 222, 220, 214, 213, 210, 212,\n       210, 214, 218, 219, 225, 223, 223, 222, 219, 218, 220, 213, 212,\n       210, 207, 200, 200, 197, 198, 197, 196, 197, 197, 190, 187, 191,\n       188, 172, 145, 127, 136, 152, 151, 152, 171, 195, 209, 217, 216,\n       216, 220, 221, 222, 221, 226, 223, 224, 224, 226, 227, 230, 228,\n       228, 228, 227, 227, 234, 229, 230, 231, 228, 229, 230, 228, 227,\n       231, 232, 228, 230, 231, 232, 232, 231, 233, 232, 233, 229, 231,\n       231, 230, 231], dtype=uint8), array([6.54541434])], [array([215, 213, 214, 212, 214, 211, 209, 211, 211, 210, 210, 205, 206,\n       201, 197, 193, 184, 169, 159, 155, 163, 175, 183, 193, 201, 201,\n       200, 198, 188, 172, 159, 159, 166, 171, 183, 190, 196, 193, 196,\n       196, 199, 209, 213, 216, 220, 220, 220, 220, 222, 223, 224, 224,\n       224, 224, 224, 224, 220, 219, 217, 213, 212, 212, 209, 208, 205,\n       203, 194, 173, 144, 136, 139, 140, 140, 157, 181, 202, 212, 217,\n       214, 219, 219, 220, 223, 226, 225, 223, 226, 229, 227, 227, 229,\n       230, 231, 231, 232, 229, 233, 231, 234, 230, 231, 232, 231, 234,\n       228, 230, 232, 233, 232, 237, 229, 230, 228, 228, 226, 227, 231,\n       230, 232, 232], dtype=uint8), array([7.03218657])], [array([210, 207, 205, 203, 198, 195, 188, 175, 163, 161, 161, 158, 153,\n       153, 159, 169, 182, 188, 199, 205, 207, 209, 208, 217, 216, 216,\n       215, 217, 218, 221, 220, 223, 226, 225, 226, 226, 227, 227, 231,\n       231, 230, 228, 226, 228, 225, 225, 224, 223, 223, 223, 219, 215,\n       215, 210, 209, 206, 200, 194, 192, 188, 184, 182, 181, 182, 181,\n       168, 147, 138, 145, 157, 158, 156, 172, 194, 206, 211, 215, 216,\n       216, 221, 223, 224, 228, 225, 225, 227, 227, 228, 231, 231, 232,\n       235, 232, 232, 230, 233, 230, 230, 234, 232, 232, 234, 231, 232,\n       233, 235, 236, 231, 227, 231, 232, 232, 233, 232, 229, 234, 232,\n       230, 228, 230], dtype=uint8), array([6.38074043])], [array([218, 220, 220, 223, 222, 222, 222, 220, 224, 226, 225, 224, 226,\n       227, 226, 225, 222, 229, 225, 227, 226, 226, 227, 226, 228, 227,\n       225, 223, 221, 218, 221, 221, 221, 225, 227, 230, 228, 230, 230,\n       230, 229, 228, 224, 225, 224, 225, 227, 225, 227, 222, 221, 225,\n       227, 222, 222, 218, 218, 218, 218, 218, 217, 216, 216, 216, 220,\n       218, 215, 213, 215, 212, 209, 206, 200, 184, 164, 157, 161, 166,\n       176, 192, 208, 217, 219, 222, 223, 229, 230, 228, 224, 229, 229,\n       227, 228, 229, 227, 226, 230, 233, 230, 230, 231, 231, 234, 233,\n       231, 229, 232, 233, 233, 233, 231, 230, 232, 234, 233, 233, 233,\n       233, 232, 231], dtype=uint8), array([5.54238319])], [array([233, 230, 232, 233, 233, 233, 234, 233, 232, 231, 231, 231, 232,\n       233, 227, 228, 228, 229, 230, 229, 229, 231, 233, 231, 229, 229,\n       227, 226, 224, 225, 222, 224, 227, 223, 225, 223, 215, 217, 212,\n       210, 209, 207, 206, 202, 198, 199, 208, 209, 211, 214, 215, 218,\n       219, 223, 223, 228, 227, 224, 226, 225, 222, 220, 222, 223, 222,\n       219, 218, 216, 212, 208, 210, 209, 202, 198, 195, 187, 179, 178,\n       183, 195, 209, 220, 225, 224, 225, 227, 227, 228, 227, 228, 230,\n       227, 226, 228, 228, 227, 229, 226, 221, 221, 220, 217, 219, 221,\n       218, 217, 218, 217, 217, 219, 219, 226, 225, 230, 227, 231, 232,\n       231, 229, 227], dtype=uint8), array([4.58639866])], [array([234, 236, 234, 236, 232, 234, 235, 233, 234, 230, 234, 235, 238,\n       240, 238, 235, 235, 236, 233, 231, 231, 230, 230, 230, 230, 230,\n       230, 231, 233, 234, 233, 233, 231, 235, 232, 232, 233, 233, 235,\n       228, 233, 232, 234, 233, 231, 232, 230, 229, 227, 228, 227, 223,\n       223, 218, 206, 193, 183, 164, 150, 151, 166, 179, 187, 190, 191,\n       191, 194, 194, 198, 204, 209, 212, 217, 217, 219, 224, 229, 228,\n       229, 233, 233, 234, 238, 237, 234, 235, 238, 235, 235, 236, 230,\n       235, 238, 237, 238, 238, 235, 238, 238, 239, 234, 233, 232, 235,\n       237, 235, 235, 235, 236, 235, 233, 234, 235, 233, 232, 234, 230,\n       235, 234, 234], dtype=uint8), array([5.4984222])], [array([207, 206, 201, 195, 185, 175, 164, 160, 157, 159, 156, 164, 168,\n       169, 173, 179, 191, 198, 207, 212, 212, 213, 217, 218, 221, 219,\n       221, 222, 221, 225, 224, 224, 222, 224, 222, 223, 226, 226, 223,\n       228, 226, 228, 223, 223, 227, 225, 224, 227, 226, 222, 224, 225,\n       224, 223, 224, 223, 223, 221, 224, 222, 222, 222, 222, 218, 213,\n       206, 191, 176, 150, 145, 140, 135, 128, 130, 142, 152, 160, 166,\n       167, 167, 175, 180, 183, 189, 191, 195, 201, 204, 205, 210, 212,\n       214, 219, 222, 222, 225, 227, 231, 228, 227, 229, 231, 231, 227,\n       228, 227, 227, 231, 228, 230, 231, 232, 232, 234, 231, 231, 231,\n       228, 232, 232], dtype=uint8), array([8.81468908])], [array([233, 230, 229, 230, 230, 231, 230, 232, 233, 231, 230, 230, 231,\n       230, 229, 230, 229, 229, 229, 228, 233, 234, 229, 227, 231, 233,\n       233, 232, 230, 231, 232, 231, 230, 232, 233, 231, 230, 230, 229,\n       227, 231, 232, 236, 234, 227, 228, 231, 231, 231, 228, 225, 229,\n       228, 227, 226, 225, 226, 225, 226, 224, 223, 226, 224, 223, 219,\n       219, 218, 217, 214, 213, 209, 210, 205, 194, 171, 137, 126, 126,\n       136, 160, 187, 204, 209, 215, 219, 224, 223, 223, 224, 225, 223,\n       231, 229, 229, 229, 227, 227, 230, 231, 232, 232, 232, 230, 228,\n       236, 228, 228, 230, 234, 234, 230, 231, 230, 230, 231, 229, 227,\n       228, 230, 231], dtype=uint8), array([5.09065576])], [array([202, 201, 204, 203, 203, 202, 200, 203, 203, 202, 201, 203, 204,\n       203, 202, 199, 200, 201, 202, 202, 201, 203, 204, 204, 202, 203,\n       204, 203, 205, 205, 204, 205, 200, 204, 203, 205, 205, 204, 204,\n       204, 205, 204, 203, 205, 202, 203, 205, 205, 207, 204, 204, 206,\n       203, 203, 205, 204, 202, 205, 208, 206, 202, 205, 204, 204, 207,\n       207, 208, 205, 206, 206, 211, 209, 208, 209, 210, 207, 206, 205,\n       206, 208, 210, 208, 209, 208, 208, 209, 209, 207, 206, 203, 205,\n       203, 203, 205, 204, 203, 209, 207, 208, 209, 209, 205, 205, 206,\n       207, 206, 205, 203, 205, 208, 209, 205, 206, 205, 206, 206, 208,\n       207, 209, 211], dtype=uint8), array([0.])], [array([228, 226, 223, 224, 226, 224, 226, 224, 221, 225, 225, 225, 226,\n       227, 223, 225, 231, 226, 223, 220, 224, 225, 226, 226, 225, 224,\n       227, 224, 225, 225, 227, 227, 226, 226, 226, 225, 224, 227, 224,\n       224, 225, 222, 225, 223, 223, 223, 226, 228, 228, 229, 228, 228,\n       227, 226, 224, 224, 224, 226, 226, 225, 221, 221, 220, 209, 194,\n       174, 158, 147, 141, 151, 167, 179, 185, 185, 188, 191, 192, 196,\n       197, 197, 200, 207, 213, 214, 216, 214, 217, 217, 219, 222, 221,\n       221, 222, 222, 228, 225, 225, 226, 226, 222, 225, 225, 227, 226,\n       223, 225, 224, 225, 223, 223, 222, 220, 220, 219, 217, 215, 208,\n       199, 194, 187], dtype=uint8), array([4.42544194])], [array([220, 221, 221, 221, 224, 224, 226, 225, 223, 223, 225, 225, 223,\n       225, 225, 227, 225, 225, 226, 227, 226, 224, 225, 224, 227, 228,\n       226, 224, 226, 224, 223, 225, 225, 228, 229, 229, 229, 228, 227,\n       227, 229, 224, 226, 224, 223, 219, 210, 198, 188, 181, 178, 176,\n       176, 185, 195, 198, 203, 206, 211, 215, 216, 217, 221, 224, 226,\n       225, 224, 221, 221, 224, 220, 213, 202, 184, 169, 158, 159, 171,\n       183, 188, 189, 188, 191, 192, 195, 197, 196, 199, 205, 204, 209,\n       210, 216, 214, 214, 217, 215, 219, 220, 224, 220, 222, 222, 222,\n       224, 224, 221, 225, 228, 228, 228, 225, 225, 226, 224, 224, 225,\n       227, 225, 224], dtype=uint8), array([4.45399496])], [array([189, 195, 201, 205, 201, 204, 203, 203, 204, 206, 207, 207, 206,\n       208, 211, 208, 209, 210, 212, 214, 215, 216, 219, 215, 215, 217,\n       218, 220, 221, 217, 220, 223, 220, 219, 217, 220, 223, 220, 220,\n       223, 223, 225, 222, 225, 225, 223, 222, 223, 226, 227, 224, 224,\n       224, 227, 226, 224, 226, 226, 224, 225, 228, 228, 224, 222, 225,\n       223, 224, 226, 226, 226, 224, 224, 223, 221, 219, 211, 193, 172,\n       157, 144, 150, 170, 184, 189, 191, 194, 196, 199, 202, 206, 208,\n       209, 211, 213, 215, 215, 216, 218, 219, 222, 223, 224, 223, 223,\n       226, 227, 226, 225, 226, 226, 226, 228, 228, 225, 220, 209, 193,\n       179, 163, 148], dtype=uint8), array([4.68352392])], [array([224, 226, 225, 224, 224, 225, 224, 222, 224, 223, 222, 225, 224,\n       223, 224, 225, 225, 223, 226, 224, 222, 220, 221, 221, 226, 224,\n       224, 221, 225, 223, 223, 222, 220, 217, 219, 221, 225, 223, 225,\n       225, 228, 228, 227, 225, 225, 223, 223, 222, 219, 218, 217, 212,\n       201, 190, 178, 171, 174, 185, 195, 202, 203, 203, 207, 206, 203,\n       204, 204, 203, 204, 202, 206, 210, 211, 213, 211, 209, 211, 211,\n       212, 217, 219, 222, 219, 222, 218, 221, 219, 218, 219, 222, 224,\n       222, 222, 220, 219, 225, 228, 227, 225, 224, 225, 225, 225, 225,\n       225, 224, 226, 226, 224, 223, 225, 225, 225, 226, 226, 225, 224,\n       223, 227, 227], dtype=uint8), array([3.48806279])], [array([206, 207, 207, 210, 211, 213, 218, 218, 217, 219, 220, 220, 223,\n       220, 220, 220, 222, 224, 223, 220, 224, 226, 224, 223, 225, 224,\n       222, 222, 221, 226, 224, 225, 225, 225, 223, 224, 227, 226, 225,\n       224, 226, 226, 224, 224, 223, 224, 222, 221, 224, 223, 224, 224,\n       225, 225, 225, 224, 224, 225, 227, 224, 225, 225, 224, 225, 224,\n       223, 223, 230, 226, 227, 224, 222, 216, 200, 177, 163, 154, 142,\n       142, 163, 178, 180, 181, 180, 180, 183, 186, 190, 192, 196, 201,\n       204, 208, 208, 211, 210, 212, 211, 213, 215, 217, 221, 223, 225,\n       226, 225, 223, 225, 225, 227, 224, 225, 224, 222, 227, 225, 227,\n       227, 226, 225], dtype=uint8), array([5.52762087])], [array([222, 222, 222, 223, 223, 223, 225, 224, 223, 222, 221, 222, 221,\n       222, 225, 225, 223, 221, 222, 223, 222, 222, 222, 223, 226, 226,\n       224, 224, 223, 223, 224, 225, 223, 221, 223, 221, 220, 223, 223,\n       220, 216, 205, 189, 179, 181, 189, 203, 213, 217, 219, 222, 223,\n       222, 221, 219, 211, 199, 182, 170, 163, 153, 146, 151, 162, 168,\n       168, 168, 168, 168, 169, 172, 175, 179, 184, 190, 195, 198, 199,\n       201, 203, 206, 208, 211, 210, 213, 216, 216, 218, 218, 219, 220,\n       220, 220, 218, 219, 223, 220, 219, 220, 222, 222, 222, 222, 220,\n       223, 224, 222, 223, 224, 227, 225, 223, 223, 225, 221, 226, 225,\n       223, 223, 224], dtype=uint8), array([5.24173503])], [array([223, 225, 223, 221, 220, 222, 223, 224, 220, 222, 222, 223, 223,\n       220, 219, 219, 221, 223, 221, 220, 217, 225, 225, 220, 216, 208,\n       204, 199, 199, 201, 208, 212, 215, 219, 222, 220, 221, 221, 220,\n       218, 220, 218, 220, 221, 221, 222, 223, 218, 218, 218, 219, 215,\n       216, 214, 214, 213, 214, 211, 208, 206, 204, 196, 196, 197, 191,\n       188, 186, 186, 185, 182, 184, 179, 177, 168, 154, 149, 157, 160,\n       174, 192, 204, 212, 215, 220, 223, 220, 219, 220, 219, 220, 222,\n       220, 218, 218, 219, 217, 218, 221, 219, 218, 220, 215, 222, 224,\n       221, 221, 221, 221, 222, 224, 226, 223, 222, 227, 222, 223, 221,\n       222, 225, 218], dtype=uint8), array([4.75818342])], [array([215, 214, 216, 219, 219, 219, 218, 217, 218, 216, 216, 218, 217,\n       217, 220, 220, 216, 214, 216, 218, 218, 217, 218, 217, 221, 221,\n       222, 221, 219, 221, 217, 217, 218, 224, 216, 216, 217, 216, 222,\n       217, 219, 217, 220, 220, 219, 222, 221, 220, 223, 223, 220, 223,\n       223, 223, 220, 219, 215, 204, 189, 176, 170, 172, 178, 184, 186,\n       185, 183, 183, 184, 183, 183, 183, 186, 192, 194, 197, 202, 206,\n       209, 211, 212, 210, 211, 214, 217, 219, 220, 216, 217, 220, 222,\n       221, 220, 224, 219, 221, 223, 222, 224, 222, 219, 225, 221, 224,\n       221, 220, 220, 220, 219, 221, 224, 221, 214, 214, 212, 210, 207,\n       205, 206, 207], dtype=uint8), array([3.84824603])], [array([215, 213, 212, 211, 213, 215, 213, 215, 215, 213, 212, 214, 212,\n       209, 207, 204, 210, 209, 212, 211, 209, 212, 207, 209, 212, 212,\n       210, 211, 211, 212, 211, 211, 211, 211, 213, 213, 212, 213, 210,\n       213, 213, 212, 215, 212, 215, 217, 216, 215, 215, 217, 215, 215,\n       215, 218, 219, 219, 218, 216, 216, 215, 212, 207, 204, 193, 183,\n       177, 169, 159, 149, 144, 150, 157, 157, 152, 150, 149, 150, 149,\n       151, 153, 160, 161, 164, 167, 171, 175, 177, 182, 184, 188, 191,\n       191, 196, 203, 203, 205, 207, 210, 211, 209, 213, 214, 213, 214,\n       215, 214, 216, 216, 215, 215, 216, 217, 216, 220, 216, 218, 218,\n       220, 218, 220], dtype=uint8), array([6.3266849])], [array([172, 176, 180, 183, 183, 183, 189, 189, 190, 190, 192, 194, 192,\n       192, 194, 196, 197, 199, 197, 199, 202, 206, 206, 207, 207, 208,\n       210, 212, 212, 213, 213, 212, 213, 211, 209, 208, 212, 212, 214,\n       216, 215, 216, 215, 214, 214, 215, 215, 213, 216, 216, 218, 214,\n       212, 208, 209, 204, 198, 189, 173, 171, 172, 180, 190, 195, 195,\n       195, 194, 191, 191, 187, 190, 189, 173, 153, 138, 132, 125, 119,\n       129, 146, 159, 166, 169, 171, 175, 177, 181, 185, 189, 191, 191,\n       195, 199, 202, 204, 206, 206, 209, 209, 207, 210, 212, 214, 214,\n       214, 216, 218, 215, 218, 218, 217, 224, 218, 220, 219, 216, 217,\n       217, 220, 215], dtype=uint8), array([5.48232787])], [array([174, 177, 174, 178, 179, 183, 181, 182, 183, 186, 184, 186, 186,\n       187, 188, 192, 190, 196, 193, 197, 191, 196, 201, 197, 200, 199,\n       203, 203, 199, 201, 206, 203, 203, 208, 203, 204, 200, 199, 199,\n       207, 207, 203, 211, 210, 208, 211, 204, 207, 208, 209, 208, 209,\n       213, 208, 212, 208, 213, 209, 211, 207, 210, 209, 211, 210, 210,\n       214, 212, 212, 214, 212, 220, 220, 215, 218, 210, 201, 184, 163,\n       151, 147, 159, 168, 172, 170, 173, 169, 167, 169, 168, 170, 176,\n       177, 178, 179, 179, 188, 187, 188, 195, 191, 197, 197, 201, 203,\n       205, 207, 207, 205, 212, 210, 211, 211, 214, 215, 214, 211, 213,\n       213, 216, 218], dtype=uint8), array([4.22418291])], [array([224, 227, 224, 224, 226, 226, 227, 228, 227, 226, 222, 226, 227,\n       230, 227, 226, 226, 225, 222, 224, 224, 222, 226, 223, 221, 225,\n       227, 225, 225, 225, 223, 227, 226, 227, 225, 222, 223, 226, 224,\n       226, 227, 224, 228, 228, 227, 227, 226, 228, 228, 224, 226, 223,\n       225, 226, 224, 227, 225, 225, 227, 228, 227, 228, 227, 226, 226,\n       223, 225, 225, 225, 228, 228, 227, 227, 226, 224, 226, 221, 223,\n       225, 228, 226, 224, 225, 228, 227, 225, 227, 228, 227, 226, 229,\n       227, 226, 226, 233, 228, 228, 228, 227, 227, 228, 226, 225, 228,\n       226, 225, 227, 225, 222, 222, 227, 226, 226, 228, 227, 224, 225,\n       227, 229, 226], dtype=uint8), array([0.])], [array([221, 223, 223, 222, 222, 221, 221, 221, 222, 223, 222, 224, 222,\n       222, 220, 220, 224, 218, 221, 222, 219, 218, 220, 218, 221, 222,\n       219, 220, 225, 225, 221, 220, 223, 220, 221, 220, 224, 224, 223,\n       222, 221, 223, 223, 219, 219, 221, 224, 224, 224, 223, 224, 221,\n       223, 221, 224, 225, 225, 224, 222, 227, 225, 225, 223, 222, 222,\n       218, 212, 197, 184, 172, 170, 177, 181, 187, 187, 184, 186, 187,\n       189, 191, 194, 197, 198, 202, 207, 207, 209, 210, 212, 214, 213,\n       219, 215, 217, 222, 222, 218, 219, 220, 222, 222, 219, 222, 225,\n       225, 222, 223, 223, 223, 226, 225, 224, 222, 222, 225, 223, 226,\n       223, 224, 225], dtype=uint8), array([3.71157107])], [array([223, 223, 222, 225, 224, 222, 220, 221, 221, 219, 222, 224, 222,\n       224, 220, 222, 224, 223, 220, 222, 221, 222, 221, 221, 222, 222,\n       225, 223, 223, 221, 220, 221, 224, 222, 221, 224, 216, 217, 218,\n       216, 210, 212, 206, 210, 210, 210, 211, 212, 217, 220, 219, 218,\n       220, 220, 215, 220, 221, 223, 221, 220, 222, 224, 217, 217, 215,\n       212, 213, 212, 211, 207, 201, 189, 171, 154, 151, 149, 156, 173,\n       183, 188, 189, 192, 194, 193, 198, 200, 201, 205, 208, 210, 213,\n       217, 217, 217, 220, 220, 220, 218, 222, 221, 220, 222, 223, 224,\n       225, 222, 221, 220, 224, 223, 224, 225, 221, 221, 224, 226, 220,\n       220, 220, 223], dtype=uint8), array([4.08382213])], [array([226, 224, 226, 225, 221, 224, 224, 223, 221, 222, 222, 225, 226,\n       224, 224, 225, 223, 223, 225, 224, 224, 222, 222, 221, 222, 223,\n       224, 224, 225, 222, 220, 219, 219, 222, 224, 225, 219, 222, 219,\n       220, 219, 216, 216, 211, 208, 204, 203, 195, 175, 162, 154, 162,\n       181, 202, 213, 215, 217, 220, 222, 225, 223, 222, 224, 227, 227,\n       228, 224, 222, 224, 224, 224, 223, 223, 221, 222, 223, 221, 223,\n       227, 225, 227, 228, 227, 225, 225, 226, 226, 226, 226, 228, 227,\n       225, 224, 224, 227, 224, 225, 222, 223, 222, 222, 223, 223, 224,\n       220, 217, 221, 220, 217, 214, 210, 210, 207, 203, 193, 185, 175,\n       170, 171, 173], dtype=uint8), array([3.69767209])], [array([217, 216, 214, 217, 214, 215, 217, 218, 215, 217, 216, 217, 220,\n       217, 222, 218, 218, 220, 218, 211, 200, 190, 182, 175, 177, 182,\n       185, 185, 182, 180, 173, 168, 164, 162, 160, 158, 158, 155, 154,\n       154, 154, 155, 161, 169, 172, 176, 185, 190, 186, 191, 191, 190,\n       193, 194, 192, 192, 198, 201, 197, 202, 204, 203, 206, 209, 211,\n       211, 209, 209, 208, 204, 196, 180, 165, 155, 154, 162, 175, 172,\n       174, 175, 173, 173, 170, 170, 174, 174, 181, 179, 183, 183, 186,\n       188, 192, 194, 195, 196, 202, 203, 205, 206, 207, 206, 211, 211,\n       212, 212, 215, 212, 215, 217, 215, 217, 215, 217, 217, 219, 217,\n       214, 218, 221], dtype=uint8), array([4.18255064])], [array([221, 220, 222, 225, 222, 222, 223, 224, 223, 223, 228, 225, 222,\n       220, 223, 224, 223, 222, 221, 223, 225, 223, 221, 221, 221, 221,\n       221, 222, 218, 221, 217, 222, 221, 222, 220, 221, 220, 221, 219,\n       219, 218, 221, 218, 212, 214, 216, 214, 213, 211, 208, 206, 204,\n       203, 201, 196, 196, 193, 189, 187, 181, 182, 181, 179, 174, 176,\n       177, 180, 180, 162, 137, 142, 163, 172, 156, 141, 156, 184, 196,\n       197, 199, 200, 208, 207, 208, 210, 211, 213, 215, 215, 220, 219,\n       217, 222, 218, 219, 225, 222, 223, 224, 221, 221, 221, 222, 222,\n       221, 216, 222, 221, 221, 221, 220, 222, 222, 219, 218, 218, 218,\n       220, 223, 223], dtype=uint8), array([9.01671984])], [array([192, 193, 191, 191, 193, 192, 195, 193, 194, 193, 195, 195, 194,\n       194, 192, 191, 193, 191, 190, 192, 192, 190, 191, 190, 192, 188,\n       186, 187, 185, 187, 188, 185, 183, 186, 188, 185, 181, 185, 186,\n       187, 185, 187, 185, 185, 180, 178, 164, 153, 145, 146, 147, 151,\n       156, 162, 168, 167, 171, 175, 176, 175, 177, 177, 171, 160, 154,\n       159, 161, 154, 168, 186, 200, 210, 211, 211, 214, 216, 217, 218,\n       217, 218, 215, 215, 217, 217, 220, 218, 217, 222, 219, 214, 214,\n       214, 216, 217, 215, 214, 214, 217, 213, 213, 216, 215, 215, 216,\n       215, 216, 216, 214, 216, 216, 215, 216, 217, 216, 214, 214, 215,\n       215, 215, 214], dtype=uint8), array([6.47364817])], [array([217, 216, 215, 216, 215, 214, 214, 213, 216, 216, 215, 213, 214,\n       219, 216, 218, 214, 216, 217, 215, 214, 215, 214, 219, 215, 213,\n       215, 215, 215, 214, 214, 218, 217, 218, 213, 212, 213, 212, 217,\n       216, 216, 215, 216, 216, 216, 217, 216, 218, 215, 216, 218, 217,\n       218, 214, 219, 217, 220, 220, 220, 219, 217, 220, 221, 221, 218,\n       219, 220, 221, 218, 215, 209, 193, 176, 169, 157, 167, 181, 184,\n       184, 183, 185, 185, 185, 189, 189, 188, 189, 193, 193, 196, 196,\n       198, 200, 199, 200, 207, 203, 208, 208, 209, 210, 213, 214, 214,\n       216, 218, 216, 215, 213, 214, 215, 213, 217, 218, 215, 217, 217,\n       216, 216, 219], dtype=uint8), array([4.51710674])], [array([228, 223, 226, 230, 223, 223, 227, 224, 228, 225, 227, 226, 226,\n       224, 222, 222, 223, 225, 224, 222, 222, 222, 220, 222, 221, 221,\n       223, 224, 223, 223, 222, 222, 224, 224, 230, 224, 223, 223, 223,\n       224, 228, 225, 225, 223, 224, 222, 226, 227, 224, 224, 225, 224,\n       223, 224, 225, 225, 224, 226, 227, 226, 227, 226, 224, 223, 226,\n       226, 225, 226, 227, 227, 224, 222, 220, 211, 202, 193, 192, 202,\n       204, 205, 206, 207, 209, 210, 212, 215, 217, 217, 216, 218, 218,\n       221, 222, 221, 218, 223, 219, 221, 224, 223, 223, 225, 223, 224,\n       224, 225, 225, 225, 224, 225, 225, 221, 222, 224, 224, 224, 222,\n       223, 223, 224], dtype=uint8), array([4.88037655])], [array([228, 229, 225, 224, 227, 224, 225, 226, 224, 225, 224, 223, 225,\n       225, 225, 223, 224, 224, 225, 225, 223, 225, 224, 222, 224, 223,\n       223, 220, 222, 225, 223, 221, 222, 224, 223, 224, 226, 226, 224,\n       224, 226, 224, 224, 222, 218, 221, 223, 221, 222, 221, 221, 222,\n       221, 221, 219, 221, 222, 221, 218, 217, 217, 211, 214, 214, 213,\n       215, 216, 215, 214, 217, 219, 220, 222, 221, 217, 216, 213, 213,\n       215, 215, 219, 218, 218, 220, 220, 219, 220, 217, 218, 210, 210,\n       213, 217, 222, 222, 223, 221, 224, 224, 219, 223, 221, 222, 219,\n       217, 218, 221, 223, 225, 222, 222, 224, 226, 223, 221, 220, 221,\n       221, 221, 217], dtype=uint8), array([4.75318777])], [array([221, 220, 221, 219, 221, 222, 221, 225, 223, 223, 224, 224, 223,\n       221, 218, 219, 218, 217, 218, 216, 215, 219, 215, 213, 210, 213,\n       210, 207, 204, 201, 199, 197, 197, 195, 193, 192, 188, 184, 184,\n       182, 182, 179, 179, 178, 182, 182, 181, 176, 159, 146, 150, 169,\n       187, 206, 216, 216, 214, 219, 216, 217, 220, 222, 222, 220, 218,\n       220, 222, 221, 223, 221, 223, 224, 224, 223, 223, 221, 221, 219,\n       218, 222, 219, 217, 223, 222, 221, 219, 223, 221, 219, 219, 222,\n       219, 221, 222, 221, 220, 221, 221, 220, 218, 220, 219, 219, 218,\n       222, 224, 219, 216, 220, 217, 219, 219, 213, 217, 218, 224, 221,\n       219, 219, 219], dtype=uint8), array([4.67930649])], [array([221, 220, 220, 222, 221, 220, 221, 219, 221, 219, 222, 220, 223,\n       223, 219, 221, 223, 224, 219, 221, 223, 219, 224, 222, 219, 221,\n       219, 220, 220, 218, 218, 218, 216, 219, 221, 220, 219, 216, 215,\n       216, 216, 219, 219, 217, 218, 217, 214, 219, 220, 217, 218, 218,\n       216, 215, 213, 214, 211, 211, 207, 209, 208, 207, 206, 206, 202,\n       200, 197, 188, 179, 175, 183, 193, 200, 203, 201, 201, 203, 206,\n       206, 209, 208, 208, 210, 212, 213, 215, 217, 214, 216, 219, 218,\n       219, 221, 219, 220, 220, 217, 219, 220, 222, 222, 221, 223, 219,\n       221, 225, 224, 223, 220, 220, 222, 223, 222, 221, 221, 221, 220,\n       222, 220, 223], dtype=uint8), array([3.66342182])], [array([197, 195, 200, 199, 196, 196, 198, 198, 199, 198, 198, 197, 198,\n       199, 199, 198, 198, 194, 194, 197, 198, 197, 196, 198, 200, 198,\n       198, 195, 195, 199, 198, 196, 198, 197, 196, 194, 195, 195, 198,\n       199, 195, 198, 197, 197, 199, 196, 197, 196, 197, 197, 197, 201,\n       199, 194, 196, 195, 196, 194, 194, 195, 194, 194, 193, 191, 191,\n       189, 187, 183, 182, 178, 169, 150, 131, 128, 135, 127, 103,  87,\n        93, 105, 102, 102, 107, 112, 118, 121, 123, 125, 126, 130, 137,\n       139, 143, 148, 150, 151, 154, 158, 159, 162, 164, 166, 169, 171,\n       174, 176, 179, 181, 183, 185, 183, 187, 188, 191, 194, 194, 194,\n       195, 197, 196], dtype=uint8), array([11.24816955])], [array([201, 204, 206, 205, 206, 204, 200, 202, 204, 205, 207, 202, 205,\n       203, 206, 202, 200, 201, 201, 200, 194, 195, 195, 191, 190, 191,\n       188, 183, 185, 184, 182, 178, 178, 176, 174, 171, 171, 170, 167,\n       166, 167, 169, 170, 171, 173, 178, 177, 177, 178, 174, 157, 146,\n       151, 171, 188, 195, 202, 207, 206, 206, 207, 209, 207, 208, 206,\n       206, 206, 209, 209, 206, 206, 206, 203, 204, 203, 206, 205, 204,\n       198, 199, 200, 200, 203, 202, 202, 204, 200, 202, 202, 200, 204,\n       201, 198, 200, 201, 200, 201, 201, 201, 202, 202, 202, 200, 201,\n       201, 201, 203, 201, 199, 201, 204, 203, 200, 198, 200, 201, 201,\n       200, 203, 201], dtype=uint8), array([5.29607184])], [array([205, 203, 207, 206, 206, 205, 205, 202, 202, 205, 205, 206, 205,\n       205, 204, 204, 203, 204, 206, 202, 201, 200, 200, 203, 198, 197,\n       196, 194, 195, 194, 188, 187, 186, 184, 180, 179, 176, 174, 172,\n       170, 166, 162, 163, 161, 157, 157, 158, 161, 157, 158, 162, 160,\n       155, 140, 126, 132, 148, 169, 190, 202, 209, 206, 206, 210, 209,\n       208, 208, 209, 209, 208, 206, 205, 205, 208, 208, 208, 204, 205,\n       203, 204, 201, 202, 202, 205, 204, 204, 201, 201, 201, 201, 201,\n       201, 200, 199, 198, 197, 195, 190, 196, 196, 196, 197, 196, 195,\n       196, 197, 194, 193, 192, 194, 196, 199, 197, 199, 201, 203, 202,\n       200, 201, 200], dtype=uint8), array([5.46791157])], [array([206, 206, 203, 202, 206, 206, 202, 204, 200, 205, 203, 203, 204,\n       205, 203, 205, 203, 206, 200, 202, 202, 200, 201, 197, 195, 197,\n       195, 196, 194, 192, 189, 190, 186, 185, 186, 183, 180, 179, 177,\n       176, 173, 169, 169, 168, 167, 163, 161, 161, 159, 157, 162, 164,\n       165, 169, 166, 166, 157, 144, 140, 157, 175, 188, 197, 204, 206,\n       210, 210, 209, 210, 212, 209, 208, 206, 206, 205, 205, 207, 207,\n       209, 205, 204, 204, 204, 205, 205, 203, 203, 201, 205, 205, 205,\n       202, 204, 206, 206, 205, 205, 207, 202, 206, 204, 207, 205, 207,\n       208, 206, 204, 205, 201, 203, 205, 205, 205, 205, 203, 205, 203,\n       203, 204, 203], dtype=uint8), array([5.45620238])], [array([223, 224, 225, 224, 224, 224, 223, 220, 221, 224, 222, 221, 224,\n       221, 220, 223, 223, 224, 222, 222, 224, 223, 223, 224, 225, 225,\n       223, 226, 225, 222, 223, 219, 218, 222, 224, 225, 226, 224, 222,\n       221, 221, 221, 221, 220, 222, 223, 224, 224, 222, 223, 226, 226,\n       226, 225, 224, 225, 223, 225, 225, 224, 227, 226, 224, 225, 225,\n       223, 223, 226, 226, 225, 227, 225, 222, 220, 216, 215, 217, 218,\n       219, 222, 224, 223, 225, 224, 225, 227, 228, 225, 224, 227, 226,\n       223, 224, 227, 226, 225, 225, 221, 221, 225, 227, 226, 224, 225,\n       226, 226, 224, 224, 225, 223, 222, 222, 222, 226, 227, 225, 225,\n       224, 224, 225], dtype=uint8), array([0.])], [array([205, 207, 215, 215, 216, 222, 222, 222, 220, 218, 223, 223, 223,\n       223, 226, 226, 227, 225, 226, 225, 227, 225, 226, 226, 225, 227,\n       228, 226, 228, 226, 229, 226, 230, 227, 228, 227, 232, 231, 229,\n       226, 232, 230, 231, 224, 230, 233, 229, 231, 229, 229, 228, 228,\n       227, 227, 227, 226, 229, 229, 227, 226, 225, 227, 222, 223, 221,\n       220, 219, 216, 212, 197, 165, 135, 119, 123, 126, 108,  87,  84,\n        91, 104, 107, 115, 125, 132, 136, 142, 149, 153, 160, 165, 165,\n       169, 175, 178, 185, 187, 192, 195, 196, 199, 206, 210, 212, 213,\n       215, 217, 217, 219, 221, 222, 221, 223, 222, 226, 226, 226, 226,\n       225, 222, 225], dtype=uint8), array([11.65322989])], [array([229, 225, 226, 224, 223, 226, 232, 230, 229, 228, 229, 227, 228,\n       226, 225, 228, 226, 225, 225, 225, 226, 227, 227, 223, 224, 227,\n       226, 227, 230, 229, 227, 225, 226, 227, 229, 233, 231, 227, 229,\n       225, 223, 223, 227, 222, 223, 224, 225, 227, 228, 230, 229, 227,\n       225, 224, 225, 224, 223, 225, 223, 221, 222, 218, 218, 213, 211,\n       205, 198, 192, 190, 184, 170, 144, 127, 129, 127, 122, 110, 100,\n       106, 119, 136, 150, 156, 158, 164, 169, 175, 179, 180, 185, 188,\n       193, 197, 201, 202, 200, 207, 208, 213, 214, 215, 216, 218, 223,\n       222, 223, 224, 221, 226, 225, 224, 223, 226, 226, 228, 230, 228,\n       225, 223, 225], dtype=uint8), array([11.24816955])], [array([226, 227, 226, 225, 224, 226, 226, 228, 226, 227, 230, 230, 228,\n       230, 231, 228, 229, 227, 226, 225, 226, 226, 225, 226, 228, 228,\n       230, 228, 229, 229, 225, 227, 226, 225, 227, 227, 225, 226, 229,\n       224, 227, 225, 224, 222, 222, 221, 220, 224, 220, 218, 217, 215,\n       211, 209, 210, 207, 203, 197, 184, 172, 164, 155, 147, 149, 150,\n       141, 134, 139, 152, 165, 186, 203, 211, 216, 218, 221, 219, 219,\n       217, 221, 223, 225, 223, 221, 223, 224, 224, 222, 225, 222, 222,\n       221, 223, 225, 225, 228, 224, 224, 225, 223, 222, 223, 229, 227,\n       224, 225, 226, 225, 225, 226, 220, 224, 224, 228, 225, 223, 223,\n       225, 225, 221], dtype=uint8), array([5.29607184])], [array([229, 231, 233, 230, 232, 231, 229, 230, 231, 227, 228, 228, 228,\n       230, 229, 229, 228, 230, 231, 229, 230, 232, 229, 228, 229, 230,\n       230, 229, 228, 227, 231, 230, 230, 233, 231, 228, 231, 230, 233,\n       228, 225, 229, 225, 228, 228, 231, 225, 225, 226, 224, 222, 212,\n       201, 183, 163, 149, 144, 156, 172, 181, 187, 190, 193, 193, 196,\n       201, 205, 211, 210, 211, 215, 216, 220, 222, 225, 227, 231, 229,\n       229, 225, 226, 227, 228, 228, 226, 228, 226, 228, 233, 232, 227,\n       231, 228, 227, 225, 226, 229, 227, 225, 226, 225, 225, 226, 226,\n       225, 222, 219, 222, 224, 224, 226, 228, 228, 226, 231, 230, 231,\n       230, 231, 230], dtype=uint8), array([5.46791157])], [array([228, 225, 225, 227, 227, 224, 223, 226, 229, 227, 228, 229, 229,\n       227, 228, 227, 228, 227, 228, 229, 227, 227, 226, 227, 228, 228,\n       229, 226, 224, 226, 224, 224, 225, 225, 224, 222, 224, 226, 225,\n       226, 230, 230, 234, 228, 227, 229, 229, 229, 225, 226, 224, 226,\n       226, 223, 213, 200, 181, 157, 140, 127, 132, 148, 167, 173, 177,\n       182, 182, 180, 187, 192, 198, 201, 205, 207, 210, 216, 218, 223,\n       223, 222, 221, 227, 227, 226, 225, 227, 225, 226, 227, 228, 223,\n       222, 228, 227, 227, 230, 232, 230, 225, 224, 228, 230, 226, 226,\n       224, 227, 226, 230, 229, 231, 228, 228, 230, 230, 231, 230, 229,\n       232, 230, 230], dtype=uint8), array([5.45620238])], [array([230, 229, 230, 230, 231, 230, 229, 230, 230, 233, 231, 230, 229,\n       230, 233, 232, 231, 230, 229, 228, 228, 230, 232, 232, 232, 233,\n       232, 232, 230, 232, 231, 230, 231, 230, 226, 229, 232, 230, 231,\n       233, 229, 229, 227, 231, 231, 230, 229, 230, 231, 231, 232, 231,\n       235, 230, 234, 230, 228, 229, 226, 229, 228, 229, 232, 232, 229,\n       227, 232, 234, 236, 233, 233, 231, 230, 225, 220, 219, 221, 222,\n       225, 225, 228, 229, 226, 224, 224, 227, 230, 231, 228, 229, 232,\n       231, 232, 231, 230, 234, 232, 229, 228, 230, 231, 232, 235, 231,\n       232, 233, 232, 230, 235, 234, 237, 232, 233, 231, 230, 231, 232,\n       232, 225, 217], dtype=uint8), array([3.54463004])], [array([208, 209, 206, 201, 204, 207, 205, 206, 206, 209, 208, 206, 208,\n       209, 212, 214, 213, 212, 210, 210, 211, 210, 211, 210, 210, 209,\n       208, 215, 211, 204, 211, 212, 210, 210, 210, 210, 211, 208, 210,\n       211, 211, 211, 211, 212, 210, 208, 213, 213, 210, 209, 210, 208,\n       206, 205, 204, 201, 201, 200, 199, 196, 194, 190, 185, 184, 181,\n       179, 178, 173, 169, 166, 163, 159, 160, 161, 160, 159, 149, 129,\n       124, 151, 172, 193, 208, 212, 215, 215, 217, 217, 212, 214, 211,\n       209, 209, 209, 209, 208, 207, 205, 204, 204, 206, 207, 206, 203,\n       201, 201, 202, 203, 204, 203, 203, 200, 199, 199, 200, 200, 197,\n       198, 197, 195], dtype=uint8), array([4.51179147])], [array([222, 221, 221, 224, 226, 220, 227, 226, 229, 225, 223, 225, 224,\n       221, 221, 224, 224, 223, 221, 219, 220, 220, 221, 217, 222, 222,\n       220, 220, 222, 223, 221, 221, 219, 218, 219, 214, 215, 211, 213,\n       209, 209, 209, 207, 208, 205, 206, 204, 204, 198, 201, 199, 197,\n       199, 198, 197, 197, 195, 195, 193, 189, 189, 182, 172, 166, 167,\n       177, 193, 207, 216, 223, 223, 223, 224, 222, 222, 224, 221, 216,\n       218, 213, 213, 212, 211, 214, 215, 210, 210, 213, 213, 212, 212,\n       210, 208, 208, 209, 211, 208, 210, 204, 206, 207, 208, 208, 207,\n       209, 208, 204, 204, 206, 210, 209, 210, 210, 207, 210, 209, 211,\n       211, 209, 208], dtype=uint8), array([4.37560143])], [array([223, 224, 223, 222, 221, 223, 220, 220, 219, 218, 218, 215, 212,\n       213, 215, 215, 220, 217, 217, 218, 221, 218, 219, 218, 218, 220,\n       220, 219, 219, 222, 216, 214, 218, 217, 216, 217, 214, 214, 213,\n       212, 212, 212, 211, 212, 217, 212, 214, 215, 213, 212, 211, 209,\n       209, 209, 206, 203, 205, 205, 200, 198, 197, 194, 194, 193, 191,\n       187, 183, 180, 178, 174, 171, 174, 177, 182, 175, 172, 152, 129,\n       132, 152, 175, 196, 213, 218, 215, 217, 215, 214, 212, 214, 211,\n       211, 211, 207, 208, 208, 207, 204, 203, 202, 206, 200, 204, 201,\n       204, 204, 202, 201, 201, 204, 204, 205, 205, 202, 199, 204, 202,\n       201, 201, 201], dtype=uint8), array([3.95002995])], [array([210, 211, 210, 208, 209, 207, 209, 210, 210, 209, 209, 211, 209,\n       210, 204, 206, 207, 205, 206, 207, 207, 207, 207, 206, 207, 204,\n       208, 207, 208, 208, 207, 206, 208, 206, 204, 209, 206, 203, 205,\n       206, 208, 205, 203, 203, 206, 205, 203, 204, 205, 205, 207, 205,\n       205, 202, 203, 201, 200, 198, 194, 192, 192, 188, 185, 182, 180,\n       182, 181, 177, 173, 173, 169, 167, 167, 162, 153, 149, 158, 179,\n       196, 208, 212, 211, 214, 212, 207, 210, 212, 205, 204, 203, 198,\n       196, 195, 190, 192, 190, 187, 184, 181, 182, 180, 182, 186, 187,\n       190, 193, 197, 197, 197, 197, 195, 198, 193, 193, 196, 193, 194,\n       190, 190, 192], dtype=uint8), array([3.53048839])], [array([181, 182, 181, 179, 179, 179, 175, 175, 174, 175, 174, 172, 171,\n       168, 166, 169, 168, 169, 168, 170, 163, 161, 160, 155, 151, 151,\n       153, 153, 152, 152, 154, 159, 157, 158, 155, 153, 154, 157, 166,\n       174, 177, 179, 181, 184, 183, 177, 173, 174, 173, 175, 179, 176,\n       180, 181, 183, 186, 187, 187, 183, 184, 181, 175, 168, 157, 147,\n       151, 169, 193, 204, 209, 211, 214, 213, 212, 214, 215, 214, 212,\n       215, 213, 211, 212, 212, 210, 208, 208, 207, 207, 205, 208, 208,\n       212, 213, 209, 209, 206, 204, 203, 202, 202, 204, 205, 203, 206,\n       205, 206, 208, 207, 204, 206, 200, 199, 192, 180, 165, 160, 166,\n       178, 188, 195], dtype=uint8), array([3.67640104])], [array([202, 204, 203, 202, 202, 201, 198, 202, 200, 200, 202, 198, 200,\n       198, 202, 198, 198, 203, 201, 200, 205, 199, 198, 201, 201, 202,\n       201, 199, 201, 202, 199, 201, 199, 196, 196, 199, 198, 197, 195,\n       194, 194, 193, 187, 184, 184, 176, 177, 172, 168, 166, 162, 158,\n       155, 152, 148, 145, 142, 139, 134, 132, 127, 121, 114, 109, 107,\n       105, 100,  95,  93, 105, 121, 137, 152, 166, 170, 177, 193, 211,\n       224, 224, 227, 226, 226, 225, 224, 222, 223, 221, 215, 216, 219,\n       216, 214, 214, 212, 207, 205, 208, 204, 201, 199, 198, 198, 197,\n       194, 197, 193, 195, 195, 193, 191, 189, 190, 192, 193, 194, 194,\n       198, 193, 191], dtype=uint8), array([8.97995119])], [array([210, 211, 210, 208, 207, 208, 210, 207, 205, 206, 205, 205, 205,\n       200, 203, 205, 202, 201, 202, 203, 200, 200, 198, 201, 202, 202,\n       199, 197, 198, 197, 193, 194, 198, 195, 199, 194, 195, 196, 194,\n       196, 196, 196, 196, 195, 194, 193, 188, 183, 177, 163, 144, 130,\n       126, 128, 144, 162, 169, 172, 173, 176, 179, 179, 177, 179, 183,\n       186, 187, 191, 190, 191, 197, 194, 193, 197, 196, 197, 196, 195,\n       197, 199, 200, 200, 198, 196, 197, 196, 198, 197, 200, 198, 200,\n       199, 198, 198, 198, 198, 199, 199, 201, 201, 199, 199, 196, 194,\n       198, 194, 198, 198, 199, 197, 201, 199, 197, 196, 198, 197, 194,\n       197, 198, 196], dtype=uint8), array([5.35827466])], [array([203, 203, 206, 202, 206, 207, 206, 207, 209, 209, 209, 210, 211,\n       211, 209, 209, 212, 212, 215, 214, 213, 213, 214, 210, 213, 214,\n       212, 210, 214, 214, 212, 211, 213, 214, 211, 209, 206, 207, 205,\n       205, 207, 204, 205, 209, 210, 209, 209, 210, 210, 209, 215, 214,\n       213, 215, 215, 214, 214, 214, 213, 215, 210, 208, 208, 209, 203,\n       202, 200, 197, 191, 178, 164, 160, 165, 169, 162, 142, 131, 125,\n       124, 128, 133, 139, 140, 143, 146, 146, 149, 151, 155, 154, 156,\n       156, 158, 160, 163, 164, 163, 166, 165, 165, 166, 169, 169, 172,\n       172, 171, 170, 175, 173, 171, 173, 170, 169, 167, 168, 170, 173,\n       174, 177, 176], dtype=uint8), array([8.97995119])], [array([168, 170, 171, 170, 170, 177, 176, 175, 179, 178, 178, 179, 179,\n       180, 182, 181, 177, 181, 182, 181, 182, 183, 182, 182, 182, 181,\n       180, 176, 177, 180, 179, 174, 171, 175, 175, 173, 172, 169, 167,\n       168, 168, 169, 170, 166, 169, 171, 169, 165, 155, 138, 134, 147,\n       160, 175, 193, 207, 214, 214, 217, 215, 216, 216, 214, 213, 213,\n       210, 211, 212, 213, 210, 209, 210, 212, 209, 212, 208, 210, 212,\n       212, 211, 211, 211, 208, 207, 209, 206, 207, 206, 208, 207, 211,\n       210, 208, 206, 208, 209, 208, 209, 210, 212, 211, 208, 208, 209,\n       210, 207, 207, 208, 208, 207, 207, 205, 203, 206, 200, 190, 177,\n       167, 170, 179], dtype=uint8), array([5.35827466])], [array([213, 214, 215, 215, 216, 211, 215, 215, 213, 216, 218, 217, 217,\n       219, 217, 217, 217, 219, 216, 217, 217, 214, 217, 215, 213, 215,\n       217, 213, 212, 214, 213, 214, 215, 215, 214, 215, 216, 215, 216,\n       214, 209, 214, 218, 215, 214, 213, 214, 217, 209, 210, 210, 211,\n       213, 215, 211, 211, 209, 209, 210, 207, 208, 206, 206, 207, 208,\n       205, 207, 207, 208, 208, 206, 203, 200, 195, 185, 174, 165, 158,\n       165, 173, 179, 178, 177, 175, 175, 176, 173, 173, 176, 175, 173,\n       173, 173, 175, 174, 173, 171, 174, 174, 174, 172, 173, 172, 173,\n       171, 170, 168, 171, 172, 168, 169, 166, 166, 166, 166, 168, 167,\n       166, 167, 169], dtype=uint8), array([3.76287851])], [array([217, 219, 219, 220, 222, 221, 217, 218, 221, 219, 219, 216, 219,\n       218, 220, 220, 219, 219, 219, 222, 220, 222, 223, 219, 219, 216,\n       211, 212, 211, 216, 215, 212, 213, 212, 209, 210, 208, 206, 199,\n       197, 194, 196, 201, 205, 208, 206, 212, 211, 213, 213, 214, 211,\n       211, 217, 219, 220, 220, 218, 217, 220, 220, 218, 220, 222, 224,\n       223, 224, 223, 222, 222, 221, 219, 211, 206, 203, 206, 204, 204,\n       207, 204, 202, 202, 202, 201, 203, 203, 205, 207, 207, 210, 214,\n       210, 210, 214, 216, 217, 217, 216, 217, 220, 220, 221, 219, 218,\n       220, 219, 221, 219, 222, 219, 220, 220, 223, 223, 221, 220, 220,\n       220, 220, 220], dtype=uint8), array([3.04808728])], [array([216, 216, 220, 218, 219, 219, 220, 222, 220, 223, 220, 222, 221,\n       221, 220, 225, 222, 219, 225, 226, 225, 222, 222, 223, 226, 221,\n       223, 223, 225, 226, 223, 221, 224, 229, 223, 222, 223, 219, 221,\n       222, 221, 223, 225, 222, 224, 224, 223, 225, 227, 223, 224, 227,\n       225, 223, 223, 220, 223, 223, 225, 220, 224, 224, 217, 224, 223,\n       224, 225, 225, 222, 219, 215, 211, 202, 191, 178, 171, 168, 175,\n       186, 191, 191, 194, 195, 196, 198, 197, 198, 200, 203, 201, 202,\n       201, 200, 201, 204, 203, 200, 207, 208, 208, 206, 208, 206, 207,\n       206, 207, 206, 208, 204, 206, 205, 202, 202, 202, 202, 203, 199,\n       197, 196, 196], dtype=uint8), array([3.04562947])], [array([226, 225, 226, 229, 229, 229, 230, 229, 227, 226, 226, 226, 228,\n       230, 231, 229, 225, 227, 229, 227, 227, 230, 231, 229, 226, 226,\n       225, 224, 229, 225, 227, 227, 229, 228, 228, 228, 230, 227, 226,\n       227, 227, 225, 226, 226, 227, 228, 226, 224, 226, 227, 228, 223,\n       226, 223, 226, 226, 226, 225, 225, 228, 226, 224, 224, 226, 227,\n       224, 223, 223, 220, 215, 209, 202, 193, 176, 172, 174, 189, 201,\n       209, 212, 214, 218, 217, 217, 216, 218, 217, 214, 216, 215, 213,\n       215, 212, 210, 208, 207, 210, 209, 206, 206, 206, 209, 205, 206,\n       206, 205, 206, 206, 203, 200, 195, 194, 189, 185, 182, 174, 161,\n       153, 139, 131], dtype=uint8), array([3.06895321])], [array([224, 224, 224, 221, 221, 219, 218, 224, 218, 216, 217, 216, 213,\n       210, 209, 207, 203, 193, 181, 169, 157, 145, 137, 140, 145, 151,\n       158, 160, 154, 156, 162, 172, 185, 189, 195, 203, 207, 207, 211,\n       213, 211, 212, 212, 214, 216, 215, 213, 215, 213, 210, 206, 204,\n       199, 189, 183, 186, 194, 204, 213, 219, 217, 220, 218, 216, 218,\n       219, 219, 219, 220, 223, 218, 219, 220, 221, 221, 221, 223, 223,\n       223, 226, 226, 222, 221, 221, 223, 223, 224, 225, 226, 226, 226,\n       227, 223, 225, 226, 229, 228, 229, 227, 228, 223, 224, 225, 223,\n       223, 220, 220, 220, 219, 219, 219, 216, 216, 213, 213, 210, 209,\n       206, 203, 200], dtype=uint8), array([2.85702873])], [array([200, 200, 201, 200, 199, 202, 202, 198, 200, 200, 201, 200, 201,\n       201, 201, 200, 201, 201, 199, 201, 200, 201, 201, 196, 198, 204,\n       203, 202, 203, 199, 200, 201, 198, 200, 198, 200, 196, 197, 198,\n       203, 202, 199, 203, 201, 200, 202, 199, 204, 201, 196, 199, 199,\n       199, 198, 199, 201, 201, 200, 199, 201, 202, 199, 201, 204, 202,\n       203, 206, 206, 207, 209, 209, 208, 211, 213, 212, 211, 210, 205,\n       195, 182, 164, 153, 156, 164, 169, 171, 173, 174, 169, 168, 168,\n       166, 167, 166, 168, 168, 171, 175, 177, 178, 181, 182, 187, 186,\n       189, 191, 192, 197, 194, 196, 197, 200, 200, 199, 198, 195, 194,\n       200, 200, 200], dtype=uint8), array([4.51179147])], [array([216, 218, 216, 217, 219, 219, 215, 210, 210, 209, 207, 203, 202,\n       196, 195, 193, 186, 182, 183, 182, 180, 177, 175, 175, 172, 168,\n       162, 156, 149, 144, 142, 140, 144, 150, 154, 160, 163, 164, 168,\n       170, 169, 169, 169, 171, 172, 172, 177, 173, 176, 173, 174, 174,\n       175, 177, 179, 176, 176, 177, 173, 169, 156, 142, 134, 134, 133,\n       142, 153, 161, 164, 163, 162, 161, 163, 161, 156, 159, 159, 163,\n       163, 163, 165, 167, 169, 167, 169, 173, 175, 176, 179, 181, 181,\n       182, 184, 185, 184, 181, 187, 187, 189, 192, 192, 190, 191, 194,\n       194, 194, 196, 195, 197, 200, 200, 199, 201, 201, 200, 199, 198,\n       200, 203, 203], dtype=uint8), array([4.37560143])], [array([173, 170, 166, 164, 161, 160, 162, 162, 158, 160, 158, 158, 158,\n       163, 162, 162, 164, 165, 167, 164, 165, 164, 164, 166, 167, 169,\n       170, 172, 172, 172, 173, 173, 175, 177, 173, 175, 179, 180, 180,\n       181, 183, 183, 185, 183, 185, 188, 189, 190, 191, 191, 192, 190,\n       190, 190, 192, 189, 193, 192, 195, 194, 196, 193, 194, 199, 200,\n       203, 206, 205, 204, 205, 206, 207, 210, 212, 211, 211, 205, 195,\n       184, 168, 149, 147, 158, 166, 166, 171, 170, 171, 173, 170, 170,\n       173, 176, 178, 179, 181, 184, 187, 191, 190, 194, 194, 199, 200,\n       198, 203, 205, 210, 207, 209, 208, 209, 209, 209, 208, 208, 208,\n       207, 210, 212], dtype=uint8), array([3.95002995])], [array([194, 196, 198, 199, 201, 202, 203, 202, 203, 203, 203, 206, 204,\n       205, 208, 209, 210, 211, 209, 211, 211, 212, 213, 213, 211, 212,\n       213, 213, 213, 213, 217, 215, 208, 213, 211, 215, 213, 212, 216,\n       214, 213, 216, 214, 216, 219, 216, 214, 215, 215, 213, 211, 211,\n       212, 214, 215, 212, 217, 213, 217, 217, 218, 215, 211, 208, 209,\n       211, 212, 215, 218, 221, 220, 216, 215, 220, 218, 206, 195, 185,\n       178, 180, 193, 192, 194, 195, 195, 193, 190, 189, 190, 191, 191,\n       194, 195, 194, 196, 199, 206, 207, 207, 208, 211, 212, 209, 208,\n       203, 203, 202, 203, 202, 202, 202, 203, 206, 202, 206, 205, 205,\n       203, 204, 202], dtype=uint8), array([3.53048839])], [array([216, 214, 218, 218, 217, 220, 222, 220, 223, 219, 222, 222, 223,\n       223, 220, 220, 218, 215, 218, 215, 212, 208, 205, 207, 203, 203,\n       204, 203, 202, 201, 201, 202, 208, 207, 207, 208, 210, 209, 208,\n       210, 214, 216, 216, 220, 220, 222, 223, 220, 221, 220, 223, 221,\n       220, 221, 221, 219, 217, 218, 217, 212, 209, 205, 197, 187, 178,\n       172, 178, 187, 197, 202, 201, 200, 202, 203, 203, 206, 208, 207,\n       209, 209, 207, 207, 206, 205, 207, 206, 206, 205, 204, 202, 205,\n       204, 200, 201, 203, 199, 194, 192, 190, 192, 193, 194, 193, 197,\n       201, 202, 206, 206, 207, 208, 211, 209, 210, 211, 209, 210, 213,\n       213, 213, 214], dtype=uint8), array([3.67640104])], [array([211, 211, 209, 209, 210, 210, 210, 208, 209, 207, 209, 208, 208,\n       208, 210, 206, 206, 206, 205, 207, 208, 208, 205, 207, 206, 204,\n       205, 205, 206, 203, 205, 204, 203, 202, 203, 204, 202, 202, 201,\n       201, 200, 201, 197, 198, 199, 201, 200, 200, 199, 198, 195, 195,\n       196, 197, 193, 196, 195, 196, 194, 192, 183, 165, 149, 144, 144,\n       151, 165, 178, 182, 187, 191, 189, 193, 195, 194, 196, 199, 200,\n       203, 203, 203, 203, 197, 195, 198, 201, 200, 201, 206, 205, 208,\n       210, 211, 210, 210, 210, 211, 210, 211, 210, 212, 208, 206, 208,\n       211, 213, 212, 212, 213, 213, 213, 212, 214, 212, 211, 214, 214,\n       211, 211, 213], dtype=uint8), array([5.21064103])], [array([241, 243, 244, 241, 244, 245, 239, 238, 234, 235, 236, 241, 235,\n       234, 235, 236, 239, 239, 235, 236, 239, 237, 240, 238, 239, 239,\n       238, 238, 239, 239, 240, 242, 244, 242, 243, 246, 240, 242, 243,\n       245, 247, 245, 244, 244, 242, 245, 246, 245, 242, 244, 247, 242,\n       245, 246, 248, 250, 247, 247, 249, 251, 250, 248, 249, 246, 248,\n       247, 238, 214, 189, 186, 198, 197, 178, 158, 157, 162, 160, 161,\n       159, 157, 152, 156, 160, 165, 167, 174, 173, 172, 173, 180, 186,\n       186, 190, 196, 196, 199, 204, 211, 214, 213, 213, 217, 218, 224,\n       225, 227, 231, 232, 236, 239, 236, 241, 243, 243, 246, 247, 247,\n       244, 249, 248], dtype=uint8), array([8.52101685])], [array([238, 240, 238, 236, 238, 238, 237, 237, 238, 238, 239, 238, 239,\n       241, 238, 237, 240, 240, 236, 237, 241, 240, 242, 242, 242, 240,\n       241, 242, 242, 239, 238, 238, 241, 240, 240, 241, 240, 242, 241,\n       242, 245, 244, 243, 243, 243, 243, 246, 247, 247, 248, 244, 246,\n       249, 249, 249, 247, 253, 254, 251, 251, 252, 252, 250, 252, 249,\n       232, 211, 178, 169, 179, 183, 168, 147, 142, 147, 152, 156, 156,\n       152, 151, 156, 158, 159, 157, 161, 162, 167, 174, 178, 178, 179,\n       186, 191, 195, 202, 202, 209, 211, 212, 213, 215, 215, 218, 225,\n       226, 228, 232, 236, 237, 241, 234, 237, 241, 244, 243, 245, 244,\n       245, 242, 243], dtype=uint8), array([8.73503977])], [array([197, 199, 200, 199, 194, 191, 187, 186, 187, 197, 206, 213, 225,\n       226, 235, 237, 241, 244, 243, 237, 239, 241, 238, 241, 241, 242,\n       240, 238, 237, 238, 238, 237, 238, 239, 238, 242, 239, 237, 236,\n       238, 237, 238, 236, 238, 238, 235, 232, 229, 230, 229, 231, 231,\n       230, 226, 226, 225, 222, 220, 218, 221, 219, 219, 217, 216, 214,\n       215, 213, 210, 212, 207, 196, 185, 180, 179, 183, 197, 207, 211,\n       215, 214, 219, 220, 221, 220, 223, 221, 225, 227, 225, 227, 229,\n       230, 230, 230, 232, 233, 233, 235, 234, 235, 234, 232, 233, 237,\n       234, 234, 234, 234, 232, 230, 230, 232, 231, 233, 236, 233, 234,\n       232, 232, 231], dtype=uint8), array([4.59109883])], [array([242, 243, 243, 239, 239, 236, 241, 242, 243, 243, 237, 239, 241,\n       241, 241, 243, 242, 239, 240, 239, 239, 240, 229, 235, 239, 239,\n       237, 237, 235, 235, 234, 235, 233, 232, 232, 232, 228, 230, 230,\n       226, 224, 225, 224, 219, 220, 216, 214, 210, 208, 208, 206, 204,\n       202, 203, 199, 203, 200, 200, 203, 201, 196, 184, 166, 166, 184,\n       201, 219, 232, 237, 238, 240, 244, 239, 238, 237, 240, 241, 239,\n       240, 240, 244, 238, 237, 235, 234, 232, 230, 234, 237, 236, 235,\n       233, 233, 233, 232, 231, 230, 232, 231, 228, 230, 229, 226, 226,\n       225, 223, 219, 223, 221, 222, 224, 223, 223, 222, 223, 217, 222,\n       220, 217, 217], dtype=uint8), array([4.34090199])], [array([234, 235, 243, 236, 236, 230, 237, 238, 233, 233, 233, 233, 235,\n       234, 235, 233, 231, 235, 236, 233, 234, 233, 235, 234, 235, 236,\n       236, 233, 233, 232, 231, 232, 232, 230, 230, 229, 227, 227, 227,\n       226, 226, 223, 219, 217, 214, 211, 212, 214, 211, 212, 209, 205,\n       209, 206, 208, 206, 208, 209, 209, 208, 204, 194, 185, 190, 205,\n       219, 228, 231, 234, 236, 235, 234, 231, 229, 229, 224, 225, 226,\n       225, 224, 226, 224, 223, 223, 223, 224, 223, 227, 226, 226, 226,\n       229, 225, 224, 224, 226, 226, 225, 228, 230, 228, 232, 230, 231,\n       227, 229, 233, 235, 231, 233, 230, 233, 230, 230, 234, 227, 223,\n       220, 224, 225], dtype=uint8), array([4.35067225])], [array([229, 236, 236, 235, 237, 237, 235, 238, 240, 241, 236, 238, 238,\n       238, 236, 234, 235, 236, 236, 237, 233, 233, 236, 236, 236, 236,\n       231, 236, 234, 236, 232, 231, 230, 228, 229, 225, 222, 221, 217,\n       215, 217, 215, 207, 203, 207, 206, 200, 202, 202, 198, 200, 200,\n       199, 201, 204, 205, 201, 205, 196, 181, 174, 188, 203, 219, 230,\n       236, 238, 239, 236, 233, 231, 232, 230, 229, 230, 225, 222, 219,\n       220, 217, 217, 216, 213, 212, 211, 210, 208, 208, 207, 205, 206,\n       199, 186, 187, 202, 218, 226, 232, 232, 231, 232, 228, 222, 222,\n       219, 220, 222, 226, 230, 223, 226, 224, 222, 221, 221, 220, 217,\n       218, 217, 216], dtype=uint8), array([4.18356936])], [array([221, 220, 221, 219, 220, 215, 219, 215, 221, 219, 216, 215, 217,\n       218, 218, 219, 218, 219, 219, 216, 219, 222, 221, 220, 218, 219,\n       219, 216, 218, 216, 217, 220, 217, 217, 219, 217, 219, 221, 219,\n       218, 218, 216, 214, 216, 219, 214, 216, 220, 217, 223, 217, 217,\n       219, 218, 218, 220, 220, 220, 219, 219, 220, 219, 221, 221, 215,\n       219, 221, 221, 216, 216, 212, 201, 187, 182, 182, 182, 190, 198,\n       198, 198, 196, 195, 192, 190, 187, 184, 184, 185, 187, 191, 191,\n       195, 198, 199, 200, 200, 201, 208, 212, 209, 211, 217, 214, 215,\n       217, 218, 218, 217, 221, 218, 218, 219, 221, 219, 217, 218, 221,\n       221, 223, 221], dtype=uint8), array([5.923182])], [array([223, 229, 224, 224, 227, 224, 223, 223, 222, 221, 223, 221, 221,\n       221, 222, 221, 220, 214, 209, 205, 198, 192, 197, 197, 204, 209,\n       212, 215, 219, 219, 209, 204, 190, 182, 181, 190, 203, 211, 210,\n       212, 218, 215, 218, 223, 224, 224, 224, 225, 229, 230, 228, 224,\n       218, 221, 225, 233, 232, 239, 240, 240, 239, 242, 242, 239, 231,\n       204, 187, 177, 178, 163, 143, 133, 130, 128, 127, 127, 134, 135,\n       140, 140, 143, 144, 148, 149, 152, 156, 159, 160, 163, 167, 173,\n       175, 178, 185, 187, 192, 196, 198, 202, 204, 204, 212, 215, 215,\n       217, 219, 218, 219, 223, 222, 224, 228, 226, 229, 228, 227, 228,\n       229, 230, 228], dtype=uint8), array([8.89809448])], [array([215, 217, 219, 217, 222, 220, 220, 218, 217, 216, 211, 207, 214,\n       220, 222, 222, 218, 219, 222, 222, 219, 220, 223, 219, 222, 221,\n       219, 226, 223, 225, 223, 225, 224, 223, 222, 218, 219, 222, 221,\n       224, 225, 224, 223, 221, 219, 219, 222, 221, 222, 222, 217, 218,\n       217, 219, 216, 214, 213, 215, 214, 212, 211, 208, 209, 209, 209,\n       208, 205, 201, 200, 198, 188, 167, 151, 152, 155, 150, 157, 179,\n       194, 199, 202, 204, 203, 203, 207, 207, 207, 210, 214, 216, 216,\n       214, 219, 220, 219, 221, 223, 224, 220, 224, 223, 221, 224, 221,\n       221, 219, 217, 211, 200, 198, 200, 198, 202, 205, 212, 214, 222,\n       223, 225, 223], dtype=uint8), array([4.7800506])], [array([223, 222, 226, 224, 222, 224, 223, 225, 223, 219, 220, 221, 226,\n       223, 224, 223, 222, 219, 222, 224, 222, 222, 223, 225, 225, 225,\n       221, 219, 220, 221, 221, 221, 223, 220, 221, 220, 222, 217, 221,\n       219, 220, 218, 218, 218, 216, 215, 214, 212, 211, 207, 205, 205,\n       203, 204, 202, 199, 196, 194, 195, 194, 195, 193, 191, 188, 189,\n       191, 187, 190, 192, 189, 175, 160, 162, 169, 166, 179, 191, 199,\n       202, 205, 205, 205, 204, 207, 208, 208, 210, 211, 212, 213, 213,\n       214, 213, 214, 215, 218, 217, 216, 217, 215, 219, 217, 218, 220,\n       215, 216, 213, 220, 218, 221, 223, 217, 223, 221, 221, 224, 218,\n       222, 222, 217], dtype=uint8), array([5.29939395])], [array([222, 221, 221, 223, 224, 216, 220, 215, 222, 222, 226, 220, 222,\n       223, 221, 223, 218, 220, 222, 222, 219, 217, 222, 218, 219, 222,\n       215, 219, 217, 218, 220, 218, 220, 216, 220, 217, 214, 220, 216,\n       220, 215, 211, 215, 215, 214, 213, 212, 217, 212, 212, 211, 215,\n       211, 210, 214, 209, 207, 207, 209, 204, 205, 207, 209, 204, 200,\n       199, 198, 201, 202, 197, 192, 175, 161, 158, 162, 168, 185, 194,\n       195, 195, 199, 194, 199, 198, 201, 200, 200, 203, 204, 199, 207,\n       208, 209, 211, 209, 217, 213, 210, 214, 213, 216, 214, 217, 214,\n       219, 214, 214, 214, 219, 216, 221, 214, 218, 218, 214, 218, 216,\n       213, 216, 217], dtype=uint8), array([5.08347615])], [array([255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 254, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 252, 251, 250, 233, 196, 177,\n       202, 228, 211, 167, 140, 160, 185, 185, 189, 192, 197, 205, 210,\n       214, 220, 225, 227, 231, 237, 239, 243, 248, 252, 253, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255], dtype=uint8), array([8.36581426])], [array([255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 254, 248, 244, 245, 243, 242, 232, 219, 214,\n       218, 227, 237, 248, 253, 255, 255, 255, 255, 255, 255, 254, 255,\n       255, 255, 255, 255, 255, 255, 252, 245, 246, 245, 244, 238, 230,\n       223, 221, 220, 213, 206, 202, 195, 195, 204, 210, 207, 201, 176,\n       142, 135, 165, 186, 177, 167, 186, 223, 244, 254, 251, 252, 254,\n       254, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255], dtype=uint8), array([8.89809448])], [array([255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 254, 248, 229, 208, 206, 199, 193, 214, 237,\n       236, 243, 244, 254, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255], dtype=uint8), array([4.7800506])], [array([255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 245, 213, 191, 194, 185, 169, 203, 234, 235,\n       239, 245, 251, 253, 254, 251, 248, 251, 254, 254, 254, 255, 255,\n       255, 255, 255, 255, 255, 255, 254, 243, 227, 219, 218, 231, 251,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255], dtype=uint8), array([5.29939395])], [array([255, 255, 255, 254, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 254, 253, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 253, 246, 217, 198, 196, 186, 208, 233,\n       241, 244, 249, 255, 255, 254, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255], dtype=uint8), array([5.08347615])], [array([255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 254, 243, 255, 255, 255, 255,\n       255, 255, 255, 253, 249, 244, 226, 202, 199, 206, 214, 230, 242,\n       238, 246, 249, 252, 253, 253, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255], dtype=uint8), array([5.923182])], [array([255, 255, 255, 255, 252, 247, 243, 237, 233, 226, 217, 214, 221,\n       224, 228, 228, 226, 225, 228, 229, 230, 232, 232, 232, 237, 237,\n       235, 237, 244, 243, 244, 247, 249, 249, 253, 254, 254, 253, 251,\n       255, 255, 254, 255, 255, 254, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 253, 236, 220, 206, 196, 199, 215, 227, 228,\n       231, 233, 234, 237, 233, 239, 245, 243, 246, 251, 254, 253, 254,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255], dtype=uint8), array([4.59109883])], [array([255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 254, 252, 251, 238, 229, 222,\n       219, 227, 230, 227, 227, 229, 228, 230, 234, 233, 234, 239, 239,\n       240, 242, 244, 248, 246, 251, 251, 251, 251, 252, 253, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255], dtype=uint8), array([4.34090199])], [array([255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 254, 255, 255, 253, 254, 255, 254, 254, 254, 255, 247,\n       243, 240, 242, 242, 237, 234, 222, 204, 175, 165, 178, 176, 153,\n       126, 140, 162, 172, 171, 172, 177, 178, 182, 185, 189, 197, 202,\n       204, 209, 210, 219, 223, 224, 232, 233, 239, 245, 245, 244, 251,\n       251, 251, 252, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 253, 254, 255, 255, 255, 252, 254, 252, 253, 255, 255,\n       255, 254, 255], dtype=uint8), array([8.52101685])], [array([255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 251, 251, 251, 251, 250, 244, 238, 223, 199, 176, 178, 195,\n       192, 163, 141, 152, 172, 180, 176, 174, 177, 182, 183, 186, 190,\n       196, 199, 202, 205, 211, 215, 221, 222, 225, 230, 233, 236, 240,\n       244, 248, 250, 250, 248, 249, 252, 255, 251, 252, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255], dtype=uint8), array([8.73503977])], [array([255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 254, 254, 247, 232, 218, 213, 203, 203, 213, 219,\n       219, 217, 221, 223, 219, 221, 224, 229, 234, 236, 238, 242, 246,\n       249, 249, 251, 254, 254, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 241, 254, 255, 255, 251, 239, 225, 218, 219, 223,\n       225, 226, 227, 229, 229, 232, 235, 236, 238, 242, 250, 250, 250,\n       253, 253, 255], dtype=uint8), array([4.18356936])], [array([255, 255, 254, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 254, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 253, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 254, 244, 230, 219,\n       214, 219, 225, 226, 224, 223, 226, 227, 229, 229, 229, 234, 235,\n       241, 244, 247, 250, 249, 252, 251, 249, 255, 254, 255, 255, 254,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 253, 249, 252, 252,\n       252, 253, 255], dtype=uint8), array([4.35067225])], [array([236, 232, 233, 233, 232, 237, 238, 237, 238, 239, 241, 242, 239,\n       237, 238, 236, 237, 238, 232, 236, 236, 237, 239, 236, 236, 237,\n       237, 236, 237, 238, 240, 241, 242, 242, 242, 238, 241, 238, 237,\n       236, 236, 238, 243, 240, 238, 237, 239, 238, 237, 238, 239, 239,\n       237, 240, 241, 239, 235, 237, 238, 238, 237, 239, 237, 236, 236,\n       237, 234, 233, 231, 232, 234, 232, 235, 236, 236, 230, 233, 233,\n       236, 232, 231, 234, 236, 235, 233, 233, 232, 231, 235, 237, 231,\n       229, 228, 229, 233, 232, 234, 232, 226, 230, 235, 230, 230, 228,\n       230, 229, 228, 230, 233, 232, 231, 229, 231, 233, 230, 230, 230,\n       236, 232, 234], dtype=uint8), array([0.])], [array([248, 248, 253, 252, 254, 253, 248, 247, 246, 251, 249, 251, 249,\n       250, 248, 248, 249, 248, 247, 250, 250, 249, 249, 248, 247, 248,\n       246, 249, 248, 251, 251, 249, 250, 250, 250, 250, 252, 253, 247,\n       246, 246, 249, 247, 248, 245, 248, 249, 246, 246, 249, 246, 248,\n       247, 246, 248, 250, 247, 249, 250, 249, 249, 250, 248, 252, 250,\n       250, 253, 254, 252, 252, 251, 250, 248, 236, 215, 190, 178, 164,\n       159, 180, 213, 212, 210, 208, 211, 210, 209, 207, 208, 211, 212,\n       216, 221, 223, 223, 224, 227, 229, 232, 237, 239, 238, 238, 243,\n       244, 245, 240, 236, 236, 242, 244, 248, 248, 248, 249, 251, 252,\n       252, 249, 251], dtype=uint8), array([4.75818342])], [array([253, 251, 250, 248, 250, 251, 249, 251, 251, 249, 249, 248, 250,\n       251, 248, 248, 253, 252, 250, 253, 251, 249, 248, 246, 248, 244,\n       245, 246, 244, 245, 244, 239, 240, 238, 237, 230, 227, 229, 226,\n       224, 221, 219, 219, 221, 219, 217, 217, 216, 217, 217, 217, 219,\n       220, 219, 219, 222, 218, 208, 203, 207, 220, 235, 247, 249, 249,\n       251, 251, 252, 250, 249, 252, 250, 248, 249, 252, 248, 245, 249,\n       246, 246, 249, 249, 249, 248, 249, 249, 247, 248, 247, 248, 250,\n       247, 246, 245, 244, 242, 237, 239, 240, 237, 241, 242, 241, 241,\n       241, 242, 243, 239, 244, 243, 245, 248, 245, 245, 245, 246, 242,\n       246, 249, 253], dtype=uint8), array([3.84824603])], [array([250, 249, 248, 245, 246, 249, 247, 246, 249, 248, 248, 245, 243,\n       245, 243, 243, 244, 243, 239, 246, 244, 245, 247, 245, 247, 242,\n       241, 241, 242, 243, 241, 242, 241, 239, 243, 239, 241, 239, 238,\n       240, 239, 239, 236, 237, 238, 232, 230, 228, 229, 226, 224, 223,\n       223, 222, 222, 220, 217, 221, 210, 206, 207, 207, 200, 203, 202,\n       200, 203, 202, 203, 185, 166, 166, 177, 187, 198, 211, 228, 234,\n       234, 236, 240, 240, 240, 239, 238, 243, 241, 241, 243, 241, 242,\n       238, 237, 235, 236, 235, 232, 233, 230, 224, 218, 208, 205, 201,\n       197, 193, 194, 203, 210, 219, 227, 231, 238, 240, 237, 236, 240,\n       243, 239, 239], dtype=uint8), array([5.52762087])], [array([247, 246, 247, 247, 249, 248, 246, 246, 248, 250, 250, 247, 246,\n       244, 247, 244, 245, 244, 246, 246, 247, 242, 242, 240, 242, 235,\n       237, 237, 237, 232, 230, 231, 226, 224, 224, 219, 220, 218, 213,\n       214, 208, 205, 200, 203, 200, 193, 192, 189, 192, 194, 198, 199,\n       201, 203, 201, 197, 178, 165, 175, 193, 210, 223, 236, 248, 249,\n       250, 250, 251, 248, 250, 251, 250, 247, 245, 246, 246, 248, 246,\n       244, 248, 246, 242, 242, 244, 242, 240, 241, 240, 244, 243, 241,\n       243, 242, 241, 241, 240, 238, 243, 246, 236, 239, 240, 242, 237,\n       238, 241, 240, 237, 237, 243, 236, 235, 237, 234, 232, 230, 226,\n       229, 226, 231], dtype=uint8), array([5.24173503])], [array([236, 233, 236, 241, 236, 237, 241, 242, 239, 238, 241, 234, 235,\n       234, 232, 235, 237, 233, 235, 230, 232, 230, 228, 226, 225, 222,\n       226, 226, 221, 220, 220, 213, 207, 206, 205, 204, 204, 202, 201,\n       199, 197, 194, 199, 196, 200, 206, 206, 209, 210, 208, 212, 209,\n       210, 208, 195, 182, 187, 207, 228, 235, 242, 241, 239, 234, 234,\n       232, 234, 231, 231, 230, 233, 233, 234, 232, 227, 232, 233, 227,\n       231, 235, 231, 229, 229, 227, 228, 229, 234, 232, 230, 230, 232,\n       230, 228, 229, 228, 229, 226, 226, 228, 226, 229, 227, 226, 228,\n       231, 229, 230, 229, 230, 231, 231, 229, 229, 230, 231, 229, 229,\n       229, 229, 229], dtype=uint8), array([3.48806279])], [array([232, 230, 234, 232, 233, 235, 234, 230, 235, 236, 231, 232, 233,\n       231, 235, 230, 227, 230, 229, 228, 227, 228, 230, 228, 225, 227,\n       230, 229, 228, 231, 229, 230, 227, 231, 231, 230, 232, 231, 232,\n       230, 230, 229, 228, 229, 230, 227, 230, 232, 229, 229, 231, 229,\n       227, 226, 223, 227, 224, 226, 226, 224, 224, 222, 222, 220, 219,\n       219, 221, 221, 221, 217, 219, 217, 218, 216, 212, 208, 190, 179,\n       172, 163, 167, 185, 197, 197, 200, 198, 198, 201, 199, 196, 202,\n       200, 201, 202, 200, 199, 203, 201, 203, 203, 202, 203, 202, 199,\n       201, 200, 200, 199, 200, 200, 200, 199, 199, 201, 198, 199, 197,\n       196, 188, 171], dtype=uint8), array([4.68352392])], [array([232, 231, 230, 233, 231, 229, 229, 228, 230, 231, 232, 229, 230,\n       229, 230, 230, 230, 226, 226, 226, 228, 226, 223, 223, 220, 223,\n       220, 216, 219, 219, 219, 217, 216, 217, 211, 212, 211, 209, 208,\n       202, 194, 180, 169, 169, 171, 174, 190, 200, 205, 206, 210, 206,\n       205, 209, 210, 208, 210, 207, 207, 210, 208, 209, 208, 207, 206,\n       210, 208, 211, 211, 210, 208, 204, 189, 169, 162, 162, 172, 191,\n       208, 216, 219, 217, 224, 224, 228, 227, 228, 228, 227, 228, 228,\n       228, 228, 227, 231, 228, 228, 227, 225, 227, 230, 229, 226, 228,\n       227, 227, 230, 226, 229, 233, 230, 231, 230, 229, 231, 230, 231,\n       229, 228, 230], dtype=uint8), array([4.45399496])], [array([248, 251, 249, 249, 249, 251, 249, 250, 247, 249, 246, 248, 247,\n       250, 253, 249, 253, 252, 250, 255, 255, 254, 251, 250, 248, 249,\n       251, 248, 248, 248, 250, 251, 252, 250, 248, 249, 249, 251, 249,\n       246, 250, 250, 250, 248, 248, 250, 249, 250, 251, 251, 249, 247,\n       249, 247, 246, 243, 246, 246, 246, 245, 248, 246, 246, 246, 245,\n       242, 252, 250, 248, 243, 248, 250, 246, 246, 249, 245, 245, 245,\n       247, 246, 247, 247, 249, 249, 248, 248, 248, 249, 249, 247, 247,\n       249, 249, 247, 247, 246, 247, 245, 243, 247, 246, 249, 246, 244,\n       247, 247, 247, 246, 244, 250, 249, 250, 243, 248, 244, 246, 244,\n       245, 245, 244], dtype=uint8), array([0.])], [array([255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 254, 252, 249, 248, 248, 247, 242, 237, 219,\n       185, 153, 162, 177, 162, 136, 143, 167, 190, 195, 195, 204, 208,\n       213, 215, 221, 226, 232, 234, 240, 242, 250, 252, 252, 251, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 254, 243, 253, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255], dtype=uint8), array([8.71474618])], [array([255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 254, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 254, 248, 253, 253, 248, 249, 246, 244, 245, 239, 233,\n       225, 192, 147, 115, 122, 150, 169, 164, 157, 171, 196, 213, 215,\n       220, 224, 225, 225, 230, 236, 239, 244, 248, 247, 249, 250, 251,\n       253, 254, 255, 255, 255, 254, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255], dtype=uint8), array([9.02551505])], [array([225, 224, 226, 233, 234, 231, 233, 237, 237, 242, 243, 242, 238,\n       242, 247, 245, 247, 249, 251, 251, 249, 253, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 254,\n       255, 255, 255, 255, 253, 255, 250, 238, 203, 165, 159, 172, 157,\n       143, 155, 172, 182, 187, 189, 195, 201, 205, 212, 219, 226, 227,\n       233, 236, 239, 241, 246, 249, 253, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255], dtype=uint8), array([7.32964192])], [array([255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 254, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 253, 249, 251,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 251, 246, 231, 213, 203,\n       194, 189, 200, 219, 227, 227, 234, 243, 247, 249, 251, 252, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 254, 254, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255], dtype=uint8), array([4.88385177])], [array([255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 254, 255, 255, 255, 255, 255, 255, 254, 254, 252, 250, 248,\n       244, 244, 246, 246, 255, 255, 255, 255, 255, 255, 255, 254, 254,\n       254, 249, 243, 240, 229, 228, 230, 229, 231, 235, 234, 231, 227,\n       223, 224, 219, 199, 157, 142, 169, 190, 182, 182, 213, 236, 245,\n       248, 252, 253, 255, 254, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255], dtype=uint8), array([6.54541434])], [array([254, 254, 253, 253, 250, 251, 250, 249, 249, 249, 247, 244, 245,\n       240, 237, 232, 229, 226, 217, 196, 183, 179, 188, 200, 214, 230,\n       232, 233, 232, 222, 206, 193, 186, 194, 201, 209, 220, 227, 234,\n       237, 238, 247, 249, 252, 254, 254, 254, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 253, 252, 251, 248, 246, 243,\n       243, 238, 239, 223, 196, 166, 168, 187, 177, 166, 193, 222, 242,\n       243, 243, 249, 252, 254, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255], dtype=uint8), array([7.03218657])], [array([242, 241, 239, 242, 239, 236, 232, 223, 220, 217, 205, 196, 187,\n       176, 171, 176, 182, 192, 210, 225, 236, 242, 242, 248, 246, 248,\n       252, 252, 253, 253, 255, 255, 255, 254, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 253, 251, 246, 242, 240, 233, 229, 226, 221, 214, 209, 210,\n       212, 210, 195, 168, 150, 165, 183, 173, 176, 207, 234, 245, 245,\n       249, 255, 253, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255], dtype=uint8), array([6.38074043])], [array([252, 252, 254, 255, 255, 254, 254, 254, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 246, 253, 255, 255, 254, 251, 248, 244, 246, 251,\n       252, 253, 252, 254, 251, 248, 245, 243, 225, 198, 185, 189, 196,\n       204, 219, 243, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255], dtype=uint8), array([5.54238319])], [array([255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 253, 253,\n       250, 247, 245, 240, 237, 240, 238, 240, 239, 235, 232, 231, 237,\n       246, 253, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 254,\n       254, 255, 253, 251, 247, 244, 243, 236, 229, 227, 223, 215, 214,\n       222, 232, 244, 252, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 254, 254, 254, 251, 255, 255,\n       252, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255], dtype=uint8), array([4.58639866])], [array([255, 255, 255, 255, 255, 255, 255, 255, 255, 246, 254, 255, 255,\n       255, 255, 255, 255, 254, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 254,\n       245, 227, 218, 202, 179, 166, 192, 216, 217, 217, 222, 220, 224,\n       226, 231, 232, 236, 246, 252, 254, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255], dtype=uint8), array([5.4984222])], [array([250, 250, 245, 241, 241, 229, 215, 201, 182, 168, 158, 159, 160,\n       161, 170, 181, 203, 214, 225, 234, 238, 238, 245, 245, 246, 246,\n       253, 254, 254, 255, 255, 255, 255, 255, 255, 255, 255, 254, 248,\n       255, 255, 255, 252, 254, 255, 255, 254, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 247,\n       235, 213, 189, 192, 203, 189, 158, 140, 159, 183, 189, 191, 195,\n       197, 203, 206, 213, 217, 224, 230, 237, 236, 241, 244, 249, 252,\n       254, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255], dtype=uint8), array([8.81468908])], [array([255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 254, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 252, 245, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       254, 255, 253, 251, 251, 248, 248, 245, 240, 226, 190, 148, 136,\n       142, 154, 188, 229, 243, 251, 255, 254, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255], dtype=uint8), array([5.09065576])], [array([235, 236, 237, 235, 236, 233, 231, 237, 237, 235, 237, 232, 237,\n       236, 235, 236, 237, 234, 237, 237, 234, 237, 239, 239, 237, 237,\n       239, 237, 241, 242, 242, 241, 236, 237, 237, 238, 241, 239, 240,\n       237, 239, 237, 236, 238, 236, 238, 242, 240, 242, 238, 237, 240,\n       240, 239, 239, 237, 236, 237, 242, 240, 239, 242, 240, 238, 242,\n       242, 244, 242, 240, 243, 245, 247, 246, 245, 240, 244, 243, 241,\n       244, 242, 247, 246, 243, 242, 245, 244, 247, 244, 244, 244, 240,\n       242, 243, 241, 243, 240, 239, 241, 244, 243, 239, 241, 240, 240,\n       244, 239, 239, 237, 239, 240, 246, 243, 243, 241, 242, 245, 245,\n       242, 241, 243], dtype=uint8), array([0.])], [array([255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 254, 255, 255, 255, 255, 255, 255, 255, 248, 231, 203,\n       182, 171, 166, 175, 198, 212, 218, 219, 220, 224, 228, 227, 231,\n       235, 237, 241, 242, 245, 249, 250, 251, 252, 254, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 254, 254, 253, 254, 255, 254, 252, 244, 228,\n       221, 217, 221], dtype=uint8), array([4.42544194])], [array([255, 255, 255, 255, 255, 254, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 254, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 252, 239, 228, 219, 215, 210, 207,\n       212, 225, 234, 234, 241, 242, 247, 253, 255, 254, 254, 255, 255,\n       255, 255, 255, 255, 255, 250, 237, 223, 200, 187, 186, 204, 217,\n       218, 222, 221, 219, 225, 225, 230, 231, 233, 235, 240, 244, 245,\n       246, 252, 255, 253, 253, 252, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255], dtype=uint8), array([4.45399496])], [array([232, 235, 236, 237, 237, 237, 242, 242, 242, 243, 243, 243, 248,\n       249, 245, 247, 249, 252, 252, 251, 251, 254, 255, 250, 252, 251,\n       254, 255, 255, 255, 255, 255, 252, 254, 255, 255, 255, 255, 255,\n       255, 254, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 254, 250, 242, 221, 199,\n       180, 165, 177, 204, 218, 222, 227, 232, 232, 233, 237, 241, 241,\n       245, 249, 249, 251, 253, 254, 255, 255, 255, 254, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 247, 229, 211,\n       194, 177, 166], dtype=uint8), array([4.68352392])], [array([255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 253, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 251, 252, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 254, 254, 254, 248, 249, 242,\n       227, 209, 196, 196, 209, 227, 236, 238, 238, 237, 240, 244, 242,\n       240, 237, 239, 240, 240, 242, 246, 246, 248, 249, 246, 247, 247,\n       255, 254, 254, 255, 253, 255, 252, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255], dtype=uint8), array([3.48806279])], [array([240, 241, 245, 246, 253, 251, 254, 255, 255, 254, 255, 255, 255,\n       255, 254, 254, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 254, 253, 242, 220, 201, 190, 170, 168,\n       186, 203, 210, 211, 215, 210, 217, 218, 223, 227, 228, 231, 237,\n       240, 244, 243, 246, 247, 250, 253, 254, 253, 255, 254, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255], dtype=uint8), array([5.52762087])], [array([255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 254, 255, 255, 255,\n       251, 241, 223, 203, 203, 222, 239, 248, 253, 254, 255, 255, 255,\n       255, 252, 242, 221, 189, 163, 150, 146, 154, 173, 188, 192, 195,\n       196, 196, 198, 199, 202, 205, 210, 215, 220, 226, 232, 233, 234,\n       234, 238, 242, 245, 247, 248, 253, 255, 255, 255, 255, 254, 254,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 254, 253, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255], dtype=uint8), array([5.24173503])], [array([255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 254, 253, 255, 255, 255, 253, 247,\n       243, 233, 228, 237, 245, 249, 253, 254, 255, 254, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 254, 253, 251, 251,\n       249, 252, 253, 251, 249, 245, 245, 243, 240, 235, 232, 232, 225,\n       225, 222, 219, 220, 217, 216, 212, 209, 210, 196, 169, 169, 173,\n       179, 209, 235, 248, 252, 249, 251, 252, 253, 251, 254, 251, 254,\n       254, 255, 255, 253, 255, 255, 255, 255, 255, 254, 251, 254, 255,\n       255, 255, 255, 254, 255, 255, 255, 255, 254, 255, 255, 255, 255,\n       255, 255, 255], dtype=uint8), array([4.75818342])], [array([251, 254, 249, 252, 255, 255, 255, 255, 254, 253, 253, 253, 252,\n       250, 254, 255, 253, 253, 254, 254, 254, 253, 252, 251, 255, 255,\n       255, 254, 253, 254, 250, 251, 255, 255, 252, 253, 252, 251, 254,\n       253, 255, 252, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 243, 223, 203, 195, 201, 211, 212, 213, 216,\n       214, 214, 213, 213, 216, 218, 219, 224, 229, 232, 238, 241, 243,\n       247, 249, 248, 250, 250, 251, 253, 254, 255, 254, 254, 254, 255,\n       255, 255, 254, 255, 255, 252, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 254, 255, 253, 254, 253, 253, 250, 246, 244, 242, 241,\n       240, 238, 241], dtype=uint8), array([3.84824603])], [array([249, 248, 248, 247, 250, 250, 249, 248, 245, 249, 251, 246, 243,\n       241, 241, 243, 245, 247, 248, 247, 244, 246, 246, 245, 246, 247,\n       247, 246, 243, 246, 248, 247, 249, 247, 247, 250, 246, 249, 249,\n       249, 250, 249, 249, 251, 249, 250, 250, 250, 253, 250, 251, 254,\n       249, 252, 255, 253, 254, 254, 251, 245, 243, 239, 229, 218, 213,\n       208, 195, 177, 171, 181, 185, 185, 181, 175, 172, 174, 176, 178,\n       181, 187, 190, 192, 201, 200, 203, 209, 213, 217, 221, 226, 230,\n       229, 233, 236, 235, 240, 243, 245, 246, 249, 249, 249, 249, 252,\n       251, 253, 252, 253, 254, 253, 252, 252, 252, 251, 254, 252, 254,\n       254, 254, 254], dtype=uint8), array([6.3266849])], [array([208, 213, 214, 218, 219, 218, 221, 222, 223, 224, 226, 226, 228,\n       231, 226, 232, 231, 235, 233, 238, 239, 240, 239, 243, 244, 244,\n       246, 247, 248, 252, 249, 252, 253, 248, 245, 244, 248, 247, 250,\n       250, 250, 250, 253, 251, 251, 250, 247, 251, 249, 248, 252, 249,\n       249, 246, 246, 244, 237, 234, 220, 210, 208, 213, 223, 232, 232,\n       231, 232, 228, 226, 226, 227, 226, 216, 193, 170, 155, 147, 136,\n       148, 173, 184, 191, 196, 200, 203, 205, 210, 214, 218, 222, 223,\n       229, 231, 235, 236, 238, 241, 241, 243, 247, 247, 249, 253, 252,\n       254, 254, 253, 252, 253, 252, 253, 255, 252, 254, 250, 249, 254,\n       255, 254, 254], dtype=uint8), array([5.48232787])], [array([211, 206, 211, 213, 214, 215, 217, 217, 219, 221, 220, 220, 224,\n       226, 227, 227, 228, 229, 231, 230, 232, 231, 229, 235, 235, 232,\n       239, 238, 236, 237, 245, 244, 242, 237, 240, 237, 234, 234, 236,\n       246, 244, 244, 244, 246, 241, 246, 243, 246, 245, 246, 245, 244,\n       249, 240, 247, 247, 250, 246, 244, 245, 248, 250, 250, 245, 249,\n       249, 251, 252, 250, 254, 253, 254, 252, 245, 234, 225, 203, 183,\n       172, 177, 187, 192, 196, 196, 196, 197, 199, 202, 201, 204, 206,\n       213, 210, 212, 220, 220, 222, 223, 226, 228, 232, 231, 237, 239,\n       242, 242, 243, 245, 244, 243, 246, 250, 247, 249, 248, 251, 250,\n       248, 250, 251], dtype=uint8), array([4.22418291])], [array([255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 253, 252, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255], dtype=uint8), array([0.])], [array([255, 255, 255, 255, 255, 254, 254, 254, 255, 255, 255, 255, 255,\n       254, 255, 255, 255, 254, 255, 255, 254, 254, 255, 254, 255, 252,\n       255, 255, 255, 255, 255, 255, 255, 251, 253, 254, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 253,\n       243, 232, 211, 199, 198, 208, 218, 218, 218, 218, 220, 219, 222,\n       225, 229, 233, 232, 237, 239, 243, 244, 246, 246, 248, 252, 253,\n       253, 253, 254, 254, 255, 255, 254, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255], dtype=uint8), array([3.71157107])], [array([255, 255, 255, 255, 255, 255, 255, 255, 255, 253, 254, 255, 255,\n       255, 255, 255, 254, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 254, 255,\n       251, 253, 251, 245, 246, 244, 237, 239, 242, 249, 253, 253, 254,\n       252, 254, 255, 255, 254, 253, 255, 255, 255, 255, 254, 254, 253,\n       254, 252, 248, 247, 245, 241, 231, 215, 191, 178, 179, 168, 189,\n       217, 220, 220, 224, 227, 228, 232, 237, 236, 241, 240, 242, 248,\n       248, 251, 254, 255, 254, 254, 252, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       253, 255, 255], dtype=uint8), array([4.08382213])], [array([255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 253, 253, 255, 255, 255, 255, 255,\n       253, 252, 253, 248, 245, 244, 237, 235, 213, 185, 174, 176, 201,\n       231, 248, 251, 252, 253, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 254, 254, 255, 255, 255, 255, 253,\n       253, 251, 255, 253, 255, 251, 249, 246, 240, 236, 223, 213, 207,\n       199, 203, 202], dtype=uint8), array([3.69767209])], [array([253, 253, 254, 255, 252, 251, 251, 250, 253, 252, 254, 253, 255,\n       255, 255, 252, 252, 250, 243, 233, 221, 214, 211, 211, 218, 227,\n       225, 224, 219, 213, 210, 207, 202, 198, 194, 193, 191, 182, 178,\n       174, 170, 176, 184, 193, 200, 209, 216, 221, 222, 224, 224, 226,\n       226, 231, 230, 229, 232, 236, 237, 239, 242, 242, 242, 245, 243,\n       245, 246, 246, 241, 232, 217, 195, 179, 176, 189, 203, 208, 205,\n       207, 203, 202, 198, 202, 200, 204, 209, 211, 215, 217, 221, 223,\n       226, 227, 229, 233, 235, 241, 242, 241, 241, 243, 247, 247, 248,\n       249, 250, 252, 252, 254, 254, 252, 250, 250, 253, 253, 253, 254,\n       252, 253, 253], dtype=uint8), array([4.18255064])], [array([255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 253, 255, 255, 255, 255, 255, 254,\n       253, 253, 250, 255, 255, 255, 255, 255, 254, 255, 255, 255, 255,\n       252, 252, 255, 254, 251, 248, 254, 249, 247, 241, 241, 243, 241,\n       238, 233, 232, 228, 226, 221, 220, 216, 215, 211, 210, 207, 204,\n       205, 203, 195, 179, 137, 122, 135, 144, 140, 147, 178, 212, 223,\n       228, 229, 236, 240, 239, 240, 247, 246, 246, 250, 249, 253, 254,\n       251, 255, 255, 255, 255, 255, 255, 255, 255, 250, 243, 255, 255,\n       255, 255, 255, 255, 255, 254, 255, 255, 255, 255, 255, 252, 254,\n       255, 255, 255], dtype=uint8), array([9.01671984])], [array([224, 223, 222, 223, 223, 223, 227, 229, 226, 226, 226, 226, 227,\n       228, 223, 225, 223, 226, 221, 224, 223, 221, 223, 221, 222, 224,\n       219, 219, 220, 219, 219, 221, 219, 217, 218, 216, 212, 216, 216,\n       214, 216, 214, 213, 210, 196, 185, 170, 169, 171, 182, 188, 195,\n       203, 211, 212, 214, 209, 213, 212, 215, 216, 213, 203, 186, 177,\n       176, 171, 180, 207, 229, 241, 247, 248, 246, 249, 252, 248, 253,\n       253, 254, 252, 253, 254, 253, 254, 253, 255, 252, 252, 252, 251,\n       250, 252, 250, 249, 251, 251, 249, 250, 251, 253, 251, 251, 251,\n       251, 247, 253, 250, 253, 252, 251, 252, 253, 254, 251, 251, 252,\n       254, 252, 249], dtype=uint8), array([6.47364817])], [array([253, 252, 251, 253, 253, 250, 248, 250, 252, 251, 250, 249, 251,\n       254, 249, 255, 250, 250, 250, 251, 251, 250, 249, 251, 250, 250,\n       251, 251, 252, 254, 252, 250, 248, 252, 251, 251, 252, 252, 252,\n       250, 250, 253, 253, 251, 252, 252, 254, 254, 251, 252, 254, 254,\n       249, 249, 255, 253, 255, 254, 255, 254, 255, 255, 254, 252, 253,\n       255, 254, 254, 255, 254, 250, 245, 220, 201, 187, 182, 192, 207,\n       214, 218, 220, 218, 221, 222, 221, 220, 219, 222, 223, 225, 225,\n       228, 229, 231, 232, 237, 237, 239, 241, 242, 243, 244, 248, 247,\n       246, 250, 251, 251, 251, 251, 250, 251, 251, 252, 250, 252, 253,\n       251, 253, 254], dtype=uint8), array([4.51710674])], [array([255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 254, 254, 254, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 254, 251, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 254, 251, 247, 241, 230, 235,\n       241, 238, 242, 238, 245, 245, 245, 249, 246, 248, 250, 253, 254,\n       255, 255, 255, 255, 255, 255, 255, 253, 254, 255, 255, 255, 255,\n       254, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255], dtype=uint8), array([4.88037655])], [array([255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 254, 250, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 254, 253, 254, 253, 254, 251, 254, 255,\n       255, 254, 254, 253, 254, 254, 254, 254, 254, 253, 248, 249, 252,\n       252, 254, 254, 251, 255, 255, 255, 255, 254, 252, 251, 247, 249,\n       252, 253, 255, 255, 255, 255, 254, 255, 255, 255, 253, 255, 254,\n       254, 255, 255, 255, 255, 255, 255, 255, 254, 254, 255, 255, 255,\n       255, 255, 255], dtype=uint8), array([4.75318777])], [array([255, 255, 255, 255, 255, 255, 255, 255, 254, 255, 255, 255, 255,\n       255, 255, 254, 253, 252, 250, 251, 252, 249, 249, 244, 244, 243,\n       244, 241, 236, 236, 232, 228, 230, 226, 223, 225, 217, 214, 215,\n       214, 213, 212, 212, 212, 211, 212, 203, 184, 174, 182, 200, 222,\n       239, 252, 254, 253, 250, 254, 254, 253, 255, 255, 254, 253, 255,\n       255, 255, 255, 254, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 254, 254,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 253, 252, 254, 255,\n       254, 255, 252, 243, 251, 253, 254, 255, 255, 254, 255, 253, 252,\n       255, 255, 255], dtype=uint8), array([4.67930649])], [array([255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 254, 255,\n       255, 252, 255, 255, 255, 251, 253, 255, 255, 255, 255, 255, 255,\n       253, 253, 254, 254, 252, 255, 254, 254, 254, 254, 253, 250, 250,\n       253, 254, 254, 251, 251, 253, 253, 252, 254, 255, 254, 254, 254,\n       253, 250, 250, 247, 248, 246, 243, 243, 242, 244, 240, 238, 237,\n       231, 227, 215, 209, 214, 224, 231, 231, 233, 235, 238, 238, 240,\n       239, 247, 243, 245, 246, 248, 247, 251, 253, 252, 253, 253, 253,\n       255, 253, 252, 254, 254, 253, 254, 255, 255, 254, 254, 255, 255,\n       252, 255, 255, 255, 253, 254, 254, 255, 253, 254, 255, 255, 255,\n       254, 253, 255], dtype=uint8), array([3.66342182])], [array([233, 229, 233, 233, 231, 230, 231, 232, 230, 231, 232, 232, 231,\n       231, 230, 231, 232, 231, 230, 231, 234, 234, 231, 229, 233, 231,\n       231, 235, 231, 231, 235, 232, 230, 232, 232, 231, 232, 230, 231,\n       230, 232, 231, 234, 229, 230, 228, 235, 232, 231, 229, 229, 231,\n       228, 228, 230, 230, 227, 225, 226, 227, 227, 227, 226, 225, 225,\n       222, 221, 219, 216, 213, 206, 189, 164, 144, 146, 154, 142, 114,\n       101, 113, 118, 117, 119, 127, 133, 139, 141, 141, 145, 147, 150,\n       152, 159, 166, 170, 175, 181, 184, 188, 189, 191, 191, 195, 198,\n       204, 206, 207, 210, 214, 216, 215, 219, 220, 222, 223, 222, 224,\n       228, 229, 231], dtype=uint8), array([11.24816955])], [array([242, 240, 240, 243, 243, 243, 236, 235, 235, 236, 238, 239, 239,\n       238, 239, 237, 236, 233, 231, 229, 230, 226, 227, 224, 221, 219,\n       217, 213, 213, 211, 209, 210, 206, 202, 200, 199, 199, 199, 197,\n       195, 198, 198, 199, 202, 205, 209, 209, 205, 198, 178, 161, 163,\n       179, 204, 222, 235, 244, 248, 243, 243, 242, 244, 241, 238, 240,\n       240, 240, 241, 241, 241, 240, 238, 237, 239, 241, 242, 239, 237,\n       236, 237, 237, 234, 238, 237, 237, 235, 234, 235, 236, 236, 233,\n       234, 235, 233, 234, 233, 233, 234, 236, 235, 233, 234, 233, 231,\n       235, 234, 236, 238, 240, 235, 233, 235, 235, 234, 233, 234, 236,\n       232, 234, 237], dtype=uint8), array([5.29607184])], [array([239, 239, 243, 239, 240, 241, 239, 236, 237, 238, 238, 238, 240,\n       239, 237, 236, 236, 233, 235, 231, 236, 235, 234, 234, 230, 231,\n       229, 225, 226, 226, 219, 217, 216, 213, 209, 206, 204, 202, 200,\n       195, 193, 191, 189, 187, 187, 189, 189, 189, 188, 189, 186, 178,\n       164, 155, 165, 183, 203, 221, 239, 243, 247, 243, 244, 246, 242,\n       242, 242, 241, 243, 243, 242, 242, 241, 239, 241, 242, 238, 240,\n       240, 238, 238, 241, 236, 239, 241, 238, 237, 237, 237, 236, 235,\n       235, 234, 235, 233, 230, 230, 229, 232, 230, 229, 227, 228, 229,\n       227, 227, 228, 226, 227, 228, 228, 233, 232, 233, 236, 236, 235,\n       236, 234, 233], dtype=uint8), array([5.46791157])], [array([237, 242, 240, 239, 238, 237, 235, 239, 240, 240, 240, 242, 241,\n       241, 238, 239, 238, 239, 237, 238, 235, 233, 233, 230, 231, 227,\n       225, 226, 222, 222, 220, 218, 216, 215, 213, 210, 209, 206, 204,\n       204, 201, 197, 194, 193, 192, 188, 190, 187, 185, 188, 192, 196,\n       197, 197, 193, 183, 169, 167, 182, 201, 215, 222, 239, 244, 240,\n       241, 240, 242, 243, 245, 242, 243, 241, 240, 239, 239, 241, 240,\n       240, 239, 237, 239, 240, 240, 240, 243, 237, 238, 241, 241, 240,\n       242, 239, 241, 239, 239, 238, 241, 240, 240, 242, 240, 239, 241,\n       238, 240, 238, 239, 241, 243, 238, 241, 239, 239, 237, 240, 240,\n       236, 236, 227], dtype=uint8), array([5.45620238])], [array([255, 255, 254, 255, 255, 255, 255, 248, 249, 255, 255, 255, 255,\n       254, 255, 255, 254, 254, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       254, 254, 254, 253, 254, 254, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 254,\n       254, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255], dtype=uint8), array([0.])], [array([229, 237, 245, 246, 252, 255, 253, 254, 255, 254, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       254, 252, 255, 255, 255, 255, 255, 255, 255, 255, 254, 255, 255,\n       255, 253, 254, 248, 236, 204, 174, 169, 164, 151, 129, 107, 107,\n       123, 127, 126, 135, 148, 159, 163, 167, 172, 178, 189, 194, 199,\n       198, 206, 209, 211, 216, 227, 231, 232, 237, 240, 244, 247, 250,\n       249, 253, 250, 254, 254, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255], dtype=uint8), array([11.65322989])], [array([255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 253, 250,\n       245, 239, 232, 231, 212, 201, 183, 151, 151, 169, 173, 162, 144,\n       135, 143, 158, 174, 185, 187, 191, 197, 200, 206, 212, 217, 222,\n       228, 227, 236, 237, 238, 242, 243, 248, 251, 253, 253, 255, 255,\n       254, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255], dtype=uint8), array([11.24816955])], [array([255, 255, 255, 255, 255, 255, 255, 253, 254, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 254, 254, 254, 254,\n       253, 247, 244, 244, 240, 234, 228, 217, 201, 188, 172, 164, 167,\n       165, 156, 138, 130, 141, 171, 205, 233, 244, 252, 254, 255, 254,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 248, 254, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255], dtype=uint8), array([5.29607184])], [array([255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 254, 249, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 248, 236,\n       218, 200, 184, 170, 183, 205, 215, 217, 221, 224, 225, 229, 234,\n       236, 241, 246, 248, 251, 253, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 254, 254, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255], dtype=uint8), array([5.46791157])], [array([255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 253, 239, 215, 193, 169, 153, 152, 172, 194, 204, 207, 211,\n       212, 212, 218, 225, 233, 238, 238, 243, 251, 249, 254, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255], dtype=uint8), array([5.45620238])], [array([255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 253, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255], dtype=uint8), array([3.54463004])], [array([243, 240, 236, 237, 240, 243, 239, 244, 248, 246, 247, 244, 239,\n       241, 249, 251, 251, 249, 246, 246, 243, 239, 245, 246, 243, 244,\n       242, 241, 242, 242, 247, 245, 246, 250, 245, 246, 247, 246, 243,\n       249, 244, 250, 249, 248, 247, 244, 244, 246, 242, 244, 245, 245,\n       241, 238, 238, 237, 235, 233, 231, 226, 222, 221, 217, 214, 210,\n       205, 203, 199, 195, 191, 189, 186, 186, 188, 186, 178, 157, 138,\n       150, 177, 208, 233, 246, 246, 250, 247, 248, 250, 248, 248, 246,\n       244, 246, 243, 242, 241, 239, 239, 243, 240, 239, 242, 240, 236,\n       236, 238, 237, 236, 235, 234, 235, 233, 232, 229, 230, 233, 230,\n       228, 228, 224], dtype=uint8), array([4.51179147])], [array([253, 254, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 252, 255, 255, 255, 255, 255, 255, 255, 253, 255, 255, 255,\n       255, 255, 253, 253, 254, 254, 252, 253, 250, 251, 248, 247, 248,\n       241, 243, 241, 239, 239, 238, 239, 241, 238, 233, 233, 231, 229,\n       230, 233, 230, 230, 229, 229, 225, 220, 215, 204, 195, 196, 204,\n       224, 247, 254, 255, 255, 255, 255, 255, 255, 255, 254, 251, 251,\n       252, 252, 253, 251, 251, 250, 249, 247, 246, 249, 250, 247, 247,\n       245, 245, 246, 244, 244, 244, 243, 240, 240, 241, 242, 241, 240,\n       241, 239, 238, 240, 244, 245, 243, 244, 248, 246, 246, 244, 242,\n       244, 246, 246], dtype=uint8), array([4.37560143])], [array([254, 255, 255, 249, 254, 255, 255, 253, 254, 254, 252, 250, 251,\n       250, 250, 251, 252, 254, 255, 254, 252, 251, 252, 253, 254, 253,\n       253, 249, 252, 255, 254, 252, 252, 252, 249, 249, 248, 249, 248,\n       248, 248, 248, 250, 247, 246, 246, 245, 251, 247, 244, 244, 243,\n       240, 240, 240, 239, 237, 233, 233, 227, 227, 225, 226, 221, 217,\n       216, 213, 209, 206, 200, 200, 207, 209, 205, 202, 194, 168, 149,\n       163, 190, 215, 231, 244, 253, 253, 248, 250, 248, 247, 247, 249,\n       249, 245, 244, 244, 241, 239, 237, 238, 236, 240, 235, 237, 237,\n       238, 241, 237, 237, 240, 239, 236, 237, 238, 237, 238, 238, 242,\n       237, 238, 240], dtype=uint8), array([3.95002995])], [array([243, 246, 246, 243, 242, 241, 244, 243, 243, 243, 244, 246, 245,\n       242, 243, 241, 241, 239, 240, 239, 241, 237, 241, 240, 240, 241,\n       240, 243, 242, 240, 240, 243, 242, 240, 242, 242, 237, 241, 246,\n       242, 241, 242, 240, 240, 239, 241, 237, 239, 241, 238, 237, 238,\n       237, 235, 236, 235, 234, 229, 225, 224, 220, 216, 214, 215, 212,\n       212, 213, 207, 203, 200, 197, 197, 195, 193, 178, 166, 172, 199,\n       227, 241, 245, 245, 248, 249, 245, 246, 244, 242, 241, 239, 234,\n       231, 227, 226, 224, 217, 214, 213, 210, 210, 210, 211, 212, 217,\n       222, 226, 230, 231, 230, 230, 231, 231, 225, 226, 228, 224, 222,\n       223, 226, 223], dtype=uint8), array([3.53048839])], [array([215, 212, 212, 211, 212, 210, 206, 205, 202, 205, 204, 199, 199,\n       198, 195, 198, 199, 199, 194, 196, 188, 182, 180, 178, 181, 181,\n       179, 177, 179, 182, 184, 185, 186, 182, 178, 175, 185, 197, 207,\n       209, 212, 216, 215, 211, 210, 206, 204, 202, 201, 206, 210, 212,\n       215, 219, 218, 220, 217, 217, 212, 213, 208, 196, 178, 168, 176,\n       202, 229, 245, 250, 252, 249, 251, 249, 248, 248, 247, 247, 246,\n       248, 247, 244, 244, 244, 247, 243, 241, 241, 242, 243, 246, 246,\n       246, 247, 244, 240, 240, 237, 238, 239, 238, 240, 240, 238, 241,\n       242, 246, 245, 236, 232, 232, 232, 228, 210, 195, 183, 197, 213,\n       228, 234, 234], dtype=uint8), array([3.67640104])], [array([237, 238, 236, 240, 235, 236, 233, 232, 233, 236, 238, 233, 235,\n       235, 235, 234, 234, 233, 234, 234, 238, 236, 235, 236, 238, 237,\n       236, 236, 235, 234, 237, 232, 230, 230, 232, 229, 229, 228, 228,\n       225, 224, 219, 216, 211, 210, 207, 208, 202, 194, 191, 184, 181,\n       179, 172, 170, 166, 163, 162, 159, 150, 143, 136, 131, 127, 124,\n       117, 109, 109, 118, 132, 146, 168, 184, 191, 200, 221, 246, 254,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 254, 255, 252, 249,\n       252, 249, 246, 248, 241, 239, 241, 237, 234, 231, 226, 231, 232,\n       228, 230, 229, 227, 225, 224, 226, 228, 226, 227, 224, 225, 224,\n       226, 222, 225], dtype=uint8), array([8.97995119])], [array([243, 243, 246, 242, 242, 239, 241, 238, 236, 240, 241, 238, 234,\n       235, 233, 239, 237, 233, 238, 235, 235, 229, 232, 230, 231, 232,\n       231, 229, 231, 232, 228, 228, 226, 228, 233, 227, 227, 228, 227,\n       227, 231, 232, 227, 227, 226, 224, 219, 214, 200, 180, 162, 148,\n       137, 154, 179, 193, 199, 202, 204, 207, 209, 211, 214, 213, 213,\n       217, 219, 224, 223, 226, 230, 224, 226, 228, 233, 231, 229, 230,\n       229, 229, 231, 233, 230, 229, 231, 231, 232, 234, 229, 232, 233,\n       232, 232, 232, 232, 232, 233, 231, 231, 232, 230, 233, 231, 231,\n       231, 232, 230, 232, 232, 233, 235, 231, 228, 230, 231, 229, 230,\n       232, 231, 228], dtype=uint8), array([5.35827466])], [array([237, 239, 240, 239, 235, 241, 243, 242, 244, 246, 244, 245, 247,\n       247, 245, 246, 246, 247, 248, 248, 246, 248, 250, 247, 248, 249,\n       248, 244, 246, 248, 249, 249, 249, 249, 245, 241, 234, 235, 235,\n       236, 237, 236, 240, 242, 244, 242, 244, 245, 246, 250, 250, 249,\n       251, 249, 249, 249, 249, 250, 248, 249, 251, 245, 244, 241, 237,\n       237, 235, 236, 224, 203, 178, 170, 184, 185, 174, 163, 150, 148,\n       150, 156, 161, 164, 167, 171, 170, 174, 177, 178, 178, 182, 184,\n       186, 188, 189, 192, 190, 191, 195, 194, 195, 199, 198, 199, 199,\n       197, 196, 196, 198, 203, 202, 200, 200, 200, 201, 203, 205, 203,\n       205, 203, 203], dtype=uint8), array([8.97995119])], [array([198, 198, 203, 201, 204, 206, 206, 205, 209, 209, 210, 212, 213,\n       213, 212, 213, 213, 212, 209, 214, 212, 211, 212, 213, 214, 212,\n       209, 207, 207, 209, 207, 201, 203, 204, 201, 198, 196, 197, 197,\n       196, 196, 199, 198, 197, 199, 198, 195, 178, 155, 155, 171, 186,\n       202, 224, 242, 252, 251, 251, 248, 250, 250, 253, 248, 246, 247,\n       247, 248, 247, 246, 243, 243, 246, 246, 244, 245, 246, 245, 245,\n       246, 247, 246, 246, 243, 242, 243, 243, 245, 245, 243, 245, 241,\n       245, 244, 244, 246, 244, 244, 247, 248, 246, 248, 245, 247, 246,\n       244, 244, 242, 242, 244, 243, 238, 238, 239, 236, 221, 203, 194,\n       196, 208, 226], dtype=uint8), array([5.35827466])], [array([247, 252, 253, 255, 255, 251, 252, 253, 251, 249, 251, 252, 251,\n       251, 254, 253, 250, 252, 252, 253, 251, 248, 253, 251, 250, 250,\n       250, 247, 248, 249, 250, 251, 251, 250, 249, 249, 249, 250, 253,\n       249, 245, 247, 248, 249, 248, 245, 246, 246, 247, 244, 246, 245,\n       244, 247, 245, 244, 244, 244, 241, 237, 237, 240, 238, 238, 242,\n       238, 240, 241, 240, 240, 237, 237, 234, 229, 218, 199, 184, 179,\n       183, 202, 207, 206, 208, 206, 203, 201, 202, 201, 203, 202, 202,\n       203, 202, 203, 203, 202, 201, 198, 199, 201, 201, 201, 199, 198,\n       198, 198, 196, 198, 197, 194, 195, 195, 195, 194, 198, 195, 196,\n       198, 195, 194], dtype=uint8), array([3.76287851])], [array([255, 255, 255, 254, 254, 255, 254, 253, 253, 254, 252, 255, 255,\n       255, 255, 255, 255, 254, 253, 254, 255, 255, 255, 255, 255, 254,\n       252, 247, 243, 244, 247, 243, 246, 248, 248, 245, 242, 242, 243,\n       237, 229, 227, 229, 234, 239, 245, 245, 244, 247, 246, 250, 250,\n       251, 254, 253, 253, 255, 255, 254, 254, 253, 254, 254, 255, 255,\n       253, 255, 255, 255, 255, 255, 253, 252, 242, 235, 237, 242, 241,\n       239, 234, 237, 237, 235, 238, 236, 238, 239, 239, 240, 243, 247,\n       248, 246, 249, 251, 250, 252, 248, 246, 255, 255, 255, 255, 253,\n       254, 252, 253, 254, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255], dtype=uint8), array([3.04808728])], [array([251, 251, 254, 254, 255, 255, 255, 254, 253, 255, 255, 255, 254,\n       253, 255, 255, 255, 255, 255, 255, 255, 255, 255, 254, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 254, 248, 251, 246, 235, 212, 201, 195, 195,\n       214, 221, 224, 228, 225, 229, 229, 227, 229, 231, 233, 233, 233,\n       232, 230, 237, 235, 234, 237, 238, 239, 238, 240, 239, 240, 238,\n       241, 241, 240, 242, 241, 242, 238, 236, 237, 233, 231, 234, 232,\n       228, 230, 227], dtype=uint8), array([3.04562947])], [array([255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 254, 255, 254, 252, 247, 238, 220, 190, 178, 192, 218, 237,\n       246, 251, 253, 255, 254, 251, 250, 251, 249, 247, 248, 249, 245,\n       246, 244, 243, 241, 244, 241, 240, 238, 237, 239, 240, 238, 238,\n       238, 239, 236, 232, 232, 229, 224, 224, 210, 204, 198, 186, 171,\n       152, 136, 132], dtype=uint8), array([3.06895321])], [array([255, 255, 255, 255, 254, 251, 255, 255, 254, 253, 255, 253, 252,\n       247, 243, 237, 232, 222, 209, 190, 176, 169, 165, 171, 176, 183,\n       185, 181, 177, 183, 192, 210, 219, 227, 229, 238, 242, 244, 245,\n       246, 245, 246, 249, 250, 250, 252, 251, 250, 249, 240, 239, 233,\n       222, 211, 211, 223, 237, 248, 252, 254, 255, 254, 253, 254, 253,\n       254, 255, 253, 252, 255, 254, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       254, 255, 255, 255, 255, 255, 254, 250, 247, 246, 242, 246, 242,\n       237, 234, 234], dtype=uint8), array([2.85702873])], [array([233, 234, 235, 233, 233, 235, 234, 234, 236, 236, 236, 233, 236,\n       236, 235, 233, 233, 233, 235, 236, 234, 231, 234, 233, 234, 236,\n       234, 232, 239, 234, 233, 235, 235, 238, 233, 234, 232, 230, 228,\n       234, 235, 232, 237, 235, 234, 236, 237, 240, 242, 235, 233, 233,\n       233, 233, 232, 234, 233, 237, 235, 234, 235, 234, 236, 239, 237,\n       237, 241, 241, 240, 241, 243, 245, 245, 246, 248, 248, 248, 247,\n       239, 226, 204, 182, 176, 188, 196, 200, 201, 204, 201, 199, 198,\n       197, 196, 197, 197, 200, 200, 205, 208, 208, 210, 212, 215, 214,\n       219, 223, 225, 227, 227, 229, 233, 235, 234, 238, 232, 235, 236,\n       237, 236, 238], dtype=uint8), array([4.51179147])], [array([251, 251, 252, 253, 254, 254, 251, 248, 247, 247, 246, 244, 242,\n       239, 236, 233, 228, 226, 227, 225, 223, 224, 221, 219, 213, 207,\n       206, 197, 190, 179, 169, 162, 166, 168, 173, 181, 184, 189, 195,\n       199, 196, 198, 201, 199, 200, 206, 207, 208, 204, 209, 209, 210,\n       211, 211, 209, 210, 211, 207, 204, 189, 166, 155, 155, 159, 170,\n       189, 194, 193, 191, 190, 188, 188, 188, 185, 187, 187, 187, 187,\n       190, 193, 192, 192, 195, 196, 197, 198, 200, 204, 207, 207, 209,\n       214, 217, 215, 216, 216, 216, 218, 220, 224, 225, 223, 223, 225,\n       230, 229, 230, 230, 231, 230, 234, 234, 234, 234, 234, 233, 237,\n       234, 237, 235], dtype=uint8), array([4.37560143])], [array([204, 200, 197, 196, 192, 192, 189, 188, 186, 186, 186, 187, 186,\n       190, 189, 191, 193, 193, 193, 193, 196, 193, 195, 197, 195, 197,\n       201, 201, 204, 206, 206, 205, 207, 207, 205, 205, 210, 210, 211,\n       211, 215, 217, 219, 217, 218, 221, 222, 223, 221, 222, 225, 226,\n       227, 227, 223, 225, 226, 222, 231, 228, 230, 229, 228, 233, 235,\n       237, 237, 237, 239, 240, 242, 243, 246, 246, 247, 248, 245, 242,\n       232, 215, 190, 170, 167, 183, 193, 198, 202, 202, 200, 199, 201,\n       202, 203, 206, 208, 210, 213, 216, 218, 219, 225, 226, 230, 232,\n       232, 237, 237, 239, 243, 242, 243, 244, 243, 244, 245, 245, 244,\n       243, 244, 246], dtype=uint8), array([3.95002995])], [array([228, 227, 227, 228, 232, 235, 236, 237, 238, 238, 241, 241, 240,\n       239, 243, 243, 245, 244, 244, 245, 246, 248, 249, 246, 250, 250,\n       247, 248, 244, 246, 251, 249, 245, 248, 246, 249, 251, 248, 249,\n       250, 251, 248, 247, 252, 253, 251, 247, 250, 249, 247, 246, 248,\n       252, 251, 249, 249, 252, 247, 252, 255, 253, 250, 251, 248, 248,\n       244, 246, 247, 249, 251, 253, 248, 252, 253, 253, 249, 243, 235,\n       222, 212, 212, 222, 226, 229, 226, 228, 225, 223, 225, 224, 221,\n       224, 224, 229, 227, 231, 236, 237, 239, 242, 243, 243, 246, 250,\n       240, 240, 237, 237, 232, 228, 231, 233, 235, 235, 236, 237, 236,\n       238, 235, 235], dtype=uint8), array([3.53048839])], [array([253, 251, 253, 253, 251, 254, 255, 255, 255, 254, 255, 255, 255,\n       255, 255, 255, 253, 254, 252, 251, 249, 245, 246, 249, 247, 247,\n       252, 251, 249, 246, 246, 248, 248, 241, 244, 246, 250, 251, 251,\n       253, 253, 251, 252, 253, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 254, 254, 253, 250, 247, 240, 233, 221, 211, 198,\n       202, 219, 229, 232, 236, 238, 238, 238, 237, 240, 242, 243, 246,\n       245, 242, 240, 240, 241, 241, 240, 243, 242, 240, 238, 239, 241,\n       242, 239, 239, 235, 227, 224, 223, 228, 232, 233, 231, 234, 239,\n       239, 240, 244, 242, 247, 248, 249, 250, 247, 248, 251, 249, 248,\n       249, 251, 251], dtype=uint8), array([3.67640104])], [array([248, 248, 247, 247, 247, 246, 242, 242, 245, 246, 245, 240, 243,\n       245, 240, 240, 239, 238, 239, 242, 240, 239, 241, 240, 237, 239,\n       240, 236, 239, 239, 238, 235, 236, 236, 238, 239, 237, 238, 235,\n       234, 230, 231, 228, 232, 230, 232, 231, 228, 229, 230, 228, 230,\n       229, 227, 228, 227, 226, 224, 227, 223, 202, 172, 163, 166, 171,\n       192, 214, 219, 219, 222, 220, 222, 221, 226, 230, 234, 233, 233,\n       239, 237, 236, 232, 230, 223, 219, 223, 228, 235, 239, 242, 243,\n       246, 248, 250, 249, 249, 247, 245, 245, 246, 246, 241, 242, 245,\n       248, 245, 248, 249, 249, 251, 251, 248, 250, 249, 247, 249, 250,\n       248, 244, 249], dtype=uint8), array([5.21064103])]] with type list",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [210]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m both_path \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_tensor_slices\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcouple\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcouple\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_feature\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_feature\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_label\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py:793\u001b[0m, in \u001b[0;36mDatasetV2.from_tensor_slices\u001b[0;34m(tensors, name)\u001b[0m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_tensor_slices\u001b[39m(tensors, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    717\u001b[0m   \u001b[38;5;124;03m\"\"\"Creates a `Dataset` whose elements are slices of the given tensors.\u001b[39;00m\n\u001b[1;32m    718\u001b[0m \n\u001b[1;32m    719\u001b[0m \u001b[38;5;124;03m  The given tensors are sliced along their first dimension. This operation\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    791\u001b[0m \u001b[38;5;124;03m    Dataset: A `Dataset`.\u001b[39;00m\n\u001b[1;32m    792\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 793\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mTensorSliceDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py:4477\u001b[0m, in \u001b[0;36mTensorSliceDataset.__init__\u001b[0;34m(self, element, is_files, name)\u001b[0m\n\u001b[1;32m   4475\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, element, is_files\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   4476\u001b[0m   \u001b[38;5;124;03m\"\"\"See `Dataset.from_tensor_slices()` for details.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 4477\u001b[0m   element \u001b[38;5;241m=\u001b[39m \u001b[43mstructure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43melement\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4478\u001b[0m   batched_spec \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mtype_spec_from_value(element)\n\u001b[1;32m   4479\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tensors \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mto_batched_tensor_list(batched_spec, element)\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/data/util/structure.py:107\u001b[0m, in \u001b[0;36mnormalize_element\u001b[0;34m(element, element_signature)\u001b[0m\n\u001b[1;32m    102\u001b[0m     spec \u001b[38;5;241m=\u001b[39m type_spec_from_value(t, use_fallback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    104\u001b[0m   \u001b[38;5;66;03m# TypeError indicates it was not possible to compute a `TypeSpec` for\u001b[39;00m\n\u001b[1;32m    105\u001b[0m   \u001b[38;5;66;03m# the value. As a fallback try converting the value to a tensor.\u001b[39;00m\n\u001b[1;32m    106\u001b[0m   normalized_components\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 107\u001b[0m       \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcomponent_\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    109\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(spec, sparse_tensor\u001b[38;5;241m.\u001b[39mSparseTensorSpec):\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/profiler/trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m Trace(trace_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrace_kwargs):\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1695\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconvert_to_tensor did not convert to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1691\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe preferred dtype: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m vs \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1692\u001b[0m                       (ret\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mbase_dtype, preferred_dtype\u001b[38;5;241m.\u001b[39mbase_dtype))\n\u001b[1;32m   1694\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1695\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mconversion_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1697\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m   1698\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py:343\u001b[0m, in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_tensor_conversion_function\u001b[39m(v, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    341\u001b[0m                                          as_ref\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    342\u001b[0m   _ \u001b[38;5;241m=\u001b[39m as_ref\n\u001b[0;32m--> 343\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py:267\u001b[0m, in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconstant\u001b[39m(value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConst\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    172\u001b[0m   \u001b[38;5;124;03m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \n\u001b[1;32m    174\u001b[0m \u001b[38;5;124;03m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;124;03m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mallow_broadcast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py:279\u001b[0m, in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.constant\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    278\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[0;32m--> 279\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_eager_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    281\u001b[0m g \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mget_default_graph()\n\u001b[1;32m    282\u001b[0m tensor_value \u001b[38;5;241m=\u001b[39m attr_value_pb2\u001b[38;5;241m.\u001b[39mAttrValue()\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py:304\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_eager_impl\u001b[39m(ctx, value, dtype, shape, verify_shape):\n\u001b[1;32m    303\u001b[0m   \u001b[38;5;124;03m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 304\u001b[0m   t \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_eager_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    101\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: Can't convert non-rectangular Python sequence to Tensor."
     ]
    }
   ],
   "source": [
    "both_path = tf.data.Dataset.from_tensor_slices(\n",
    "        [list(couple) for couple in zip([np.array(train_feature[i,:]) for i in range(len(train_feature))], train_label)]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "b7a02141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(527, 120)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "75695e35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([527, 80, 1])"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_augmentation(train_feature).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "9e848b4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([527, 80, 1])"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_augmentation(train_feature).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "50a9c35a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "in user code:\n\n    File \"/tmp/ipykernel_21812/3081659417.py\", line 2, in None  *\n        lambda x: np.expand_dims(x, 0)\n    File \"<__array_function__ internals>\", line 180, in expand_dims  **\n        \n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/numpy/lib/shape_base.py\", line 591, in expand_dims\n        a = asanyarray(a)\n\n    NotImplementedError: Cannot convert a symbolic Tensor (args_0:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [230]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m d1 \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mfrom_tensor_slices(train_feature)\n\u001b[0;32m----> 2\u001b[0m d1_ \u001b[38;5;241m=\u001b[39m \u001b[43md1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand_dims\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py:2016\u001b[0m, in \u001b[0;36mDatasetV2.map\u001b[0;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m   2013\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m deterministic \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m DEBUG_MODE:\n\u001b[1;32m   2014\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `deterministic` argument has no effect unless the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2015\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`num_parallel_calls` argument is specified.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2016\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mMapDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreserve_cardinality\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2017\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2018\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m ParallelMapDataset(\n\u001b[1;32m   2019\u001b[0m       \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2020\u001b[0m       map_func,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2023\u001b[0m       preserve_cardinality\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   2024\u001b[0m       name\u001b[38;5;241m=\u001b[39mname)\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py:5191\u001b[0m, in \u001b[0;36mMapDataset.__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[1;32m   5189\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_inter_op_parallelism \u001b[38;5;241m=\u001b[39m use_inter_op_parallelism\n\u001b[1;32m   5190\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preserve_cardinality \u001b[38;5;241m=\u001b[39m preserve_cardinality\n\u001b[0;32m-> 5191\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func \u001b[38;5;241m=\u001b[39m \u001b[43mstructured_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStructuredFunctionWrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5193\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transformation_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5194\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5195\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_legacy_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_legacy_function\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5196\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata \u001b[38;5;241m=\u001b[39m dataset_metadata_pb2\u001b[38;5;241m.\u001b[39mMetadata()\n\u001b[1;32m   5197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name:\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/data/ops/structured_function.py:271\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m    264\u001b[0m       warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    265\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    266\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    267\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    268\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    269\u001b[0m     fn_factory \u001b[38;5;241m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[0;32m--> 271\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function \u001b[38;5;241m=\u001b[39m \u001b[43mfn_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;66;03m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[1;32m    273\u001b[0m add_to_graph \u001b[38;5;241m&\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly()\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3070\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_concrete_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   3062\u001b[0m   \u001b[38;5;124;03m\"\"\"Returns a `ConcreteFunction` specialized to inputs and execution context.\u001b[39;00m\n\u001b[1;32m   3063\u001b[0m \n\u001b[1;32m   3064\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3068\u001b[0m \u001b[38;5;124;03m       or `tf.Tensor` or `tf.TensorSpec`.\u001b[39;00m\n\u001b[1;32m   3069\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3070\u001b[0m   graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3071\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3072\u001b[0m   graph_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   3073\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3036\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3034\u001b[0m   args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3035\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m-> 3036\u001b[0m   graph_function, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3037\u001b[0m   seen_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[1;32m   3038\u001b[0m   captured \u001b[38;5;241m=\u001b[39m object_identity\u001b[38;5;241m.\u001b[39mObjectIdentitySet(\n\u001b[1;32m   3039\u001b[0m       graph_function\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39minternal_captures)\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3292\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3288\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_define_function_with_shape_relaxation(\n\u001b[1;32m   3289\u001b[0m       args, kwargs, flat_args, filtered_flat_args)\n\u001b[1;32m   3291\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39madd_call_context(cache_key\u001b[38;5;241m.\u001b[39mcall_context)\n\u001b[0;32m-> 3292\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_graph_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3293\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39madd(cache_key, cache_key_deletion_observer,\n\u001b[1;32m   3294\u001b[0m                          graph_function)\n\u001b[1;32m   3296\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function, filtered_flat_args\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3130\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3125\u001b[0m missing_arg_names \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   3126\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (arg, i) \u001b[38;5;28;01mfor\u001b[39;00m i, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(missing_arg_names)\n\u001b[1;32m   3127\u001b[0m ]\n\u001b[1;32m   3128\u001b[0m arg_names \u001b[38;5;241m=\u001b[39m base_arg_names \u001b[38;5;241m+\u001b[39m missing_arg_names\n\u001b[1;32m   3129\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m ConcreteFunction(\n\u001b[0;32m-> 3130\u001b[0m     \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3131\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3132\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3133\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3134\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3135\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3136\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3137\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3138\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3139\u001b[0m \u001b[43m        \u001b[49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3140\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_by_value\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   3141\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_attributes,\n\u001b[1;32m   3142\u001b[0m     function_spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_spec,\n\u001b[1;32m   3143\u001b[0m     \u001b[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[1;32m   3144\u001b[0m     \u001b[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[1;32m   3145\u001b[0m     \u001b[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[1;32m   3146\u001b[0m     \u001b[38;5;66;03m# ConcreteFunction.\u001b[39;00m\n\u001b[1;32m   3147\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   3148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:1161\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1158\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1159\u001b[0m   _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1161\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1163\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1165\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mmap_structure(convert, func_outputs,\n\u001b[1;32m   1166\u001b[0m                                   expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/data/ops/structured_function.py:248\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;129m@eager_function\u001b[39m\u001b[38;5;241m.\u001b[39mdefun_with_attributes(\n\u001b[1;32m    243\u001b[0m     input_signature\u001b[38;5;241m=\u001b[39mstructure\u001b[38;5;241m.\u001b[39mget_flat_tensor_specs(\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_structure),\n\u001b[1;32m    245\u001b[0m     autograph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    246\u001b[0m     attributes\u001b[38;5;241m=\u001b[39mdefun_kwargs)\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_fn\u001b[39m(\u001b[38;5;241m*\u001b[39margs):  \u001b[38;5;66;03m# pylint: disable=missing-docstring\u001b[39;00m\n\u001b[0;32m--> 248\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mwrapper_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    249\u001b[0m   ret \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mto_tensor_list(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_structure, ret)\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m [ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m ret]\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/data/ops/structured_function.py:177\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _should_unpack(nested_args):\n\u001b[1;32m    176\u001b[0m   nested_args \u001b[38;5;241m=\u001b[39m (nested_args,)\n\u001b[0;32m--> 177\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mautograph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtf_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag_ctx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnested_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _should_pack(ret):\n\u001b[1;32m    179\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(ret)\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:692\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    691\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 692\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[1;32m    693\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    694\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: in user code:\n\n    File \"/tmp/ipykernel_21812/3081659417.py\", line 2, in None  *\n        lambda x: np.expand_dims(x, 0)\n    File \"<__array_function__ internals>\", line 180, in expand_dims  **\n        \n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/numpy/lib/shape_base.py\", line 591, in expand_dims\n        a = asanyarray(a)\n\n    NotImplementedError: Cannot convert a symbolic Tensor (args_0:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported\n"
     ]
    }
   ],
   "source": [
    "d1 = tf.data.Dataset.from_tensor_slices(train_feature)\n",
    "d1_ = d1.map(lambda x: np.expand_dims(x, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "9d83d58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 = tf.data.Dataset.from_tensor_slices(train_label)\n",
    "d3 = tf.data.Dataset.zip((d1, d2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "910f3881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 120, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 120, 1), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\"), but it was called on an input with incompatible shape (120,).\n",
      "2022-08-16 18:05:48,465-[WARNING]- tensorflow:665 -> Model was constructed with shape (None, 120, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 120, 1), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\"), but it was called on an input with incompatible shape (120,).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/tmp/ipykernel_21812/1607789451.py\", line 2, in None  *\n        lambda x, y: (data_augmentation(x, training=True), y)\n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/felix/Wks/AMFtrack/amftrack/ml/width/data_augmentation.py\", line 80, in <lambda>\n        lambda x: random_crop_slice(x, original_size, input_size, offset),\n\n    ValueError: Exception encountered when calling layer \"random_crop_with_offset_0\" (type Lambda).\n    \n    in user code:\n    \n        File \"/home/felix/Wks/AMFtrack/amftrack/ml/width/data_augmentation.py\", line 74, in random_crop_slice  *\n            return x[..., start_index : start_index + input_size, :]\n    \n        ValueError: Index out of range using input dim 1; input has only 1 dims for '{{node strided_slice}} = StridedSlice[Index=DT_INT64, T=DT_FLOAT, begin_mask=4, ellipsis_mask=1, end_mask=4, new_axis_mask=0, shrink_axis_mask=0](x, strided_slice/stack, strided_slice/stack_1, strided_slice/Cast)' with input shapes: [120], [3], [3], [3] and with computed input tensors: input[3] = <1 1 1>.\n    \n    \n    Call arguments received:\n      â¢ inputs=tf.Tensor(shape=(120,), dtype=float32)\n      â¢ mask=None\n      â¢ training=True\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [225]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m train \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m----> 2\u001b[0m     \u001b[43md3\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_augmentation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;241m.\u001b[39munbatch()\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;241m.\u001b[39mbatch(BATCHSIZE)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;241m.\u001b[39mprefetch(tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mAUTOTUNE)\n\u001b[1;32m      6\u001b[0m )\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py:2016\u001b[0m, in \u001b[0;36mDatasetV2.map\u001b[0;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m   2013\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m deterministic \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m DEBUG_MODE:\n\u001b[1;32m   2014\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `deterministic` argument has no effect unless the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2015\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`num_parallel_calls` argument is specified.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2016\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mMapDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreserve_cardinality\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2017\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2018\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m ParallelMapDataset(\n\u001b[1;32m   2019\u001b[0m       \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2020\u001b[0m       map_func,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2023\u001b[0m       preserve_cardinality\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   2024\u001b[0m       name\u001b[38;5;241m=\u001b[39mname)\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py:5191\u001b[0m, in \u001b[0;36mMapDataset.__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[1;32m   5189\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_inter_op_parallelism \u001b[38;5;241m=\u001b[39m use_inter_op_parallelism\n\u001b[1;32m   5190\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preserve_cardinality \u001b[38;5;241m=\u001b[39m preserve_cardinality\n\u001b[0;32m-> 5191\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func \u001b[38;5;241m=\u001b[39m \u001b[43mstructured_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStructuredFunctionWrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5193\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transformation_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5194\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5195\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_legacy_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_legacy_function\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5196\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata \u001b[38;5;241m=\u001b[39m dataset_metadata_pb2\u001b[38;5;241m.\u001b[39mMetadata()\n\u001b[1;32m   5197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name:\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/data/ops/structured_function.py:271\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m    264\u001b[0m       warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    265\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    266\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    267\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    268\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    269\u001b[0m     fn_factory \u001b[38;5;241m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[0;32m--> 271\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function \u001b[38;5;241m=\u001b[39m \u001b[43mfn_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;66;03m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[1;32m    273\u001b[0m add_to_graph \u001b[38;5;241m&\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly()\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3070\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_concrete_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   3062\u001b[0m   \u001b[38;5;124;03m\"\"\"Returns a `ConcreteFunction` specialized to inputs and execution context.\u001b[39;00m\n\u001b[1;32m   3063\u001b[0m \n\u001b[1;32m   3064\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3068\u001b[0m \u001b[38;5;124;03m       or `tf.Tensor` or `tf.TensorSpec`.\u001b[39;00m\n\u001b[1;32m   3069\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3070\u001b[0m   graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3071\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3072\u001b[0m   graph_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   3073\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3036\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3034\u001b[0m   args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3035\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m-> 3036\u001b[0m   graph_function, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3037\u001b[0m   seen_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[1;32m   3038\u001b[0m   captured \u001b[38;5;241m=\u001b[39m object_identity\u001b[38;5;241m.\u001b[39mObjectIdentitySet(\n\u001b[1;32m   3039\u001b[0m       graph_function\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39minternal_captures)\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3292\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3288\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_define_function_with_shape_relaxation(\n\u001b[1;32m   3289\u001b[0m       args, kwargs, flat_args, filtered_flat_args)\n\u001b[1;32m   3291\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39madd_call_context(cache_key\u001b[38;5;241m.\u001b[39mcall_context)\n\u001b[0;32m-> 3292\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_graph_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3293\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39madd(cache_key, cache_key_deletion_observer,\n\u001b[1;32m   3294\u001b[0m                          graph_function)\n\u001b[1;32m   3296\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function, filtered_flat_args\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3130\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3125\u001b[0m missing_arg_names \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   3126\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (arg, i) \u001b[38;5;28;01mfor\u001b[39;00m i, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(missing_arg_names)\n\u001b[1;32m   3127\u001b[0m ]\n\u001b[1;32m   3128\u001b[0m arg_names \u001b[38;5;241m=\u001b[39m base_arg_names \u001b[38;5;241m+\u001b[39m missing_arg_names\n\u001b[1;32m   3129\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m ConcreteFunction(\n\u001b[0;32m-> 3130\u001b[0m     \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3131\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3132\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3133\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3134\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3135\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3136\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3137\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3138\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3139\u001b[0m \u001b[43m        \u001b[49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3140\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_by_value\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   3141\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_attributes,\n\u001b[1;32m   3142\u001b[0m     function_spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_spec,\n\u001b[1;32m   3143\u001b[0m     \u001b[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[1;32m   3144\u001b[0m     \u001b[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[1;32m   3145\u001b[0m     \u001b[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[1;32m   3146\u001b[0m     \u001b[38;5;66;03m# ConcreteFunction.\u001b[39;00m\n\u001b[1;32m   3147\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   3148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:1161\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1158\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1159\u001b[0m   _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1161\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1163\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1165\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mmap_structure(convert, func_outputs,\n\u001b[1;32m   1166\u001b[0m                                   expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/data/ops/structured_function.py:248\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;129m@eager_function\u001b[39m\u001b[38;5;241m.\u001b[39mdefun_with_attributes(\n\u001b[1;32m    243\u001b[0m     input_signature\u001b[38;5;241m=\u001b[39mstructure\u001b[38;5;241m.\u001b[39mget_flat_tensor_specs(\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_structure),\n\u001b[1;32m    245\u001b[0m     autograph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    246\u001b[0m     attributes\u001b[38;5;241m=\u001b[39mdefun_kwargs)\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_fn\u001b[39m(\u001b[38;5;241m*\u001b[39margs):  \u001b[38;5;66;03m# pylint: disable=missing-docstring\u001b[39;00m\n\u001b[0;32m--> 248\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mwrapper_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    249\u001b[0m   ret \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mto_tensor_list(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_structure, ret)\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m [ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m ret]\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/data/ops/structured_function.py:177\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _should_unpack(nested_args):\n\u001b[1;32m    176\u001b[0m   nested_args \u001b[38;5;241m=\u001b[39m (nested_args,)\n\u001b[0;32m--> 177\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mautograph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtf_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag_ctx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnested_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _should_pack(ret):\n\u001b[1;32m    179\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(ret)\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:692\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    691\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 692\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[1;32m    693\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    694\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/tmp/ipykernel_21812/1607789451.py\", line 2, in None  *\n        lambda x, y: (data_augmentation(x, training=True), y)\n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/felix/Wks/AMFtrack/amftrack/ml/width/data_augmentation.py\", line 80, in <lambda>\n        lambda x: random_crop_slice(x, original_size, input_size, offset),\n\n    ValueError: Exception encountered when calling layer \"random_crop_with_offset_0\" (type Lambda).\n    \n    in user code:\n    \n        File \"/home/felix/Wks/AMFtrack/amftrack/ml/width/data_augmentation.py\", line 74, in random_crop_slice  *\n            return x[..., start_index : start_index + input_size, :]\n    \n        ValueError: Index out of range using input dim 1; input has only 1 dims for '{{node strided_slice}} = StridedSlice[Index=DT_INT64, T=DT_FLOAT, begin_mask=4, ellipsis_mask=1, end_mask=4, new_axis_mask=0, shrink_axis_mask=0](x, strided_slice/stack, strided_slice/stack_1, strided_slice/Cast)' with input shapes: [120], [3], [3], [3] and with computed input tensors: input[3] = <1 1 1>.\n    \n    \n    Call arguments received:\n      â¢ inputs=tf.Tensor(shape=(120,), dtype=float32)\n      â¢ mask=None\n      â¢ training=True\n"
     ]
    }
   ],
   "source": [
    "train = (\n",
    "    d3.map(lambda x, y: (data_augmentation(x, training=True), y))\n",
    "    .unbatch()\n",
    "    .batch(BATCHSIZE)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7892890c",
   "metadata": {},
   "source": [
    "## BROUILLON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "07f31a2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(377, 120)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1c0fbd40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prov = np.expand_dims(train_feature, axis=-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "91b87668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function from_tensor_slices in module tensorflow.python.data.ops.dataset_ops:\n",
      "\n",
      "from_tensor_slices(tensors, name=None)\n",
      "    Creates a `Dataset` whose elements are slices of the given tensors.\n",
      "    \n",
      "    The given tensors are sliced along their first dimension. This operation\n",
      "    preserves the structure of the input tensors, removing the first dimension\n",
      "    of each tensor and using it as the dataset dimension. All input tensors\n",
      "    must have the same size in their first dimensions.\n",
      "    \n",
      "    >>> # Slicing a 1D tensor produces scalar tensor elements.\n",
      "    >>> dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
      "    >>> list(dataset.as_numpy_iterator())\n",
      "    [1, 2, 3]\n",
      "    \n",
      "    >>> # Slicing a 2D tensor produces 1D tensor elements.\n",
      "    >>> dataset = tf.data.Dataset.from_tensor_slices([[1, 2], [3, 4]])\n",
      "    >>> list(dataset.as_numpy_iterator())\n",
      "    [array([1, 2], dtype=int32), array([3, 4], dtype=int32)]\n",
      "    \n",
      "    >>> # Slicing a tuple of 1D tensors produces tuple elements containing\n",
      "    >>> # scalar tensors.\n",
      "    >>> dataset = tf.data.Dataset.from_tensor_slices(([1, 2], [3, 4], [5, 6]))\n",
      "    >>> list(dataset.as_numpy_iterator())\n",
      "    [(1, 3, 5), (2, 4, 6)]\n",
      "    \n",
      "    >>> # Dictionary structure is also preserved.\n",
      "    >>> dataset = tf.data.Dataset.from_tensor_slices({\"a\": [1, 2], \"b\": [3, 4]})\n",
      "    >>> list(dataset.as_numpy_iterator()) == [{'a': 1, 'b': 3},\n",
      "    ...                                       {'a': 2, 'b': 4}]\n",
      "    True\n",
      "    \n",
      "    >>> # Two tensors can be combined into one Dataset object.\n",
      "    >>> features = tf.constant([[1, 3], [2, 1], [3, 3]]) # ==> 3x2 tensor\n",
      "    >>> labels = tf.constant(['A', 'B', 'A']) # ==> 3x1 tensor\n",
      "    >>> dataset = Dataset.from_tensor_slices((features, labels))\n",
      "    >>> # Both the features and the labels tensors can be converted\n",
      "    >>> # to a Dataset object separately and combined after.\n",
      "    >>> features_dataset = Dataset.from_tensor_slices(features)\n",
      "    >>> labels_dataset = Dataset.from_tensor_slices(labels)\n",
      "    >>> dataset = Dataset.zip((features_dataset, labels_dataset))\n",
      "    >>> # A batched feature and label set can be converted to a Dataset\n",
      "    >>> # in similar fashion.\n",
      "    >>> batched_features = tf.constant([[[1, 3], [2, 3]],\n",
      "    ...                                 [[2, 1], [1, 2]],\n",
      "    ...                                 [[3, 3], [3, 2]]], shape=(3, 2, 2))\n",
      "    >>> batched_labels = tf.constant([['A', 'A'],\n",
      "    ...                               ['B', 'B'],\n",
      "    ...                               ['A', 'B']], shape=(3, 2, 1))\n",
      "    >>> dataset = Dataset.from_tensor_slices((batched_features, batched_labels))\n",
      "    >>> for element in dataset.as_numpy_iterator():\n",
      "    ...   print(element)\n",
      "    (array([[1, 3],\n",
      "           [2, 3]], dtype=int32), array([[b'A'],\n",
      "           [b'A']], dtype=object))\n",
      "    (array([[2, 1],\n",
      "           [1, 2]], dtype=int32), array([[b'B'],\n",
      "           [b'B']], dtype=object))\n",
      "    (array([[3, 3],\n",
      "           [3, 2]], dtype=int32), array([[b'A'],\n",
      "           [b'B']], dtype=object))\n",
      "    \n",
      "    Note that if `tensors` contains a NumPy array, and eager execution is not\n",
      "    enabled, the values will be embedded in the graph as one or more\n",
      "    `tf.constant` operations. For large datasets (> 1 GB), this can waste\n",
      "    memory and run into byte limits of graph serialization. If `tensors`\n",
      "    contains one or more large NumPy arrays, consider the alternative described\n",
      "    in [this guide](\n",
      "    https://tensorflow.org/guide/data#consuming_numpy_arrays).\n",
      "    \n",
      "    Args:\n",
      "      tensors: A dataset element, whose components have the same first\n",
      "        dimension. Supported values are documented\n",
      "        [here](https://www.tensorflow.org/guide/data#dataset_structure).\n",
      "      name: (Optional.) A name for the tf.data operation.\n",
      "    \n",
      "    Returns:\n",
      "      Dataset: A `Dataset`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.data.Dataset.from_tensor_slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fa6672f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unbatching a tensor is only supported for rank >= 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [78]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_ds \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_tensor_slices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprov\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py:793\u001b[0m, in \u001b[0;36mDatasetV2.from_tensor_slices\u001b[0;34m(tensors, name)\u001b[0m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_tensor_slices\u001b[39m(tensors, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    717\u001b[0m   \u001b[38;5;124;03m\"\"\"Creates a `Dataset` whose elements are slices of the given tensors.\u001b[39;00m\n\u001b[1;32m    718\u001b[0m \n\u001b[1;32m    719\u001b[0m \u001b[38;5;124;03m  The given tensors are sliced along their first dimension. This operation\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    791\u001b[0m \u001b[38;5;124;03m    Dataset: A `Dataset`.\u001b[39;00m\n\u001b[1;32m    792\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 793\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mTensorSliceDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py:4482\u001b[0m, in \u001b[0;36mTensorSliceDataset.__init__\u001b[0;34m(self, element, is_files, name)\u001b[0m\n\u001b[1;32m   4480\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tensors:\n\u001b[1;32m   4481\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid `element`. `element` should not be empty.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 4482\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_structure \u001b[38;5;241m=\u001b[39m \u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4483\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcomponent_spec\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomponent_spec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_unbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatched_spec\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   4484\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata \u001b[38;5;241m=\u001b[39m dataset_metadata_pb2\u001b[38;5;241m.\u001b[39mMetadata()\n\u001b[1;32m   4485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name:\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/data/util/nest.py:228\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **check_types_dict)\u001b[0m\n\u001b[1;32m    224\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m    225\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 228\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [func(\u001b[38;5;241m*\u001b[39mx) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries])\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/data/util/nest.py:228\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    224\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m    225\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 228\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries])\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py:4483\u001b[0m, in \u001b[0;36mTensorSliceDataset.__init__.<locals>.<lambda>\u001b[0;34m(component_spec)\u001b[0m\n\u001b[1;32m   4480\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tensors:\n\u001b[1;32m   4481\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid `element`. `element` should not be empty.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   4482\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_structure \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mmap_structure(\n\u001b[0;32m-> 4483\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m component_spec: \u001b[43mcomponent_spec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_unbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, batched_spec)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   4484\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata \u001b[38;5;241m=\u001b[39m dataset_metadata_pb2\u001b[38;5;241m.\u001b[39mMetadata()\n\u001b[1;32m   4485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name:\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/framework/tensor_spec.py:216\u001b[0m, in \u001b[0;36mTensorSpec._unbatch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_unbatch\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    215\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shape\u001b[38;5;241m.\u001b[39mndims \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnbatching a tensor is only supported for rank >= 1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m TensorSpec(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shape[\u001b[38;5;241m1\u001b[39m:], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dtype)\n",
      "\u001b[0;31mValueError\u001b[0m: Unbatching a tensor is only supported for rank >= 1"
     ]
    }
   ],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices(prov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "eb1b9690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n"
     ]
    }
   ],
   "source": [
    "for e in train_ds:\n",
    "    print(e.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ba25fc97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([377, 80, 1])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_preparation(train_feature).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "970cf762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset element_spec=TensorSpec(shape=(120,), dtype=tf.uint8, name=None)>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_feature)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9764f210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 120, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 120, 1), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\"), but it was called on an input with incompatible shape (120,).\n",
      "2022-08-16 16:51:06,205-[WARNING]- tensorflow:665 -> Model was constructed with shape (None, 120, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 120, 1), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\"), but it was called on an input with incompatible shape (120,).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/tmp/ipykernel_21812/1439737797.py\", line 2, in None  *\n        lambda x: (data_augmentation(x, training=True))\n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/felix/Wks/AMFtrack/amftrack/ml/width/data_augmentation.py\", line 80, in <lambda>\n        lambda x: random_crop_slice(x, original_size, input_size, offset),\n\n    ValueError: Exception encountered when calling layer \"random_crop_with_offset_0\" (type Lambda).\n    \n    in user code:\n    \n        File \"/home/felix/Wks/AMFtrack/amftrack/ml/width/data_augmentation.py\", line 74, in random_crop_slice  *\n            return x[..., start_index : start_index + input_size, :]\n    \n        ValueError: Index out of range using input dim 1; input has only 1 dims for '{{node strided_slice}} = StridedSlice[Index=DT_INT64, T=DT_FLOAT, begin_mask=4, ellipsis_mask=1, end_mask=4, new_axis_mask=0, shrink_axis_mask=0](x, strided_slice/stack, strided_slice/stack_1, strided_slice/Cast)' with input shapes: [120], [3], [3], [3] and with computed input tensors: input[3] = <1 1 1>.\n    \n    \n    Call arguments received:\n      â¢ inputs=tf.Tensor(shape=(120,), dtype=float32)\n      â¢ mask=None\n      â¢ training=True\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [57]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m train \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_augmentation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;241m.\u001b[39munbatch()\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;241m.\u001b[39mbatch(BATCHSIZE)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;241m.\u001b[39mprefetch(tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mAUTOTUNE)\n\u001b[1;32m      6\u001b[0m )\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py:2016\u001b[0m, in \u001b[0;36mDatasetV2.map\u001b[0;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m   2013\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m deterministic \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m DEBUG_MODE:\n\u001b[1;32m   2014\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `deterministic` argument has no effect unless the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2015\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`num_parallel_calls` argument is specified.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2016\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mMapDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreserve_cardinality\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2017\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2018\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m ParallelMapDataset(\n\u001b[1;32m   2019\u001b[0m       \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2020\u001b[0m       map_func,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2023\u001b[0m       preserve_cardinality\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   2024\u001b[0m       name\u001b[38;5;241m=\u001b[39mname)\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py:5191\u001b[0m, in \u001b[0;36mMapDataset.__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[1;32m   5189\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_inter_op_parallelism \u001b[38;5;241m=\u001b[39m use_inter_op_parallelism\n\u001b[1;32m   5190\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preserve_cardinality \u001b[38;5;241m=\u001b[39m preserve_cardinality\n\u001b[0;32m-> 5191\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func \u001b[38;5;241m=\u001b[39m \u001b[43mstructured_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStructuredFunctionWrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5193\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transformation_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5194\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5195\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_legacy_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_legacy_function\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5196\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata \u001b[38;5;241m=\u001b[39m dataset_metadata_pb2\u001b[38;5;241m.\u001b[39mMetadata()\n\u001b[1;32m   5197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name:\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/data/ops/structured_function.py:271\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m    264\u001b[0m       warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    265\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    266\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    267\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    268\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    269\u001b[0m     fn_factory \u001b[38;5;241m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[0;32m--> 271\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function \u001b[38;5;241m=\u001b[39m \u001b[43mfn_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;66;03m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[1;32m    273\u001b[0m add_to_graph \u001b[38;5;241m&\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly()\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3070\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_concrete_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   3062\u001b[0m   \u001b[38;5;124;03m\"\"\"Returns a `ConcreteFunction` specialized to inputs and execution context.\u001b[39;00m\n\u001b[1;32m   3063\u001b[0m \n\u001b[1;32m   3064\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3068\u001b[0m \u001b[38;5;124;03m       or `tf.Tensor` or `tf.TensorSpec`.\u001b[39;00m\n\u001b[1;32m   3069\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3070\u001b[0m   graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3071\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3072\u001b[0m   graph_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   3073\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3036\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3034\u001b[0m   args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3035\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m-> 3036\u001b[0m   graph_function, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3037\u001b[0m   seen_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[1;32m   3038\u001b[0m   captured \u001b[38;5;241m=\u001b[39m object_identity\u001b[38;5;241m.\u001b[39mObjectIdentitySet(\n\u001b[1;32m   3039\u001b[0m       graph_function\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39minternal_captures)\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3292\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3288\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_define_function_with_shape_relaxation(\n\u001b[1;32m   3289\u001b[0m       args, kwargs, flat_args, filtered_flat_args)\n\u001b[1;32m   3291\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39madd_call_context(cache_key\u001b[38;5;241m.\u001b[39mcall_context)\n\u001b[0;32m-> 3292\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_graph_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3293\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39madd(cache_key, cache_key_deletion_observer,\n\u001b[1;32m   3294\u001b[0m                          graph_function)\n\u001b[1;32m   3296\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function, filtered_flat_args\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3130\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3125\u001b[0m missing_arg_names \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   3126\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (arg, i) \u001b[38;5;28;01mfor\u001b[39;00m i, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(missing_arg_names)\n\u001b[1;32m   3127\u001b[0m ]\n\u001b[1;32m   3128\u001b[0m arg_names \u001b[38;5;241m=\u001b[39m base_arg_names \u001b[38;5;241m+\u001b[39m missing_arg_names\n\u001b[1;32m   3129\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m ConcreteFunction(\n\u001b[0;32m-> 3130\u001b[0m     \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3131\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3132\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3133\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3134\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3135\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3136\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3137\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3138\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3139\u001b[0m \u001b[43m        \u001b[49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3140\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_by_value\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   3141\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_attributes,\n\u001b[1;32m   3142\u001b[0m     function_spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_spec,\n\u001b[1;32m   3143\u001b[0m     \u001b[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[1;32m   3144\u001b[0m     \u001b[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[1;32m   3145\u001b[0m     \u001b[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[1;32m   3146\u001b[0m     \u001b[38;5;66;03m# ConcreteFunction.\u001b[39;00m\n\u001b[1;32m   3147\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   3148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:1161\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1158\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1159\u001b[0m   _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1161\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1163\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1165\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mmap_structure(convert, func_outputs,\n\u001b[1;32m   1166\u001b[0m                                   expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/data/ops/structured_function.py:248\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;129m@eager_function\u001b[39m\u001b[38;5;241m.\u001b[39mdefun_with_attributes(\n\u001b[1;32m    243\u001b[0m     input_signature\u001b[38;5;241m=\u001b[39mstructure\u001b[38;5;241m.\u001b[39mget_flat_tensor_specs(\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_structure),\n\u001b[1;32m    245\u001b[0m     autograph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    246\u001b[0m     attributes\u001b[38;5;241m=\u001b[39mdefun_kwargs)\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_fn\u001b[39m(\u001b[38;5;241m*\u001b[39margs):  \u001b[38;5;66;03m# pylint: disable=missing-docstring\u001b[39;00m\n\u001b[0;32m--> 248\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mwrapper_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    249\u001b[0m   ret \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mto_tensor_list(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_structure, ret)\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m [ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m ret]\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/data/ops/structured_function.py:177\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _should_unpack(nested_args):\n\u001b[1;32m    176\u001b[0m   nested_args \u001b[38;5;241m=\u001b[39m (nested_args,)\n\u001b[0;32m--> 177\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mautograph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtf_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag_ctx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnested_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _should_pack(ret):\n\u001b[1;32m    179\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(ret)\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:692\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    691\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 692\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[1;32m    693\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    694\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/tmp/ipykernel_21812/1439737797.py\", line 2, in None  *\n        lambda x: (data_augmentation(x, training=True))\n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/felix/Wks/AMFtrack/amftrack/ml/width/data_augmentation.py\", line 80, in <lambda>\n        lambda x: random_crop_slice(x, original_size, input_size, offset),\n\n    ValueError: Exception encountered when calling layer \"random_crop_with_offset_0\" (type Lambda).\n    \n    in user code:\n    \n        File \"/home/felix/Wks/AMFtrack/amftrack/ml/width/data_augmentation.py\", line 74, in random_crop_slice  *\n            return x[..., start_index : start_index + input_size, :]\n    \n        ValueError: Index out of range using input dim 1; input has only 1 dims for '{{node strided_slice}} = StridedSlice[Index=DT_INT64, T=DT_FLOAT, begin_mask=4, ellipsis_mask=1, end_mask=4, new_axis_mask=0, shrink_axis_mask=0](x, strided_slice/stack, strided_slice/stack_1, strided_slice/Cast)' with input shapes: [120], [3], [3], [3] and with computed input tensors: input[3] = <1 1 1>.\n    \n    \n    Call arguments received:\n      â¢ inputs=tf.Tensor(shape=(120,), dtype=float32)\n      â¢ mask=None\n      â¢ training=True\n"
     ]
    }
   ],
   "source": [
    "train = (\n",
    "    train_dataset.map(lambda x: (data_augmentation(x, training=True)))\n",
    "    .unbatch()\n",
    "    .batch(BATCHSIZE)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cef90cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 120, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 120, 1), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\"), but it was called on an input with incompatible shape (120,).\n",
      "2022-08-16 16:49:36,925-[WARNING]- tensorflow:665 -> Model was constructed with shape (None, 120, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 120, 1), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\"), but it was called on an input with incompatible shape (120,).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"random_crop_with_offset_0\" (type Lambda).\n\nin user code:\n\n    File \"/home/felix/Wks/AMFtrack/amftrack/ml/width/data_augmentation.py\", line 74, in random_crop_slice  *\n        return x[..., start_index : start_index + input_size, :]\n\n    ValueError: Index out of range using input dim 1; input has only 1 dims for '{{node strided_slice}} = StridedSlice[Index=DT_INT64, T=DT_FLOAT, begin_mask=4, ellipsis_mask=1, end_mask=4, new_axis_mask=0, shrink_axis_mask=0](x, strided_slice/stack, strided_slice/stack_1, strided_slice/Cast)' with input shapes: [120], [3], [3], [3] and with computed input tensors: input[3] = <1 1 1>.\n\n\nCall arguments received:\n  â¢ inputs=tf.Tensor(shape=(120,), dtype=float32)\n  â¢ mask=None\n  â¢ training=False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [55]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m----> 2\u001b[0m         \u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_augmentation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;241m.\u001b[39munbatch()\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;241m.\u001b[39mbatch(BATCHSIZE)\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;241m.\u001b[39mprefetch(tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mAUTOTUNE)\n\u001b[1;32m      6\u001b[0m     )\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py:2016\u001b[0m, in \u001b[0;36mDatasetV2.map\u001b[0;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m   2013\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m deterministic \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m DEBUG_MODE:\n\u001b[1;32m   2014\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `deterministic` argument has no effect unless the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2015\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`num_parallel_calls` argument is specified.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2016\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mMapDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreserve_cardinality\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2017\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2018\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m ParallelMapDataset(\n\u001b[1;32m   2019\u001b[0m       \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2020\u001b[0m       map_func,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2023\u001b[0m       preserve_cardinality\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   2024\u001b[0m       name\u001b[38;5;241m=\u001b[39mname)\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py:5191\u001b[0m, in \u001b[0;36mMapDataset.__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[1;32m   5189\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_inter_op_parallelism \u001b[38;5;241m=\u001b[39m use_inter_op_parallelism\n\u001b[1;32m   5190\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preserve_cardinality \u001b[38;5;241m=\u001b[39m preserve_cardinality\n\u001b[0;32m-> 5191\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func \u001b[38;5;241m=\u001b[39m \u001b[43mstructured_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStructuredFunctionWrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5193\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transformation_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5194\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5195\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_legacy_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_legacy_function\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5196\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata \u001b[38;5;241m=\u001b[39m dataset_metadata_pb2\u001b[38;5;241m.\u001b[39mMetadata()\n\u001b[1;32m   5197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name:\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/data/ops/structured_function.py:271\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m    264\u001b[0m       warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    265\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    266\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    267\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    268\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    269\u001b[0m     fn_factory \u001b[38;5;241m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[0;32m--> 271\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function \u001b[38;5;241m=\u001b[39m \u001b[43mfn_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;66;03m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[1;32m    273\u001b[0m add_to_graph \u001b[38;5;241m&\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly()\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3070\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_concrete_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   3062\u001b[0m   \u001b[38;5;124;03m\"\"\"Returns a `ConcreteFunction` specialized to inputs and execution context.\u001b[39;00m\n\u001b[1;32m   3063\u001b[0m \n\u001b[1;32m   3064\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3068\u001b[0m \u001b[38;5;124;03m       or `tf.Tensor` or `tf.TensorSpec`.\u001b[39;00m\n\u001b[1;32m   3069\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3070\u001b[0m   graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3071\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3072\u001b[0m   graph_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   3073\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3036\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3034\u001b[0m   args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3035\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m-> 3036\u001b[0m   graph_function, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3037\u001b[0m   seen_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[1;32m   3038\u001b[0m   captured \u001b[38;5;241m=\u001b[39m object_identity\u001b[38;5;241m.\u001b[39mObjectIdentitySet(\n\u001b[1;32m   3039\u001b[0m       graph_function\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39minternal_captures)\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3292\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3288\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_define_function_with_shape_relaxation(\n\u001b[1;32m   3289\u001b[0m       args, kwargs, flat_args, filtered_flat_args)\n\u001b[1;32m   3291\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39madd_call_context(cache_key\u001b[38;5;241m.\u001b[39mcall_context)\n\u001b[0;32m-> 3292\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_graph_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3293\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39madd(cache_key, cache_key_deletion_observer,\n\u001b[1;32m   3294\u001b[0m                          graph_function)\n\u001b[1;32m   3296\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function, filtered_flat_args\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3130\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3125\u001b[0m missing_arg_names \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   3126\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (arg, i) \u001b[38;5;28;01mfor\u001b[39;00m i, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(missing_arg_names)\n\u001b[1;32m   3127\u001b[0m ]\n\u001b[1;32m   3128\u001b[0m arg_names \u001b[38;5;241m=\u001b[39m base_arg_names \u001b[38;5;241m+\u001b[39m missing_arg_names\n\u001b[1;32m   3129\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m ConcreteFunction(\n\u001b[0;32m-> 3130\u001b[0m     \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3131\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3132\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3133\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3134\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3135\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3136\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3137\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3138\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3139\u001b[0m \u001b[43m        \u001b[49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3140\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_by_value\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   3141\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_attributes,\n\u001b[1;32m   3142\u001b[0m     function_spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_spec,\n\u001b[1;32m   3143\u001b[0m     \u001b[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[1;32m   3144\u001b[0m     \u001b[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[1;32m   3145\u001b[0m     \u001b[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[1;32m   3146\u001b[0m     \u001b[38;5;66;03m# ConcreteFunction.\u001b[39;00m\n\u001b[1;32m   3147\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   3148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:1161\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1158\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1159\u001b[0m   _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1161\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1163\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1165\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mmap_structure(convert, func_outputs,\n\u001b[1;32m   1166\u001b[0m                                   expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/data/ops/structured_function.py:248\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;129m@eager_function\u001b[39m\u001b[38;5;241m.\u001b[39mdefun_with_attributes(\n\u001b[1;32m    243\u001b[0m     input_signature\u001b[38;5;241m=\u001b[39mstructure\u001b[38;5;241m.\u001b[39mget_flat_tensor_specs(\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_structure),\n\u001b[1;32m    245\u001b[0m     autograph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    246\u001b[0m     attributes\u001b[38;5;241m=\u001b[39mdefun_kwargs)\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_fn\u001b[39m(\u001b[38;5;241m*\u001b[39margs):  \u001b[38;5;66;03m# pylint: disable=missing-docstring\u001b[39;00m\n\u001b[0;32m--> 248\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mwrapper_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    249\u001b[0m   ret \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mto_tensor_list(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_structure, ret)\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m [ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m ret]\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/data/ops/structured_function.py:177\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _should_unpack(nested_args):\n\u001b[1;32m    176\u001b[0m   nested_args \u001b[38;5;241m=\u001b[39m (nested_args,)\n\u001b[0;32m--> 177\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mautograph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtf_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag_ctx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnested_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _should_pack(ret):\n\u001b[1;32m    179\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(ret)\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:689\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    688\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 689\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    691\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    374\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39muser_requested \u001b[38;5;129;01mand\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_allowlisted(f):\n\u001b[0;32m--> 377\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;66;03m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;66;03m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;66;03m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;66;03m# things like builtins.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:458\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    455\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m\u001b[38;5;241m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 458\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Wks/AMFtrack/amftrack/ml/width/data_augmentation.py:80\u001b[0m, in \u001b[0;36mrandom_crop.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrandom_crop\u001b[39m(original_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m120\u001b[39m, input_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m80\u001b[39m, offset\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWrapper function to generate a random croping layer\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mLambda(\n\u001b[0;32m---> 80\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mrandom_crop_slice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moriginal_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     81\u001b[0m         name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrandom_crop_with_offset_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moffset\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     82\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"random_crop_with_offset_0\" (type Lambda).\n\nin user code:\n\n    File \"/home/felix/Wks/AMFtrack/amftrack/ml/width/data_augmentation.py\", line 74, in random_crop_slice  *\n        return x[..., start_index : start_index + input_size, :]\n\n    ValueError: Index out of range using input dim 1; input has only 1 dims for '{{node strided_slice}} = StridedSlice[Index=DT_INT64, T=DT_FLOAT, begin_mask=4, ellipsis_mask=1, end_mask=4, new_axis_mask=0, shrink_axis_mask=0](x, strided_slice/stack, strided_slice/stack_1, strided_slice/Cast)' with input shapes: [120], [3], [3], [3] and with computed input tensors: input[3] = <1 1 1>.\n\n\nCall arguments received:\n  â¢ inputs=tf.Tensor(shape=(120,), dtype=float32)\n  â¢ mask=None\n  â¢ training=False"
     ]
    }
   ],
   "source": [
    "train_dataset = (\n",
    "        train_dataset.map(data_augmentation)\n",
    "        .unbatch()\n",
    "        .batch(BATCHSIZE)\n",
    "        .prefetch(tf.data.AUTOTUNE)\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
