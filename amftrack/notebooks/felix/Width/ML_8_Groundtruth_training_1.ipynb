{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a88eb95",
   "metadata": {},
   "source": [
    "# Groundtruth training on focused edges (training 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46b5b487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "$('<div id=\"toc\"></div>').css({position: 'fixed', top: '120px', left: 0}).appendTo(document.body);\n",
       "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js');\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "$('<div id=\"toc\"></div>').css({position: 'fixed', top: '120px', left: 0}).appendTo(document.body);\n",
    "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa80930",
   "metadata": {},
   "source": [
    "## Presentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90444c84",
   "metadata": {},
   "source": [
    "For each different training we proceed as follow:\n",
    "\n",
    "Step 1: random search or bayesian search over a lot of models and parameters\\\n",
    "Step 2: evaluate the 3 best models with cross validation and chose the best out of the 3\n",
    "\n",
    "For the seed, we always take the same seed: 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870525d5",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "060f5678",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "import imageio\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import regularizers\n",
    "import keras_tuner as kt\n",
    "\n",
    "from amftrack.ml.width.models import (\n",
    "    hyper_model_builder_simple,\n",
    "    build_model_dense,\n",
    "    build_model_conv,\n",
    "    build_model_conv_small,\n",
    ")\n",
    "from amftrack.util.sys import storage_path\n",
    "from amftrack.ml.width.data_augmentation import data_augmentation, data_preparation\n",
    "from keras.utils.layer_utils import count_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fa4a491a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485285ad",
   "metadata": {},
   "source": [
    "### Fetch data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b305e51e",
   "metadata": {},
   "source": [
    "Repository with all possible datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9c884c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = os.path.join(storage_path, \"datasets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b9bdd8",
   "metadata": {},
   "source": [
    "Two datasets that I have choosen to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82126ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "focused_dataset_path = os.path.join(\n",
    "    dataset_path, \"focused_with_varying_lum_train\"\n",
    ")  # dataset with varying lumination but consistent focus\n",
    "extended_dataset_path = os.path.join(\n",
    "    dataset_path, \"varying_lum_and_focus_train\"\n",
    ")  # dataset with varying lumination but consistent focus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2653ccf5",
   "metadata": {},
   "source": [
    "For now: using the focused dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9f1d2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = focused_dataset_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e5d9e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_path = os.path.join(path, \"slices.png\")\n",
    "label_path = os.path.join(path, \"labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cab14b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(527, 120)\n"
     ]
    }
   ],
   "source": [
    "im = imageio.imread(im_path)\n",
    "print(im.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c26d17c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(527,)\n"
     ]
    }
   ],
   "source": [
    "with open(label_path, \"rb\") as f:\n",
    "    label = np.load(f)\n",
    "print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c568feb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = np.expand_dims(label, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d530f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(527, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4d5dd1",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37844b7",
   "metadata": {},
   "source": [
    "For seperating the test set (not used for now as the test is done in another notebookÂ²)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e76a7826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "377\n",
      "150\n"
     ]
    }
   ],
   "source": [
    "seed = 11\n",
    "np.random.seed(11)\n",
    "p = np.random.permutation(len(label))\n",
    "training = p[:-150]\n",
    "valid = p[-150:]\n",
    "print(len(training))\n",
    "print(len(valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a513000",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature = im[training, :]\n",
    "train_label = label[training, :]\n",
    "valid_feature = im[valid, :]\n",
    "valid_label = label[valid, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fdb088",
   "metadata": {},
   "source": [
    "Instead we just take it all"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d9f95f1c",
   "metadata": {},
   "source": [
    "train_feature = im\n",
    "train_label = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aeb87d01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(377, 120)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feature.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26c2475",
   "metadata": {},
   "source": [
    "### Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a8a0447",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "197fd5be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8bd1764970>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(im[i, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a27e66af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.54463004])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label[i, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e69aa32",
   "metadata": {},
   "source": [
    "## Mean predicting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8bbb1b88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(377, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "07f41a64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.982430809438182"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.var(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4546373c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2321359298748322"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "13ef7529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean is: 5.279759580329631, Mean squarred error is: 4.982430809438182\n"
     ]
    }
   ],
   "source": [
    "mean = np.mean(train_label)\n",
    "pred = np.full(train_label.shape, mean)\n",
    "res = np.mean((train_label - pred) ** 2)\n",
    "print(f\"Mean is: {mean}, Mean squarred error is: {res}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ddd21728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean is: 5.279759580329631, Mean absolute error is: 1.5887181524020357\n"
     ]
    }
   ],
   "source": [
    "mean = np.mean(train_label)\n",
    "pred = np.full(train_label.shape, mean)\n",
    "res = np.mean(abs(train_label - pred))\n",
    "print(f\"Mean is: {mean}, Mean absolute error is: {res}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3fa786",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3a0b4c",
   "metadata": {},
   "source": [
    "### Train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3a80fc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from amftrack.ml.width.data_augmentation import (\n",
    "    data_preparation,\n",
    "    data_augmentation,\n",
    "    random_crop,\n",
    "    random_mirror,\n",
    "    random_invert,\n",
    "    random_brightness,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ff749531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(377, 120)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feature.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc203714",
   "metadata": {},
   "source": [
    "PROPRE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c413fa9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature_ds = np.expand_dims(train_feature, axis=-1)\n",
    "train_feature_ds = np.expand_dims(train_feature_ds, axis=-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1b465374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(377, 1, 120, 1)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feature_ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a678f245",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = tf.data.Dataset.from_tensor_slices(train_feature_ds)\n",
    "d2 = tf.data.Dataset.from_tensor_slices(train_label)\n",
    "train_ds = tf.data.Dataset.zip((d1, d2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2ee85d00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset element_spec=TensorSpec(shape=(1, 120, 1), dtype=tf.uint8, name=None)>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST\n",
    "d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8b2bc3b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset element_spec=TensorSpec(shape=(1,), dtype=tf.float64, name=None)>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST\n",
    "d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9e138b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(377, 1)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST\n",
    "train_label.shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "670dbadf",
   "metadata": {},
   "source": [
    "# TEST\n",
    "for e in train_ds:\n",
    "    break\n",
    "data_augmentation(e[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "57e84709",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = (\n",
    "    train_ds.map(lambda x, y: (data_augmentation(x, training=True), y))\n",
    "    # .unbatch()\n",
    "    .batch(16).prefetch(tf.data.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "801ef0f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec=(TensorSpec(shape=(None, None, None, 1), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1), dtype=tf.float64, name=None))>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e8282e",
   "metadata": {},
   "source": [
    "TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f584bf12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for e in train_ds:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e92a6148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 1, 100, 1)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(e[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "cfe9aa3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8bb33f3910>]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.array(e[0][0, 0, :, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a7570352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8bb0350730>]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.array(e[0][0, 0, :, 0]))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "200903d9",
   "metadata": {},
   "source": [
    "plt.plot(np.array(e[0][0,:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "48588d12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8bb04783d0>]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.array(e[0][0, 0, :, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0af29fc",
   "metadata": {},
   "source": [
    "### Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b161e2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_feature_ds = np.expand_dims(valid_feature, axis=-1)\n",
    "valid_feature_ds = np.expand_dims(valid_feature_ds, axis=-3)\n",
    "d1 = tf.data.Dataset.from_tensor_slices(valid_feature_ds)\n",
    "d2 = tf.data.Dataset.from_tensor_slices(valid_label)\n",
    "valid_ds = tf.data.Dataset.zip((d1, d2))\n",
    "valid_ds = (\n",
    "    valid_ds.map(lambda x, y: (data_preparation(x, training=True), y))\n",
    "    .unbatch()\n",
    "    .batch(16)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8eb49638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(16, 100, 1), dtype=float32, numpy=\n",
      "array([[[140.],\n",
      "        [138.],\n",
      "        [142.],\n",
      "        ...,\n",
      "        [132.],\n",
      "        [134.],\n",
      "        [132.]],\n",
      "\n",
      "       [[185.],\n",
      "        [185.],\n",
      "        [189.],\n",
      "        ...,\n",
      "        [175.],\n",
      "        [175.],\n",
      "        [173.]],\n",
      "\n",
      "       [[165.],\n",
      "        [164.],\n",
      "        [164.],\n",
      "        ...,\n",
      "        [166.],\n",
      "        [168.],\n",
      "        [167.]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[224.],\n",
      "        [224.],\n",
      "        [223.],\n",
      "        ...,\n",
      "        [216.],\n",
      "        [220.],\n",
      "        [217.]],\n",
      "\n",
      "       [[255.],\n",
      "        [254.],\n",
      "        [255.],\n",
      "        ...,\n",
      "        [255.],\n",
      "        [255.],\n",
      "        [255.]],\n",
      "\n",
      "       [[150.],\n",
      "        [150.],\n",
      "        [148.],\n",
      "        ...,\n",
      "        [144.],\n",
      "        [144.],\n",
      "        [145.]]], dtype=float32)>, <tf.Tensor: shape=(16,), dtype=float64, numpy=\n",
      "array([5.24173503, 4.34090199, 3.71157107, 8.97995119, 5.29939395,\n",
      "       5.29939395, 5.4984222 , 2.85702873, 5.35827466, 4.18356936,\n",
      "       4.34090199, 3.06895321, 4.45399496, 4.67930649, 4.88385177,\n",
      "       4.51179147])>)\n"
     ]
    }
   ],
   "source": [
    "for e in valid_ds:\n",
    "    print(e)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b62d96f",
   "metadata": {},
   "source": [
    "## Training a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2e11d251",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_function = build_model_conv_small"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8363a6e",
   "metadata": {},
   "source": [
    "### 1/ Run hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ec3b8902",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp = kt.HyperParameters()\n",
    "hp.Fixed(\"input_size\", 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deecb417",
   "metadata": {},
   "source": [
    "Randomgridsearch tuner"
   ]
  },
  {
   "cell_type": "raw",
   "id": "24861c11",
   "metadata": {},
   "source": [
    "tuner = kt.RandomSearch(\n",
    "    build_function,\n",
    "    objective='val_mean_absolute_error',\n",
    "    max_trials=2,\n",
    "    seed=seed,\n",
    "    hyperparameters=hp,\n",
    "    tune_new_entries=True,\n",
    "    allow_new_entries=True,\n",
    "    overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab19cb4",
   "metadata": {},
   "source": [
    "Other tuner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a4ed30c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.BayesianOptimization(\n",
    "    hypermodel=build_model_conv,  # CAREFUL\n",
    "    objective=\"val_mean_absolute_error\",\n",
    "    max_trials=1,\n",
    "    max_model_size=5000000,  # CAREFUL\n",
    "    num_initial_points=50,\n",
    "    alpha=0.0001,\n",
    "    beta=2.6,  # explorative factor\n",
    "    seed=seed,\n",
    "    hyperparameters=hp,\n",
    "    allow_new_entries=True,\n",
    "    tune_new_entries=True,\n",
    "    overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a381007e",
   "metadata": {},
   "source": [
    "Without augmentation:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1419fe70",
   "metadata": {},
   "source": [
    "tuner.search(train_feature,\n",
    "             train_label,\n",
    "             validation_split=0.2,\n",
    "             epochs=50,\n",
    "             callbacks=[tf.keras.callbacks.EarlyStopping(patience=8)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9596a0ac",
   "metadata": {},
   "source": [
    "Actual search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "904cbdd2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search: Running Trial #1\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "100               |?                 |input_size\n",
      "0.00079119        |?                 |regul\n",
      "2                 |?                 |conv_blocks\n",
      "32                |?                 |filters_0\n",
      "15                |?                 |kernel_size0\n",
      "1                 |?                 |strides\n",
      "136               |?                 |filters_1\n",
      "5                 |?                 |kernel_size1\n",
      "70                |?                 |hidden_size\n",
      "3                 |?                 |dense_blocks\n",
      "0.05              |?                 |dropout\n",
      "0.056138          |?                 |learning_rate\n",
      "False             |?                 |batch_normalization\n",
      "none              |?                 |pooling_1\n",
      "\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-18 18:14:27.475118: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at conv_ops.cc:675 : INVALID_ARGUMENT: Computed output size would be negative: -13 [input_size: 1, effective_filter_size: 15, stride: 1]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'model/conv1d/Conv1D' defined at (most recent call last):\n    File \"/usr/local/lib/python3.8/runpy.py\", line 192, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/local/lib/python3.8/runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 707, in start\n      self.io_loop.start()\n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/local/lib/python3.8/asyncio/base_events.py\", line 563, in run_forever\n      self._run_once()\n    File \"/usr/local/lib/python3.8/asyncio/base_events.py\", line 1844, in _run_once\n      handle._run()\n    File \"/usr/local/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 502, in dispatch_queue\n      await self.process_one()\n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 491, in process_one\n      await dispatch(*args)\n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 398, in dispatch_shell\n      await result\n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 722, in execute_request\n      reply_content = await reply_content\n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 389, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2863, in run_cell\n      result = self._run_cell(\n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2909, in _run_cell\n      return runner(coro)\n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3106, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3309, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3369, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_13858/1510589327.py\", line 1, in <cell line: 1>\n      tuner.search(train_ds,\n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/keras_tuner/engine/base_tuner.py\", line 179, in search\n      results = self.run_trial(trial, *fit_args, **fit_kwargs)\n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/keras_tuner/engine/tuner.py\", line 294, in run_trial\n      obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/keras_tuner/engine/tuner.py\", line 222, in _build_and_fit_model\n      results = self.hypermodel.fit(hp, model, *args, **kwargs)\n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/keras_tuner/engine/hypermodel.py\", line 137, in fit\n      return model.fit(*args, **kwargs)\n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/keras/engine/training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/keras/engine/training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/keras/engine/training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/keras/engine/training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/keras/engine/training.py\", line 859, in train_step\n      y_pred = self(x, training=True)\n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/keras/engine/functional.py\", line 451, in call\n      return self._run_internal_graph(\n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/keras/engine/functional.py\", line 589, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/keras/layers/convolutional.py\", line 248, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/keras/layers/convolutional.py\", line 233, in convolution_op\n      return tf.nn.convolution(\nNode: 'model/conv1d/Conv1D'\nComputed output size would be negative: -13 [input_size: 1, effective_filter_size: 15, stride: 1]\n\t [[{{node model/conv1d/Conv1D}}]] [Op:__inference_train_function_8904]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Input \u001b[0;32mIn [95]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m             \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvalid_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m             \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m150\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m             \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEarlyStopping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/keras_tuner/engine/base_tuner.py:179\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_begin(trial)\n\u001b[0;32m--> 179\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;66;03m# `results` is None indicates user updated oracle in `run_trial()`.\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m results \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/keras_tuner/engine/tuner.py:294\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(model_checkpoint)\n\u001b[1;32m    293\u001b[0m     copied_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m callbacks\n\u001b[0;32m--> 294\u001b[0m     obj_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_and_fit_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcopied_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m     histories\u001b[38;5;241m.\u001b[39mappend(obj_value)\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m histories\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/keras_tuner/engine/tuner.py:222\u001b[0m, in \u001b[0;36mTuner._build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m hp \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39mhyperparameters\n\u001b[1;32m    221\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_build(hp)\n\u001b[0;32m--> 222\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhypermodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tuner_utils\u001b[38;5;241m.\u001b[39mconvert_to_metrics_dict(\n\u001b[1;32m    224\u001b[0m     results, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mobjective, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHyperModel.fit()\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    225\u001b[0m )\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/keras_tuner/engine/hypermodel.py:137\u001b[0m, in \u001b[0;36mHyperModel.fit\u001b[0;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, hp, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;124;03m\"\"\"Train the model.\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \n\u001b[1;32m    116\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03m        If return a float, it should be the `objective` value.\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'model/conv1d/Conv1D' defined at (most recent call last):\n    File \"/usr/local/lib/python3.8/runpy.py\", line 192, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/local/lib/python3.8/runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 707, in start\n      self.io_loop.start()\n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/local/lib/python3.8/asyncio/base_events.py\", line 563, in run_forever\n      self._run_once()\n    File \"/usr/local/lib/python3.8/asyncio/base_events.py\", line 1844, in _run_once\n      handle._run()\n    File \"/usr/local/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 502, in dispatch_queue\n      await self.process_one()\n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 491, in process_one\n      await dispatch(*args)\n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 398, in dispatch_shell\n      await result\n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 722, in execute_request\n      reply_content = await reply_content\n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 389, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2863, in run_cell\n      result = self._run_cell(\n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2909, in _run_cell\n      return runner(coro)\n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3106, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3309, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3369, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_13858/1510589327.py\", line 1, in <cell line: 1>\n      tuner.search(train_ds,\n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/keras_tuner/engine/base_tuner.py\", line 179, in search\n      results = self.run_trial(trial, *fit_args, **fit_kwargs)\n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/keras_tuner/engine/tuner.py\", line 294, in run_trial\n      obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/keras_tuner/engine/tuner.py\", line 222, in _build_and_fit_model\n      results = self.hypermodel.fit(hp, model, *args, **kwargs)\n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/keras_tuner/engine/hypermodel.py\", line 137, in fit\n      return model.fit(*args, **kwargs)\n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/keras/engine/training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/keras/engine/training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/keras/engine/training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/keras/engine/training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/keras/engine/training.py\", line 859, in train_step\n      y_pred = self(x, training=True)\n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/keras/engine/functional.py\", line 451, in call\n      return self._run_internal_graph(\n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/keras/engine/functional.py\", line 589, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/keras/engine/base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/keras/layers/convolutional.py\", line 248, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/keras/layers/convolutional.py\", line 233, in convolution_op\n      return tf.nn.convolution(\nNode: 'model/conv1d/Conv1D'\nComputed output size would be negative: -13 [input_size: 1, effective_filter_size: 15, stride: 1]\n\t [[{{node model/conv1d/Conv1D}}]] [Op:__inference_train_function_8904]"
     ]
    }
   ],
   "source": [
    "tuner.search(\n",
    "    train_ds,\n",
    "    validation_data=valid_ds,\n",
    "    epochs=150,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=8)],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bafe37f",
   "metadata": {},
   "source": [
    "### 2/ Analyse hyperparameter search results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c594e72",
   "metadata": {},
   "source": [
    "#### Search space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "7b8a5e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 17\n",
      "input_size (Fixed)\n",
      "{'conditions': [], 'value': 100}\n",
      "regul (Float)\n",
      "{'default': 0.0001, 'conditions': [], 'min_value': 1e-05, 'max_value': 0.1, 'step': None, 'sampling': 'log'}\n",
      "batch_normalization (Boolean)\n",
      "{'default': False, 'conditions': []}\n",
      "conv_blocks (Int)\n",
      "{'default': 2, 'conditions': [], 'min_value': 1, 'max_value': 3, 'step': 1, 'sampling': None}\n",
      "filters_0 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 256, 'step': 32, 'sampling': None}\n",
      "kernel_size0 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 5, 'max_value': 20, 'step': 1, 'sampling': None}\n",
      "filters_1 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 256, 'step': 32, 'sampling': None}\n",
      "kernel_size1 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 5, 'max_value': 20, 'step': 1, 'sampling': None}\n",
      "pooling_1 (Choice)\n",
      "{'default': 'avg', 'conditions': [], 'values': ['avg', 'max', 'none'], 'ordered': False}\n",
      "hidden_size (Int)\n",
      "{'default': 32, 'conditions': [], 'min_value': 10, 'max_value': 100, 'step': 32, 'sampling': None}\n",
      "dense_blocks (Int)\n",
      "{'default': 1, 'conditions': [], 'min_value': 1, 'max_value': 3, 'step': 1, 'sampling': None}\n",
      "dropout (Float)\n",
      "{'default': 0.5, 'conditions': [], 'min_value': 0.0, 'max_value': 0.5, 'step': 0.1, 'sampling': None}\n",
      "learning_rate (Float)\n",
      "{'default': 0.001, 'conditions': [], 'min_value': 1e-05, 'max_value': 0.1, 'step': None, 'sampling': 'log'}\n",
      "pooling_0 (Choice)\n",
      "{'default': 'avg', 'conditions': [], 'values': ['avg', 'max', 'none'], 'ordered': False}\n",
      "filters_2 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 256, 'step': 32, 'sampling': None}\n",
      "kernel_size2 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 5, 'max_value': 20, 'step': 1, 'sampling': None}\n",
      "pooling_2 (Choice)\n",
      "{'default': 'avg', 'conditions': [], 'values': ['avg', 'max', 'none'], 'ordered': False}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2734bd6",
   "metadata": {},
   "source": [
    "#### Best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "00be1ffa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in ./untitled_project\n",
      "Showing 10 best trials\n",
      "<keras_tuner.engine.objective.Objective object at 0x7ff9716fac10>\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "input_size: 100\n",
      "regul: 0.00032199506051567314\n",
      "batch_normalization: True\n",
      "conv_blocks: 2\n",
      "filters_0: 64\n",
      "kernel_size0: 13\n",
      "filters_1: 160\n",
      "kernel_size1: 5\n",
      "pooling_1: avg\n",
      "hidden_size: 74\n",
      "dense_blocks: 2\n",
      "dropout: 0.30000000000000004\n",
      "learning_rate: 0.00020644391295639603\n",
      "pooling_0: none\n",
      "Score: 0.7165171504020691\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "input_size: 100\n",
      "regul: 0.00020843798952555745\n",
      "batch_normalization: True\n",
      "conv_blocks: 2\n",
      "filters_0: 128\n",
      "kernel_size0: 20\n",
      "filters_1: 192\n",
      "kernel_size1: 5\n",
      "pooling_1: avg\n",
      "hidden_size: 74\n",
      "dense_blocks: 3\n",
      "dropout: 0.2\n",
      "learning_rate: 0.00037799533912759005\n",
      "pooling_0: none\n",
      "filters_2: 32\n",
      "kernel_size2: 13\n",
      "pooling_2: avg\n",
      "Score: 0.7778459191322327\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "input_size: 100\n",
      "regul: 0.0007469179347180683\n",
      "batch_normalization: True\n",
      "conv_blocks: 2\n",
      "filters_0: 32\n",
      "kernel_size0: 20\n",
      "filters_1: 128\n",
      "kernel_size1: 5\n",
      "pooling_1: max\n",
      "hidden_size: 74\n",
      "dense_blocks: 2\n",
      "dropout: 0.30000000000000004\n",
      "learning_rate: 0.000802164502626052\n",
      "pooling_0: none\n",
      "filters_2: 32\n",
      "kernel_size2: 5\n",
      "pooling_2: avg\n",
      "Score: 0.7858437895774841\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "input_size: 100\n",
      "regul: 7.55981495330342e-05\n",
      "batch_normalization: True\n",
      "conv_blocks: 2\n",
      "filters_0: 32\n",
      "kernel_size0: 16\n",
      "filters_1: 160\n",
      "kernel_size1: 5\n",
      "pooling_1: max\n",
      "hidden_size: 74\n",
      "dense_blocks: 2\n",
      "dropout: 0.2\n",
      "learning_rate: 0.0005581019820643\n",
      "pooling_0: avg\n",
      "filters_2: 32\n",
      "kernel_size2: 7\n",
      "pooling_2: avg\n",
      "Score: 0.7888842225074768\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "input_size: 100\n",
      "regul: 0.00030389246930894354\n",
      "batch_normalization: True\n",
      "conv_blocks: 1\n",
      "filters_0: 256\n",
      "kernel_size0: 6\n",
      "filters_1: 96\n",
      "kernel_size1: 12\n",
      "pooling_1: max\n",
      "hidden_size: 42\n",
      "dense_blocks: 1\n",
      "dropout: 0.0\n",
      "learning_rate: 0.0004831323790896749\n",
      "pooling_0: none\n",
      "filters_2: 224\n",
      "kernel_size2: 17\n",
      "pooling_2: avg\n",
      "Score: 0.7936887741088867\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "input_size: 100\n",
      "regul: 8.36888906944629e-05\n",
      "batch_normalization: True\n",
      "conv_blocks: 1\n",
      "filters_0: 160\n",
      "kernel_size0: 20\n",
      "filters_1: 32\n",
      "kernel_size1: 18\n",
      "pooling_1: avg\n",
      "hidden_size: 74\n",
      "dense_blocks: 3\n",
      "dropout: 0.0\n",
      "learning_rate: 0.0001430678295824808\n",
      "pooling_0: none\n",
      "filters_2: 32\n",
      "kernel_size2: 18\n",
      "pooling_2: avg\n",
      "Score: 0.799139142036438\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "input_size: 100\n",
      "regul: 1e-05\n",
      "batch_normalization: True\n",
      "conv_blocks: 1\n",
      "filters_0: 128\n",
      "kernel_size0: 10\n",
      "filters_1: 32\n",
      "kernel_size1: 5\n",
      "pooling_1: avg\n",
      "hidden_size: 74\n",
      "dense_blocks: 3\n",
      "dropout: 0.0\n",
      "learning_rate: 0.0002475337024914044\n",
      "pooling_0: avg\n",
      "filters_2: 32\n",
      "kernel_size2: 16\n",
      "pooling_2: avg\n",
      "Score: 0.8093088269233704\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "input_size: 100\n",
      "regul: 1e-05\n",
      "batch_normalization: True\n",
      "conv_blocks: 3\n",
      "filters_0: 32\n",
      "kernel_size0: 20\n",
      "filters_1: 32\n",
      "kernel_size1: 13\n",
      "pooling_1: none\n",
      "hidden_size: 74\n",
      "dense_blocks: 3\n",
      "dropout: 0.30000000000000004\n",
      "learning_rate: 7.54155046561189e-05\n",
      "pooling_0: max\n",
      "filters_2: 32\n",
      "kernel_size2: 5\n",
      "pooling_2: avg\n",
      "Score: 0.8105588555335999\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "input_size: 100\n",
      "regul: 0.0010849287220037601\n",
      "batch_normalization: True\n",
      "conv_blocks: 1\n",
      "filters_0: 256\n",
      "kernel_size0: 12\n",
      "filters_1: 32\n",
      "kernel_size1: 5\n",
      "pooling_1: avg\n",
      "hidden_size: 74\n",
      "dense_blocks: 3\n",
      "dropout: 0.0\n",
      "learning_rate: 0.002520398806392755\n",
      "pooling_0: none\n",
      "filters_2: 128\n",
      "kernel_size2: 18\n",
      "pooling_2: avg\n",
      "Score: 0.8143752217292786\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "input_size: 100\n",
      "regul: 0.00018955572019309564\n",
      "batch_normalization: True\n",
      "conv_blocks: 1\n",
      "filters_0: 160\n",
      "kernel_size0: 13\n",
      "filters_1: 32\n",
      "kernel_size1: 7\n",
      "pooling_1: none\n",
      "hidden_size: 74\n",
      "dense_blocks: 3\n",
      "dropout: 0.30000000000000004\n",
      "learning_rate: 0.00101659758850157\n",
      "pooling_0: none\n",
      "filters_2: 32\n",
      "kernel_size2: 11\n",
      "pooling_2: avg\n",
      "Score: 0.8170084953308105\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "74f9ea97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "2022-08-18 12:51:24,039-[WARNING]- tensorflow:185 -> Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "2022-08-18 12:51:24,040-[WARNING]- tensorflow:194 -> Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
      "2022-08-18 12:51:24,041-[WARNING]- tensorflow:194 -> Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
      "2022-08-18 12:51:24,042-[WARNING]- tensorflow:194 -> Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "2022-08-18 12:51:24,043-[WARNING]- tensorflow:194 -> Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
      "2022-08-18 12:51:24,045-[WARNING]- tensorflow:194 -> Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "2022-08-18 12:51:24,049-[WARNING]- tensorflow:185 -> Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "2022-08-18 12:51:24,057-[WARNING]- tensorflow:194 -> Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
      "2022-08-18 12:51:24,059-[WARNING]- tensorflow:194 -> Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
      "2022-08-18 12:51:24,060-[WARNING]- tensorflow:194 -> Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "2022-08-18 12:51:24,061-[WARNING]- tensorflow:194 -> Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
      "2022-08-18 12:51:24,067-[WARNING]- tensorflow:194 -> Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "2022-08-18 12:51:24,071-[WARNING]- tensorflow:185 -> Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "2022-08-18 12:51:24,073-[WARNING]- tensorflow:194 -> Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
      "2022-08-18 12:51:24,074-[WARNING]- tensorflow:194 -> Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
      "2022-08-18 12:51:24,075-[WARNING]- tensorflow:194 -> Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "2022-08-18 12:51:24,083-[WARNING]- tensorflow:194 -> Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
      "2022-08-18 12:51:24,086-[WARNING]- tensorflow:194 -> Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "2022-08-18 12:51:24,090-[WARNING]- tensorflow:185 -> Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "2022-08-18 12:51:24,091-[WARNING]- tensorflow:194 -> Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
      "2022-08-18 12:51:24,093-[WARNING]- tensorflow:194 -> Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
      "2022-08-18 12:51:24,094-[WARNING]- tensorflow:194 -> Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "2022-08-18 12:51:24,099-[WARNING]- tensorflow:194 -> Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
      "2022-08-18 12:51:24,101-[WARNING]- tensorflow:194 -> Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-18 12:51:24,108-[WARNING]- tensorflow:185 -> Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "2022-08-18 12:51:24,109-[WARNING]- tensorflow:194 -> Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
      "2022-08-18 12:51:24,110-[WARNING]- tensorflow:194 -> Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
      "2022-08-18 12:51:24,111-[WARNING]- tensorflow:194 -> Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "2022-08-18 12:51:24,115-[WARNING]- tensorflow:194 -> Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
      "2022-08-18 12:51:24,116-[WARNING]- tensorflow:194 -> Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "2022-08-18 12:51:24,119-[WARNING]- tensorflow:185 -> Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "2022-08-18 12:51:24,120-[WARNING]- tensorflow:194 -> Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
      "2022-08-18 12:51:24,120-[WARNING]- tensorflow:194 -> Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
      "2022-08-18 12:51:24,121-[WARNING]- tensorflow:194 -> Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "2022-08-18 12:51:24,122-[WARNING]- tensorflow:194 -> Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
      "2022-08-18 12:51:24,122-[WARNING]- tensorflow:194 -> Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "2022-08-18 12:51:24,130-[WARNING]- tensorflow:185 -> Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "2022-08-18 12:51:24,132-[WARNING]- tensorflow:194 -> Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
      "2022-08-18 12:51:24,133-[WARNING]- tensorflow:194 -> Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
      "2022-08-18 12:51:24,134-[WARNING]- tensorflow:194 -> Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "2022-08-18 12:51:24,137-[WARNING]- tensorflow:194 -> Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
      "2022-08-18 12:51:24,139-[WARNING]- tensorflow:194 -> Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "2022-08-18 12:51:24,143-[WARNING]- tensorflow:185 -> Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "2022-08-18 12:51:24,147-[WARNING]- tensorflow:194 -> Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
      "2022-08-18 12:51:24,150-[WARNING]- tensorflow:194 -> Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
      "2022-08-18 12:51:24,152-[WARNING]- tensorflow:194 -> Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "2022-08-18 12:51:24,155-[WARNING]- tensorflow:194 -> Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
      "2022-08-18 12:51:24,157-[WARNING]- tensorflow:194 -> Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "2022-08-18 12:51:24,165-[WARNING]- tensorflow:185 -> Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "2022-08-18 12:51:24,166-[WARNING]- tensorflow:194 -> Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
      "2022-08-18 12:51:24,168-[WARNING]- tensorflow:194 -> Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
      "2022-08-18 12:51:24,169-[WARNING]- tensorflow:194 -> Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "2022-08-18 12:51:24,170-[WARNING]- tensorflow:194 -> Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
      "2022-08-18 12:51:24,172-[WARNING]- tensorflow:194 -> Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n"
     ]
    }
   ],
   "source": [
    "best_models = tuner.get_best_models(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "1db17612",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hyperparameters = tuner.get_best_hyperparameters(10)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0811a733",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "dir(tuner)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c874a3",
   "metadata": {},
   "source": [
    "#### Best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "96694849",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = best_models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "f48c513c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 100, 1)]          0         \n",
      "                                                                 \n",
      " rescaling (Rescaling)       (None, 100, 1)            0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 91, 64)            704       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 91, 64)           256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 91, 64)            0         \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 82, 160)           102560    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 82, 160)          640       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 82, 160)           0         \n",
      "                                                                 \n",
      " average_pooling1d (AverageP  (None, 41, 160)          0         \n",
      " ooling1D)                                                       \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6560)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 74)                485514    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 74)                5550      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 74)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 75        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 595,299\n",
      "Trainable params: 594,851\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "18f92423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_size': 100,\n",
       " 'regul': 0.00032199506051567314,\n",
       " 'batch_normalization': True,\n",
       " 'conv_blocks': 2,\n",
       " 'filters_0': 64,\n",
       " 'kernel_size0': 13,\n",
       " 'filters_1': 160,\n",
       " 'kernel_size1': 5,\n",
       " 'pooling_1': 'avg',\n",
       " 'hidden_size': 74,\n",
       " 'dense_blocks': 2,\n",
       " 'dropout': 0.30000000000000004,\n",
       " 'learning_rate': 0.00020644391295639603,\n",
       " 'pooling_0': 'none'}"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hyperparameters[0].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04b138b",
   "metadata": {},
   "source": [
    "#### Size of best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "1a7d28e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0\n",
      "594851\n",
      "\n",
      "Model 1\n",
      "841777\n",
      "\n",
      "Model 2\n",
      "435811\n",
      "\n",
      "Model 3\n",
      "543235\n",
      "\n",
      "Model 4\n",
      "981845\n",
      "\n",
      "Model 5\n",
      "1090769\n",
      "\n",
      "Model 6\n",
      "439153\n",
      "\n",
      "Model 7\n",
      "117585\n",
      "\n",
      "Model 8\n",
      "1738481\n",
      "\n",
      "Model 9\n",
      "1090769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(f\"Model {i}\")\n",
    "    print(count_params(best_models[i].trainable_weights))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9252386",
   "metadata": {},
   "source": [
    "#### Visualize prediction on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "1d696ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_against(model, test_feature, test_label):\n",
    "    predicted = model.predict(test_feature)\n",
    "    plt.scatter(test_label, predicted, marker=\"o\")\n",
    "    plt.plot([0, 12], [0, 12])\n",
    "    plt.xlim(2, 16)\n",
    "    plt.ylim(2, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "4f177b4f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_against(best_model, data_preparation(train_feature), train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "6c96324b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 7ms/step - loss: 2.9143 - mean_absolute_error: 0.7165\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.9142723083496094, 0.7165171504020691]"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.evaluate(data_preparation(valid_feature), valid_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "4971c3b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 120)"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_feature.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a083a2",
   "metadata": {},
   "source": [
    "### 3/ Evaluate the best models with cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c604bb08",
   "metadata": {},
   "source": [
    "valid_e is the validation set for early stopping\\\n",
    "valid is the validation set to evaluate a split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9532cd0b",
   "metadata": {},
   "source": [
    "#### Model hyperparameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769d6673",
   "metadata": {},
   "source": [
    "**a. From a saved dictionnary**"
   ]
  },
  {
   "cell_type": "raw",
   "id": "858d42b1",
   "metadata": {},
   "source": [
    "best_config = {'input_size': 100,\n",
    " 'hidden_size': 42,\n",
    " 'regul': 0.0035557261842639634,\n",
    " 'dense_blocks': 3,\n",
    " 'dropout': 0.0,\n",
    " 'learning_rate': 0.0016003804865801434}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "331fa2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_fixed_hp_from_dict(d):\n",
    "    Ä¥p = kt.HyperParameters()\n",
    "    for key in d.keys():\n",
    "        hp.Fixed(key, d[key])\n",
    "    return hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "ecf2523f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = make_fixed_hp_from_dict(best_config)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c810e9eb",
   "metadata": {},
   "source": [
    "# Equivalent to doing:\n",
    "hp = kt.HyperParameters()\n",
    "hp.Fixed('input_size', 100)\n",
    "hp.Fixed('hidden_size', 42)\n",
    "hp.Fixed('regul', 0.0035)\n",
    "hp.Fixed('dense_blocks', 3)\n",
    "hp.Fixed('dropout', 0.0)\n",
    "hp.Fixed('learning_rate', 0.0016)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052160a3",
   "metadata": {},
   "source": [
    "**b. From a hyperparameter instance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "d9a5a798",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = best_hyperparameters[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b640e82",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "0b72e66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = build_function(hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "086ab7c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 100, 1)]          0         \n",
      "                                                                 \n",
      " rescaling_5 (Rescaling)     (None, 100, 1)            0         \n",
      "                                                                 \n",
      " conv1d_7 (Conv1D)           (None, 91, 32)            352       \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 91, 32)           128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_7 (ReLU)              (None, 91, 32)            0         \n",
      "                                                                 \n",
      " conv1d_8 (Conv1D)           (None, 82, 160)           51360     \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 82, 160)          640       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_8 (ReLU)              (None, 82, 160)           0         \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 41, 160)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 6560)              0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 74)                485514    \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 74)                5550      \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 74)                0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 1)                 75        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 543,619\n",
      "Trainable params: 543,235\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950b860e",
   "metadata": {},
   "source": [
    "#### Cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fa1b56",
   "metadata": {},
   "source": [
    "Creating the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "8f10a6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature_ds = np.expand_dims(train_feature, axis=-1)\n",
    "train_feature_ds = np.expand_dims(train_feature_ds, axis=-3)\n",
    "d1 = tf.data.Dataset.from_tensor_slices(train_feature_ds)\n",
    "d2 = tf.data.Dataset.from_tensor_slices(train_label)\n",
    "train_ds = tf.data.Dataset.zip((d1, d2))\n",
    "train_ds = (\n",
    "    train_ds.map(lambda x, y: (data_augmentation(x, training=True), y))\n",
    "    .unbatch()\n",
    "    .batch(16)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "f9e412fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_feature_ds = np.expand_dims(valid_feature, axis=-1)\n",
    "valid_feature_ds = np.expand_dims(valid_feature_ds, axis=-3)\n",
    "d1 = tf.data.Dataset.from_tensor_slices(valid_feature_ds)\n",
    "d2 = tf.data.Dataset.from_tensor_slices(valid_label)\n",
    "valid_ds = tf.data.Dataset.zip((d1, d2))\n",
    "valid_ds = (\n",
    "    valid_ds.map(lambda x, y: (data_preparation(x, training=True), y))\n",
    "    .unbatch()\n",
    "    .batch(16)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "15b308c9",
   "metadata": {},
   "source": [
    "new_model.fit(train_ds,\n",
    "             validation_data= valid_ds,\n",
    "             epochs=10,\n",
    "             callbacks=[tf.keras.callbacks.EarlyStopping(patience=8)])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f689c7c3",
   "metadata": {},
   "source": [
    "new_model.fit(train_ds,\n",
    "             #validation_data= valid_ds,\n",
    "             epochs=10)\n",
    "             #callbacks=[tf.keras.callbacks.EarlyStopping(patience=8)])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "99969d45",
   "metadata": {},
   "source": [
    "new_model.fit(train_ds,\n",
    "             validation_data= valid_ds,\n",
    "             epochs=100,\n",
    "             callbacks=[tf.keras.callbacks.EarlyStopping(patience=8)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "03dbeabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy_to_ds(feature, label):\n",
    "    feature_ds = np.expand_dims(feature, axis=-1)\n",
    "    feature_ds = np.expand_dims(feature_ds, axis=-3)\n",
    "    d1 = tf.data.Dataset.from_tensor_slices(feature_ds)\n",
    "    d2 = tf.data.Dataset.from_tensor_slices(label)\n",
    "    ds = tf.data.Dataset.zip((d1, d2))\n",
    "    ds = (\n",
    "        ds.map(lambda x, y: (data_augmentation(x, training=True), y))\n",
    "        .unbatch()\n",
    "        .batch(16)\n",
    "        .prefetch(tf.data.AUTOTUNE)\n",
    "    )\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "fe16408d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy_to_ds_preparation(feature, label):\n",
    "    feature_ds = np.expand_dims(feature, axis=-1)\n",
    "    feature_ds = np.expand_dims(feature_ds, axis=-3)\n",
    "    d1 = tf.data.Dataset.from_tensor_slices(feature_ds)\n",
    "    d2 = tf.data.Dataset.from_tensor_slices(label)\n",
    "    ds = tf.data.Dataset.zip((d1, d2))\n",
    "    ds = (\n",
    "        ds.map(lambda x, y: (data_preparation(x, training=True), y))\n",
    "        .unbatch()\n",
    "        .batch(16)\n",
    "        .prefetch(tf.data.AUTOTUNE)\n",
    "    )\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "67f4028c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0005581019820643"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp.values[\"learning_rate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "e0ab4cc9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def generalisation_estimator(model, hp, n_split=4):\n",
    "    evaluations = []\n",
    "    history = []\n",
    "    for train_g, valid in KFold(n_split).split(training):\n",
    "        train, valid_e = next(KFold(n_split).split(train_g))\n",
    "        train_feature = im[train, :]\n",
    "        train_label = label[train, :]\n",
    "        valid_e_feature = im[valid_e, :]\n",
    "        valid_e_label = label[valid_e, :]\n",
    "        valid_feature = im[valid, :]\n",
    "        valid_label = label[valid, :]\n",
    "\n",
    "        train_ds = numpy_to_ds(train_feature, train_label)\n",
    "        valid_e_ds = numpy_to_ds_preparation(valid_e_feature, valid_e_label)\n",
    "        # valid_ds = numpy_to_ds_preparation(valid_feature, valid_label)\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=keras.optimizers.Adam(learning_rate=hp.values[\"learning_rate\"]),\n",
    "            loss=keras.losses.MeanSquaredError(name=\"mean_squared_error\"),\n",
    "            metrics=[tf.keras.metrics.mean_absolute_error],\n",
    "        )\n",
    "\n",
    "        print(valid_e)\n",
    "\n",
    "        history.append(\n",
    "            model.fit(\n",
    "                train_ds,\n",
    "                validation_data=valid_e_ds,\n",
    "                # batch_size=16,\n",
    "                epochs=200,\n",
    "                callbacks=[tf.keras.callbacks.EarlyStopping(patience=4)]  # CAREFUL\n",
    "                # validation_data = (data_preparation(valid_e_feature), valid_e_label),\n",
    "            )\n",
    "        )\n",
    "        evaluations.append(model.evaluate(data_preparation(valid_feature), valid_label))\n",
    "\n",
    "    return model, history, evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "fd19cd1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70]\n",
      "Epoch 1/200\n",
      "14/14 [==============================] - 1s 29ms/step - loss: 7.2616 - mean_absolute_error: 1.8243 - val_loss: 31.4294 - val_mean_absolute_error: 5.1296\n",
      "Epoch 2/200\n",
      "14/14 [==============================] - 0s 18ms/step - loss: 3.3958 - mean_absolute_error: 1.2820 - val_loss: 30.7947 - val_mean_absolute_error: 5.0764\n",
      "Epoch 3/200\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 3.9612 - mean_absolute_error: 1.4288 - val_loss: 30.3231 - val_mean_absolute_error: 5.0374\n",
      "Epoch 4/200\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 3.4857 - mean_absolute_error: 1.3351 - val_loss: 29.7732 - val_mean_absolute_error: 4.9913\n",
      "Epoch 5/200\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 3.1162 - mean_absolute_error: 1.2479 - val_loss: 29.1164 - val_mean_absolute_error: 4.9349\n",
      "Epoch 6/200\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 3.1691 - mean_absolute_error: 1.2338 - val_loss: 27.7132 - val_mean_absolute_error: 4.8117\n",
      "Epoch 7/200\n",
      "14/14 [==============================] - 0s 18ms/step - loss: 3.6232 - mean_absolute_error: 1.3427 - val_loss: 27.1100 - val_mean_absolute_error: 4.7574\n",
      "Epoch 8/200\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 3.3368 - mean_absolute_error: 1.2801 - val_loss: 26.8947 - val_mean_absolute_error: 4.7379\n",
      "Epoch 9/200\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 2.7484 - mean_absolute_error: 1.1482 - val_loss: 26.7939 - val_mean_absolute_error: 4.7273\n",
      "Epoch 10/200\n",
      "14/14 [==============================] - 0s 18ms/step - loss: 2.5820 - mean_absolute_error: 1.0719 - val_loss: 27.2169 - val_mean_absolute_error: 4.7671\n",
      "Epoch 11/200\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 2.3734 - mean_absolute_error: 1.0362 - val_loss: 27.0287 - val_mean_absolute_error: 4.7509\n",
      "Epoch 12/200\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 2.9950 - mean_absolute_error: 1.1932 - val_loss: 27.4246 - val_mean_absolute_error: 4.7886\n",
      "Epoch 13/200\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 2.4569 - mean_absolute_error: 1.0754 - val_loss: 26.4393 - val_mean_absolute_error: 4.7007\n",
      "Epoch 14/200\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 2.4032 - mean_absolute_error: 1.0826 - val_loss: 26.5381 - val_mean_absolute_error: 4.7133\n",
      "Epoch 15/200\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 2.5805 - mean_absolute_error: 1.1306 - val_loss: 26.1133 - val_mean_absolute_error: 4.6782\n",
      "Epoch 16/200\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 2.8705 - mean_absolute_error: 1.1804 - val_loss: 26.9883 - val_mean_absolute_error: 4.7559\n",
      "Epoch 17/200\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 2.6282 - mean_absolute_error: 1.0954 - val_loss: 26.0707 - val_mean_absolute_error: 4.6753\n",
      "Epoch 18/200\n",
      "14/14 [==============================] - 0s 25ms/step - loss: 2.7021 - mean_absolute_error: 1.1266 - val_loss: 27.8325 - val_mean_absolute_error: 4.8379\n",
      "Epoch 19/200\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 2.4299 - mean_absolute_error: 1.0643 - val_loss: 27.4036 - val_mean_absolute_error: 4.8067\n",
      "Epoch 20/200\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 2.0708 - mean_absolute_error: 0.9587 - val_loss: 27.8512 - val_mean_absolute_error: 4.8467\n",
      "Epoch 21/200\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 2.3556 - mean_absolute_error: 1.0266 - val_loss: 25.9902 - val_mean_absolute_error: 4.6831\n",
      "Epoch 22/200\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 2.2423 - mean_absolute_error: 0.9888 - val_loss: 24.4954 - val_mean_absolute_error: 4.5387\n",
      "Epoch 23/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 2.6891 - mean_absolute_error: 1.0675 - val_loss: 26.2791 - val_mean_absolute_error: 4.7075\n",
      "Epoch 24/200\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 2.3966 - mean_absolute_error: 1.0320 - val_loss: 23.7160 - val_mean_absolute_error: 4.4682\n",
      "Epoch 25/200\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 2.4062 - mean_absolute_error: 1.0340 - val_loss: 25.3970 - val_mean_absolute_error: 4.6135\n",
      "Epoch 26/200\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 2.4037 - mean_absolute_error: 1.0346 - val_loss: 22.0042 - val_mean_absolute_error: 4.2816\n",
      "Epoch 27/200\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 2.3822 - mean_absolute_error: 1.0057 - val_loss: 21.7545 - val_mean_absolute_error: 4.2587\n",
      "Epoch 28/200\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 2.1926 - mean_absolute_error: 0.9603 - val_loss: 19.2428 - val_mean_absolute_error: 4.0017\n",
      "Epoch 29/200\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 2.0098 - mean_absolute_error: 0.9254 - val_loss: 16.0555 - val_mean_absolute_error: 3.6213\n",
      "Epoch 30/200\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 2.3862 - mean_absolute_error: 0.9875 - val_loss: 15.6416 - val_mean_absolute_error: 3.5667\n",
      "Epoch 31/200\n",
      "14/14 [==============================] - 0s 18ms/step - loss: 2.1324 - mean_absolute_error: 0.9474 - val_loss: 15.8856 - val_mean_absolute_error: 3.5921\n",
      "Epoch 32/200\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 1.8330 - mean_absolute_error: 0.8443 - val_loss: 11.6414 - val_mean_absolute_error: 2.9935\n",
      "Epoch 33/200\n",
      "14/14 [==============================] - 0s 18ms/step - loss: 2.1990 - mean_absolute_error: 0.9680 - val_loss: 9.8542 - val_mean_absolute_error: 2.7448\n",
      "Epoch 34/200\n",
      "14/14 [==============================] - 0s 18ms/step - loss: 2.2586 - mean_absolute_error: 0.9625 - val_loss: 11.3898 - val_mean_absolute_error: 2.9884\n",
      "Epoch 35/200\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 1.9293 - mean_absolute_error: 0.9241 - val_loss: 10.3767 - val_mean_absolute_error: 2.8499\n",
      "Epoch 36/200\n",
      "14/14 [==============================] - 0s 18ms/step - loss: 2.0516 - mean_absolute_error: 0.8869 - val_loss: 7.4103 - val_mean_absolute_error: 2.2937\n",
      "Epoch 37/200\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 1.8863 - mean_absolute_error: 0.8532 - val_loss: 11.8102 - val_mean_absolute_error: 3.0670\n",
      "Epoch 38/200\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 2.3090 - mean_absolute_error: 0.9986 - val_loss: 5.7272 - val_mean_absolute_error: 1.9186\n",
      "Epoch 39/200\n",
      "14/14 [==============================] - 0s 29ms/step - loss: 2.2772 - mean_absolute_error: 1.0141 - val_loss: 4.9243 - val_mean_absolute_error: 1.7118\n",
      "Epoch 40/200\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 2.3134 - mean_absolute_error: 1.0229 - val_loss: 5.0740 - val_mean_absolute_error: 1.8096\n",
      "Epoch 41/200\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 2.0569 - mean_absolute_error: 0.9338 - val_loss: 3.9920 - val_mean_absolute_error: 1.4917\n",
      "Epoch 42/200\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 2.1043 - mean_absolute_error: 0.9413 - val_loss: 3.6237 - val_mean_absolute_error: 1.3879\n",
      "Epoch 43/200\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 2.1556 - mean_absolute_error: 0.9723 - val_loss: 4.7452 - val_mean_absolute_error: 1.6686\n",
      "Epoch 44/200\n",
      "14/14 [==============================] - 0s 23ms/step - loss: 2.0464 - mean_absolute_error: 0.9643 - val_loss: 4.3370 - val_mean_absolute_error: 1.5574\n",
      "Epoch 45/200\n",
      "14/14 [==============================] - 0s 27ms/step - loss: 2.0031 - mean_absolute_error: 0.9159 - val_loss: 3.8858 - val_mean_absolute_error: 1.4543\n",
      "Epoch 46/200\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 1.8253 - mean_absolute_error: 0.8821 - val_loss: 3.2086 - val_mean_absolute_error: 1.2751\n",
      "Epoch 47/200\n",
      "14/14 [==============================] - 0s 18ms/step - loss: 1.9242 - mean_absolute_error: 0.8962 - val_loss: 3.1599 - val_mean_absolute_error: 1.2769\n",
      "Epoch 48/200\n",
      "14/14 [==============================] - 0s 18ms/step - loss: 1.8050 - mean_absolute_error: 0.8474 - val_loss: 2.4602 - val_mean_absolute_error: 1.1073\n",
      "Epoch 49/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 18ms/step - loss: 1.7211 - mean_absolute_error: 0.8417 - val_loss: 3.7359 - val_mean_absolute_error: 1.4919\n",
      "Epoch 50/200\n",
      "14/14 [==============================] - 0s 18ms/step - loss: 1.7844 - mean_absolute_error: 0.8199 - val_loss: 2.8969 - val_mean_absolute_error: 1.1963\n",
      "Epoch 51/200\n",
      "14/14 [==============================] - 0s 18ms/step - loss: 1.7130 - mean_absolute_error: 0.8373 - val_loss: 2.6819 - val_mean_absolute_error: 1.2065\n",
      "Epoch 52/200\n",
      "14/14 [==============================] - 0s 18ms/step - loss: 1.8507 - mean_absolute_error: 0.9011 - val_loss: 2.2328 - val_mean_absolute_error: 1.0230\n",
      "Epoch 53/200\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 1.7001 - mean_absolute_error: 0.8477 - val_loss: 2.5709 - val_mean_absolute_error: 1.1648\n",
      "Epoch 54/200\n",
      "14/14 [==============================] - 0s 17ms/step - loss: 1.7931 - mean_absolute_error: 0.8526 - val_loss: 2.8983 - val_mean_absolute_error: 1.2150\n",
      "Epoch 55/200\n",
      "14/14 [==============================] - 0s 18ms/step - loss: 1.9704 - mean_absolute_error: 0.9322 - val_loss: 4.9896 - val_mean_absolute_error: 1.7115\n",
      "Epoch 56/200\n",
      "14/14 [==============================] - 0s 18ms/step - loss: 1.6806 - mean_absolute_error: 0.8309 - val_loss: 3.6766 - val_mean_absolute_error: 1.4659\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 3.8939 - mean_absolute_error: 1.5318\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70]\n",
      "Epoch 1/200\n",
      "14/14 [==============================] - 1s 27ms/step - loss: 2.1757 - mean_absolute_error: 0.9782 - val_loss: 3.1142 - val_mean_absolute_error: 1.3037\n",
      "Epoch 2/200\n",
      "14/14 [==============================] - 0s 16ms/step - loss: 1.9146 - mean_absolute_error: 0.9590 - val_loss: 4.7133 - val_mean_absolute_error: 1.7140\n",
      "Epoch 3/200\n",
      "14/14 [==============================] - 0s 17ms/step - loss: 1.9166 - mean_absolute_error: 0.9127 - val_loss: 2.1555 - val_mean_absolute_error: 1.0339\n",
      "Epoch 4/200\n",
      "14/14 [==============================] - 0s 17ms/step - loss: 1.7836 - mean_absolute_error: 0.9453 - val_loss: 3.1991 - val_mean_absolute_error: 1.3786\n",
      "Epoch 5/200\n",
      "14/14 [==============================] - 0s 17ms/step - loss: 1.7260 - mean_absolute_error: 0.8788 - val_loss: 2.8803 - val_mean_absolute_error: 1.3005\n",
      "Epoch 6/200\n",
      "14/14 [==============================] - 0s 17ms/step - loss: 1.7151 - mean_absolute_error: 0.9285 - val_loss: 2.8409 - val_mean_absolute_error: 1.2787\n",
      "Epoch 7/200\n",
      "14/14 [==============================] - 0s 17ms/step - loss: 1.6661 - mean_absolute_error: 0.8856 - val_loss: 2.6101 - val_mean_absolute_error: 1.2120\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1.9742 - mean_absolute_error: 0.9360\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70]\n",
      "Epoch 1/200\n",
      "14/14 [==============================] - 1s 28ms/step - loss: 2.4686 - mean_absolute_error: 1.1253 - val_loss: 2.8645 - val_mean_absolute_error: 1.2807\n",
      "Epoch 2/200\n",
      "14/14 [==============================] - 0s 17ms/step - loss: 2.0466 - mean_absolute_error: 0.9853 - val_loss: 2.0404 - val_mean_absolute_error: 1.0285\n",
      "Epoch 3/200\n",
      "14/14 [==============================] - 0s 17ms/step - loss: 1.6815 - mean_absolute_error: 0.8738 - val_loss: 4.2004 - val_mean_absolute_error: 1.7000\n",
      "Epoch 4/200\n",
      "14/14 [==============================] - 0s 17ms/step - loss: 1.4330 - mean_absolute_error: 0.8167 - val_loss: 5.9716 - val_mean_absolute_error: 2.0156\n",
      "Epoch 5/200\n",
      "14/14 [==============================] - 0s 17ms/step - loss: 1.4773 - mean_absolute_error: 0.8461 - val_loss: 3.3448 - val_mean_absolute_error: 1.4468\n",
      "Epoch 6/200\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 1.7193 - mean_absolute_error: 0.9181 - val_loss: 5.0691 - val_mean_absolute_error: 1.8115\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1.8122 - mean_absolute_error: 0.9861\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70]\n",
      "Epoch 1/200\n",
      "14/14 [==============================] - 1s 27ms/step - loss: 2.0947 - mean_absolute_error: 1.0308 - val_loss: 3.1241 - val_mean_absolute_error: 1.3963\n",
      "Epoch 2/200\n",
      "14/14 [==============================] - 0s 17ms/step - loss: 2.1311 - mean_absolute_error: 1.0084 - val_loss: 7.8565 - val_mean_absolute_error: 2.2204\n",
      "Epoch 3/200\n",
      "14/14 [==============================] - 0s 17ms/step - loss: 2.0579 - mean_absolute_error: 0.9881 - val_loss: 5.6853 - val_mean_absolute_error: 2.0410\n",
      "Epoch 4/200\n",
      "14/14 [==============================] - 0s 17ms/step - loss: 1.8904 - mean_absolute_error: 0.9352 - val_loss: 3.5903 - val_mean_absolute_error: 1.5126\n",
      "Epoch 5/200\n",
      "14/14 [==============================] - 0s 17ms/step - loss: 1.3554 - mean_absolute_error: 0.7788 - val_loss: 2.1836 - val_mean_absolute_error: 1.0876\n",
      "Epoch 6/200\n",
      "14/14 [==============================] - 0s 18ms/step - loss: 1.6106 - mean_absolute_error: 0.8363 - val_loss: 3.1983 - val_mean_absolute_error: 1.3857\n",
      "Epoch 7/200\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 1.7240 - mean_absolute_error: 0.8941 - val_loss: 4.6999 - val_mean_absolute_error: 1.7000\n",
      "Epoch 8/200\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 1.5789 - mean_absolute_error: 0.9036 - val_loss: 5.7178 - val_mean_absolute_error: 1.9517\n",
      "Epoch 9/200\n",
      "14/14 [==============================] - 0s 24ms/step - loss: 1.6650 - mean_absolute_error: 0.8931 - val_loss: 2.1196 - val_mean_absolute_error: 1.0573\n",
      "Epoch 10/200\n",
      "14/14 [==============================] - 0s 28ms/step - loss: 1.5080 - mean_absolute_error: 0.8286 - val_loss: 2.9747 - val_mean_absolute_error: 1.3291\n",
      "Epoch 11/200\n",
      "14/14 [==============================] - 0s 33ms/step - loss: 1.4190 - mean_absolute_error: 0.8106 - val_loss: 2.5419 - val_mean_absolute_error: 1.2447\n",
      "Epoch 12/200\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 1.5758 - mean_absolute_error: 0.8630 - val_loss: 2.5349 - val_mean_absolute_error: 1.2301\n",
      "Epoch 13/200\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 1.5479 - mean_absolute_error: 0.8599 - val_loss: 2.0622 - val_mean_absolute_error: 1.0650\n",
      "Epoch 14/200\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 1.4144 - mean_absolute_error: 0.8023 - val_loss: 2.3594 - val_mean_absolute_error: 1.1773\n",
      "Epoch 15/200\n",
      "14/14 [==============================] - 0s 17ms/step - loss: 1.5420 - mean_absolute_error: 0.8578 - val_loss: 3.7576 - val_mean_absolute_error: 1.5707\n",
      "Epoch 16/200\n",
      "14/14 [==============================] - 0s 17ms/step - loss: 1.3630 - mean_absolute_error: 0.7633 - val_loss: 3.0280 - val_mean_absolute_error: 1.3729\n",
      "Epoch 17/200\n",
      "14/14 [==============================] - 0s 18ms/step - loss: 1.4891 - mean_absolute_error: 0.8133 - val_loss: 2.1218 - val_mean_absolute_error: 1.0809\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 2.6480 - mean_absolute_error: 1.1565\n"
     ]
    }
   ],
   "source": [
    "model, history, evaluations = generalisation_estimator(new_model, hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "219f7d86",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 2.907501369714737 Std: 1.8429777684483992\n"
     ]
    }
   ],
   "source": [
    "acc = [e[1] for e in evaluations]\n",
    "mean = np.mean(acc)\n",
    "std_dev = np.std(acc)\n",
    "print(f\"Mean: {mean} Std: {std_dev}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "1f53d9a0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'mean_absolute_error', 'val_loss', 'val_mean_absolute_error'])"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history[0].history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "6e52d0b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff96d319850>]"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history[0].history[\"val_loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "9b124b41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff96d4e6550>]"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history[0].history[\"loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "f869e69d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_size': 100,\n",
       " 'regul': 0.00032199506051567314,\n",
       " 'batch_normalization': True,\n",
       " 'conv_blocks': 2,\n",
       " 'filters_0': 64,\n",
       " 'kernel_size0': 13,\n",
       " 'filters_1': 160,\n",
       " 'kernel_size1': 5,\n",
       " 'pooling_1': 'avg',\n",
       " 'hidden_size': 74,\n",
       " 'dense_blocks': 2,\n",
       " 'dropout': 0.30000000000000004,\n",
       " 'learning_rate': 0.00020644391295639603,\n",
       " 'pooling_0': 'none'}"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hyperparameters[0].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7606a7",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883f8516",
   "metadata": {},
   "source": [
    "Run for the dense function"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d1fbd00a",
   "metadata": {},
   "source": [
    "Result for model 1:\n",
    "Mean: 0.7909855842590332 Std: 0.03858017884919341\n",
    "{'input_size': 100,\n",
    " 'hidden_size': 74,\n",
    " 'regul': 0.0005677953653291085,\n",
    " 'dense_blocks': 10,\n",
    " 'dropout': 0.0,\n",
    " 'learning_rate': 0.0004614331680175835}\n",
    " \n",
    "Result for model 2:\n",
    "Mean: 0.759149506688118 Std: 0.0460086760081415\n",
    "{'input_size': 100,\n",
    " 'hidden_size': 42,\n",
    " 'regul': 0.0036787999149105136,\n",
    " 'dense_blocks': 9,\n",
    " 'dropout': 0.0,\n",
    " 'learning_rate': 0.0003168240557749865}\n",
    " \n",
    "Result for model 3:\n",
    "Mean: 0.777322068810463 Std: 0.0474525842345124\n",
    "{'input_size': 100,\n",
    " 'hidden_size': 74,\n",
    " 'regul': 1e-05,\n",
    " 'dense_blocks': 2,\n",
    " 'dropout': 0.0,\n",
    " 'learning_rate': 0.0008055913640444876}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5e3a7d",
   "metadata": {},
   "source": [
    "Conclusion: keeping model 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f36a38",
   "metadata": {},
   "source": [
    "### 4/ Retrain the best model on all the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f1ad8d",
   "metadata": {},
   "source": [
    "#### Intel on the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "17c4f697",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = best_hyperparameters[1]\n",
    "model = build_model_dense(hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "783770f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"dense_02_focused_edge\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "ebba5579",
   "metadata": {},
   "outputs": [],
   "source": [
    "info = f\"\"\"\n",
    "Trained on focused slices with illumination variation:\n",
    "{path}\n",
    "\n",
    "Hyperparameters:\n",
    "{str(hp.values)}\n",
    " \n",
    "Cross validation results:\n",
    "Mean: 0.759149506688118 Std: 0.0460086760081415\n",
    "\n",
    "Size: {count_params(model.trainable_weights)}\n",
    "\n",
    "Training on {len(training)} points and {len(im) - len(training)} used for early stopping validation.\n",
    "\n",
    "Input size: 100\n",
    "\n",
    "Data augmentation: random_crop + random_mirror\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "b8ddb98a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trained on focused slices with illumination variation:\n",
      "/media/felix/AMFtopology02/storage/datasets/focused_with_varying_lum_train\n",
      "\n",
      "Hyperparameters:\n",
      "{'input_size': 100, 'hidden_size': 42, 'regul': 0.0036787999149105136, 'dense_blocks': 9, 'dropout': 0.0, 'learning_rate': 0.0003168240557749865}\n",
      " \n",
      "Cross validation results:\n",
      "Mean: 0.759149506688118 Std: 0.0460086760081415\n",
      "\n",
      "Size: 18733\n",
      "\n",
      "Training on 377 points and 150 used for early stopping validation.\n",
      "\n",
      "Input size: 100\n",
      "\n",
      "Data augmentation: random_crop + random_mirror\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4982e5",
   "metadata": {},
   "source": [
    "#### Saving location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "e2e58501",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(storage_path, \"models\", name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "710253a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/felix/AMFtopology02/storage/models/dense_02_focused_edge'"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "8ea794c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "7a78bebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(model_path, \"info_general.txt\"), \"w\") as f:\n",
    "    f.write(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffebdf20",
   "metadata": {},
   "source": [
    "#### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "f0a94794",
   "metadata": {},
   "outputs": [],
   "source": [
    "from amftrack.ml.callbacks import SavePlots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "ffccee0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_path = os.path.join(os.path.dirname(model_path), \"tensorboard\")\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(tensorboard_path, update_freq=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "6dd0e6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=8,\n",
    "    verbose=0,\n",
    "    restore_best_weights=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "9d77ebc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr_callback = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.5,\n",
    "    patience=6,\n",
    "    verbose=0,\n",
    "    min_delta=0.001,\n",
    "    cooldown=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "fcbb7108",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_callback = SavePlots(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "5439d8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_logger = tf.keras.callbacks.CSVLogger(os.path.join(model_path, \"training.log\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "e95e2d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    csv_logger,\n",
    "    # reduce_lr_callback,\n",
    "    early_stopping_callback,\n",
    "    tb_callback,\n",
    "    plot_callback,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e3fcf1",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b71112a",
   "metadata": {},
   "source": [
    "Full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "84e76c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      " 1/24 [>.............................] - ETA: 14s - loss: 42.4254 - mean_absolute_error: 5.1726WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0019s vs `on_train_batch_end` time: 0.0033s). Check your callbacks.\n",
      "2022-08-18 12:03:18,340-[WARNING]- tensorflow:339 -> Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0019s vs `on_train_batch_end` time: 0.0033s). Check your callbacks.\n",
      "24/24 [==============================] - 1s 10ms/step - loss: 40.9923 - mean_absolute_error: 5.2588 - val_loss: 36.1437 - val_mean_absolute_error: 4.7988\n",
      "Epoch 2/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 37.3782 - mean_absolute_error: 4.9478 - val_loss: 28.4087 - val_mean_absolute_error: 4.0756\n",
      "Epoch 3/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 24.5433 - mean_absolute_error: 3.3887 - val_loss: 19.7733 - val_mean_absolute_error: 2.8916\n",
      "Epoch 4/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 20.3633 - mean_absolute_error: 2.8256 - val_loss: 17.6286 - val_mean_absolute_error: 2.6278\n",
      "Epoch 5/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 18.8391 - mean_absolute_error: 2.6926 - val_loss: 16.5199 - val_mean_absolute_error: 2.4965\n",
      "Epoch 6/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 17.3776 - mean_absolute_error: 2.5010 - val_loss: 15.0227 - val_mean_absolute_error: 2.2865\n",
      "Epoch 7/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 14.9944 - mean_absolute_error: 2.1985 - val_loss: 12.8813 - val_mean_absolute_error: 1.9264\n",
      "Epoch 8/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 11.9687 - mean_absolute_error: 1.7140 - val_loss: 10.3290 - val_mean_absolute_error: 1.3883\n",
      "Epoch 9/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 9.5618 - mean_absolute_error: 1.2185 - val_loss: 9.2622 - val_mean_absolute_error: 1.1976\n",
      "Epoch 10/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.7510 - mean_absolute_error: 1.1043 - val_loss: 8.8428 - val_mean_absolute_error: 1.1759\n",
      "Epoch 11/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 8.2601 - mean_absolute_error: 1.0257 - val_loss: 8.4454 - val_mean_absolute_error: 1.1201\n",
      "Epoch 12/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.9626 - mean_absolute_error: 0.9843 - val_loss: 8.5034 - val_mean_absolute_error: 1.1912\n",
      "Epoch 13/200\n",
      "24/24 [==============================] - 0s 7ms/step - loss: 7.9705 - mean_absolute_error: 1.0379 - val_loss: 8.1013 - val_mean_absolute_error: 1.1138\n",
      "Epoch 14/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.5475 - mean_absolute_error: 0.9690 - val_loss: 7.8661 - val_mean_absolute_error: 1.1179\n",
      "Epoch 15/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.2546 - mean_absolute_error: 0.9447 - val_loss: 7.7047 - val_mean_absolute_error: 1.1107\n",
      "Epoch 16/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.2118 - mean_absolute_error: 0.9462 - val_loss: 7.6080 - val_mean_absolute_error: 1.1056\n",
      "Epoch 17/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.9494 - mean_absolute_error: 0.9300 - val_loss: 7.2862 - val_mean_absolute_error: 1.0567\n",
      "Epoch 18/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.8237 - mean_absolute_error: 0.9444 - val_loss: 7.2460 - val_mean_absolute_error: 1.0697\n",
      "Epoch 19/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.5862 - mean_absolute_error: 0.8974 - val_loss: 6.9586 - val_mean_absolute_error: 1.0337\n",
      "Epoch 20/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 6.4294 - mean_absolute_error: 0.8834 - val_loss: 6.9854 - val_mean_absolute_error: 1.0629\n",
      "Epoch 21/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 6.3651 - mean_absolute_error: 0.9129 - val_loss: 6.7192 - val_mean_absolute_error: 1.0192\n",
      "Epoch 22/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.3321 - mean_absolute_error: 0.9365 - val_loss: 6.5278 - val_mean_absolute_error: 1.0126\n",
      "Epoch 23/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 6.1059 - mean_absolute_error: 0.9078 - val_loss: 6.3971 - val_mean_absolute_error: 1.0013\n",
      "Epoch 24/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.9525 - mean_absolute_error: 0.8867 - val_loss: 6.3688 - val_mean_absolute_error: 1.0114\n",
      "Epoch 25/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.7838 - mean_absolute_error: 0.8658 - val_loss: 6.2889 - val_mean_absolute_error: 1.0181\n",
      "Epoch 26/200\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 5.7353 - mean_absolute_error: 0.8733 - val_loss: 6.2790 - val_mean_absolute_error: 1.0290\n",
      "Epoch 27/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.6043 - mean_absolute_error: 0.8665 - val_loss: 6.1316 - val_mean_absolute_error: 1.0117\n",
      "Epoch 28/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.6696 - mean_absolute_error: 0.8886 - val_loss: 5.8110 - val_mean_absolute_error: 0.9501\n",
      "Epoch 29/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.4989 - mean_absolute_error: 0.8868 - val_loss: 5.7654 - val_mean_absolute_error: 0.9630\n",
      "Epoch 30/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 5.3548 - mean_absolute_error: 0.8494 - val_loss: 5.8294 - val_mean_absolute_error: 0.9880\n",
      "Epoch 31/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 5.2815 - mean_absolute_error: 0.8433 - val_loss: 5.7259 - val_mean_absolute_error: 0.9612\n",
      "Epoch 32/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 5.2518 - mean_absolute_error: 0.8630 - val_loss: 5.7682 - val_mean_absolute_error: 1.0070\n",
      "Epoch 33/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 5.1963 - mean_absolute_error: 0.8589 - val_loss: 5.5717 - val_mean_absolute_error: 0.9588\n",
      "Epoch 34/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.1535 - mean_absolute_error: 0.8741 - val_loss: 5.5222 - val_mean_absolute_error: 0.9542\n",
      "Epoch 35/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.0821 - mean_absolute_error: 0.8579 - val_loss: 5.4473 - val_mean_absolute_error: 0.9479\n",
      "Epoch 36/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.0269 - mean_absolute_error: 0.8538 - val_loss: 5.3538 - val_mean_absolute_error: 0.9222\n",
      "Epoch 37/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4.9324 - mean_absolute_error: 0.8196 - val_loss: 5.3385 - val_mean_absolute_error: 0.9371\n",
      "Epoch 38/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4.9502 - mean_absolute_error: 0.8392 - val_loss: 5.2908 - val_mean_absolute_error: 0.9302\n",
      "Epoch 39/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4.9725 - mean_absolute_error: 0.8457 - val_loss: 5.2588 - val_mean_absolute_error: 0.9204\n",
      "Epoch 40/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4.8955 - mean_absolute_error: 0.8447 - val_loss: 5.2673 - val_mean_absolute_error: 0.9340\n",
      "Epoch 41/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4.7976 - mean_absolute_error: 0.8161 - val_loss: 5.2899 - val_mean_absolute_error: 0.9477\n",
      "Epoch 42/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4.8666 - mean_absolute_error: 0.8479 - val_loss: 5.1254 - val_mean_absolute_error: 0.9066\n",
      "Epoch 43/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4.8282 - mean_absolute_error: 0.8467 - val_loss: 5.2465 - val_mean_absolute_error: 0.9717\n",
      "Epoch 44/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4.7471 - mean_absolute_error: 0.8224 - val_loss: 5.0757 - val_mean_absolute_error: 0.9197\n",
      "Epoch 45/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4.6827 - mean_absolute_error: 0.8101 - val_loss: 5.2370 - val_mean_absolute_error: 0.9673\n",
      "Epoch 46/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4.6695 - mean_absolute_error: 0.8154 - val_loss: 5.0154 - val_mean_absolute_error: 0.9183\n",
      "Epoch 47/200\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 4.6138 - mean_absolute_error: 0.8000 - val_loss: 5.0014 - val_mean_absolute_error: 0.9174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4.6613 - mean_absolute_error: 0.8381 - val_loss: 4.9623 - val_mean_absolute_error: 0.9057\n",
      "Epoch 49/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4.5879 - mean_absolute_error: 0.8166 - val_loss: 4.9183 - val_mean_absolute_error: 0.9020\n",
      "Epoch 50/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4.5994 - mean_absolute_error: 0.8368 - val_loss: 4.9563 - val_mean_absolute_error: 0.9229\n",
      "Epoch 51/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4.5782 - mean_absolute_error: 0.8235 - val_loss: 4.8560 - val_mean_absolute_error: 0.8974\n",
      "Epoch 52/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4.5387 - mean_absolute_error: 0.8100 - val_loss: 4.8829 - val_mean_absolute_error: 0.9035\n",
      "Epoch 53/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4.5008 - mean_absolute_error: 0.8220 - val_loss: 4.8465 - val_mean_absolute_error: 0.9099\n",
      "Epoch 54/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4.5046 - mean_absolute_error: 0.8140 - val_loss: 4.9159 - val_mean_absolute_error: 0.9226\n",
      "Epoch 55/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4.4586 - mean_absolute_error: 0.8088 - val_loss: 4.7900 - val_mean_absolute_error: 0.8966\n",
      "Epoch 56/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4.4548 - mean_absolute_error: 0.8089 - val_loss: 4.9014 - val_mean_absolute_error: 0.9257\n",
      "Epoch 57/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4.3794 - mean_absolute_error: 0.7982 - val_loss: 4.7037 - val_mean_absolute_error: 0.8786\n",
      "Epoch 58/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4.4748 - mean_absolute_error: 0.8440 - val_loss: 4.6998 - val_mean_absolute_error: 0.8885\n",
      "Epoch 59/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4.3804 - mean_absolute_error: 0.8057 - val_loss: 4.8013 - val_mean_absolute_error: 0.9191\n",
      "Epoch 60/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4.4208 - mean_absolute_error: 0.8315 - val_loss: 4.6618 - val_mean_absolute_error: 0.8940\n",
      "Epoch 61/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4.3628 - mean_absolute_error: 0.8066 - val_loss: 4.7184 - val_mean_absolute_error: 0.9246\n",
      "Epoch 62/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4.4209 - mean_absolute_error: 0.8468 - val_loss: 4.5901 - val_mean_absolute_error: 0.8806\n",
      "Epoch 63/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4.3623 - mean_absolute_error: 0.8372 - val_loss: 4.6918 - val_mean_absolute_error: 0.8961\n",
      "Epoch 64/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4.3441 - mean_absolute_error: 0.8307 - val_loss: 4.5846 - val_mean_absolute_error: 0.8815\n",
      "Epoch 65/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4.2562 - mean_absolute_error: 0.8035 - val_loss: 4.5709 - val_mean_absolute_error: 0.8970\n",
      "Epoch 66/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4.3040 - mean_absolute_error: 0.8337 - val_loss: 4.6661 - val_mean_absolute_error: 0.9341\n",
      "Epoch 67/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4.2674 - mean_absolute_error: 0.8153 - val_loss: 4.6360 - val_mean_absolute_error: 0.9353\n",
      "Epoch 68/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4.3095 - mean_absolute_error: 0.8283 - val_loss: 4.5705 - val_mean_absolute_error: 0.9052\n",
      "Epoch 69/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4.2605 - mean_absolute_error: 0.8223 - val_loss: 4.5501 - val_mean_absolute_error: 0.9090\n",
      "Epoch 70/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4.2049 - mean_absolute_error: 0.8101 - val_loss: 4.5260 - val_mean_absolute_error: 0.9073\n",
      "Epoch 71/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4.1388 - mean_absolute_error: 0.7817 - val_loss: 4.6351 - val_mean_absolute_error: 0.9372\n",
      "Epoch 72/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4.1413 - mean_absolute_error: 0.8037 - val_loss: 4.4680 - val_mean_absolute_error: 0.8956\n",
      "Epoch 73/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4.1636 - mean_absolute_error: 0.8017 - val_loss: 4.4316 - val_mean_absolute_error: 0.8842\n",
      "Epoch 74/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4.1774 - mean_absolute_error: 0.8139 - val_loss: 4.5224 - val_mean_absolute_error: 0.9168\n",
      "Epoch 75/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4.1375 - mean_absolute_error: 0.8145 - val_loss: 4.5532 - val_mean_absolute_error: 0.9303\n",
      "Epoch 76/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4.1372 - mean_absolute_error: 0.8139 - val_loss: 4.4378 - val_mean_absolute_error: 0.8953\n",
      "Epoch 77/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4.0675 - mean_absolute_error: 0.7996 - val_loss: 4.4966 - val_mean_absolute_error: 0.9104\n",
      "Epoch 78/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4.0534 - mean_absolute_error: 0.7866 - val_loss: 4.4538 - val_mean_absolute_error: 0.9188\n",
      "Epoch 79/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4.1147 - mean_absolute_error: 0.8175 - val_loss: 4.3382 - val_mean_absolute_error: 0.8804\n",
      "Epoch 80/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4.0568 - mean_absolute_error: 0.7932 - val_loss: 4.3703 - val_mean_absolute_error: 0.8870\n",
      "Epoch 81/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4.0051 - mean_absolute_error: 0.7830 - val_loss: 4.4040 - val_mean_absolute_error: 0.9117\n",
      "Epoch 82/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4.0870 - mean_absolute_error: 0.8238 - val_loss: 4.4085 - val_mean_absolute_error: 0.8990\n",
      "Epoch 83/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4.0179 - mean_absolute_error: 0.8002 - val_loss: 4.3649 - val_mean_absolute_error: 0.8967\n",
      "Epoch 84/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3.9457 - mean_absolute_error: 0.7718 - val_loss: 4.2600 - val_mean_absolute_error: 0.8836\n",
      "Epoch 85/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 4.0382 - mean_absolute_error: 0.8110 - val_loss: 4.3075 - val_mean_absolute_error: 0.8954\n",
      "Epoch 86/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3.9926 - mean_absolute_error: 0.8107 - val_loss: 4.3082 - val_mean_absolute_error: 0.8872\n",
      "Epoch 87/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3.9695 - mean_absolute_error: 0.8022 - val_loss: 4.2939 - val_mean_absolute_error: 0.8969\n",
      "Epoch 88/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3.9747 - mean_absolute_error: 0.8124 - val_loss: 4.2718 - val_mean_absolute_error: 0.8957\n",
      "Epoch 89/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3.9084 - mean_absolute_error: 0.7922 - val_loss: 4.2608 - val_mean_absolute_error: 0.8913\n",
      "Epoch 90/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3.9521 - mean_absolute_error: 0.8062 - val_loss: 4.2136 - val_mean_absolute_error: 0.8790\n",
      "Epoch 91/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3.8899 - mean_absolute_error: 0.7925 - val_loss: 4.4354 - val_mean_absolute_error: 0.9639\n",
      "Epoch 92/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3.8837 - mean_absolute_error: 0.7861 - val_loss: 4.2893 - val_mean_absolute_error: 0.9031\n",
      "Epoch 93/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3.9040 - mean_absolute_error: 0.7978 - val_loss: 4.2501 - val_mean_absolute_error: 0.8930\n",
      "Epoch 94/200\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 3.9111 - mean_absolute_error: 0.7985 - val_loss: 4.2907 - val_mean_absolute_error: 0.9130\n",
      "Epoch 95/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3.8855 - mean_absolute_error: 0.8044 - val_loss: 4.2459 - val_mean_absolute_error: 0.9017\n",
      "Epoch 96/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3.8595 - mean_absolute_error: 0.7984 - val_loss: 4.2977 - val_mean_absolute_error: 0.9112\n",
      "Epoch 97/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3.8336 - mean_absolute_error: 0.8021 - val_loss: 4.1419 - val_mean_absolute_error: 0.8740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3.8774 - mean_absolute_error: 0.8193 - val_loss: 4.1699 - val_mean_absolute_error: 0.8855\n",
      "Epoch 99/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3.8432 - mean_absolute_error: 0.8064 - val_loss: 4.1651 - val_mean_absolute_error: 0.8842\n",
      "Epoch 100/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3.8376 - mean_absolute_error: 0.8055 - val_loss: 4.1314 - val_mean_absolute_error: 0.8939\n",
      "Epoch 101/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3.8159 - mean_absolute_error: 0.8032 - val_loss: 4.1736 - val_mean_absolute_error: 0.8833\n",
      "Epoch 102/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3.7889 - mean_absolute_error: 0.7923 - val_loss: 4.2300 - val_mean_absolute_error: 0.9186\n",
      "Epoch 103/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3.7950 - mean_absolute_error: 0.7951 - val_loss: 4.0241 - val_mean_absolute_error: 0.8636\n",
      "Epoch 104/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3.7433 - mean_absolute_error: 0.7920 - val_loss: 4.1518 - val_mean_absolute_error: 0.8866\n",
      "Epoch 105/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3.7522 - mean_absolute_error: 0.7880 - val_loss: 4.0853 - val_mean_absolute_error: 0.8848\n",
      "Epoch 106/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3.7547 - mean_absolute_error: 0.8024 - val_loss: 4.1195 - val_mean_absolute_error: 0.8975\n",
      "Epoch 107/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3.7499 - mean_absolute_error: 0.7952 - val_loss: 4.0621 - val_mean_absolute_error: 0.8811\n",
      "Epoch 108/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3.8025 - mean_absolute_error: 0.8255 - val_loss: 4.0001 - val_mean_absolute_error: 0.8661\n",
      "Epoch 109/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3.6974 - mean_absolute_error: 0.7826 - val_loss: 4.1045 - val_mean_absolute_error: 0.8938\n",
      "Epoch 110/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3.6649 - mean_absolute_error: 0.7808 - val_loss: 4.0642 - val_mean_absolute_error: 0.8991\n",
      "Epoch 111/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3.7024 - mean_absolute_error: 0.8056 - val_loss: 4.0282 - val_mean_absolute_error: 0.8791\n",
      "Epoch 112/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3.7182 - mean_absolute_error: 0.8104 - val_loss: 4.0878 - val_mean_absolute_error: 0.9055\n",
      "Epoch 113/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3.6708 - mean_absolute_error: 0.7948 - val_loss: 3.9634 - val_mean_absolute_error: 0.8816\n",
      "Epoch 114/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3.6481 - mean_absolute_error: 0.7965 - val_loss: 3.9918 - val_mean_absolute_error: 0.9029\n",
      "Epoch 115/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3.6993 - mean_absolute_error: 0.8153 - val_loss: 4.1199 - val_mean_absolute_error: 0.9106\n",
      "Epoch 116/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3.6633 - mean_absolute_error: 0.8059 - val_loss: 4.0082 - val_mean_absolute_error: 0.8982\n",
      "Epoch 117/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3.6527 - mean_absolute_error: 0.7969 - val_loss: 3.9367 - val_mean_absolute_error: 0.8928\n",
      "Epoch 118/200\n",
      "24/24 [==============================] - 0s 3ms/step - loss: 3.5864 - mean_absolute_error: 0.7795 - val_loss: 3.8955 - val_mean_absolute_error: 0.8890\n",
      "Epoch 119/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3.6667 - mean_absolute_error: 0.8095 - val_loss: 4.0152 - val_mean_absolute_error: 0.8854\n",
      "Epoch 120/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3.6076 - mean_absolute_error: 0.7938 - val_loss: 4.0041 - val_mean_absolute_error: 0.9063\n",
      "Epoch 121/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3.6035 - mean_absolute_error: 0.8085 - val_loss: 3.8519 - val_mean_absolute_error: 0.8641\n",
      "Epoch 122/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3.5516 - mean_absolute_error: 0.7930 - val_loss: 3.8659 - val_mean_absolute_error: 0.8690\n",
      "Epoch 123/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3.5908 - mean_absolute_error: 0.8049 - val_loss: 3.9107 - val_mean_absolute_error: 0.8930\n",
      "Epoch 124/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3.5913 - mean_absolute_error: 0.8046 - val_loss: 3.8337 - val_mean_absolute_error: 0.8654\n",
      "Epoch 125/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3.6048 - mean_absolute_error: 0.8123 - val_loss: 3.8381 - val_mean_absolute_error: 0.8578\n",
      "Epoch 126/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3.6195 - mean_absolute_error: 0.8158 - val_loss: 3.9524 - val_mean_absolute_error: 0.9244\n",
      "Epoch 127/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3.5684 - mean_absolute_error: 0.8081 - val_loss: 3.8144 - val_mean_absolute_error: 0.8732\n",
      "Epoch 128/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3.5820 - mean_absolute_error: 0.8160 - val_loss: 3.8598 - val_mean_absolute_error: 0.8850\n",
      "Epoch 129/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3.5618 - mean_absolute_error: 0.8125 - val_loss: 3.8623 - val_mean_absolute_error: 0.8791\n",
      "Epoch 130/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3.5226 - mean_absolute_error: 0.7941 - val_loss: 3.8926 - val_mean_absolute_error: 0.9062\n",
      "Epoch 131/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3.5240 - mean_absolute_error: 0.7961 - val_loss: 3.9478 - val_mean_absolute_error: 0.9235\n",
      "Epoch 132/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3.5773 - mean_absolute_error: 0.8256 - val_loss: 3.8233 - val_mean_absolute_error: 0.8791\n",
      "Epoch 133/200\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 3.4957 - mean_absolute_error: 0.7928 - val_loss: 3.8223 - val_mean_absolute_error: 0.8875\n",
      "Epoch 134/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3.4595 - mean_absolute_error: 0.7814 - val_loss: 3.8672 - val_mean_absolute_error: 0.9111\n",
      "Epoch 135/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3.4859 - mean_absolute_error: 0.7997 - val_loss: 3.8563 - val_mean_absolute_error: 0.9025\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff96a1b8040>"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds, validation_data=valid_ds, epochs=200, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0cf342",
   "metadata": {},
   "source": [
    "**Saving model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "5053075f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(os.path.join(model_path, \"saved_model_retrained.h5\"))\n",
    "\n",
    "with open(os.path.join(model_path, \"model_summary.txt\"), \"w\") as fh:\n",
    "    model.summary(print_fn=lambda x: fh.write(x + \"\\n\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c19409",
   "metadata": {},
   "source": [
    "**Saving the model obtained during bayesian search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "43754b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models[1].save(os.path.join(model_path, \"saved_model_from_search.h5\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30e4301",
   "metadata": {},
   "source": [
    "## Random search with conv model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bd2ea9",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d1148ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.RandomSearch(\n",
    "    build_model_conv,\n",
    "    objective=\"val_mean_absolute_error\",\n",
    "    max_trials=50,\n",
    "    seed=seed,\n",
    "    hyperparameters=None,\n",
    "    tune_new_entries=True,\n",
    "    allow_new_entries=True,\n",
    "    overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b8ff0b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 50 Complete [00h 02m 13s]\n",
      "val_mean_absolute_error: 0.8619729280471802\n",
      "\n",
      "Best val_mean_absolute_error So Far: 0.702015221118927\n",
      "Total elapsed time: 01h 30m 12s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "2022-08-12 15:44:42,115-[INFO]- tensorflow:1 -> Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(\n",
    "    data_preparation(im),\n",
    "    label,\n",
    "    validation_split=0.2,\n",
    "    epochs=200,\n",
    "    callbacks=[tf.keras.callbacks.EarlyStopping(patience=8, restore_best_weights=True)],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492ab450",
   "metadata": {},
   "source": [
    "### Analyse results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c9d257f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in ./untitled_project\n",
      "Showing 10 best trials\n",
      "<keras_tuner.engine.objective.Objective object at 0x7f75c4753eb0>\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "input_size: 80\n",
      "regul: 0.0002707623734125964\n",
      "batch_normalization: True\n",
      "conv_blocks: 3\n",
      "filters_0: 224\n",
      "kernel_size0: 19\n",
      "filters_1: 160\n",
      "kernel_size1: 20\n",
      "pooling_1: avg\n",
      "hidden_size: 10\n",
      "dense_blocks: 3\n",
      "dropout: 0.1\n",
      "learning_rate: 0.020272548846591663\n",
      "pooling_0: avg\n",
      "filters_2: 256\n",
      "kernel_size2: 17\n",
      "pooling_2: none\n",
      "Score: 0.702015221118927\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "input_size: 80\n",
      "regul: 0.00010991863288278036\n",
      "batch_normalization: False\n",
      "conv_blocks: 2\n",
      "filters_0: 64\n",
      "kernel_size0: 14\n",
      "filters_1: 160\n",
      "kernel_size1: 18\n",
      "pooling_1: avg\n",
      "hidden_size: 42\n",
      "dense_blocks: 3\n",
      "dropout: 0.5\n",
      "learning_rate: 0.00638224910178181\n",
      "pooling_0: max\n",
      "filters_2: 192\n",
      "kernel_size2: 15\n",
      "pooling_2: max\n",
      "Score: 0.704502284526825\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "input_size: 80\n",
      "regul: 0.00032199506051567314\n",
      "batch_normalization: True\n",
      "conv_blocks: 2\n",
      "filters_0: 64\n",
      "kernel_size0: 13\n",
      "filters_1: 160\n",
      "kernel_size1: 5\n",
      "pooling_1: avg\n",
      "hidden_size: 74\n",
      "dense_blocks: 2\n",
      "dropout: 0.30000000000000004\n",
      "learning_rate: 0.00020644391295639603\n",
      "pooling_0: none\n",
      "Score: 0.7146832942962646\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "input_size: 80\n",
      "regul: 6.908837503318941e-05\n",
      "batch_normalization: False\n",
      "conv_blocks: 2\n",
      "filters_0: 160\n",
      "kernel_size0: 6\n",
      "filters_1: 128\n",
      "kernel_size1: 9\n",
      "pooling_1: avg\n",
      "hidden_size: 42\n",
      "dense_blocks: 2\n",
      "dropout: 0.0\n",
      "learning_rate: 0.0009775664203574934\n",
      "pooling_0: avg\n",
      "Score: 0.7626064419746399\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "input_size: 80\n",
      "regul: 0.0010562376768930327\n",
      "batch_normalization: True\n",
      "conv_blocks: 2\n",
      "filters_0: 192\n",
      "kernel_size0: 8\n",
      "filters_1: 224\n",
      "kernel_size1: 7\n",
      "pooling_1: max\n",
      "hidden_size: 10\n",
      "dense_blocks: 1\n",
      "dropout: 0.0\n",
      "learning_rate: 0.0004832573378556583\n",
      "pooling_0: max\n",
      "Score: 0.7866157293319702\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "input_size: 80\n",
      "regul: 1.619773895005048e-05\n",
      "batch_normalization: False\n",
      "conv_blocks: 3\n",
      "filters_0: 160\n",
      "kernel_size0: 6\n",
      "filters_1: 256\n",
      "kernel_size1: 14\n",
      "pooling_1: none\n",
      "hidden_size: 42\n",
      "dense_blocks: 2\n",
      "dropout: 0.2\n",
      "learning_rate: 0.0008639229762234833\n",
      "pooling_0: none\n",
      "filters_2: 160\n",
      "kernel_size2: 6\n",
      "pooling_2: avg\n",
      "Score: 0.7882844805717468\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "input_size: 80\n",
      "regul: 0.00050472731221573\n",
      "batch_normalization: False\n",
      "conv_blocks: 1\n",
      "filters_0: 224\n",
      "kernel_size0: 8\n",
      "filters_1: 160\n",
      "kernel_size1: 8\n",
      "pooling_1: max\n",
      "hidden_size: 74\n",
      "dense_blocks: 2\n",
      "dropout: 0.1\n",
      "learning_rate: 0.0004956405624619392\n",
      "pooling_0: max\n",
      "filters_2: 64\n",
      "kernel_size2: 16\n",
      "pooling_2: max\n",
      "Score: 0.8011331558227539\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "input_size: 80\n",
      "regul: 0.0097400166982067\n",
      "batch_normalization: True\n",
      "conv_blocks: 1\n",
      "filters_0: 224\n",
      "kernel_size0: 17\n",
      "filters_1: 160\n",
      "kernel_size1: 5\n",
      "pooling_1: avg\n",
      "hidden_size: 74\n",
      "dense_blocks: 2\n",
      "dropout: 0.30000000000000004\n",
      "learning_rate: 0.0001465777550436778\n",
      "pooling_0: max\n",
      "filters_2: 192\n",
      "kernel_size2: 13\n",
      "pooling_2: avg\n",
      "Score: 0.8049061298370361\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "input_size: 80\n",
      "regul: 1.5061420490559164e-05\n",
      "batch_normalization: True\n",
      "conv_blocks: 2\n",
      "filters_0: 64\n",
      "kernel_size0: 12\n",
      "filters_1: 160\n",
      "kernel_size1: 16\n",
      "pooling_1: avg\n",
      "hidden_size: 42\n",
      "dense_blocks: 2\n",
      "dropout: 0.30000000000000004\n",
      "learning_rate: 0.0008758408573224307\n",
      "pooling_0: avg\n",
      "filters_2: 160\n",
      "kernel_size2: 19\n",
      "pooling_2: none\n",
      "Score: 0.807873547077179\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "input_size: 80\n",
      "regul: 0.00030389246930894354\n",
      "batch_normalization: True\n",
      "conv_blocks: 1\n",
      "filters_0: 256\n",
      "kernel_size0: 6\n",
      "filters_1: 96\n",
      "kernel_size1: 12\n",
      "pooling_1: max\n",
      "hidden_size: 42\n",
      "dense_blocks: 1\n",
      "dropout: 0.0\n",
      "learning_rate: 0.0004831323790896749\n",
      "pooling_0: none\n",
      "filters_2: 224\n",
      "kernel_size2: 17\n",
      "pooling_2: avg\n",
      "Score: 0.8135343194007874\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1a04d770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "2022-08-12 15:46:06,331-[WARNING]- tensorflow:185 -> Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "2022-08-12 15:46:06,332-[WARNING]- tensorflow:194 -> Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
      "2022-08-12 15:46:06,332-[WARNING]- tensorflow:194 -> Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
      "2022-08-12 15:46:06,333-[WARNING]- tensorflow:194 -> Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "2022-08-12 15:46:06,333-[WARNING]- tensorflow:194 -> Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
      "2022-08-12 15:46:06,334-[WARNING]- tensorflow:194 -> Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n"
     ]
    }
   ],
   "source": [
    "best_model = tuner.get_best_models(2)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "17fe4590",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hyperparameters = tuner.get_best_hyperparameters(1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "899c8b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 80, 1)]           0         \n",
      "                                                                 \n",
      " rescaling (Rescaling)       (None, 80, 1)             0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 71, 64)            704       \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 71, 64)            0         \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 62, 160)           102560    \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 62, 160)           0         \n",
      "                                                                 \n",
      " average_pooling1d (AverageP  (None, 31, 160)          0         \n",
      " ooling1D)                                                       \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4960)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 42)                208362    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 42)                1806      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 42)                1806      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 42)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 43        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 315,281\n",
      "Trainable params: 315,281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "802d0f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 17\n",
      "input_size (Fixed)\n",
      "{'conditions': [], 'value': 80}\n",
      "regul (Float)\n",
      "{'default': 0.0001, 'conditions': [], 'min_value': 1e-05, 'max_value': 0.1, 'step': None, 'sampling': 'log'}\n",
      "batch_normalization (Boolean)\n",
      "{'default': False, 'conditions': []}\n",
      "conv_blocks (Int)\n",
      "{'default': 2, 'conditions': [], 'min_value': 1, 'max_value': 3, 'step': 1, 'sampling': None}\n",
      "filters_0 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 256, 'step': 32, 'sampling': None}\n",
      "kernel_size0 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 5, 'max_value': 20, 'step': 1, 'sampling': None}\n",
      "filters_1 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 256, 'step': 32, 'sampling': None}\n",
      "kernel_size1 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 5, 'max_value': 20, 'step': 1, 'sampling': None}\n",
      "pooling_1 (Choice)\n",
      "{'default': 'avg', 'conditions': [], 'values': ['avg', 'max', 'none'], 'ordered': False}\n",
      "hidden_size (Int)\n",
      "{'default': 32, 'conditions': [], 'min_value': 10, 'max_value': 100, 'step': 32, 'sampling': None}\n",
      "dense_blocks (Int)\n",
      "{'default': 1, 'conditions': [], 'min_value': 1, 'max_value': 3, 'step': 1, 'sampling': None}\n",
      "dropout (Float)\n",
      "{'default': 0.5, 'conditions': [], 'min_value': 0.0, 'max_value': 0.5, 'step': 0.1, 'sampling': None}\n",
      "learning_rate (Float)\n",
      "{'default': 0.001, 'conditions': [], 'min_value': 1e-05, 'max_value': 0.1, 'step': None, 'sampling': 'log'}\n",
      "pooling_0 (Choice)\n",
      "{'default': 'avg', 'conditions': [], 'values': ['avg', 'max', 'none'], 'ordered': False}\n",
      "filters_2 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 256, 'step': 32, 'sampling': None}\n",
      "kernel_size2 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 5, 'max_value': 20, 'step': 1, 'sampling': None}\n",
      "pooling_2 (Choice)\n",
      "{'default': 'avg', 'conditions': [], 'values': ['avg', 'max', 'none'], 'ordered': False}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "504d343e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_against(model, test_feature, test_label):\n",
    "    predicted = model.predict(test_feature)\n",
    "    plt.scatter(test_label, predicted, marker=\"o\")\n",
    "    plt.plot([0, 12], [0, 12])\n",
    "    plt.xlim(2, 16)\n",
    "    plt.ylim(2, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7c343ab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[179, 178, 179, ..., 166, 169, 169],\n",
       "       [188, 185, 185, ..., 191, 193, 192],\n",
       "       [184, 186, 184, ..., 183, 182, 180],\n",
       "       ...,\n",
       "       [191, 189, 191, ..., 195, 193, 195],\n",
       "       [187, 187, 188, ..., 189, 190, 190],\n",
       "       [187, 185, 186, ..., 163, 162, 166]], dtype=uint8)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7a2d0c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(storage_path, \"test_final\")\n",
    "im_path_test = os.path.join(path, \"slices.png\")\n",
    "label_path_test = os.path.join(path, \"labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d0e19521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(810, 120)\n"
     ]
    }
   ],
   "source": [
    "im_test = imageio.imread(im_path_test)\n",
    "print(im_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e2dcfdd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(810,)\n"
     ]
    }
   ],
   "source": [
    "with open(label_path, \"rb\") as f:\n",
    "    label_test = np.load(f)\n",
    "print(label_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a3055d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_test = np.expand_dims(label_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8218f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "13b40dc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a42bf64ae3144808defd36fa7e1c212",
       "version_major": 2,
       "version_minor": 0
      },
      "image/png": "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",
      "text/html": [
       "\n",
       "            <div style=\"display: inline-block;\">\n",
       "                <div class=\"jupyter-widgets widget-label\" style=\"text-align: center;\">\n",
       "                    Figure\n",
       "                </div>\n",
       "                <img src='data:image/png;base64,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' width=640.0/>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "plot_against(best_model, data_preparation(im_test), label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a5100144",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-12 16:34:00.585513: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /media/kahane/AMFtopology02/storage/models/model_vendredi/assets\n",
      "2022-08-12 16:34:02,605-[INFO]- tensorflow:779 -> Assets written to: /media/kahane/AMFtopology02/storage/models/model_vendredi/assets\n"
     ]
    }
   ],
   "source": [
    "save_path = os.path.join(storage_path, \"models\", \"model_vendredi\")\n",
    "best_model.save(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4f889166",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 6ms/step - loss: 2.2786 - mean_absolute_error: 1.0133\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.278571844100952, 1.0132561922073364]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.evaluate(test_feature, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "80d3a718",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 120, 1)]          0         \n",
      "                                                                 \n",
      " rescaling (Rescaling)       (None, 120, 1)            0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 111, 160)          1760      \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 111, 160)          0         \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 102, 128)          204928    \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 102, 128)          0         \n",
      "                                                                 \n",
      " average_pooling1d (AverageP  (None, 51, 128)          0         \n",
      " ooling1D)                                                       \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6528)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 42)                274218    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 42)                1806      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 42)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 43        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 482,755\n",
      "Trainable params: 482,755\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bbe87426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "2022-06-07 15:53:58,773-[WARNING]- tensorflow:185 -> Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "2022-06-07 15:53:58,774-[WARNING]- tensorflow:194 -> Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
      "2022-06-07 15:53:58,775-[WARNING]- tensorflow:194 -> Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
      "2022-06-07 15:53:58,777-[WARNING]- tensorflow:194 -> Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "2022-06-07 15:53:58,778-[WARNING]- tensorflow:194 -> Value in checkpoint could not be found in the restored object: (root).optimizer.decay\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n",
      "2022-06-07 15:53:58,779-[WARNING]- tensorflow:194 -> Value in checkpoint could not be found in the restored object: (root).optimizer.learning_rate\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<keras.engine.functional.Functional at 0x7fcbc5fc2460>,\n",
       " <keras.engine.functional.Functional at 0x7fcbc5fd1040>,\n",
       " <keras.engine.functional.Functional at 0x7fcbc5ff2370>,\n",
       " <keras.engine.functional.Functional at 0x7fcbe442f370>,\n",
       " <keras.engine.functional.Functional at 0x7fcbe460e8e0>]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner.get_best_models(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7656f24e",
   "metadata": {},
   "source": [
    "### Evaluate with data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "91028823",
   "metadata": {},
   "outputs": [],
   "source": [
    "from amftrack.ml.width.data_augmentation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32aabccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.Input(shape=(120, 1)),\n",
    "        random_crop(120),\n",
    "        # random_invert(p=0.5),  # TODO(FK): keep?\n",
    "        random_mirror(p=0.5),\n",
    "        random_brightness(20),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "81f531c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7fcbf42ec700>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f08d1d37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[199, 198, 197, ..., 203, 204, 207],\n",
       "       [175, 177, 176, ..., 167, 166, 166],\n",
       "       [194, 194, 194, ..., 146, 134, 120],\n",
       "       ...,\n",
       "       [186, 186, 186, ..., 179, 177, 179],\n",
       "       [204, 206, 206, ..., 205, 206, 206],\n",
       "       [188, 189, 188, ..., 174, 177, 179]], dtype=uint8)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f8ea1200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74, 1)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "61098b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feature_ = data_augmentation(test_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2bea5a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 80, 1])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f80240",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.evaluate(test_feature, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5d366d12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7fcbf74f6b20>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc39908",
   "metadata": {},
   "source": [
    "## BROUILLON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "7d0564cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(32, 80, 1), dtype=float32, numpy=\n",
       " array([[[130.],\n",
       "         [130.],\n",
       "         [130.],\n",
       "         ...,\n",
       "         [127.],\n",
       "         [128.],\n",
       "         [129.]],\n",
       " \n",
       "        [[113.],\n",
       "         [111.],\n",
       "         [109.],\n",
       "         ...,\n",
       "         [129.],\n",
       "         [128.],\n",
       "         [125.]],\n",
       " \n",
       "        [[119.],\n",
       "         [120.],\n",
       "         [120.],\n",
       "         ...,\n",
       "         [122.],\n",
       "         [123.],\n",
       "         [122.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[146.],\n",
       "         [144.],\n",
       "         [141.],\n",
       "         ...,\n",
       "         [148.],\n",
       "         [147.],\n",
       "         [147.]],\n",
       " \n",
       "        [[110.],\n",
       "         [107.],\n",
       "         [106.],\n",
       "         ...,\n",
       "         [116.],\n",
       "         [115.],\n",
       "         [114.]],\n",
       " \n",
       "        [[124.],\n",
       "         [124.],\n",
       "         [124.],\n",
       "         ...,\n",
       "         [124.],\n",
       "         [123.],\n",
       "         [123.]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(32,), dtype=float64, numpy=\n",
       " array([7.26221294, 5.93755418, 5.5774322 , 4.19787153, 3.7441611 ,\n",
       "        5.20109506, 4.87914297, 0.        , 8.52101685, 8.73503977,\n",
       "        4.59109883, 4.34090199, 4.35067225, 4.18356936, 5.923182  ,\n",
       "        8.89809448, 4.7800506 , 5.29939395, 5.08347615, 8.36581426,\n",
       "        8.89809448, 4.7800506 , 5.29939395, 5.08347615, 5.923182  ,\n",
       "        4.59109883, 4.34090199, 8.52101685, 8.73503977, 4.18356936,\n",
       "        4.35067225, 0.        ])>)"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2df246",
   "metadata": {},
   "source": [
    "TEST 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fb73a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "9e486f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([527, 80, 1])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_augmentation(train_feature).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbe79fc",
   "metadata": {},
   "source": [
    "TEST 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "a19a6ab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3, 1), dtype=float32, numpy=\n",
       "array([[[131.],\n",
       "        [130.],\n",
       "        [129.]],\n",
       "\n",
       "       [[130.],\n",
       "        [130.],\n",
       "        [128.]],\n",
       "\n",
       "       [[130.],\n",
       "        [131.],\n",
       "        [131.]]], dtype=float32)>"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_augmentation(train_feature)[:3, :3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c10f7a",
   "metadata": {},
   "source": [
    "TEST 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "55c8d9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method search in module keras_tuner.engine.base_tuner:\n",
      "\n",
      "search(*fit_args, **fit_kwargs) method of keras_tuner.tuners.randomsearch.RandomSearch instance\n",
      "    Performs a search for best hyperparameter configuations.\n",
      "    \n",
      "    Args:\n",
      "        *fit_args: Positional arguments that should be passed to\n",
      "          `run_trial`, for example the training and validation data.\n",
      "        **fit_kwargs: Keyword arguments that should be passed to\n",
      "          `run_trial`, for example the training and validation data.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tuner.search)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d874adb",
   "metadata": {},
   "source": [
    "TEST 4: making an augmented dataset from the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b625707",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "a1ffe145",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class DatasetV2 in module tensorflow.python.data.ops.dataset_ops:\n",
      "\n",
      "class DatasetV2(collections.abc.Iterable, tensorflow.python.training.tracking.base.Trackable, tensorflow.python.framework.composite_tensor.CompositeTensor)\n",
      " |  DatasetV2(variant_tensor)\n",
      " |  \n",
      " |  Represents a potentially large set of elements.\n",
      " |  \n",
      " |  The `tf.data.Dataset` API supports writing descriptive and efficient input\n",
      " |  pipelines. `Dataset` usage follows a common pattern:\n",
      " |  \n",
      " |  1. Create a source dataset from your input data.\n",
      " |  2. Apply dataset transformations to preprocess the data.\n",
      " |  3. Iterate over the dataset and process the elements.\n",
      " |  \n",
      " |  Iteration happens in a streaming fashion, so the full dataset does not need to\n",
      " |  fit into memory.\n",
      " |  \n",
      " |  Source Datasets:\n",
      " |  \n",
      " |  The simplest way to create a dataset is to create it from a python `list`:\n",
      " |  \n",
      " |  >>> dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
      " |  >>> for element in dataset:\n",
      " |  ...   print(element)\n",
      " |  tf.Tensor(1, shape=(), dtype=int32)\n",
      " |  tf.Tensor(2, shape=(), dtype=int32)\n",
      " |  tf.Tensor(3, shape=(), dtype=int32)\n",
      " |  \n",
      " |  To process lines from files, use `tf.data.TextLineDataset`:\n",
      " |  \n",
      " |  >>> dataset = tf.data.TextLineDataset([\"file1.txt\", \"file2.txt\"])\n",
      " |  \n",
      " |  To process records written in the `TFRecord` format, use `TFRecordDataset`:\n",
      " |  \n",
      " |  >>> dataset = tf.data.TFRecordDataset([\"file1.tfrecords\", \"file2.tfrecords\"])\n",
      " |  \n",
      " |  To create a dataset of all files matching a pattern, use\n",
      " |  `tf.data.Dataset.list_files`:\n",
      " |  \n",
      " |  ```python\n",
      " |  dataset = tf.data.Dataset.list_files(\"/path/*.txt\")\n",
      " |  ```\n",
      " |  \n",
      " |  See `tf.data.FixedLengthRecordDataset` and `tf.data.Dataset.from_generator`\n",
      " |  for more ways to create datasets.\n",
      " |  \n",
      " |  Transformations:\n",
      " |  \n",
      " |  Once you have a dataset, you can apply transformations to prepare the data for\n",
      " |  your model:\n",
      " |  \n",
      " |  >>> dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
      " |  >>> dataset = dataset.map(lambda x: x*2)\n",
      " |  >>> list(dataset.as_numpy_iterator())\n",
      " |  [2, 4, 6]\n",
      " |  \n",
      " |  Common Terms:\n",
      " |  \n",
      " |  **Element**: A single output from calling `next()` on a dataset iterator.\n",
      " |    Elements may be nested structures containing multiple components. For\n",
      " |    example, the element `(1, (3, \"apple\"))` has one tuple nested in another\n",
      " |    tuple. The components are `1`, `3`, and `\"apple\"`.\n",
      " |  \n",
      " |  **Component**: The leaf in the nested structure of an element.\n",
      " |  \n",
      " |  Supported types:\n",
      " |  \n",
      " |  Elements can be nested structures of tuples, named tuples, and dictionaries.\n",
      " |  Note that Python lists are *not* treated as nested structures of components.\n",
      " |  Instead, lists are converted to tensors and treated as components. For\n",
      " |  example, the element `(1, [1, 2, 3])` has only two components; the tensor `1`\n",
      " |  and the tensor `[1, 2, 3]`. Element components can be of any type\n",
      " |  representable by `tf.TypeSpec`, including `tf.Tensor`, `tf.data.Dataset`,\n",
      " |  `tf.sparse.SparseTensor`, `tf.RaggedTensor`, and `tf.TensorArray`.\n",
      " |  \n",
      " |  ```python\n",
      " |  a = 1 # Integer element\n",
      " |  b = 2.0 # Float element\n",
      " |  c = (1, 2) # Tuple element with 2 components\n",
      " |  d = {\"a\": (2, 2), \"b\": 3} # Dict element with 3 components\n",
      " |  Point = collections.namedtuple(\"Point\", [\"x\", \"y\"])\n",
      " |  e = Point(1, 2) # Named tuple\n",
      " |  f = tf.data.Dataset.range(10) # Dataset element\n",
      " |  ```\n",
      " |  \n",
      " |  For more information,\n",
      " |  read [this guide](https://www.tensorflow.org/guide/data).\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      DatasetV2\n",
      " |      collections.abc.Iterable\n",
      " |      tensorflow.python.training.tracking.base.Trackable\n",
      " |      tensorflow.python.framework.composite_tensor.CompositeTensor\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __bool__(self)\n",
      " |  \n",
      " |  __debug_string__(self)\n",
      " |      Returns a string showing the type of the dataset and its inputs.\n",
      " |      \n",
      " |      This string is intended only for debugging purposes, and may change without\n",
      " |      warning.\n",
      " |  \n",
      " |  __init__(self, variant_tensor)\n",
      " |      Creates a DatasetV2 object.\n",
      " |      \n",
      " |      This is a difference between DatasetV1 and DatasetV2. DatasetV1 does not\n",
      " |      take anything in its constructor whereas in the DatasetV2, we expect\n",
      " |      subclasses to create a variant_tensor and pass it in to the super() call.\n",
      " |      \n",
      " |      Args:\n",
      " |        variant_tensor: A DT_VARIANT tensor that represents the dataset.\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |      Creates an iterator for elements of this dataset.\n",
      " |      \n",
      " |      The returned iterator implements the Python Iterator protocol.\n",
      " |      \n",
      " |      Returns:\n",
      " |        An `tf.data.Iterator` for the elements of this dataset.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If not inside of tf.function and not executing eagerly.\n",
      " |  \n",
      " |  __len__(self)\n",
      " |      Returns the length of the dataset if it is known and finite.\n",
      " |      \n",
      " |      This method requires that you are running in eager mode, and that the\n",
      " |      length of the dataset is known and non-infinite. When the length may be\n",
      " |      unknown or infinite, or if you are running in graph mode, use\n",
      " |      `tf.data.Dataset.cardinality` instead.\n",
      " |      \n",
      " |      Returns:\n",
      " |        An integer representing the length of the dataset.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If the dataset length is unknown or infinite, or if eager\n",
      " |          execution is not enabled.\n",
      " |  \n",
      " |  __nonzero__ = __bool__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  apply(self, transformation_func)\n",
      " |      Applies a transformation function to this dataset.\n",
      " |      \n",
      " |      `apply` enables chaining of custom `Dataset` transformations, which are\n",
      " |      represented as functions that take one `Dataset` argument and return a\n",
      " |      transformed `Dataset`.\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.range(100)\n",
      " |      >>> def dataset_fn(ds):\n",
      " |      ...   return ds.filter(lambda x: x < 5)\n",
      " |      >>> dataset = dataset.apply(dataset_fn)\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [0, 1, 2, 3, 4]\n",
      " |      \n",
      " |      Args:\n",
      " |        transformation_func: A function that takes one `Dataset` argument and\n",
      " |          returns a `Dataset`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: The `Dataset` returned by applying `transformation_func` to this\n",
      " |            dataset.\n",
      " |  \n",
      " |  as_numpy_iterator(self)\n",
      " |      Returns an iterator which converts all elements of the dataset to numpy.\n",
      " |      \n",
      " |      Use `as_numpy_iterator` to inspect the content of your dataset. To see\n",
      " |      element shapes and types, print dataset elements directly instead of using\n",
      " |      `as_numpy_iterator`.\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
      " |      >>> for element in dataset:\n",
      " |      ...   print(element)\n",
      " |      tf.Tensor(1, shape=(), dtype=int32)\n",
      " |      tf.Tensor(2, shape=(), dtype=int32)\n",
      " |      tf.Tensor(3, shape=(), dtype=int32)\n",
      " |      \n",
      " |      This method requires that you are running in eager mode and the dataset's\n",
      " |      element_spec contains only `TensorSpec` components.\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
      " |      >>> for element in dataset.as_numpy_iterator():\n",
      " |      ...   print(element)\n",
      " |      1\n",
      " |      2\n",
      " |      3\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
      " |      >>> print(list(dataset.as_numpy_iterator()))\n",
      " |      [1, 2, 3]\n",
      " |      \n",
      " |      `as_numpy_iterator()` will preserve the nested structure of dataset\n",
      " |      elements.\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.from_tensor_slices({'a': ([1, 2], [3, 4]),\n",
      " |      ...                                               'b': [5, 6]})\n",
      " |      >>> list(dataset.as_numpy_iterator()) == [{'a': (1, 3), 'b': 5},\n",
      " |      ...                                       {'a': (2, 4), 'b': 6}]\n",
      " |      True\n",
      " |      \n",
      " |      Returns:\n",
      " |        An iterable over the elements of the dataset, with their tensors converted\n",
      " |        to numpy arrays.\n",
      " |      \n",
      " |      Raises:\n",
      " |        TypeError: if an element contains a non-`Tensor` value.\n",
      " |        RuntimeError: if eager execution is not enabled.\n",
      " |  \n",
      " |  batch(self, batch_size, drop_remainder=False, num_parallel_calls=None, deterministic=None, name=None)\n",
      " |      Combines consecutive elements of this dataset into batches.\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.range(8)\n",
      " |      >>> dataset = dataset.batch(3)\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [array([0, 1, 2]), array([3, 4, 5]), array([6, 7])]\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.range(8)\n",
      " |      >>> dataset = dataset.batch(3, drop_remainder=True)\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [array([0, 1, 2]), array([3, 4, 5])]\n",
      " |      \n",
      " |      The components of the resulting element will have an additional outer\n",
      " |      dimension, which will be `batch_size` (or `N % batch_size` for the last\n",
      " |      element if `batch_size` does not divide the number of input elements `N`\n",
      " |      evenly and `drop_remainder` is `False`). If your program depends on the\n",
      " |      batches having the same outer dimension, you should set the `drop_remainder`\n",
      " |      argument to `True` to prevent the smaller batch from being produced.\n",
      " |      \n",
      " |      Note: If your program requires data to have a statically known shape (e.g.,\n",
      " |      when using XLA), you should use `drop_remainder=True`. Without\n",
      " |      `drop_remainder=True` the shape of the output dataset will have an unknown\n",
      " |      leading dimension due to the possibility of a smaller final batch.\n",
      " |      \n",
      " |      Args:\n",
      " |        batch_size: A `tf.int64` scalar `tf.Tensor`, representing the number of\n",
      " |          consecutive elements of this dataset to combine in a single batch.\n",
      " |        drop_remainder: (Optional.) A `tf.bool` scalar `tf.Tensor`, representing\n",
      " |          whether the last batch should be dropped in the case it has fewer than\n",
      " |          `batch_size` elements; the default behavior is not to drop the smaller\n",
      " |          batch.\n",
      " |        num_parallel_calls: (Optional.) A `tf.int64` scalar `tf.Tensor`,\n",
      " |          representing the number of batches to compute asynchronously in\n",
      " |          parallel.\n",
      " |          If not specified, batches will be computed sequentially. If the value\n",
      " |          `tf.data.AUTOTUNE` is used, then the number of parallel\n",
      " |          calls is set dynamically based on available resources.\n",
      " |        deterministic: (Optional.) When `num_parallel_calls` is specified, if this\n",
      " |          boolean is specified (`True` or `False`), it controls the order in which\n",
      " |          the transformation produces elements. If set to `False`, the\n",
      " |          transformation is allowed to yield elements out of order to trade\n",
      " |          determinism for performance. If not specified, the\n",
      " |          `tf.data.Options.deterministic` option (`True` by default) controls the\n",
      " |          behavior.\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset`.\n",
      " |  \n",
      " |  bucket_by_sequence_length(self, element_length_func, bucket_boundaries, bucket_batch_sizes, padded_shapes=None, padding_values=None, pad_to_bucket_boundary=False, no_padding=False, drop_remainder=False, name=None)\n",
      " |      A transformation that buckets elements in a `Dataset` by length.\n",
      " |      \n",
      " |      Elements of the `Dataset` are grouped together by length and then are padded\n",
      " |      and batched.\n",
      " |      \n",
      " |      This is useful for sequence tasks in which the elements have variable\n",
      " |      length. Grouping together elements that have similar lengths reduces the\n",
      " |      total fraction of padding in a batch which increases training step\n",
      " |      efficiency.\n",
      " |      \n",
      " |      Below is an example to bucketize the input data to the 3 buckets\n",
      " |      \"[0, 3), [3, 5), [5, inf)\" based on sequence length, with batch size 2.\n",
      " |      \n",
      " |      >>> elements = [\n",
      " |      ...   [0], [1, 2, 3, 4], [5, 6, 7],\n",
      " |      ...   [7, 8, 9, 10, 11], [13, 14, 15, 16, 19, 20], [21, 22]]\n",
      " |      >>> dataset = tf.data.Dataset.from_generator(\n",
      " |      ...     lambda: elements, tf.int64, output_shapes=[None])\n",
      " |      >>> dataset = dataset.bucket_by_sequence_length(\n",
      " |      ...         element_length_func=lambda elem: tf.shape(elem)[0],\n",
      " |      ...         bucket_boundaries=[3, 5],\n",
      " |      ...         bucket_batch_sizes=[2, 2, 2])\n",
      " |      >>> for elem in dataset.as_numpy_iterator():\n",
      " |      ...   print(elem)\n",
      " |      [[1 2 3 4]\n",
      " |      [5 6 7 0]]\n",
      " |      [[ 7  8  9 10 11  0]\n",
      " |      [13 14 15 16 19 20]]\n",
      " |      [[ 0  0]\n",
      " |      [21 22]]\n",
      " |      \n",
      " |      Args:\n",
      " |        element_length_func: function from element in `Dataset` to `tf.int32`,\n",
      " |          determines the length of the element, which will determine the bucket it\n",
      " |          goes into.\n",
      " |        bucket_boundaries: `list<int>`, upper length boundaries of the buckets.\n",
      " |        bucket_batch_sizes: `list<int>`, batch size per bucket. Length should be\n",
      " |          `len(bucket_boundaries) + 1`.\n",
      " |        padded_shapes: Nested structure of `tf.TensorShape` to pass to\n",
      " |          `tf.data.Dataset.padded_batch`. If not provided, will use\n",
      " |          `dataset.output_shapes`, which will result in variable length dimensions\n",
      " |          being padded out to the maximum length in each batch.\n",
      " |        padding_values: Values to pad with, passed to\n",
      " |          `tf.data.Dataset.padded_batch`. Defaults to padding with 0.\n",
      " |        pad_to_bucket_boundary: bool, if `False`, will pad dimensions with unknown\n",
      " |          size to maximum length in batch. If `True`, will pad dimensions with\n",
      " |          unknown size to bucket boundary minus 1 (i.e., the maximum length in\n",
      " |          each bucket), and caller must ensure that the source `Dataset` does not\n",
      " |          contain any elements with length longer than `max(bucket_boundaries)`.\n",
      " |        no_padding: `bool`, indicates whether to pad the batch features (features\n",
      " |          need to be either of type `tf.sparse.SparseTensor` or of same shape).\n",
      " |        drop_remainder: (Optional.) A `tf.bool` scalar `tf.Tensor`, representing\n",
      " |          whether the last batch should be dropped in the case it has fewer than\n",
      " |          `batch_size` elements; the default behavior is not to drop the smaller\n",
      " |          batch.\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `Dataset`.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: if `len(bucket_batch_sizes) != len(bucket_boundaries) + 1`.\n",
      " |  \n",
      " |  cache(self, filename='', name=None)\n",
      " |      Caches the elements in this dataset.\n",
      " |      \n",
      " |      The first time the dataset is iterated over, its elements will be cached\n",
      " |      either in the specified file or in memory. Subsequent iterations will\n",
      " |      use the cached data.\n",
      " |      \n",
      " |      Note: For the cache to be finalized, the input dataset must be iterated\n",
      " |      through in its entirety. Otherwise, subsequent iterations will not use\n",
      " |      cached data.\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.range(5)\n",
      " |      >>> dataset = dataset.map(lambda x: x**2)\n",
      " |      >>> dataset = dataset.cache()\n",
      " |      >>> # The first time reading through the data will generate the data using\n",
      " |      >>> # `range` and `map`.\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [0, 1, 4, 9, 16]\n",
      " |      >>> # Subsequent iterations read from the cache.\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [0, 1, 4, 9, 16]\n",
      " |      \n",
      " |      When caching to a file, the cached data will persist across runs. Even the\n",
      " |      first iteration through the data will read from the cache file. Changing\n",
      " |      the input pipeline before the call to `.cache()` will have no effect until\n",
      " |      the cache file is removed or the filename is changed.\n",
      " |      \n",
      " |      ```python\n",
      " |      dataset = tf.data.Dataset.range(5)\n",
      " |      dataset = dataset.cache(\"/path/to/file\")\n",
      " |      list(dataset.as_numpy_iterator())\n",
      " |      # [0, 1, 2, 3, 4]\n",
      " |      dataset = tf.data.Dataset.range(10)\n",
      " |      dataset = dataset.cache(\"/path/to/file\")  # Same file!\n",
      " |      list(dataset.as_numpy_iterator())\n",
      " |      # [0, 1, 2, 3, 4]\n",
      " |      ```\n",
      " |      \n",
      " |      Note: `cache` will produce exactly the same elements during each iteration\n",
      " |      through the dataset. If you wish to randomize the iteration order, make sure\n",
      " |      to call `shuffle` *after* calling `cache`.\n",
      " |      \n",
      " |      Args:\n",
      " |        filename: A `tf.string` scalar `tf.Tensor`, representing the name of a\n",
      " |          directory on the filesystem to use for caching elements in this Dataset.\n",
      " |          If a filename is not provided, the dataset will be cached in memory.\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset`.\n",
      " |  \n",
      " |  cardinality(self)\n",
      " |      Returns the cardinality of the dataset, if known.\n",
      " |      \n",
      " |      `cardinality` may return `tf.data.INFINITE_CARDINALITY` if the dataset\n",
      " |      contains an infinite number of elements or `tf.data.UNKNOWN_CARDINALITY` if\n",
      " |      the analysis fails to determine the number of elements in the dataset\n",
      " |      (e.g. when the dataset source is a file).\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.range(42)\n",
      " |      >>> print(dataset.cardinality().numpy())\n",
      " |      42\n",
      " |      >>> dataset = dataset.repeat()\n",
      " |      >>> cardinality = dataset.cardinality()\n",
      " |      >>> print((cardinality == tf.data.INFINITE_CARDINALITY).numpy())\n",
      " |      True\n",
      " |      >>> dataset = dataset.filter(lambda x: True)\n",
      " |      >>> cardinality = dataset.cardinality()\n",
      " |      >>> print((cardinality == tf.data.UNKNOWN_CARDINALITY).numpy())\n",
      " |      True\n",
      " |      \n",
      " |      Returns:\n",
      " |        A scalar `tf.int64` `Tensor` representing the cardinality of the dataset.\n",
      " |        If the cardinality is infinite or unknown, `cardinality` returns the\n",
      " |        named constants `tf.data.INFINITE_CARDINALITY` and\n",
      " |        `tf.data.UNKNOWN_CARDINALITY` respectively.\n",
      " |  \n",
      " |  concatenate(self, dataset, name=None)\n",
      " |      Creates a `Dataset` by concatenating the given dataset with this dataset.\n",
      " |      \n",
      " |      >>> a = tf.data.Dataset.range(1, 4)  # ==> [ 1, 2, 3 ]\n",
      " |      >>> b = tf.data.Dataset.range(4, 8)  # ==> [ 4, 5, 6, 7 ]\n",
      " |      >>> ds = a.concatenate(b)\n",
      " |      >>> list(ds.as_numpy_iterator())\n",
      " |      [1, 2, 3, 4, 5, 6, 7]\n",
      " |      >>> # The input dataset and dataset to be concatenated should have\n",
      " |      >>> # compatible element specs.\n",
      " |      >>> c = tf.data.Dataset.zip((a, b))\n",
      " |      >>> a.concatenate(c)\n",
      " |      Traceback (most recent call last):\n",
      " |      TypeError: Two datasets to concatenate have different types\n",
      " |      <dtype: 'int64'> and (tf.int64, tf.int64)\n",
      " |      >>> d = tf.data.Dataset.from_tensor_slices([\"a\", \"b\", \"c\"])\n",
      " |      >>> a.concatenate(d)\n",
      " |      Traceback (most recent call last):\n",
      " |      TypeError: Two datasets to concatenate have different types\n",
      " |      <dtype: 'int64'> and <dtype: 'string'>\n",
      " |      \n",
      " |      Args:\n",
      " |        dataset: `Dataset` to be concatenated.\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset`.\n",
      " |  \n",
      " |  enumerate(self, start=0, name=None)\n",
      " |      Enumerates the elements of this dataset.\n",
      " |      \n",
      " |      It is similar to python's `enumerate`.\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
      " |      >>> dataset = dataset.enumerate(start=5)\n",
      " |      >>> for element in dataset.as_numpy_iterator():\n",
      " |      ...   print(element)\n",
      " |      (5, 1)\n",
      " |      (6, 2)\n",
      " |      (7, 3)\n",
      " |      \n",
      " |      >>> # The (nested) structure of the input dataset determines the\n",
      " |      >>> # structure of elements in the resulting dataset.\n",
      " |      >>> dataset = tf.data.Dataset.from_tensor_slices([(7, 8), (9, 10)])\n",
      " |      >>> dataset = dataset.enumerate()\n",
      " |      >>> for element in dataset.as_numpy_iterator():\n",
      " |      ...   print(element)\n",
      " |      (0, array([7, 8], dtype=int32))\n",
      " |      (1, array([ 9, 10], dtype=int32))\n",
      " |      \n",
      " |      Args:\n",
      " |        start: A `tf.int64` scalar `tf.Tensor`, representing the start value for\n",
      " |          enumeration.\n",
      " |        name: Optional. A name for the tf.data operations used by `enumerate`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset`.\n",
      " |  \n",
      " |  filter(self, predicate, name=None)\n",
      " |      Filters this dataset according to `predicate`.\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
      " |      >>> dataset = dataset.filter(lambda x: x < 3)\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [1, 2]\n",
      " |      >>> # `tf.math.equal(x, y)` is required for equality comparison\n",
      " |      >>> def filter_fn(x):\n",
      " |      ...   return tf.math.equal(x, 1)\n",
      " |      >>> dataset = dataset.filter(filter_fn)\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [1]\n",
      " |      \n",
      " |      Args:\n",
      " |        predicate: A function mapping a dataset element to a boolean.\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: The `Dataset` containing the elements of this dataset for which\n",
      " |            `predicate` is `True`.\n",
      " |  \n",
      " |  flat_map(self, map_func, name=None)\n",
      " |      Maps `map_func` across this dataset and flattens the result.\n",
      " |      \n",
      " |      The type signature is:\n",
      " |      \n",
      " |      ```\n",
      " |      def flat_map(\n",
      " |        self: Dataset[T],\n",
      " |        map_func: Callable[[T], Dataset[S]]\n",
      " |      ) -> Dataset[S]\n",
      " |      ```\n",
      " |      \n",
      " |      Use `flat_map` if you want to make sure that the order of your dataset\n",
      " |      stays the same. For example, to flatten a dataset of batches into a\n",
      " |      dataset of their elements:\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.from_tensor_slices(\n",
      " |      ...     [[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
      " |      >>> dataset = dataset.flat_map(\n",
      " |      ...     lambda x: tf.data.Dataset.from_tensor_slices(x))\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      " |      \n",
      " |      `tf.data.Dataset.interleave()` is a generalization of `flat_map`, since\n",
      " |      `flat_map` produces the same output as\n",
      " |      `tf.data.Dataset.interleave(cycle_length=1)`\n",
      " |      \n",
      " |      Args:\n",
      " |        map_func: A function mapping a dataset element to a dataset.\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset`.\n",
      " |  \n",
      " |  get_single_element(self, name=None)\n",
      " |      Returns the single element of the `dataset`.\n",
      " |      \n",
      " |      The function enables you to use a `tf.data.Dataset` in a stateless\n",
      " |      \"tensor-in tensor-out\" expression, without creating an iterator.\n",
      " |      This facilitates the ease of data transformation on tensors using the\n",
      " |      optimized `tf.data.Dataset` abstraction on top of them.\n",
      " |      \n",
      " |      For example, lets consider a `preprocessing_fn` which would take as an\n",
      " |      input the raw features and returns the processed feature along with\n",
      " |      it's label.\n",
      " |      \n",
      " |      ```python\n",
      " |      def preprocessing_fn(raw_feature):\n",
      " |        # ... the raw_feature is preprocessed as per the use-case\n",
      " |        return feature\n",
      " |      \n",
      " |      raw_features = ...  # input batch of BATCH_SIZE elements.\n",
      " |      dataset = (tf.data.Dataset.from_tensor_slices(raw_features)\n",
      " |                .map(preprocessing_fn, num_parallel_calls=BATCH_SIZE)\n",
      " |                .batch(BATCH_SIZE))\n",
      " |      \n",
      " |      processed_features = dataset.get_single_element()\n",
      " |      ```\n",
      " |      \n",
      " |      In the above example, the `raw_features` tensor of length=BATCH_SIZE\n",
      " |      was converted to a `tf.data.Dataset`. Next, each of the `raw_feature` was\n",
      " |      mapped using the `preprocessing_fn` and the processed features were\n",
      " |      grouped into a single batch. The final `dataset` contains only one element\n",
      " |      which is a batch of all the processed features.\n",
      " |      \n",
      " |      NOTE: The `dataset` should contain only one element.\n",
      " |      \n",
      " |      Now, instead of creating an iterator for the `dataset` and retrieving the\n",
      " |      batch of features, the `tf.data.get_single_element()` function is used\n",
      " |      to skip the iterator creation process and directly output the batch of\n",
      " |      features.\n",
      " |      \n",
      " |      This can be particularly useful when your tensor transformations are\n",
      " |      expressed as `tf.data.Dataset` operations, and you want to use those\n",
      " |      transformations while serving your model.\n",
      " |      \n",
      " |      #### Keras\n",
      " |      \n",
      " |      ```python\n",
      " |      \n",
      " |      model = ... # A pre-built or custom model\n",
      " |      \n",
      " |      class PreprocessingModel(tf.keras.Model):\n",
      " |        def __init__(self, model):\n",
      " |          super().__init__(self)\n",
      " |          self.model = model\n",
      " |      \n",
      " |        @tf.function(input_signature=[...])\n",
      " |        def serving_fn(self, data):\n",
      " |          ds = tf.data.Dataset.from_tensor_slices(data)\n",
      " |          ds = ds.map(preprocessing_fn, num_parallel_calls=BATCH_SIZE)\n",
      " |          ds = ds.batch(batch_size=BATCH_SIZE)\n",
      " |          return tf.argmax(self.model(ds.get_single_element()), axis=-1)\n",
      " |      \n",
      " |      preprocessing_model = PreprocessingModel(model)\n",
      " |      your_exported_model_dir = ... # save the model to this path.\n",
      " |      tf.saved_model.save(preprocessing_model, your_exported_model_dir,\n",
      " |                    signatures={'serving_default': preprocessing_model.serving_fn}\n",
      " |                    )\n",
      " |      ```\n",
      " |      \n",
      " |      #### Estimator\n",
      " |      \n",
      " |      In the case of estimators, you need to generally define a `serving_input_fn`\n",
      " |      which would require the features to be processed by the model while\n",
      " |      inferencing.\n",
      " |      \n",
      " |      ```python\n",
      " |      def serving_input_fn():\n",
      " |      \n",
      " |        raw_feature_spec = ... # Spec for the raw_features\n",
      " |        input_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(\n",
      " |            raw_feature_spec, default_batch_size=None)\n",
      " |        )\n",
      " |        serving_input_receiver = input_fn()\n",
      " |        raw_features = serving_input_receiver.features\n",
      " |      \n",
      " |        def preprocessing_fn(raw_feature):\n",
      " |          # ... the raw_feature is preprocessed as per the use-case\n",
      " |          return feature\n",
      " |      \n",
      " |        dataset = (tf.data.Dataset.from_tensor_slices(raw_features)\n",
      " |                  .map(preprocessing_fn, num_parallel_calls=BATCH_SIZE)\n",
      " |                  .batch(BATCH_SIZE))\n",
      " |      \n",
      " |        processed_features = dataset.get_single_element()\n",
      " |      \n",
      " |        # Please note that the value of `BATCH_SIZE` should be equal to\n",
      " |        # the size of the leading dimension of `raw_features`. This ensures\n",
      " |        # that `dataset` has only element, which is a pre-requisite for\n",
      " |        # using `dataset.get_single_element()`.\n",
      " |      \n",
      " |        return tf.estimator.export.ServingInputReceiver(\n",
      " |            processed_features, serving_input_receiver.receiver_tensors)\n",
      " |      \n",
      " |      estimator = ... # A pre-built or custom estimator\n",
      " |      estimator.export_saved_model(your_exported_model_dir, serving_input_fn)\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A nested structure of `tf.Tensor` objects, corresponding to the single\n",
      " |        element of `dataset`.\n",
      " |      \n",
      " |      Raises:\n",
      " |        InvalidArgumentError: (at runtime) if `dataset` does not contain exactly\n",
      " |          one element.\n",
      " |  \n",
      " |  group_by_window(self, key_func, reduce_func, window_size=None, window_size_func=None, name=None)\n",
      " |      Groups windows of elements by key and reduces them.\n",
      " |      \n",
      " |      This transformation maps each consecutive element in a dataset to a key\n",
      " |      using `key_func` and groups the elements by key. It then applies\n",
      " |      `reduce_func` to at most `window_size_func(key)` elements matching the same\n",
      " |      key. All except the final window for each key will contain\n",
      " |      `window_size_func(key)` elements; the final window may be smaller.\n",
      " |      \n",
      " |      You may provide either a constant `window_size` or a window size determined\n",
      " |      by the key through `window_size_func`.\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.range(10)\n",
      " |      >>> window_size = 5\n",
      " |      >>> key_func = lambda x: x%2\n",
      " |      >>> reduce_func = lambda key, dataset: dataset.batch(window_size)\n",
      " |      >>> dataset = dataset.group_by_window(\n",
      " |      ...           key_func=key_func,\n",
      " |      ...           reduce_func=reduce_func,\n",
      " |      ...           window_size=window_size)\n",
      " |      >>> for elem in dataset.as_numpy_iterator():\n",
      " |      ...   print(elem)\n",
      " |      [0 2 4 6 8]\n",
      " |      [1 3 5 7 9]\n",
      " |      \n",
      " |      Args:\n",
      " |        key_func: A function mapping a nested structure of tensors (having shapes\n",
      " |          and types defined by `self.output_shapes` and `self.output_types`) to a\n",
      " |          scalar `tf.int64` tensor.\n",
      " |        reduce_func: A function mapping a key and a dataset of up to `window_size`\n",
      " |          consecutive elements matching that key to another dataset.\n",
      " |        window_size: A `tf.int64` scalar `tf.Tensor`, representing the number of\n",
      " |          consecutive elements matching the same key to combine in a single batch,\n",
      " |          which will be passed to `reduce_func`. Mutually exclusive with\n",
      " |          `window_size_func`.\n",
      " |        window_size_func: A function mapping a key to a `tf.int64` scalar\n",
      " |          `tf.Tensor`, representing the number of consecutive elements matching\n",
      " |          the same key to combine in a single batch, which will be passed to\n",
      " |          `reduce_func`. Mutually exclusive with `window_size`.\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `Dataset`.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: if neither or both of {`window_size`, `window_size_func`} are\n",
      " |          passed.\n",
      " |  \n",
      " |  interleave(self, map_func, cycle_length=None, block_length=None, num_parallel_calls=None, deterministic=None, name=None)\n",
      " |      Maps `map_func` across this dataset, and interleaves the results.\n",
      " |      \n",
      " |      The type signature is:\n",
      " |      \n",
      " |      ```\n",
      " |      def interleave(\n",
      " |        self: Dataset[T],\n",
      " |        map_func: Callable[[T], Dataset[S]]\n",
      " |      ) -> Dataset[S]\n",
      " |      ```\n",
      " |      \n",
      " |      For example, you can use `Dataset.interleave()` to process many input files\n",
      " |      concurrently:\n",
      " |      \n",
      " |      >>> # Preprocess 4 files concurrently, and interleave blocks of 16 records\n",
      " |      >>> # from each file.\n",
      " |      >>> filenames = [\"/var/data/file1.txt\", \"/var/data/file2.txt\",\n",
      " |      ...              \"/var/data/file3.txt\", \"/var/data/file4.txt\"]\n",
      " |      >>> dataset = tf.data.Dataset.from_tensor_slices(filenames)\n",
      " |      >>> def parse_fn(filename):\n",
      " |      ...   return tf.data.Dataset.range(10)\n",
      " |      >>> dataset = dataset.interleave(lambda x:\n",
      " |      ...     tf.data.TextLineDataset(x).map(parse_fn, num_parallel_calls=1),\n",
      " |      ...     cycle_length=4, block_length=16)\n",
      " |      \n",
      " |      The `cycle_length` and `block_length` arguments control the order in which\n",
      " |      elements are produced. `cycle_length` controls the number of input elements\n",
      " |      that are processed concurrently. If you set `cycle_length` to 1, this\n",
      " |      transformation will handle one input element at a time, and will produce\n",
      " |      identical results to `tf.data.Dataset.flat_map`. In general,\n",
      " |      this transformation will apply `map_func` to `cycle_length` input elements,\n",
      " |      open iterators on the returned `Dataset` objects, and cycle through them\n",
      " |      producing `block_length` consecutive elements from each iterator, and\n",
      " |      consuming the next input element each time it reaches the end of an\n",
      " |      iterator.\n",
      " |      \n",
      " |      For example:\n",
      " |      \n",
      " |      >>> dataset = Dataset.range(1, 6)  # ==> [ 1, 2, 3, 4, 5 ]\n",
      " |      >>> # NOTE: New lines indicate \"block\" boundaries.\n",
      " |      >>> dataset = dataset.interleave(\n",
      " |      ...     lambda x: Dataset.from_tensors(x).repeat(6),\n",
      " |      ...     cycle_length=2, block_length=4)\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [1, 1, 1, 1,\n",
      " |       2, 2, 2, 2,\n",
      " |       1, 1,\n",
      " |       2, 2,\n",
      " |       3, 3, 3, 3,\n",
      " |       4, 4, 4, 4,\n",
      " |       3, 3,\n",
      " |       4, 4,\n",
      " |       5, 5, 5, 5,\n",
      " |       5, 5]\n",
      " |      \n",
      " |      Note: The order of elements yielded by this transformation is\n",
      " |      deterministic, as long as `map_func` is a pure function and\n",
      " |      `deterministic=True`. If `map_func` contains any stateful operations, the\n",
      " |      order in which that state is accessed is undefined.\n",
      " |      \n",
      " |      Performance can often be improved by setting `num_parallel_calls` so that\n",
      " |      `interleave` will use multiple threads to fetch elements. If determinism\n",
      " |      isn't required, it can also improve performance to set\n",
      " |      `deterministic=False`.\n",
      " |      \n",
      " |      >>> filenames = [\"/var/data/file1.txt\", \"/var/data/file2.txt\",\n",
      " |      ...              \"/var/data/file3.txt\", \"/var/data/file4.txt\"]\n",
      " |      >>> dataset = tf.data.Dataset.from_tensor_slices(filenames)\n",
      " |      >>> dataset = dataset.interleave(lambda x: tf.data.TFRecordDataset(x),\n",
      " |      ...     cycle_length=4, num_parallel_calls=tf.data.AUTOTUNE,\n",
      " |      ...     deterministic=False)\n",
      " |      \n",
      " |      Args:\n",
      " |        map_func: A function that takes a dataset element and returns a\n",
      " |          `tf.data.Dataset`.\n",
      " |        cycle_length: (Optional.) The number of input elements that will be\n",
      " |          processed concurrently. If not set, the tf.data runtime decides what it\n",
      " |          should be based on available CPU. If `num_parallel_calls` is set to\n",
      " |          `tf.data.AUTOTUNE`, the `cycle_length` argument identifies\n",
      " |          the maximum degree of parallelism.\n",
      " |        block_length: (Optional.) The number of consecutive elements to produce\n",
      " |          from each input element before cycling to another input element. If not\n",
      " |          set, defaults to 1.\n",
      " |        num_parallel_calls: (Optional.) If specified, the implementation creates a\n",
      " |          threadpool, which is used to fetch inputs from cycle elements\n",
      " |          asynchronously and in parallel. The default behavior is to fetch inputs\n",
      " |          from cycle elements synchronously with no parallelism. If the value\n",
      " |          `tf.data.AUTOTUNE` is used, then the number of parallel\n",
      " |          calls is set dynamically based on available CPU.\n",
      " |        deterministic: (Optional.) When `num_parallel_calls` is specified, if this\n",
      " |          boolean is specified (`True` or `False`), it controls the order in which\n",
      " |          the transformation produces elements. If set to `False`, the\n",
      " |          transformation is allowed to yield elements out of order to trade\n",
      " |          determinism for performance. If not specified, the\n",
      " |          `tf.data.Options.deterministic` option (`True` by default) controls the\n",
      " |          behavior.\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset`.\n",
      " |  \n",
      " |  map(self, map_func, num_parallel_calls=None, deterministic=None, name=None)\n",
      " |      Maps `map_func` across the elements of this dataset.\n",
      " |      \n",
      " |      This transformation applies `map_func` to each element of this dataset, and\n",
      " |      returns a new dataset containing the transformed elements, in the same\n",
      " |      order as they appeared in the input. `map_func` can be used to change both\n",
      " |      the values and the structure of a dataset's elements. Supported structure\n",
      " |      constructs are documented\n",
      " |      [here](https://www.tensorflow.org/guide/data#dataset_structure).\n",
      " |      \n",
      " |      For example, `map` can be used for adding 1 to each element, or projecting a\n",
      " |      subset of element components.\n",
      " |      \n",
      " |      >>> dataset = Dataset.range(1, 6)  # ==> [ 1, 2, 3, 4, 5 ]\n",
      " |      >>> dataset = dataset.map(lambda x: x + 1)\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [2, 3, 4, 5, 6]\n",
      " |      \n",
      " |      The input signature of `map_func` is determined by the structure of each\n",
      " |      element in this dataset.\n",
      " |      \n",
      " |      >>> dataset = Dataset.range(5)\n",
      " |      >>> # `map_func` takes a single argument of type `tf.Tensor` with the same\n",
      " |      >>> # shape and dtype.\n",
      " |      >>> result = dataset.map(lambda x: x + 1)\n",
      " |      \n",
      " |      >>> # Each element is a tuple containing two `tf.Tensor` objects.\n",
      " |      >>> elements = [(1, \"foo\"), (2, \"bar\"), (3, \"baz\")]\n",
      " |      >>> dataset = tf.data.Dataset.from_generator(\n",
      " |      ...     lambda: elements, (tf.int32, tf.string))\n",
      " |      >>> # `map_func` takes two arguments of type `tf.Tensor`. This function\n",
      " |      >>> # projects out just the first component.\n",
      " |      >>> result = dataset.map(lambda x_int, y_str: x_int)\n",
      " |      >>> list(result.as_numpy_iterator())\n",
      " |      [1, 2, 3]\n",
      " |      \n",
      " |      >>> # Each element is a dictionary mapping strings to `tf.Tensor` objects.\n",
      " |      >>> elements =  ([{\"a\": 1, \"b\": \"foo\"},\n",
      " |      ...               {\"a\": 2, \"b\": \"bar\"},\n",
      " |      ...               {\"a\": 3, \"b\": \"baz\"}])\n",
      " |      >>> dataset = tf.data.Dataset.from_generator(\n",
      " |      ...     lambda: elements, {\"a\": tf.int32, \"b\": tf.string})\n",
      " |      >>> # `map_func` takes a single argument of type `dict` with the same keys\n",
      " |      >>> # as the elements.\n",
      " |      >>> result = dataset.map(lambda d: str(d[\"a\"]) + d[\"b\"])\n",
      " |      \n",
      " |      The value or values returned by `map_func` determine the structure of each\n",
      " |      element in the returned dataset.\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.range(3)\n",
      " |      >>> # `map_func` returns two `tf.Tensor` objects.\n",
      " |      >>> def g(x):\n",
      " |      ...   return tf.constant(37.0), tf.constant([\"Foo\", \"Bar\", \"Baz\"])\n",
      " |      >>> result = dataset.map(g)\n",
      " |      >>> result.element_spec\n",
      " |      (TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(3,), dtype=tf.string, name=None))\n",
      " |      >>> # Python primitives, lists, and NumPy arrays are implicitly converted to\n",
      " |      >>> # `tf.Tensor`.\n",
      " |      >>> def h(x):\n",
      " |      ...   return 37.0, [\"Foo\", \"Bar\"], np.array([1.0, 2.0], dtype=np.float64)\n",
      " |      >>> result = dataset.map(h)\n",
      " |      >>> result.element_spec\n",
      " |      (TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(2,), dtype=tf.string, name=None), TensorSpec(shape=(2,), dtype=tf.float64, name=None))\n",
      " |      >>> # `map_func` can return nested structures.\n",
      " |      >>> def i(x):\n",
      " |      ...   return (37.0, [42, 16]), \"foo\"\n",
      " |      >>> result = dataset.map(i)\n",
      " |      >>> result.element_spec\n",
      " |      ((TensorSpec(shape=(), dtype=tf.float32, name=None),\n",
      " |        TensorSpec(shape=(2,), dtype=tf.int32, name=None)),\n",
      " |       TensorSpec(shape=(), dtype=tf.string, name=None))\n",
      " |      \n",
      " |      `map_func` can accept as arguments and return any type of dataset element.\n",
      " |      \n",
      " |      Note that irrespective of the context in which `map_func` is defined (eager\n",
      " |      vs. graph), tf.data traces the function and executes it as a graph. To use\n",
      " |      Python code inside of the function you have a few options:\n",
      " |      \n",
      " |      1) Rely on AutoGraph to convert Python code into an equivalent graph\n",
      " |      computation. The downside of this approach is that AutoGraph can convert\n",
      " |      some but not all Python code.\n",
      " |      \n",
      " |      2) Use `tf.py_function`, which allows you to write arbitrary Python code but\n",
      " |      will generally result in worse performance than 1). For example:\n",
      " |      \n",
      " |      >>> d = tf.data.Dataset.from_tensor_slices(['hello', 'world'])\n",
      " |      >>> # transform a string tensor to upper case string using a Python function\n",
      " |      >>> def upper_case_fn(t: tf.Tensor):\n",
      " |      ...   return t.numpy().decode('utf-8').upper()\n",
      " |      >>> d = d.map(lambda x: tf.py_function(func=upper_case_fn,\n",
      " |      ...           inp=[x], Tout=tf.string))\n",
      " |      >>> list(d.as_numpy_iterator())\n",
      " |      [b'HELLO', b'WORLD']\n",
      " |      \n",
      " |      3) Use `tf.numpy_function`, which also allows you to write arbitrary\n",
      " |      Python code. Note that `tf.py_function` accepts `tf.Tensor` whereas\n",
      " |      `tf.numpy_function` accepts numpy arrays and returns only numpy arrays.\n",
      " |      For example:\n",
      " |      \n",
      " |      >>> d = tf.data.Dataset.from_tensor_slices(['hello', 'world'])\n",
      " |      >>> def upper_case_fn(t: np.ndarray):\n",
      " |      ...   return t.decode('utf-8').upper()\n",
      " |      >>> d = d.map(lambda x: tf.numpy_function(func=upper_case_fn,\n",
      " |      ...           inp=[x], Tout=tf.string))\n",
      " |      >>> list(d.as_numpy_iterator())\n",
      " |      [b'HELLO', b'WORLD']\n",
      " |      \n",
      " |      Note that the use of `tf.numpy_function` and `tf.py_function`\n",
      " |      in general precludes the possibility of executing user-defined\n",
      " |      transformations in parallel (because of Python GIL).\n",
      " |      \n",
      " |      Performance can often be improved by setting `num_parallel_calls` so that\n",
      " |      `map` will use multiple threads to process elements. If deterministic order\n",
      " |      isn't required, it can also improve performance to set\n",
      " |      `deterministic=False`.\n",
      " |      \n",
      " |      >>> dataset = Dataset.range(1, 6)  # ==> [ 1, 2, 3, 4, 5 ]\n",
      " |      >>> dataset = dataset.map(lambda x: x + 1,\n",
      " |      ...     num_parallel_calls=tf.data.AUTOTUNE,\n",
      " |      ...     deterministic=False)\n",
      " |      \n",
      " |      The order of elements yielded by this transformation is deterministic if\n",
      " |      `deterministic=True`. If `map_func` contains stateful operations and\n",
      " |      `num_parallel_calls > 1`, the order in which that state is accessed is\n",
      " |      undefined, so the values of output elements may not be deterministic\n",
      " |      regardless of the `deterministic` flag value.\n",
      " |      \n",
      " |      Args:\n",
      " |        map_func: A function mapping a dataset element to another dataset element.\n",
      " |        num_parallel_calls: (Optional.) A `tf.int64` scalar `tf.Tensor`,\n",
      " |          representing the number elements to process asynchronously in parallel.\n",
      " |          If not specified, elements will be processed sequentially. If the value\n",
      " |          `tf.data.AUTOTUNE` is used, then the number of parallel\n",
      " |          calls is set dynamically based on available CPU.\n",
      " |        deterministic: (Optional.) When `num_parallel_calls` is specified, if this\n",
      " |          boolean is specified (`True` or `False`), it controls the order in which\n",
      " |          the transformation produces elements. If set to `False`, the\n",
      " |          transformation is allowed to yield elements out of order to trade\n",
      " |          determinism for performance. If not specified, the\n",
      " |          `tf.data.Options.deterministic` option (`True` by default) controls the\n",
      " |          behavior.\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset`.\n",
      " |  \n",
      " |  options(self)\n",
      " |      Returns the options for this dataset and its inputs.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `tf.data.Options` object representing the dataset options.\n",
      " |  \n",
      " |  padded_batch(self, batch_size, padded_shapes=None, padding_values=None, drop_remainder=False, name=None)\n",
      " |      Combines consecutive elements of this dataset into padded batches.\n",
      " |      \n",
      " |      This transformation combines multiple consecutive elements of the input\n",
      " |      dataset into a single element.\n",
      " |      \n",
      " |      Like `tf.data.Dataset.batch`, the components of the resulting element will\n",
      " |      have an additional outer dimension, which will be `batch_size` (or\n",
      " |      `N % batch_size` for the last element if `batch_size` does not divide the\n",
      " |      number of input elements `N` evenly and `drop_remainder` is `False`). If\n",
      " |      your program depends on the batches having the same outer dimension, you\n",
      " |      should set the `drop_remainder` argument to `True` to prevent the smaller\n",
      " |      batch from being produced.\n",
      " |      \n",
      " |      Unlike `tf.data.Dataset.batch`, the input elements to be batched may have\n",
      " |      different shapes, and this transformation will pad each component to the\n",
      " |      respective shape in `padded_shapes`. The `padded_shapes` argument\n",
      " |      determines the resulting shape for each dimension of each component in an\n",
      " |      output element:\n",
      " |      \n",
      " |      * If the dimension is a constant, the component will be padded out to that\n",
      " |        length in that dimension.\n",
      " |      * If the dimension is unknown, the component will be padded out to the\n",
      " |        maximum length of all elements in that dimension.\n",
      " |      \n",
      " |      >>> A = (tf.data.Dataset\n",
      " |      ...      .range(1, 5, output_type=tf.int32)\n",
      " |      ...      .map(lambda x: tf.fill([x], x)))\n",
      " |      >>> # Pad to the smallest per-batch size that fits all elements.\n",
      " |      >>> B = A.padded_batch(2)\n",
      " |      >>> for element in B.as_numpy_iterator():\n",
      " |      ...   print(element)\n",
      " |      [[1 0]\n",
      " |       [2 2]]\n",
      " |      [[3 3 3 0]\n",
      " |       [4 4 4 4]]\n",
      " |      >>> # Pad to a fixed size.\n",
      " |      >>> C = A.padded_batch(2, padded_shapes=5)\n",
      " |      >>> for element in C.as_numpy_iterator():\n",
      " |      ...   print(element)\n",
      " |      [[1 0 0 0 0]\n",
      " |       [2 2 0 0 0]]\n",
      " |      [[3 3 3 0 0]\n",
      " |       [4 4 4 4 0]]\n",
      " |      >>> # Pad with a custom value.\n",
      " |      >>> D = A.padded_batch(2, padded_shapes=5, padding_values=-1)\n",
      " |      >>> for element in D.as_numpy_iterator():\n",
      " |      ...   print(element)\n",
      " |      [[ 1 -1 -1 -1 -1]\n",
      " |       [ 2  2 -1 -1 -1]]\n",
      " |      [[ 3  3  3 -1 -1]\n",
      " |       [ 4  4  4  4 -1]]\n",
      " |      >>> # Components of nested elements can be padded independently.\n",
      " |      >>> elements = [([1, 2, 3], [10]),\n",
      " |      ...             ([4, 5], [11, 12])]\n",
      " |      >>> dataset = tf.data.Dataset.from_generator(\n",
      " |      ...     lambda: iter(elements), (tf.int32, tf.int32))\n",
      " |      >>> # Pad the first component of the tuple to length 4, and the second\n",
      " |      >>> # component to the smallest size that fits.\n",
      " |      >>> dataset = dataset.padded_batch(2,\n",
      " |      ...     padded_shapes=([4], [None]),\n",
      " |      ...     padding_values=(-1, 100))\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [(array([[ 1,  2,  3, -1], [ 4,  5, -1, -1]], dtype=int32),\n",
      " |        array([[ 10, 100], [ 11,  12]], dtype=int32))]\n",
      " |      >>> # Pad with a single value and multiple components.\n",
      " |      >>> E = tf.data.Dataset.zip((A, A)).padded_batch(2, padding_values=-1)\n",
      " |      >>> for element in E.as_numpy_iterator():\n",
      " |      ...   print(element)\n",
      " |      (array([[ 1, -1],\n",
      " |             [ 2,  2]], dtype=int32), array([[ 1, -1],\n",
      " |             [ 2,  2]], dtype=int32))\n",
      " |      (array([[ 3,  3,  3, -1],\n",
      " |             [ 4,  4,  4,  4]], dtype=int32), array([[ 3,  3,  3, -1],\n",
      " |             [ 4,  4,  4,  4]], dtype=int32))\n",
      " |      \n",
      " |      See also `tf.data.experimental.dense_to_sparse_batch`, which combines\n",
      " |      elements that may have different shapes into a `tf.sparse.SparseTensor`.\n",
      " |      \n",
      " |      Args:\n",
      " |        batch_size: A `tf.int64` scalar `tf.Tensor`, representing the number of\n",
      " |          consecutive elements of this dataset to combine in a single batch.\n",
      " |        padded_shapes: (Optional.) A (nested) structure of `tf.TensorShape` or\n",
      " |          `tf.int64` vector tensor-like objects representing the shape to which\n",
      " |          the respective component of each input element should be padded prior\n",
      " |          to batching. Any unknown dimensions will be padded to the maximum size\n",
      " |          of that dimension in each batch. If unset, all dimensions of all\n",
      " |          components are padded to the maximum size in the batch. `padded_shapes`\n",
      " |          must be set if any component has an unknown rank.\n",
      " |        padding_values: (Optional.) A (nested) structure of scalar-shaped\n",
      " |          `tf.Tensor`, representing the padding values to use for the respective\n",
      " |          components. None represents that the (nested) structure should be padded\n",
      " |          with default values.  Defaults are `0` for numeric types and the empty\n",
      " |          string for string types. The `padding_values` should have the same\n",
      " |          (nested) structure as the input dataset. If `padding_values` is a single\n",
      " |          element and the input dataset has multiple components, then the same\n",
      " |          `padding_values` will be used to pad every component of the dataset.\n",
      " |          If `padding_values` is a scalar, then its value will be broadcasted\n",
      " |          to match the shape of each component.\n",
      " |        drop_remainder: (Optional.) A `tf.bool` scalar `tf.Tensor`, representing\n",
      " |          whether the last batch should be dropped in the case it has fewer than\n",
      " |          `batch_size` elements; the default behavior is not to drop the smaller\n",
      " |          batch.\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset`.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: If a component has an unknown rank, and the `padded_shapes`\n",
      " |          argument is not set.\n",
      " |        TypeError: If a component is of an unsupported type. The list of supported\n",
      " |          types is documented in\n",
      " |          https://www.tensorflow.org/guide/data#dataset_structure.\n",
      " |  \n",
      " |  prefetch(self, buffer_size, name=None)\n",
      " |      Creates a `Dataset` that prefetches elements from this dataset.\n",
      " |      \n",
      " |      Most dataset input pipelines should end with a call to `prefetch`. This\n",
      " |      allows later elements to be prepared while the current element is being\n",
      " |      processed. This often improves latency and throughput, at the cost of\n",
      " |      using additional memory to store prefetched elements.\n",
      " |      \n",
      " |      Note: Like other `Dataset` methods, prefetch operates on the\n",
      " |      elements of the input dataset. It has no concept of examples vs. batches.\n",
      " |      `examples.prefetch(2)` will prefetch two elements (2 examples),\n",
      " |      while `examples.batch(20).prefetch(2)` will prefetch 2 elements\n",
      " |      (2 batches, of 20 examples each).\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.range(3)\n",
      " |      >>> dataset = dataset.prefetch(2)\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [0, 1, 2]\n",
      " |      \n",
      " |      Args:\n",
      " |        buffer_size: A `tf.int64` scalar `tf.Tensor`, representing the maximum\n",
      " |          number of elements that will be buffered when prefetching. If the value\n",
      " |          `tf.data.AUTOTUNE` is used, then the buffer size is dynamically tuned.\n",
      " |        name: Optional. A name for the tf.data transformation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset`.\n",
      " |  \n",
      " |  reduce(self, initial_state, reduce_func, name=None)\n",
      " |      Reduces the input dataset to a single element.\n",
      " |      \n",
      " |      The transformation calls `reduce_func` successively on every element of\n",
      " |      the input dataset until the dataset is exhausted, aggregating information in\n",
      " |      its internal state. The `initial_state` argument is used for the initial\n",
      " |      state and the final state is returned as the result.\n",
      " |      \n",
      " |      >>> tf.data.Dataset.range(5).reduce(np.int64(0), lambda x, _: x + 1).numpy()\n",
      " |      5\n",
      " |      >>> tf.data.Dataset.range(5).reduce(np.int64(0), lambda x, y: x + y).numpy()\n",
      " |      10\n",
      " |      \n",
      " |      Args:\n",
      " |        initial_state: An element representing the initial state of the\n",
      " |          transformation.\n",
      " |        reduce_func: A function that maps `(old_state, input_element)` to\n",
      " |          `new_state`. It must take two arguments and return a new element\n",
      " |          The structure of `new_state` must match the structure of\n",
      " |          `initial_state`.\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A dataset element corresponding to the final state of the transformation.\n",
      " |  \n",
      " |  rejection_resample(self, class_func, target_dist, initial_dist=None, seed=None, name=None)\n",
      " |      A transformation that resamples a dataset to a target distribution.\n",
      " |      \n",
      " |      Lets consider the following example where a dataset with an initial data\n",
      " |      distribution of `init_dist` needs to be resampled into a dataset with\n",
      " |      `target_dist` distribution.\n",
      " |      \n",
      " |      >>> import collections\n",
      " |      >>> initial_dist = [0.5, 0.5]\n",
      " |      >>> target_dist = [0.6, 0.4]\n",
      " |      >>> num_classes = len(initial_dist)\n",
      " |      >>> num_samples = 100000\n",
      " |      >>> data_np = np.random.choice(num_classes, num_samples, p=initial_dist)\n",
      " |      >>> dataset = tf.data.Dataset.from_tensor_slices(data_np)\n",
      " |      >>> x = collections.defaultdict(int)\n",
      " |      >>> for i in dataset:\n",
      " |      ...   x[i.numpy()] += 1\n",
      " |      \n",
      " |      The value of `x` will be close to `{0: 50000, 1: 50000}` as per the\n",
      " |      `initial_dist` distribution.\n",
      " |      \n",
      " |      >>> dataset = dataset.rejection_resample(\n",
      " |      ...    class_func=lambda x: x % 2,\n",
      " |      ...    target_dist=target_dist,\n",
      " |      ...    initial_dist=initial_dist)\n",
      " |      \n",
      " |      >>> y = collections.defaultdict(int)\n",
      " |      >>> for i in dataset:\n",
      " |      ...   cls, _ = i\n",
      " |      ...   y[cls.numpy()] += 1\n",
      " |      \n",
      " |      The value of `y` will be now be close to `{0: 75000, 1: 50000}` thus\n",
      " |      satisfying the `target_dist` distribution.\n",
      " |      \n",
      " |      Args:\n",
      " |        class_func: A function mapping an element of the input dataset to a scalar\n",
      " |          `tf.int32` tensor. Values should be in `[0, num_classes)`.\n",
      " |        target_dist: A floating point type tensor, shaped `[num_classes]`.\n",
      " |        initial_dist: (Optional.)  A floating point type tensor, shaped\n",
      " |          `[num_classes]`.  If not provided, the true class distribution is\n",
      " |          estimated live in a streaming fashion.\n",
      " |        seed: (Optional.) Python integer seed for the resampler.\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `Dataset`\n",
      " |  \n",
      " |  repeat(self, count=None, name=None)\n",
      " |      Repeats this dataset so each original value is seen `count` times.\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
      " |      >>> dataset = dataset.repeat(3)\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [1, 2, 3, 1, 2, 3, 1, 2, 3]\n",
      " |      \n",
      " |      Note: If this dataset is a function of global state (e.g. a random number\n",
      " |      generator), then different repetitions may produce different elements.\n",
      " |      \n",
      " |      Args:\n",
      " |        count: (Optional.) A `tf.int64` scalar `tf.Tensor`, representing the\n",
      " |          number of times the dataset should be repeated. The default behavior (if\n",
      " |          `count` is `None` or `-1`) is for the dataset be repeated indefinitely.\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset`.\n",
      " |  \n",
      " |  scan(self, initial_state, scan_func, name=None)\n",
      " |      A transformation that scans a function across an input dataset.\n",
      " |      \n",
      " |      This transformation is a stateful relative of `tf.data.Dataset.map`.\n",
      " |      In addition to mapping `scan_func` across the elements of the input dataset,\n",
      " |      `scan()` accumulates one or more state tensors, whose initial values are\n",
      " |      `initial_state`.\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.range(10)\n",
      " |      >>> initial_state = tf.constant(0, dtype=tf.int64)\n",
      " |      >>> scan_func = lambda state, i: (state + i, state + i)\n",
      " |      >>> dataset = dataset.scan(initial_state=initial_state, scan_func=scan_func)\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [0, 1, 3, 6, 10, 15, 21, 28, 36, 45]\n",
      " |      \n",
      " |      Args:\n",
      " |        initial_state: A nested structure of tensors, representing the initial\n",
      " |          state of the accumulator.\n",
      " |        scan_func: A function that maps `(old_state, input_element)` to\n",
      " |          `(new_state, output_element)`. It must take two arguments and return a\n",
      " |          pair of nested structures of tensors. The `new_state` must match the\n",
      " |          structure of `initial_state`.\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `Dataset`.\n",
      " |  \n",
      " |  shard(self, num_shards, index, name=None)\n",
      " |      Creates a `Dataset` that includes only 1/`num_shards` of this dataset.\n",
      " |      \n",
      " |      `shard` is deterministic. The Dataset produced by `A.shard(n, i)` will\n",
      " |      contain all elements of A whose index mod n = i.\n",
      " |      \n",
      " |      >>> A = tf.data.Dataset.range(10)\n",
      " |      >>> B = A.shard(num_shards=3, index=0)\n",
      " |      >>> list(B.as_numpy_iterator())\n",
      " |      [0, 3, 6, 9]\n",
      " |      >>> C = A.shard(num_shards=3, index=1)\n",
      " |      >>> list(C.as_numpy_iterator())\n",
      " |      [1, 4, 7]\n",
      " |      >>> D = A.shard(num_shards=3, index=2)\n",
      " |      >>> list(D.as_numpy_iterator())\n",
      " |      [2, 5, 8]\n",
      " |      \n",
      " |      This dataset operator is very useful when running distributed training, as\n",
      " |      it allows each worker to read a unique subset.\n",
      " |      \n",
      " |      When reading a single input file, you can shard elements as follows:\n",
      " |      \n",
      " |      ```python\n",
      " |      d = tf.data.TFRecordDataset(input_file)\n",
      " |      d = d.shard(num_workers, worker_index)\n",
      " |      d = d.repeat(num_epochs)\n",
      " |      d = d.shuffle(shuffle_buffer_size)\n",
      " |      d = d.map(parser_fn, num_parallel_calls=num_map_threads)\n",
      " |      ```\n",
      " |      \n",
      " |      Important caveats:\n",
      " |      \n",
      " |      - Be sure to shard before you use any randomizing operator (such as\n",
      " |        shuffle).\n",
      " |      - Generally it is best if the shard operator is used early in the dataset\n",
      " |        pipeline. For example, when reading from a set of TFRecord files, shard\n",
      " |        before converting the dataset to input samples. This avoids reading every\n",
      " |        file on every worker. The following is an example of an efficient\n",
      " |        sharding strategy within a complete pipeline:\n",
      " |      \n",
      " |      ```python\n",
      " |      d = Dataset.list_files(pattern)\n",
      " |      d = d.shard(num_workers, worker_index)\n",
      " |      d = d.repeat(num_epochs)\n",
      " |      d = d.shuffle(shuffle_buffer_size)\n",
      " |      d = d.interleave(tf.data.TFRecordDataset,\n",
      " |                       cycle_length=num_readers, block_length=1)\n",
      " |      d = d.map(parser_fn, num_parallel_calls=num_map_threads)\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        num_shards: A `tf.int64` scalar `tf.Tensor`, representing the number of\n",
      " |          shards operating in parallel.\n",
      " |        index: A `tf.int64` scalar `tf.Tensor`, representing the worker index.\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset`.\n",
      " |      \n",
      " |      Raises:\n",
      " |        InvalidArgumentError: if `num_shards` or `index` are illegal values.\n",
      " |      \n",
      " |          Note: error checking is done on a best-effort basis, and errors aren't\n",
      " |          guaranteed to be caught upon dataset creation. (e.g. providing in a\n",
      " |          placeholder tensor bypasses the early checking, and will instead result\n",
      " |          in an error during a session.run call.)\n",
      " |  \n",
      " |  shuffle(self, buffer_size, seed=None, reshuffle_each_iteration=None, name=None)\n",
      " |      Randomly shuffles the elements of this dataset.\n",
      " |      \n",
      " |      This dataset fills a buffer with `buffer_size` elements, then randomly\n",
      " |      samples elements from this buffer, replacing the selected elements with new\n",
      " |      elements. For perfect shuffling, a buffer size greater than or equal to the\n",
      " |      full size of the dataset is required.\n",
      " |      \n",
      " |      For instance, if your dataset contains 10,000 elements but `buffer_size` is\n",
      " |      set to 1,000, then `shuffle` will initially select a random element from\n",
      " |      only the first 1,000 elements in the buffer. Once an element is selected,\n",
      " |      its space in the buffer is replaced by the next (i.e. 1,001-st) element,\n",
      " |      maintaining the 1,000 element buffer.\n",
      " |      \n",
      " |      `reshuffle_each_iteration` controls whether the shuffle order should be\n",
      " |      different for each epoch. In TF 1.X, the idiomatic way to create epochs\n",
      " |      was through the `repeat` transformation:\n",
      " |      \n",
      " |      ```python\n",
      " |      dataset = tf.data.Dataset.range(3)\n",
      " |      dataset = dataset.shuffle(3, reshuffle_each_iteration=True)\n",
      " |      dataset = dataset.repeat(2)\n",
      " |      # [1, 0, 2, 1, 2, 0]\n",
      " |      \n",
      " |      dataset = tf.data.Dataset.range(3)\n",
      " |      dataset = dataset.shuffle(3, reshuffle_each_iteration=False)\n",
      " |      dataset = dataset.repeat(2)\n",
      " |      # [1, 0, 2, 1, 0, 2]\n",
      " |      ```\n",
      " |      \n",
      " |      In TF 2.0, `tf.data.Dataset` objects are Python iterables which makes it\n",
      " |      possible to also create epochs through Python iteration:\n",
      " |      \n",
      " |      ```python\n",
      " |      dataset = tf.data.Dataset.range(3)\n",
      " |      dataset = dataset.shuffle(3, reshuffle_each_iteration=True)\n",
      " |      list(dataset.as_numpy_iterator())\n",
      " |      # [1, 0, 2]\n",
      " |      list(dataset.as_numpy_iterator())\n",
      " |      # [1, 2, 0]\n",
      " |      ```\n",
      " |      \n",
      " |      ```python\n",
      " |      dataset = tf.data.Dataset.range(3)\n",
      " |      dataset = dataset.shuffle(3, reshuffle_each_iteration=False)\n",
      " |      list(dataset.as_numpy_iterator())\n",
      " |      # [1, 0, 2]\n",
      " |      list(dataset.as_numpy_iterator())\n",
      " |      # [1, 0, 2]\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        buffer_size: A `tf.int64` scalar `tf.Tensor`, representing the number of\n",
      " |          elements from this dataset from which the new dataset will sample.\n",
      " |        seed: (Optional.) A `tf.int64` scalar `tf.Tensor`, representing the random\n",
      " |          seed that will be used to create the distribution. See\n",
      " |          `tf.random.set_seed` for behavior.\n",
      " |        reshuffle_each_iteration: (Optional.) A boolean, which if true indicates\n",
      " |          that the dataset should be pseudorandomly reshuffled each time it is\n",
      " |          iterated over. (Defaults to `True`.)\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset`.\n",
      " |  \n",
      " |  skip(self, count, name=None)\n",
      " |      Creates a `Dataset` that skips `count` elements from this dataset.\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.range(10)\n",
      " |      >>> dataset = dataset.skip(7)\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [7, 8, 9]\n",
      " |      \n",
      " |      Args:\n",
      " |        count: A `tf.int64` scalar `tf.Tensor`, representing the number of\n",
      " |          elements of this dataset that should be skipped to form the new dataset.\n",
      " |          If `count` is greater than the size of this dataset, the new dataset\n",
      " |          will contain no elements.  If `count` is -1, skips the entire dataset.\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset`.\n",
      " |  \n",
      " |  snapshot(self, path, compression='AUTO', reader_func=None, shard_func=None, name=None)\n",
      " |      API to persist the output of the input dataset.\n",
      " |      \n",
      " |      The snapshot API allows users to transparently persist the output of their\n",
      " |      preprocessing pipeline to disk, and materialize the pre-processed data on a\n",
      " |      different training run.\n",
      " |      \n",
      " |      This API enables repeated preprocessing steps to be consolidated, and allows\n",
      " |      re-use of already processed data, trading off disk storage and network\n",
      " |      bandwidth for freeing up more valuable CPU resources and accelerator compute\n",
      " |      time.\n",
      " |      \n",
      " |      https://github.com/tensorflow/community/blob/master/rfcs/20200107-tf-data-snapshot.md\n",
      " |      has detailed design documentation of this feature.\n",
      " |      \n",
      " |      Users can specify various options to control the behavior of snapshot,\n",
      " |      including how snapshots are read from and written to by passing in\n",
      " |      user-defined functions to the `reader_func` and `shard_func` parameters.\n",
      " |      \n",
      " |      `shard_func` is a user specified function that maps input elements to\n",
      " |      snapshot shards.\n",
      " |      \n",
      " |      Users may want to specify this function to control how snapshot files should\n",
      " |      be written to disk. Below is an example of how a potential `shard_func`\n",
      " |      could be written.\n",
      " |      \n",
      " |      ```python\n",
      " |      dataset = ...\n",
      " |      dataset = dataset.enumerate()\n",
      " |      dataset = dataset.snapshot(\"/path/to/snapshot/dir\",\n",
      " |          shard_func=lambda x, y: x % NUM_SHARDS, ...)\n",
      " |      dataset = dataset.map(lambda x, y: y)\n",
      " |      ```\n",
      " |      \n",
      " |      `reader_func` is a user specified function that accepts a single argument:\n",
      " |      (1) a Dataset of Datasets, each representing a \"split\" of elements of the\n",
      " |      original dataset. The cardinality of the input dataset matches the\n",
      " |      number of the shards specified in the `shard_func` (see above). The function\n",
      " |      should return a Dataset of elements of the original dataset.\n",
      " |      \n",
      " |      Users may want specify this function to control how snapshot files should be\n",
      " |      read from disk, including the amount of shuffling and parallelism.\n",
      " |      \n",
      " |      Here is an example of a standard reader function a user can define. This\n",
      " |      function enables both dataset shuffling and parallel reading of datasets:\n",
      " |      \n",
      " |      ```python\n",
      " |      def user_reader_func(datasets):\n",
      " |        # shuffle the datasets splits\n",
      " |        datasets = datasets.shuffle(NUM_CORES)\n",
      " |        # read datasets in parallel and interleave their elements\n",
      " |        return datasets.interleave(lambda x: x, num_parallel_calls=AUTOTUNE)\n",
      " |      \n",
      " |      dataset = dataset.snapshot(\"/path/to/snapshot/dir\",\n",
      " |          reader_func=user_reader_func)\n",
      " |      ```\n",
      " |      \n",
      " |      By default, snapshot parallelizes reads by the number of cores available on\n",
      " |      the system, but will not attempt to shuffle the data.\n",
      " |      \n",
      " |      Args:\n",
      " |        path: Required. A directory to use for storing / loading the snapshot to /\n",
      " |          from.\n",
      " |        compression: Optional. The type of compression to apply to the snapshot\n",
      " |          written to disk. Supported options are `GZIP`, `SNAPPY`, `AUTO` or None.\n",
      " |          Defaults to `AUTO`, which attempts to pick an appropriate compression\n",
      " |          algorithm for the dataset.\n",
      " |        reader_func: Optional. A function to control how to read data from\n",
      " |          snapshot shards.\n",
      " |        shard_func: Optional. A function to control how to shard data when writing\n",
      " |          a snapshot.\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `Dataset`.\n",
      " |  \n",
      " |  take(self, count, name=None)\n",
      " |      Creates a `Dataset` with at most `count` elements from this dataset.\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.range(10)\n",
      " |      >>> dataset = dataset.take(3)\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [0, 1, 2]\n",
      " |      \n",
      " |      Args:\n",
      " |        count: A `tf.int64` scalar `tf.Tensor`, representing the number of\n",
      " |          elements of this dataset that should be taken to form the new dataset.\n",
      " |          If `count` is -1, or if `count` is greater than the size of this\n",
      " |          dataset, the new dataset will contain all elements of this dataset.\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset`.\n",
      " |  \n",
      " |  take_while(self, predicate, name=None)\n",
      " |      A transformation that stops dataset iteration based on a `predicate`.\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.range(10)\n",
      " |      >>> dataset = dataset.take_while(lambda x: x < 5)\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [0, 1, 2, 3, 4]\n",
      " |      \n",
      " |      Args:\n",
      " |        predicate: A function that maps a nested structure of tensors (having\n",
      " |          shapes and types defined by `self.output_shapes` and\n",
      " |          `self.output_types`) to a scalar `tf.bool` tensor.\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `Dataset`.\n",
      " |  \n",
      " |  unbatch(self, name=None)\n",
      " |      Splits elements of a dataset into multiple elements.\n",
      " |      \n",
      " |      For example, if elements of the dataset are shaped `[B, a0, a1, ...]`,\n",
      " |      where `B` may vary for each input element, then for each element in the\n",
      " |      dataset, the unbatched dataset will contain `B` consecutive elements\n",
      " |      of shape `[a0, a1, ...]`.\n",
      " |      \n",
      " |      >>> elements = [ [1, 2, 3], [1, 2], [1, 2, 3, 4] ]\n",
      " |      >>> dataset = tf.data.Dataset.from_generator(lambda: elements, tf.int64)\n",
      " |      >>> dataset = dataset.unbatch()\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [1, 2, 3, 1, 2, 1, 2, 3, 4]\n",
      " |      \n",
      " |      Note: `unbatch` requires a data copy to slice up the batched tensor into\n",
      " |      smaller, unbatched tensors. When optimizing performance, try to avoid\n",
      " |      unnecessary usage of `unbatch`.\n",
      " |      \n",
      " |      Args:\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `Dataset`.\n",
      " |  \n",
      " |  unique(self, name=None)\n",
      " |      A transformation that discards duplicate elements of a `Dataset`.\n",
      " |      \n",
      " |      Use this transformation to produce a dataset that contains one instance of\n",
      " |      each unique element in the input. For example:\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.from_tensor_slices([1, 37, 2, 37, 2, 1])\n",
      " |      >>> dataset = dataset.unique()\n",
      " |      >>> sorted(list(dataset.as_numpy_iterator()))\n",
      " |      [1, 2, 37]\n",
      " |      \n",
      " |      Note: This transformation only supports datasets which fit into memory\n",
      " |      and have elements of either `tf.int32`, `tf.int64` or `tf.string` type.\n",
      " |      \n",
      " |      Args:\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A `Dataset`.\n",
      " |  \n",
      " |  window(self, size, shift=None, stride=1, drop_remainder=False, name=None)\n",
      " |      Returns a dataset of \"windows\".\n",
      " |      \n",
      " |      Each \"window\" is a dataset that contains a subset of elements of the\n",
      " |      input dataset. These are finite datasets of size `size` (or possibly fewer\n",
      " |      if there are not enough input elements to fill the window and\n",
      " |      `drop_remainder` evaluates to `False`).\n",
      " |      \n",
      " |      For example:\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.range(7).window(3)\n",
      " |      >>> for window in dataset:\n",
      " |      ...   print(window)\n",
      " |      <...Dataset element_spec=TensorSpec(shape=(), dtype=tf.int64, name=None)>\n",
      " |      <...Dataset element_spec=TensorSpec(shape=(), dtype=tf.int64, name=None)>\n",
      " |      <...Dataset element_spec=TensorSpec(shape=(), dtype=tf.int64, name=None)>\n",
      " |      \n",
      " |      Since windows are datasets, they can be iterated over:\n",
      " |      \n",
      " |      >>> for window in dataset:\n",
      " |      ...   print([item.numpy() for item in window])\n",
      " |      [0, 1, 2]\n",
      " |      [3, 4, 5]\n",
      " |      [6]\n",
      " |      \n",
      " |      #### Shift\n",
      " |      \n",
      " |      The `shift` argument determines the number of input elements to shift\n",
      " |      between the start of each window. If windows and elements are both numbered\n",
      " |      starting at 0, the first element in window `k` will be element `k * shift`\n",
      " |      of the input dataset. In particular, the first element of the first window\n",
      " |      will always be the first element of the input dataset.\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.range(7).window(3, shift=1,\n",
      " |      ...                                           drop_remainder=True)\n",
      " |      >>> for window in dataset:\n",
      " |      ...   print(list(window.as_numpy_iterator()))\n",
      " |      [0, 1, 2]\n",
      " |      [1, 2, 3]\n",
      " |      [2, 3, 4]\n",
      " |      [3, 4, 5]\n",
      " |      [4, 5, 6]\n",
      " |      \n",
      " |      #### Stride\n",
      " |      \n",
      " |      The `stride` argument determines the stride between input elements within a\n",
      " |      window.\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.range(7).window(3, shift=1, stride=2,\n",
      " |      ...                                           drop_remainder=True)\n",
      " |      >>> for window in dataset:\n",
      " |      ...   print(list(window.as_numpy_iterator()))\n",
      " |      [0, 2, 4]\n",
      " |      [1, 3, 5]\n",
      " |      [2, 4, 6]\n",
      " |      \n",
      " |      #### Nested elements\n",
      " |      \n",
      " |      When the `window` transformation is applied to a dataset whos elements are\n",
      " |      nested structures, it produces a dataset where the elements have the same\n",
      " |      nested structure but each leaf is replaced by a window. In other words,\n",
      " |      the nesting is applied outside of the windows as opposed inside of them.\n",
      " |      \n",
      " |      The type signature is:\n",
      " |      \n",
      " |      ```\n",
      " |      def window(\n",
      " |          self: Dataset[Nest[T]], ...\n",
      " |      ) -> Dataset[Nest[Dataset[T]]]\n",
      " |      ```\n",
      " |      \n",
      " |      Applying `window` to a `Dataset` of tuples gives a tuple of windows:\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.from_tensor_slices(([1, 2, 3, 4, 5],\n",
      " |      ...                                               [6, 7, 8, 9, 10]))\n",
      " |      >>> dataset = dataset.window(2)\n",
      " |      >>> windows = next(iter(dataset))\n",
      " |      >>> windows\n",
      " |      (<...Dataset element_spec=TensorSpec(shape=(), dtype=tf.int32, name=None)>,\n",
      " |       <...Dataset element_spec=TensorSpec(shape=(), dtype=tf.int32, name=None)>)\n",
      " |      \n",
      " |      >>> def to_numpy(ds):\n",
      " |      ...   return list(ds.as_numpy_iterator())\n",
      " |      >>>\n",
      " |      >>> for windows in dataset:\n",
      " |      ...   print(to_numpy(windows[0]), to_numpy(windows[1]))\n",
      " |      [1, 2] [6, 7]\n",
      " |      [3, 4] [8, 9]\n",
      " |      [5] [10]\n",
      " |      \n",
      " |      Applying `window` to a `Dataset` of dictionaries gives a dictionary of\n",
      " |      `Datasets`:\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.from_tensor_slices({'a': [1, 2, 3],\n",
      " |      ...                                               'b': [4, 5, 6],\n",
      " |      ...                                               'c': [7, 8, 9]})\n",
      " |      >>> dataset = dataset.window(2)\n",
      " |      >>> def to_numpy(ds):\n",
      " |      ...   return list(ds.as_numpy_iterator())\n",
      " |      >>>\n",
      " |      >>> for windows in dataset:\n",
      " |      ...   print(tf.nest.map_structure(to_numpy, windows))\n",
      " |      {'a': [1, 2], 'b': [4, 5], 'c': [7, 8]}\n",
      " |      {'a': [3], 'b': [6], 'c': [9]}\n",
      " |      \n",
      " |      #### Flatten a dataset of windows\n",
      " |      \n",
      " |      The `Dataset.flat_map` and `Dataset.interleave` methods can be used to\n",
      " |      flatten a dataset of windows into a single dataset.\n",
      " |      \n",
      " |      The argument to `flat_map` is a function that takes an element from the\n",
      " |      dataset and returns a `Dataset`. `flat_map` chains together the resulting\n",
      " |      datasets sequentially.\n",
      " |      \n",
      " |      For example, to turn each window into a dense tensor:\n",
      " |      \n",
      " |      >>> size = 3\n",
      " |      >>> dataset = tf.data.Dataset.range(7).window(size, shift=1,\n",
      " |      ...                                           drop_remainder=True)\n",
      " |      >>> batched = dataset.flat_map(lambda x:x.batch(3))\n",
      " |      >>> for batch in batched:\n",
      " |      ...   print(batch.numpy())\n",
      " |      [0 1 2]\n",
      " |      [1 2 3]\n",
      " |      [2 3 4]\n",
      " |      [3 4 5]\n",
      " |      [4 5 6]\n",
      " |      \n",
      " |      Args:\n",
      " |        size: A `tf.int64` scalar `tf.Tensor`, representing the number of elements\n",
      " |          of the input dataset to combine into a window. Must be positive.\n",
      " |        shift: (Optional.) A `tf.int64` scalar `tf.Tensor`, representing the\n",
      " |          number of input elements by which the window moves in each iteration.\n",
      " |          Defaults to `size`. Must be positive.\n",
      " |        stride: (Optional.) A `tf.int64` scalar `tf.Tensor`, representing the\n",
      " |          stride of the input elements in the sliding window. Must be positive.\n",
      " |          The default value of 1 means \"retain every input element\".\n",
      " |        drop_remainder: (Optional.) A `tf.bool` scalar `tf.Tensor`, representing\n",
      " |          whether the last windows should be dropped if their size is smaller than\n",
      " |          `size`.\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset` of (nests of) windows. Each window is a finite\n",
      " |          datasets of flat elements.\n",
      " |  \n",
      " |  with_options(self, options, name=None)\n",
      " |      Returns a new `tf.data.Dataset` with the given options set.\n",
      " |      \n",
      " |      The options are \"global\" in the sense they apply to the entire dataset.\n",
      " |      If options are set multiple times, they are merged as long as different\n",
      " |      options do not use different non-default values.\n",
      " |      \n",
      " |      >>> ds = tf.data.Dataset.range(5)\n",
      " |      >>> ds = ds.interleave(lambda x: tf.data.Dataset.range(5),\n",
      " |      ...                    cycle_length=3,\n",
      " |      ...                    num_parallel_calls=3)\n",
      " |      >>> options = tf.data.Options()\n",
      " |      >>> # This will make the interleave order non-deterministic.\n",
      " |      >>> options.deterministic = False\n",
      " |      >>> ds = ds.with_options(options)\n",
      " |      \n",
      " |      Args:\n",
      " |        options: A `tf.data.Options` that identifies the options the use.\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset` with the given options.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: when an option is set more than once to a non-default value\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  choose_from_datasets(datasets, choice_dataset, stop_on_empty_dataset=True)\n",
      " |      Creates a dataset that deterministically chooses elements from `datasets`.\n",
      " |      \n",
      " |      For example, given the following datasets:\n",
      " |      \n",
      " |      ```python\n",
      " |      datasets = [tf.data.Dataset.from_tensors(\"foo\").repeat(),\n",
      " |                  tf.data.Dataset.from_tensors(\"bar\").repeat(),\n",
      " |                  tf.data.Dataset.from_tensors(\"baz\").repeat()]\n",
      " |      \n",
      " |      # Define a dataset containing `[0, 1, 2, 0, 1, 2, 0, 1, 2]`.\n",
      " |      choice_dataset = tf.data.Dataset.range(3).repeat(3)\n",
      " |      \n",
      " |      result = tf.data.Dataset.choose_from_datasets(datasets, choice_dataset)\n",
      " |      ```\n",
      " |      \n",
      " |      The elements of `result` will be:\n",
      " |      \n",
      " |      ```\n",
      " |      \"foo\", \"bar\", \"baz\", \"foo\", \"bar\", \"baz\", \"foo\", \"bar\", \"baz\"\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        datasets: A non-empty list of `tf.data.Dataset` objects with compatible\n",
      " |          structure.\n",
      " |        choice_dataset: A `tf.data.Dataset` of scalar `tf.int64` tensors between\n",
      " |          `0` and `len(datasets) - 1`.\n",
      " |        stop_on_empty_dataset: If `True`, selection stops if it encounters an\n",
      " |          empty dataset. If `False`, it skips empty datasets. It is recommended to\n",
      " |          set it to `True`. Otherwise, the selected elements start off as the user\n",
      " |          intends, but may change as input datasets become empty. This can be\n",
      " |          difficult to detect since the dataset starts off looking correct.\n",
      " |          Defaults to `True`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A dataset that interleaves elements from `datasets` according to the\n",
      " |        values of `choice_dataset`.\n",
      " |      \n",
      " |      Raises:\n",
      " |        TypeError: If `datasets` or `choice_dataset` has the wrong type.\n",
      " |        ValueError: If `datasets` is empty.\n",
      " |  \n",
      " |  from_generator(generator, output_types=None, output_shapes=None, args=None, output_signature=None, name=None)\n",
      " |      Creates a `Dataset` whose elements are generated by `generator`. (deprecated arguments)\n",
      " |      \n",
      " |      Warning: SOME ARGUMENTS ARE DEPRECATED: `(output_shapes, output_types)`. They will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      Use output_signature instead\n",
      " |      \n",
      " |      The `generator` argument must be a callable object that returns\n",
      " |      an object that supports the `iter()` protocol (e.g. a generator function).\n",
      " |      \n",
      " |      The elements generated by `generator` must be compatible with either the\n",
      " |      given `output_signature` argument or with the given `output_types` and\n",
      " |      (optionally) `output_shapes` arguments, whichever was specified.\n",
      " |      \n",
      " |      The recommended way to call `from_generator` is to use the\n",
      " |      `output_signature` argument. In this case the output will be assumed to\n",
      " |      consist of objects with the classes, shapes and types defined by\n",
      " |      `tf.TypeSpec` objects from `output_signature` argument:\n",
      " |      \n",
      " |      >>> def gen():\n",
      " |      ...   ragged_tensor = tf.ragged.constant([[1, 2], [3]])\n",
      " |      ...   yield 42, ragged_tensor\n",
      " |      >>>\n",
      " |      >>> dataset = tf.data.Dataset.from_generator(\n",
      " |      ...      gen,\n",
      " |      ...      output_signature=(\n",
      " |      ...          tf.TensorSpec(shape=(), dtype=tf.int32),\n",
      " |      ...          tf.RaggedTensorSpec(shape=(2, None), dtype=tf.int32)))\n",
      " |      >>>\n",
      " |      >>> list(dataset.take(1))\n",
      " |      [(<tf.Tensor: shape=(), dtype=int32, numpy=42>,\n",
      " |      <tf.RaggedTensor [[1, 2], [3]]>)]\n",
      " |      \n",
      " |      There is also a deprecated way to call `from_generator` by either with\n",
      " |      `output_types` argument alone or together with `output_shapes` argument.\n",
      " |      In this case the output of the function will be assumed to consist of\n",
      " |      `tf.Tensor` objects with the types defined by `output_types` and with the\n",
      " |      shapes which are either unknown or defined by `output_shapes`.\n",
      " |      \n",
      " |      Note: The current implementation of `Dataset.from_generator()` uses\n",
      " |      `tf.numpy_function` and inherits the same constraints. In particular, it\n",
      " |      requires the dataset and iterator related operations to be placed\n",
      " |      on a device in the same process as the Python program that called\n",
      " |      `Dataset.from_generator()`. The body of `generator` will not be\n",
      " |      serialized in a `GraphDef`, and you should not use this method if you\n",
      " |      need to serialize your model and restore it in a different environment.\n",
      " |      \n",
      " |      Note: If `generator` depends on mutable global variables or other external\n",
      " |      state, be aware that the runtime may invoke `generator` multiple times\n",
      " |      (in order to support repeating the `Dataset`) and at any time\n",
      " |      between the call to `Dataset.from_generator()` and the production of the\n",
      " |      first element from the generator. Mutating global variables or external\n",
      " |      state can cause undefined behavior, and we recommend that you explicitly\n",
      " |      cache any external state in `generator` before calling\n",
      " |      `Dataset.from_generator()`.\n",
      " |      \n",
      " |      Note: While the `output_signature` parameter makes it possible to yield\n",
      " |      `Dataset` elements, the scope of `Dataset.from_generator()` should be\n",
      " |      limited to logic that cannot be expressed through tf.data operations. Using\n",
      " |      tf.data operations within the generator function is an anti-pattern and may\n",
      " |      result in incremental memory growth.\n",
      " |      \n",
      " |      Args:\n",
      " |        generator: A callable object that returns an object that supports the\n",
      " |          `iter()` protocol. If `args` is not specified, `generator` must take no\n",
      " |          arguments; otherwise it must take as many arguments as there are values\n",
      " |          in `args`.\n",
      " |        output_types: (Optional.) A (nested) structure of `tf.DType` objects\n",
      " |          corresponding to each component of an element yielded by `generator`.\n",
      " |        output_shapes: (Optional.) A (nested) structure of `tf.TensorShape`\n",
      " |          objects corresponding to each component of an element yielded by\n",
      " |          `generator`.\n",
      " |        args: (Optional.) A tuple of `tf.Tensor` objects that will be evaluated\n",
      " |          and passed to `generator` as NumPy-array arguments.\n",
      " |        output_signature: (Optional.) A (nested) structure of `tf.TypeSpec`\n",
      " |          objects corresponding to each component of an element yielded by\n",
      " |          `generator`.\n",
      " |        name: (Optional.) A name for the tf.data operations used by\n",
      " |          `from_generator`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset`.\n",
      " |  \n",
      " |  from_tensor_slices(tensors, name=None)\n",
      " |      Creates a `Dataset` whose elements are slices of the given tensors.\n",
      " |      \n",
      " |      The given tensors are sliced along their first dimension. This operation\n",
      " |      preserves the structure of the input tensors, removing the first dimension\n",
      " |      of each tensor and using it as the dataset dimension. All input tensors\n",
      " |      must have the same size in their first dimensions.\n",
      " |      \n",
      " |      >>> # Slicing a 1D tensor produces scalar tensor elements.\n",
      " |      >>> dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [1, 2, 3]\n",
      " |      \n",
      " |      >>> # Slicing a 2D tensor produces 1D tensor elements.\n",
      " |      >>> dataset = tf.data.Dataset.from_tensor_slices([[1, 2], [3, 4]])\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [array([1, 2], dtype=int32), array([3, 4], dtype=int32)]\n",
      " |      \n",
      " |      >>> # Slicing a tuple of 1D tensors produces tuple elements containing\n",
      " |      >>> # scalar tensors.\n",
      " |      >>> dataset = tf.data.Dataset.from_tensor_slices(([1, 2], [3, 4], [5, 6]))\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [(1, 3, 5), (2, 4, 6)]\n",
      " |      \n",
      " |      >>> # Dictionary structure is also preserved.\n",
      " |      >>> dataset = tf.data.Dataset.from_tensor_slices({\"a\": [1, 2], \"b\": [3, 4]})\n",
      " |      >>> list(dataset.as_numpy_iterator()) == [{'a': 1, 'b': 3},\n",
      " |      ...                                       {'a': 2, 'b': 4}]\n",
      " |      True\n",
      " |      \n",
      " |      >>> # Two tensors can be combined into one Dataset object.\n",
      " |      >>> features = tf.constant([[1, 3], [2, 1], [3, 3]]) # ==> 3x2 tensor\n",
      " |      >>> labels = tf.constant(['A', 'B', 'A']) # ==> 3x1 tensor\n",
      " |      >>> dataset = Dataset.from_tensor_slices((features, labels))\n",
      " |      >>> # Both the features and the labels tensors can be converted\n",
      " |      >>> # to a Dataset object separately and combined after.\n",
      " |      >>> features_dataset = Dataset.from_tensor_slices(features)\n",
      " |      >>> labels_dataset = Dataset.from_tensor_slices(labels)\n",
      " |      >>> dataset = Dataset.zip((features_dataset, labels_dataset))\n",
      " |      >>> # A batched feature and label set can be converted to a Dataset\n",
      " |      >>> # in similar fashion.\n",
      " |      >>> batched_features = tf.constant([[[1, 3], [2, 3]],\n",
      " |      ...                                 [[2, 1], [1, 2]],\n",
      " |      ...                                 [[3, 3], [3, 2]]], shape=(3, 2, 2))\n",
      " |      >>> batched_labels = tf.constant([['A', 'A'],\n",
      " |      ...                               ['B', 'B'],\n",
      " |      ...                               ['A', 'B']], shape=(3, 2, 1))\n",
      " |      >>> dataset = Dataset.from_tensor_slices((batched_features, batched_labels))\n",
      " |      >>> for element in dataset.as_numpy_iterator():\n",
      " |      ...   print(element)\n",
      " |      (array([[1, 3],\n",
      " |             [2, 3]], dtype=int32), array([[b'A'],\n",
      " |             [b'A']], dtype=object))\n",
      " |      (array([[2, 1],\n",
      " |             [1, 2]], dtype=int32), array([[b'B'],\n",
      " |             [b'B']], dtype=object))\n",
      " |      (array([[3, 3],\n",
      " |             [3, 2]], dtype=int32), array([[b'A'],\n",
      " |             [b'B']], dtype=object))\n",
      " |      \n",
      " |      Note that if `tensors` contains a NumPy array, and eager execution is not\n",
      " |      enabled, the values will be embedded in the graph as one or more\n",
      " |      `tf.constant` operations. For large datasets (> 1 GB), this can waste\n",
      " |      memory and run into byte limits of graph serialization. If `tensors`\n",
      " |      contains one or more large NumPy arrays, consider the alternative described\n",
      " |      in [this guide](\n",
      " |      https://tensorflow.org/guide/data#consuming_numpy_arrays).\n",
      " |      \n",
      " |      Args:\n",
      " |        tensors: A dataset element, whose components have the same first\n",
      " |          dimension. Supported values are documented\n",
      " |          [here](https://www.tensorflow.org/guide/data#dataset_structure).\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset`.\n",
      " |  \n",
      " |  from_tensors(tensors, name=None)\n",
      " |      Creates a `Dataset` with a single element, comprising the given tensors.\n",
      " |      \n",
      " |      `from_tensors` produces a dataset containing only a single element. To slice\n",
      " |      the input tensor into multiple elements, use `from_tensor_slices` instead.\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.from_tensors([1, 2, 3])\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [array([1, 2, 3], dtype=int32)]\n",
      " |      >>> dataset = tf.data.Dataset.from_tensors(([1, 2, 3], 'A'))\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [(array([1, 2, 3], dtype=int32), b'A')]\n",
      " |      \n",
      " |      >>> # You can use `from_tensors` to produce a dataset which repeats\n",
      " |      >>> # the same example many times.\n",
      " |      >>> example = tf.constant([1,2,3])\n",
      " |      >>> dataset = tf.data.Dataset.from_tensors(example).repeat(2)\n",
      " |      >>> list(dataset.as_numpy_iterator())\n",
      " |      [array([1, 2, 3], dtype=int32), array([1, 2, 3], dtype=int32)]\n",
      " |      \n",
      " |      Note that if `tensors` contains a NumPy array, and eager execution is not\n",
      " |      enabled, the values will be embedded in the graph as one or more\n",
      " |      `tf.constant` operations. For large datasets (> 1 GB), this can waste\n",
      " |      memory and run into byte limits of graph serialization. If `tensors`\n",
      " |      contains one or more large NumPy arrays, consider the alternative described\n",
      " |      in [this\n",
      " |      guide](https://tensorflow.org/guide/data#consuming_numpy_arrays).\n",
      " |      \n",
      " |      Args:\n",
      " |        tensors: A dataset \"element\". Supported values are documented\n",
      " |          [here](https://www.tensorflow.org/guide/data#dataset_structure).\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset`.\n",
      " |  \n",
      " |  list_files(file_pattern, shuffle=None, seed=None, name=None)\n",
      " |      A dataset of all files matching one or more glob patterns.\n",
      " |      \n",
      " |      The `file_pattern` argument should be a small number of glob patterns.\n",
      " |      If your filenames have already been globbed, use\n",
      " |      `Dataset.from_tensor_slices(filenames)` instead, as re-globbing every\n",
      " |      filename with `list_files` may result in poor performance with remote\n",
      " |      storage systems.\n",
      " |      \n",
      " |      Note: The default behavior of this method is to return filenames in\n",
      " |      a non-deterministic random shuffled order. Pass a `seed` or `shuffle=False`\n",
      " |      to get results in a deterministic order.\n",
      " |      \n",
      " |      Example:\n",
      " |        If we had the following files on our filesystem:\n",
      " |      \n",
      " |          - /path/to/dir/a.txt\n",
      " |          - /path/to/dir/b.py\n",
      " |          - /path/to/dir/c.py\n",
      " |      \n",
      " |        If we pass \"/path/to/dir/*.py\" as the directory, the dataset\n",
      " |        would produce:\n",
      " |      \n",
      " |          - /path/to/dir/b.py\n",
      " |          - /path/to/dir/c.py\n",
      " |      \n",
      " |      Args:\n",
      " |        file_pattern: A string, a list of strings, or a `tf.Tensor` of string type\n",
      " |          (scalar or vector), representing the filename glob (i.e. shell wildcard)\n",
      " |          pattern(s) that will be matched.\n",
      " |        shuffle: (Optional.) If `True`, the file names will be shuffled randomly.\n",
      " |          Defaults to `True`.\n",
      " |        seed: (Optional.) A `tf.int64` scalar `tf.Tensor`, representing the random\n",
      " |          seed that will be used to create the distribution. See\n",
      " |          `tf.random.set_seed` for behavior.\n",
      " |        name: Optional. A name for the tf.data operations used by `list_files`.\n",
      " |      \n",
      " |      Returns:\n",
      " |       Dataset: A `Dataset` of strings corresponding to file names.\n",
      " |  \n",
      " |  random(seed=None, name=None)\n",
      " |      Creates a `Dataset` of pseudorandom values.\n",
      " |      \n",
      " |      The dataset generates a sequence of uniformly distributed integer values.\n",
      " |      \n",
      " |      >>> ds1 = tf.data.Dataset.random(seed=4).take(10)\n",
      " |      >>> ds2 = tf.data.Dataset.random(seed=4).take(10)\n",
      " |      >>> print(list(ds2.as_numpy_iterator())==list(ds2.as_numpy_iterator()))\n",
      " |      True\n",
      " |      \n",
      " |      Args:\n",
      " |        seed: (Optional) If specified, the dataset produces a deterministic\n",
      " |          sequence of values.\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset`.\n",
      " |  \n",
      " |  range(*args, **kwargs)\n",
      " |      Creates a `Dataset` of a step-separated range of values.\n",
      " |      \n",
      " |      >>> list(Dataset.range(5).as_numpy_iterator())\n",
      " |      [0, 1, 2, 3, 4]\n",
      " |      >>> list(Dataset.range(2, 5).as_numpy_iterator())\n",
      " |      [2, 3, 4]\n",
      " |      >>> list(Dataset.range(1, 5, 2).as_numpy_iterator())\n",
      " |      [1, 3]\n",
      " |      >>> list(Dataset.range(1, 5, -2).as_numpy_iterator())\n",
      " |      []\n",
      " |      >>> list(Dataset.range(5, 1).as_numpy_iterator())\n",
      " |      []\n",
      " |      >>> list(Dataset.range(5, 1, -2).as_numpy_iterator())\n",
      " |      [5, 3]\n",
      " |      >>> list(Dataset.range(2, 5, output_type=tf.int32).as_numpy_iterator())\n",
      " |      [2, 3, 4]\n",
      " |      >>> list(Dataset.range(1, 5, 2, output_type=tf.float32).as_numpy_iterator())\n",
      " |      [1.0, 3.0]\n",
      " |      \n",
      " |      Args:\n",
      " |        *args: follows the same semantics as python's range.\n",
      " |          len(args) == 1 -> start = 0, stop = args[0], step = 1.\n",
      " |          len(args) == 2 -> start = args[0], stop = args[1], step = 1.\n",
      " |          len(args) == 3 -> start = args[0], stop = args[1], step = args[2].\n",
      " |        **kwargs:\n",
      " |          - output_type: Its expected dtype. (Optional, default: `tf.int64`).\n",
      " |          - name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `RangeDataset`.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: if len(args) == 0.\n",
      " |  \n",
      " |  sample_from_datasets(datasets, weights=None, seed=None, stop_on_empty_dataset=False)\n",
      " |      Samples elements at random from the datasets in `datasets`.\n",
      " |      \n",
      " |      Creates a dataset by interleaving elements of `datasets` with `weight[i]`\n",
      " |      probability of picking an element from dataset `i`. Sampling is done without\n",
      " |      replacement. For example, suppose we have 2 datasets:\n",
      " |      \n",
      " |      ```python\n",
      " |      dataset1 = tf.data.Dataset.range(0, 3)\n",
      " |      dataset2 = tf.data.Dataset.range(100, 103)\n",
      " |      ```\n",
      " |      \n",
      " |      Suppose that we sample from these 2 datasets with the following weights:\n",
      " |      \n",
      " |      ```python\n",
      " |      sample_dataset = tf.data.Dataset.sample_from_datasets(\n",
      " |          [dataset1, dataset2], weights=[0.5, 0.5])\n",
      " |      ```\n",
      " |      \n",
      " |      One possible outcome of elements in sample_dataset is:\n",
      " |      \n",
      " |      ```\n",
      " |      print(list(sample_dataset.as_numpy_iterator()))\n",
      " |      # [100, 0, 1, 101, 2, 102]\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        datasets: A non-empty list of `tf.data.Dataset` objects with compatible\n",
      " |          structure.\n",
      " |        weights: (Optional.) A list or Tensor of `len(datasets)` floating-point\n",
      " |          values where `weights[i]` represents the probability to sample from\n",
      " |          `datasets[i]`, or a `tf.data.Dataset` object where each element is such\n",
      " |          a list. Defaults to a uniform distribution across `datasets`.\n",
      " |        seed: (Optional.) A `tf.int64` scalar `tf.Tensor`, representing the random\n",
      " |          seed that will be used to create the distribution. See\n",
      " |          `tf.random.set_seed` for behavior.\n",
      " |        stop_on_empty_dataset: If `True`, sampling stops if it encounters an empty\n",
      " |          dataset. If `False`, it skips empty datasets. It is recommended to set\n",
      " |          it to `True`. Otherwise, the distribution of samples starts off as the\n",
      " |          user intends, but may change as input datasets become empty. This can be\n",
      " |          difficult to detect since the dataset starts off looking correct.\n",
      " |          Default to `False` for backward compatibility.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A dataset that interleaves elements from `datasets` at random, according\n",
      " |        to `weights` if provided, otherwise with uniform probability.\n",
      " |      \n",
      " |      Raises:\n",
      " |        TypeError: If the `datasets` or `weights` arguments have the wrong type.\n",
      " |        ValueError:\n",
      " |          - If `datasets` is empty, or\n",
      " |          - If `weights` is specified and does not match the length of `datasets`.\n",
      " |  \n",
      " |  zip(datasets, name=None)\n",
      " |      Creates a `Dataset` by zipping together the given datasets.\n",
      " |      \n",
      " |      This method has similar semantics to the built-in `zip()` function\n",
      " |      in Python, with the main difference being that the `datasets`\n",
      " |      argument can be a (nested) structure of `Dataset` objects. The supported\n",
      " |      nesting mechanisms are documented\n",
      " |      [here] (https://www.tensorflow.org/guide/data#dataset_structure).\n",
      " |      \n",
      " |      >>> # The nested structure of the `datasets` argument determines the\n",
      " |      >>> # structure of elements in the resulting dataset.\n",
      " |      >>> a = tf.data.Dataset.range(1, 4)  # ==> [ 1, 2, 3 ]\n",
      " |      >>> b = tf.data.Dataset.range(4, 7)  # ==> [ 4, 5, 6 ]\n",
      " |      >>> ds = tf.data.Dataset.zip((a, b))\n",
      " |      >>> list(ds.as_numpy_iterator())\n",
      " |      [(1, 4), (2, 5), (3, 6)]\n",
      " |      >>> ds = tf.data.Dataset.zip((b, a))\n",
      " |      >>> list(ds.as_numpy_iterator())\n",
      " |      [(4, 1), (5, 2), (6, 3)]\n",
      " |      >>>\n",
      " |      >>> # The `datasets` argument may contain an arbitrary number of datasets.\n",
      " |      >>> c = tf.data.Dataset.range(7, 13).batch(2)  # ==> [ [7, 8],\n",
      " |      ...                                            #       [9, 10],\n",
      " |      ...                                            #       [11, 12] ]\n",
      " |      >>> ds = tf.data.Dataset.zip((a, b, c))\n",
      " |      >>> for element in ds.as_numpy_iterator():\n",
      " |      ...   print(element)\n",
      " |      (1, 4, array([7, 8]))\n",
      " |      (2, 5, array([ 9, 10]))\n",
      " |      (3, 6, array([11, 12]))\n",
      " |      >>>\n",
      " |      >>> # The number of elements in the resulting dataset is the same as\n",
      " |      >>> # the size of the smallest dataset in `datasets`.\n",
      " |      >>> d = tf.data.Dataset.range(13, 15)  # ==> [ 13, 14 ]\n",
      " |      >>> ds = tf.data.Dataset.zip((a, d))\n",
      " |      >>> list(ds.as_numpy_iterator())\n",
      " |      [(1, 13), (2, 14)]\n",
      " |      \n",
      " |      Args:\n",
      " |        datasets: A (nested) structure of datasets.\n",
      " |        name: (Optional.) A name for the tf.data operation.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Dataset: A `Dataset`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |  \n",
      " |  element_spec\n",
      " |      The type specification of an element of this dataset.\n",
      " |      \n",
      " |      >>> dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
      " |      >>> dataset.element_spec\n",
      " |      TensorSpec(shape=(), dtype=tf.int32, name=None)\n",
      " |      \n",
      " |      For more information,\n",
      " |      read [this guide](https://www.tensorflow.org/guide/data#dataset_structure).\n",
      " |      \n",
      " |      Returns:\n",
      " |        A (nested) structure of `tf.TypeSpec` objects matching the structure of an\n",
      " |        element of this dataset and specifying the type of individual components.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset({'_inputs', 'element_spec'})\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from collections.abc.Iterable:\n",
      " |  \n",
      " |  __subclasshook__(C) from abc.ABCMeta\n",
      " |      Abstract classes can override this to customize issubclass().\n",
      " |      \n",
      " |      This is invoked early on by abc.ABCMeta.__subclasscheck__().\n",
      " |      It should return True, False or NotImplemented.  If it returns\n",
      " |      NotImplemented, the normal algorithm is used.  Otherwise, it\n",
      " |      overrides the normal algorithm (and the outcome is cached).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from tensorflow.python.framework.composite_tensor.CompositeTensor:\n",
      " |  \n",
      " |  __tf_tracing_type__(self, context)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.data.Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad30f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "  file_path_features = [data_path_from_slice_path(path) for path in file_paths]\n",
    "\n",
    "    both_path = tf.data.Dataset.from_tensor_slices(\n",
    "        [list(couple) for couple in zip(file_paths, file_path_features)]\n",
    "    )\n",
    "    general_dataset = both_path.interleave(single_slice_dataset, cycle_length=n_readers)\n",
    "    general_dataset = general_dataset.shuffle(shuffle_buffer_size).repeat(repeat)\n",
    "    return general_dataset.batch(1)  # Output shape: (1, 120, 1)\n",
    "    # TODO(FK): remove the batching here and the prefetch  .prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "7a3b5cd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(527, 120)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "6376cd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prov = np.expand_dims(train_feature[4, :], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "a90735e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 120)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prov.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "8d9f8575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 120, 1)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prov = np.expand_dims(train_feature[4, :], axis=-1)\n",
    "prov = np.expand_dims(prov, axis=0)\n",
    "prov.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "62667bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_crop(output_size):\n",
    "    # TODO(FK): add name\n",
    "    # TODO(FK): handle size\n",
    "    size = [74, output_size, 1]\n",
    "    return tf.keras.layers.Lambda(lambda x: tf.image.random_crop(x, size=size))\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def center_crop_slice(x, margin):\n",
    "    return x[..., margin:-margin, :]\n",
    "\n",
    "\n",
    "def center_crop(input_size=120, output_size=80):\n",
    "    return tf.keras.layers.Lambda(\n",
    "        lambda x: center_crop_slice(x, (input_size - output_size) // 2)\n",
    "    )\n",
    "\n",
    "\n",
    "data_augmentation = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.Input(shape=(120, 1)),\n",
    "        random_crop(80),\n",
    "        # random_invert(p=0.5),  # TODO(FK): keep?\n",
    "        # random_mirror(p=0.5),\n",
    "        # random_brightness(10),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "90acfae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from amftrack.ml.width.data_augmentation import *"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bfbb8ffb",
   "metadata": {},
   "source": [
    "data_augmentation = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.Input(shape=(120, 1)),\n",
    "        random_crop(120),\n",
    "        # random_invert(p=0.5),  # TODO(FK): keep?\n",
    "        random_mirror(p=0.5),\n",
    "        random_brightness(20),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8a53a48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.Input(shape=(120, 1)),\n",
    "        random_crop(80),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "1ed5fa01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[199, 198, 197, ..., 203, 204, 207],\n",
       "       [175, 177, 176, ..., 167, 166, 166],\n",
       "       [194, 194, 194, ..., 146, 134, 120],\n",
       "       ...,\n",
       "       [186, 186, 186, ..., 179, 177, 179],\n",
       "       [204, 206, 206, ..., 205, 206, 206],\n",
       "       [188, 189, 188, ..., 174, 177, 179]], dtype=uint8)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "d4ae11b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vector = data_augmentation(test_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "c74b492f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "4a2789df",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(74,), dtype=float32, numpy=\n",
       "array([196., 166., 188., 186., 162., 200., 198., 157., 201., 180., 194.,\n",
       "       188., 184., 189., 183., 180., 165., 155., 202., 171., 171., 203.,\n",
       "       186., 173., 206., 176., 161., 200., 187., 175., 177., 194., 184.,\n",
       "       181., 189., 194., 197., 194., 193., 200., 165., 183., 197., 205.,\n",
       "       191., 155., 167., 168., 182., 178., 185., 192., 198., 158., 196.,\n",
       "       168., 199., 177., 196., 203., 164., 193., 174., 189., 178., 197.,\n",
       "       178., 202., 126., 175., 146., 170., 209., 186.], dtype=float32)>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_vector[:, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "e0a635e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(74,), dtype=float32, numpy=\n",
       "array([196., 166., 188., 186., 162., 200., 198., 157., 201., 180., 194.,\n",
       "       188., 184., 189., 183., 180., 165., 155., 202., 171., 171., 203.,\n",
       "       186., 173., 206., 176., 161., 200., 187., 175., 177., 194., 184.,\n",
       "       181., 189., 194., 197., 194., 193., 200., 165., 183., 197., 205.,\n",
       "       191., 155., 167., 168., 182., 178., 185., 192., 198., 158., 196.,\n",
       "       168., 199., 177., 196., 203., 164., 193., 174., 189., 178., 197.,\n",
       "       178., 202., 126., 175., 146., 170., 209., 186.], dtype=float32)>"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_vector[:, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "2707a279",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 1ms/step - loss: 5.2993 - mean_absolute_error: 1.2498\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5.299310207366943, 1.2498197555541992]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.evaluate(feature_vector, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "5bd83327",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_against(best_model, feature_vector, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "773b7a22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 80, 1), dtype=float32, numpy=\n",
       "array([[[117.],\n",
       "        [115.],\n",
       "        [116.],\n",
       "        [117.],\n",
       "        [118.],\n",
       "        [117.],\n",
       "        [118.],\n",
       "        [119.],\n",
       "        [118.],\n",
       "        [120.],\n",
       "        [123.],\n",
       "        [123.],\n",
       "        [124.],\n",
       "        [125.],\n",
       "        [126.],\n",
       "        [127.],\n",
       "        [131.],\n",
       "        [130.],\n",
       "        [131.],\n",
       "        [136.],\n",
       "        [138.],\n",
       "        [140.],\n",
       "        [145.],\n",
       "        [156.],\n",
       "        [163.],\n",
       "        [160.],\n",
       "        [152.],\n",
       "        [140.],\n",
       "        [132.],\n",
       "        [131.],\n",
       "        [126.],\n",
       "        [124.],\n",
       "        [124.],\n",
       "        [123.],\n",
       "        [122.],\n",
       "        [118.],\n",
       "        [119.],\n",
       "        [121.],\n",
       "        [124.],\n",
       "        [125.],\n",
       "        [121.],\n",
       "        [122.],\n",
       "        [122.],\n",
       "        [121.],\n",
       "        [121.],\n",
       "        [120.],\n",
       "        [118.],\n",
       "        [119.],\n",
       "        [120.],\n",
       "        [119.],\n",
       "        [116.],\n",
       "        [118.],\n",
       "        [118.],\n",
       "        [117.],\n",
       "        [118.],\n",
       "        [119.],\n",
       "        [119.],\n",
       "        [117.],\n",
       "        [115.],\n",
       "        [117.],\n",
       "        [116.],\n",
       "        [117.],\n",
       "        [116.],\n",
       "        [116.],\n",
       "        [118.],\n",
       "        [117.],\n",
       "        [113.],\n",
       "        [116.],\n",
       "        [116.],\n",
       "        [114.],\n",
       "        [116.],\n",
       "        [116.],\n",
       "        [117.],\n",
       "        [118.],\n",
       "        [118.],\n",
       "        [118.],\n",
       "        [116.],\n",
       "        [117.],\n",
       "        [115.],\n",
       "        [115.]]], dtype=float32)>"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_augmentation(prov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "d8517151",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120,)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feature[5, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "21091b50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_label[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "4b6aba28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(np.array(train_feature[6, :]))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "92e1001f",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "list(zip([train_feature[i,:] for i in range(len(train_feature))], train_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "0b33abeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "527"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "baad05d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Can't convert non-rectangular Python sequence to Tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/data/util/structure.py:102\u001b[0m, in \u001b[0;36mnormalize_element\u001b[0;34m(element, element_signature)\u001b[0m\n\u001b[1;32m    101\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 102\u001b[0m     spec \u001b[38;5;241m=\u001b[39m \u001b[43mtype_spec_from_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_fallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    104\u001b[0m   \u001b[38;5;66;03m# TypeError indicates it was not possible to compute a `TypeSpec` for\u001b[39;00m\n\u001b[1;32m    105\u001b[0m   \u001b[38;5;66;03m# the value. As a fallback try converting the value to a tensor.\u001b[39;00m\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/data/util/structure.py:485\u001b[0m, in \u001b[0;36mtype_spec_from_value\u001b[0;34m(element, use_fallback)\u001b[0m\n\u001b[1;32m    482\u001b[0m     logging\u001b[38;5;241m.\u001b[39mvlog(\n\u001b[1;32m    483\u001b[0m         \u001b[38;5;241m3\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to convert \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m to tensor: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mtype\u001b[39m(element)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, e))\n\u001b[0;32m--> 485\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not build a `TypeSpec` for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m with type \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    486\u001b[0m     element,\n\u001b[1;32m    487\u001b[0m     \u001b[38;5;28mtype\u001b[39m(element)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m))\n",
      "\u001b[0;31mTypeError\u001b[0m: Could not build a `TypeSpec` for [[array([129, 129, 130, 130, 128, 130, 130, 128, 130, 128, 129, 131, 129,\n       130, 133, 131, 130, 132, 130, 129, 131, 130, 129, 131, 129, 126,\n       127, 128, 130, 130, 130, 131, 133, 130, 130, 130, 131, 131, 127,\n       131, 128, 128, 126, 125, 129, 127, 126, 125, 121, 116, 107,  92,\n        82,  84,  92, 101, 107, 112, 113, 111, 110, 107, 111, 106, 106,\n       104, 101,  94,  83,  75,  74,  73,  68,  65,  80,  93,  98,  97,\n       101, 106, 107, 107, 110, 112, 112, 108, 107, 108, 109, 111, 114,\n       116, 119, 121, 121, 124, 123, 126, 124, 125, 125, 126, 127, 126,\n       125, 127, 128, 129, 129, 129, 130, 130, 129, 128, 129, 127, 127,\n       126, 125, 126], dtype=uint8), array([7.26221294])], [array([130, 130, 128, 127, 129, 129, 130, 130, 127, 126, 125, 125, 128,\n       129, 129, 130, 130, 132, 131, 130, 130, 130, 128, 126, 128, 128,\n       128, 128, 128, 128, 129, 129, 130, 131, 131, 131, 129, 131, 133,\n       131, 130, 128, 129, 128, 130, 129, 129, 130, 133, 130, 128, 127,\n       129, 133, 130, 133, 134, 134, 134, 134, 134, 135, 136, 137, 138,\n       139, 140, 138, 139, 138, 134, 123, 118, 102,  85,  83,  97, 103,\n       103, 103, 100, 101, 100, 100, 102, 103, 104, 106, 109, 111, 113,\n       115, 117, 119, 118, 119, 120, 125, 124, 126, 127, 127, 128, 131,\n       130, 133, 133, 133, 132, 132, 131, 132, 134, 136, 135, 136, 135,\n       134, 133, 134], dtype=uint8), array([5.93755418])], [array([130, 129, 130, 129, 131, 131, 130, 129, 131, 132, 130, 129, 128,\n       131, 132, 130, 130, 130, 128, 128, 130, 131, 131, 131, 130, 130,\n       129, 130, 132, 130, 130, 132, 131, 134, 133, 131, 131, 133, 132,\n       133, 133, 133, 130, 132, 134, 134, 134, 136, 132, 135, 135, 134,\n       135, 135, 133, 135, 134, 133, 136, 135, 137, 140, 136, 136, 138,\n       139, 139, 140, 139, 139, 134, 125, 116, 104,  91,  91, 105, 105,\n       105, 105, 104, 103, 105, 104, 104, 106, 106, 107, 111, 111, 113,\n       114, 115, 117, 121, 121, 123, 125, 125, 126, 131, 129, 129, 131,\n       132, 129, 133, 132, 132, 135, 136, 138, 136, 133, 135, 135, 136,\n       135, 136, 137], dtype=uint8), array([5.5774322])], [array([140, 139, 138, 137, 136, 137, 138, 138, 137, 135, 138, 137, 137,\n       136, 137, 138, 138, 138, 139, 140, 139, 138, 137, 137, 138, 138,\n       140, 140, 141, 143, 142, 140, 141, 138, 139, 139, 140, 139, 137,\n       140, 139, 140, 139, 140, 139, 136, 135, 135, 135, 136, 136, 135,\n       134, 133, 132, 131, 131, 131, 129, 131, 126, 124, 126, 122, 119,\n       117, 106,  95,  93,  93, 101, 113, 120, 124, 125, 126, 125, 127,\n       129, 128, 130, 133, 132, 132, 134, 136, 137, 135, 134, 133, 134,\n       134, 134, 136, 136, 137, 134, 137, 138, 136, 139, 137, 137, 139,\n       139, 138, 135, 134, 134, 136, 135, 136, 135, 136, 137, 137, 136,\n       135, 135, 139], dtype=uint8), array([4.19787153])], [array([137, 135, 134, 132, 136, 134, 137, 137, 137, 139, 139, 139, 138,\n       139, 141, 141, 139, 140, 140, 138, 139, 137, 137, 137, 138, 139,\n       139, 141, 139, 139, 142, 138, 137, 139, 139, 138, 139, 138, 140,\n       138, 136, 136, 137, 138, 137, 137, 139, 136, 135, 136, 137, 135,\n       134, 134, 133, 133, 134, 130, 131, 134, 136, 137, 133, 132, 131,\n       131, 129, 124, 123, 115, 103,  95,  92,  99, 110, 115, 117, 119,\n       124, 125, 124, 128, 129, 130, 131, 132, 132, 135, 137, 136, 137,\n       138, 137, 138, 139, 140, 138, 138, 140, 141, 141, 141, 141, 141,\n       140, 140, 138, 137, 135, 138, 139, 139, 141, 140, 142, 142, 140,\n       140, 139, 138], dtype=uint8), array([3.7441611])], [array([125, 125, 125, 125, 123, 124, 126, 127, 127, 125, 126, 125, 125,\n       125, 126, 127, 125, 124, 121, 121, 117, 119, 119, 119, 120, 121,\n       121, 124, 123, 125, 125, 126, 127, 125, 124, 126, 127, 126, 125,\n       125, 127, 127, 127, 127, 127, 126, 125, 126, 127, 126, 124, 126,\n       128, 127, 127, 126, 128, 127, 127, 131, 128, 129, 134, 132, 133,\n       132, 133, 134, 135, 131, 128, 120, 105,  89,  82,  92, 104, 106,\n       104, 104, 103, 101, 103, 106, 108, 107, 108, 111, 113, 113, 115,\n       117, 120, 118, 121, 124, 124, 123, 125, 126, 126, 129, 127, 127,\n       128, 130, 127, 128, 129, 126, 127, 129, 128, 128, 127, 126, 129,\n       128, 130, 132], dtype=uint8), array([5.20109506])], [array([119, 118, 116, 117, 118, 117, 116, 116, 117, 118, 119, 120, 121,\n       120, 121, 122, 122, 122, 122, 122, 123, 120, 122, 124, 122, 122,\n       122, 121, 120, 121, 122, 124, 121, 124, 123, 119, 122, 119, 123,\n       123, 122, 123, 120, 123, 122, 123, 121, 122, 120, 121, 122, 124,\n       123, 125, 122, 121, 120, 121, 124, 124, 124, 125, 126, 128, 131,\n       131, 131, 133, 134, 132, 130, 127, 117, 105,  90,  82,  90, 100,\n       103, 103, 101, 100,  99, 100, 100, 100, 100, 102, 104, 103, 108,\n       108, 109, 112, 109, 111, 114, 114, 112, 116, 116, 116, 114, 116,\n       115, 115, 115, 117, 115, 117, 117, 117, 116, 115, 115, 116, 115,\n       114, 115, 113], dtype=uint8), array([4.87914297])], [array([146, 144, 140, 145, 146, 147, 145, 146, 149, 147, 148, 146, 148,\n       145, 145, 145, 145, 145, 147, 150, 148, 147, 147, 146, 146, 149,\n       146, 148, 147, 149, 148, 147, 145, 143, 146, 145, 147, 148, 146,\n       146, 147, 147, 145, 146, 149, 146, 146, 146, 147, 146, 146, 145,\n       145, 144, 143, 145, 145, 147, 146, 147, 147, 146, 144, 147, 146,\n       147, 146, 146, 147, 146, 146, 146, 145, 145, 146, 148, 148, 145,\n       145, 146, 147, 147, 144, 147, 147, 148, 148, 148, 147, 146, 145,\n       146, 147, 145, 145, 147, 148, 146, 146, 147, 147, 145, 147, 146,\n       146, 147, 146, 148, 147, 150, 145, 146, 145, 146, 146, 144, 146,\n       147, 147, 149], dtype=uint8), array([0.])], [array([135, 135, 135, 137, 137, 137, 136, 136, 133, 132, 134, 132, 131,\n       131, 131, 131, 133, 132, 134, 132, 133, 131, 132, 133, 137, 134,\n       133, 136, 133, 133, 136, 133, 135, 134, 137, 138, 136, 136, 137,\n       137, 138, 138, 139, 137, 138, 140, 139, 138, 137, 137, 137, 137,\n       138, 137, 140, 141, 145, 140, 141, 141, 139, 141, 140, 139, 140,\n       139, 133, 125, 110, 108, 112, 116, 111, 100,  93,  94,  95,  92,\n        91,  89,  86,  86,  91,  94,  93,  94,  97,  98,  99,  98, 101,\n       102, 105, 108, 112, 113, 112, 115, 117, 119, 121, 121, 122, 125,\n       126, 128, 131, 132, 135, 132, 132, 134, 137, 139, 137, 137, 136,\n       141, 139, 137], dtype=uint8), array([8.52101685])], [array([134, 131, 130, 132, 135, 132, 132, 133, 133, 133, 132, 134, 134,\n       134, 134, 134, 134, 133, 132, 133, 134, 135, 136, 135, 135, 134,\n       135, 135, 135, 134, 135, 134, 138, 136, 138, 137, 135, 135, 134,\n       137, 133, 135, 139, 136, 136, 136, 137, 141, 143, 140, 138, 138,\n       139, 141, 141, 139, 143, 142, 142, 141, 142, 143, 143, 143, 140,\n       133, 118, 104,  99, 106, 111, 104,  92,  89,  86,  83,  84,  84,\n        84,  86,  88,  91,  88,  87,  89,  91,  95,  97,  98,  98, 101,\n       102, 104, 109, 110, 111, 114, 115, 116, 120, 120, 120, 124, 125,\n       125, 125, 126, 133, 131, 135, 133, 134, 134, 136, 137, 138, 137,\n       137, 138, 140], dtype=uint8), array([8.73503977])], [array([113, 110, 110, 113, 114, 110, 104, 104, 105, 109, 112, 120, 125,\n       126, 128, 133, 135, 137, 135, 135, 137, 137, 135, 135, 134, 135,\n       135, 133, 133, 133, 134, 134, 135, 134, 132, 134, 134, 133, 132,\n       133, 132, 130, 133, 132, 134, 133, 130, 127, 129, 129, 129, 128,\n       127, 129, 127, 125, 124, 124, 123, 124, 121, 121, 122, 120, 120,\n       121, 120, 119, 118, 117, 114, 109, 103, 101,  99, 104, 113, 120,\n       121, 121, 121, 123, 124, 124, 126, 125, 126, 128, 127, 129, 128,\n       129, 129, 129, 131, 129, 128, 131, 132, 131, 130, 129, 129, 131,\n       131, 130, 132, 133, 130, 130, 133, 130, 127, 129, 131, 130, 130,\n       132, 132, 132], dtype=uint8), array([4.59109883])], [array([139, 139, 137, 131, 132, 133, 138, 136, 136, 135, 134, 135, 134,\n       137, 136, 135, 136, 135, 138, 136, 135, 136, 134, 134, 133, 134,\n       133, 132, 133, 133, 133, 133, 131, 131, 131, 131, 129, 131, 128,\n       127, 125, 124, 124, 125, 121, 122, 122, 121, 117, 116, 115, 116,\n       117, 115, 112, 114, 113, 114, 115, 113, 113, 107,  94,  91, 105,\n       115, 123, 130, 134, 134, 135, 135, 134, 135, 134, 134, 133, 135,\n       135, 135, 135, 132, 133, 132, 132, 133, 131, 131, 130, 131, 133,\n       131, 130, 131, 130, 132, 130, 129, 130, 131, 130, 129, 129, 130,\n       126, 125, 127, 125, 126, 127, 125, 125, 127, 124, 122, 124, 127,\n       122, 122, 124], dtype=uint8), array([4.34090199])], [array([132, 132, 131, 131, 132, 132, 132, 132, 131, 132, 132, 131, 132,\n       133, 132, 131, 130, 130, 133, 130, 129, 133, 135, 131, 131, 133,\n       134, 132, 131, 132, 131, 129, 129, 130, 131, 128, 127, 124, 127,\n       126, 126, 125, 123, 123, 121, 119, 119, 121, 119, 117, 116, 117,\n       118, 115, 114, 114, 114, 116, 117, 116, 116, 112, 102, 103, 110,\n       119, 127, 131, 131, 132, 133, 131, 131, 128, 128, 126, 126, 126,\n       124, 123, 124, 125, 125, 125, 126, 125, 126, 124, 128, 127, 126,\n       126, 126, 126, 127, 127, 126, 129, 128, 130, 127, 128, 128, 129,\n       129, 130, 131, 131, 130, 130, 132, 130, 132, 131, 127, 127, 124,\n       123, 126, 126], dtype=uint8), array([4.35067225])], [array([125, 130, 133, 134, 135, 136, 136, 135, 134, 132, 133, 134, 134,\n       134, 133, 131, 131, 130, 132, 133, 134, 133, 134, 134, 132, 132,\n       133, 132, 135, 132, 131, 130, 129, 129, 127, 126, 124, 124, 124,\n       118, 117, 119, 115, 114, 114, 115, 112, 112, 113, 112, 110, 110,\n       113, 114, 113, 113, 112, 114, 113, 105,  93, 101, 111, 122, 129,\n       130, 132, 133, 132, 129, 131, 130, 130, 129, 125, 127, 128, 124,\n       122, 121, 124, 122, 122, 119, 118, 117, 117, 116, 115, 114, 117,\n       114, 104, 102, 108, 121, 125, 130, 131, 130, 130, 128, 125, 122,\n       120, 124, 124, 125, 128, 125, 126, 124, 124, 124, 125, 125, 123,\n       120, 121, 123], dtype=uint8), array([4.18356936])], [array([122, 122, 124, 124, 121, 122, 123, 118, 126, 124, 124, 121, 121,\n       123, 122, 120, 122, 122, 121, 122, 123, 121, 123, 122, 120, 120,\n       122, 120, 121, 121, 122, 123, 123, 122, 121, 123, 123, 121, 121,\n       122, 121, 121, 120, 122, 123, 121, 122, 124, 121, 121, 121, 122,\n       120, 122, 123, 122, 123, 123, 123, 124, 123, 123, 121, 121, 121,\n       123, 123, 121, 121, 120, 121, 115, 106, 100, 100, 101, 103, 108,\n       110, 111, 110, 109, 106, 105, 103, 103, 103, 103, 104, 104, 107,\n       110, 110, 110, 111, 113, 113, 115, 117, 116, 116, 122, 120, 120,\n       120, 121, 121, 122, 122, 122, 123, 125, 124, 122, 122, 125, 124,\n       122, 123, 125], dtype=uint8), array([5.923182])], [array([124, 125, 125, 126, 126, 125, 126, 125, 125, 127, 126, 125, 125,\n       125, 126, 125, 122, 120, 119, 117, 114, 113, 117, 116, 117, 119,\n       119, 121, 124, 123, 118, 114, 109, 102,  99, 103, 110, 116, 118,\n       119, 122, 123, 123, 124, 124, 125, 127, 127, 129, 129, 128, 124,\n       124, 124, 126, 131, 132, 135, 136, 136, 134, 137, 138, 136, 130,\n       122, 114, 116, 116, 102,  87,  77,  74,  71,  70,  72,  73,  75,\n        78,  79,  78,  78,  82,  83,  85,  87,  88,  90,  91,  93,  96,\n        99, 100, 101, 104, 108, 109, 110, 113, 114, 116, 116, 119, 119,\n       121, 122, 123, 124, 125, 124, 126, 127, 124, 128, 125, 126, 128,\n       128, 129, 130], dtype=uint8), array([8.89809448])], [array([122, 122, 122, 122, 124, 123, 123, 123, 122, 119, 119, 117, 118,\n       120, 125, 123, 124, 123, 125, 125, 124, 122, 122, 126, 128, 122,\n       122, 127, 125, 126, 126, 125, 124, 123, 124, 125, 125, 122, 122,\n       126, 124, 123, 124, 124, 121, 123, 125, 125, 124, 123, 121, 122,\n       121, 122, 122, 120, 117, 118, 120, 120, 117, 116, 117, 117, 115,\n       113, 113, 115, 112, 110, 108, 100,  88,  81,  83,  83,  83,  94,\n       105, 111, 111, 110, 113, 114, 114, 115, 114, 116, 119, 122, 122,\n       121, 121, 123, 124, 126, 123, 125, 124, 124, 126, 125, 125, 126,\n       123, 122, 121, 119, 118, 113, 112, 110, 112, 115, 118, 121, 127,\n       124, 124, 122], dtype=uint8), array([4.7800506])], [array([126, 123, 125, 125, 125, 125, 124, 125, 126, 125, 125, 124, 127,\n       125, 123, 124, 125, 124, 125, 125, 123, 124, 125, 124, 123, 125,\n       125, 123, 122, 125, 125, 125, 126, 126, 126, 125, 123, 122, 124,\n       123, 121, 124, 125, 121, 119, 121, 121, 123, 119, 115, 114, 113,\n       114, 114, 113, 111, 109, 109, 108, 108, 108, 107, 106, 105, 106,\n       106, 105, 105, 106, 105, 103,  89,  86,  92,  94,  95, 105, 112,\n       113, 114, 116, 116, 116, 114, 115, 115, 116, 117, 120, 120, 119,\n       118, 122, 122, 120, 121, 122, 122, 120, 121, 123, 122, 122, 122,\n       121, 118, 117, 122, 120, 120, 125, 122, 125, 124, 122, 124, 123,\n       126, 123, 121], dtype=uint8), array([5.29939395])], [array([124, 127, 123, 125, 125, 123, 125, 122, 123, 121, 127, 124, 123,\n       125, 124, 126, 126, 124, 124, 122, 125, 124, 123, 121, 122, 123,\n       119, 124, 123, 122, 122, 123, 119, 124, 125, 122, 120, 123, 123,\n       122, 120, 119, 121, 122, 124, 123, 120, 117, 121, 120, 121, 120,\n       118, 121, 116, 117, 117, 117, 114, 117, 115, 116, 117, 116, 113,\n       114, 115, 114, 113, 112, 112,  98,  96,  91,  95,  94,  98, 107,\n       110, 109, 110, 107, 114, 111, 107, 113, 113, 112, 112, 113, 116,\n       116, 119, 117, 115, 120, 120, 119, 119, 119, 118, 121, 120, 121,\n       120, 123, 118, 122, 120, 124, 123, 119, 123, 120, 122, 125, 120,\n       120, 122, 121], dtype=uint8), array([5.08347615])], [array([153, 153, 154, 154, 155, 153, 153, 155, 153, 156, 155, 153, 153,\n       155, 153, 152, 151, 151, 152, 153, 156, 154, 153, 152, 150, 152,\n       154, 155, 151, 156, 155, 156, 155, 153, 153, 153, 153, 152, 151,\n       153, 150, 150, 150, 151, 149, 147, 145, 144, 142, 140, 130, 106,\n        85,  93, 107,  98,  78,  69,  81,  98, 104, 105, 107, 111, 114,\n       116, 121, 124, 127, 128, 129, 133, 136, 139, 141, 142, 145, 143,\n       149, 146, 150, 149, 149, 151, 149, 148, 152, 149, 152, 151, 152,\n       153, 152, 153, 153, 153, 153, 151, 156, 154, 155, 154, 154, 154,\n       153, 153, 156, 155, 156, 154, 153, 153, 153, 153, 159, 157, 151,\n       153, 153, 152], dtype=uint8), array([8.36581426])], [array([151, 151, 152, 151, 153, 153, 150, 153, 148, 150, 148, 146, 146,\n       148, 148, 144, 144, 140, 139, 137, 139, 137, 129, 121, 121, 123,\n       131, 138, 146, 145, 147, 147, 147, 147, 149, 147, 147, 149, 148,\n       146, 145, 146, 147, 146, 144, 139, 139, 140, 136, 132, 128, 126,\n       125, 121, 118, 117, 112, 110, 107, 110, 114, 116, 112,  99,  83,\n        83, 100, 108,  99,  93, 106, 127, 137, 140, 144, 143, 146, 147,\n       147, 148, 150, 153, 151, 149, 149, 150, 150, 150, 151, 151, 153,\n       153, 151, 153, 151, 153, 153, 153, 153, 153, 150, 154, 149, 154,\n       155, 153, 153, 153, 153, 153, 154, 154, 152, 153, 152, 151, 152,\n       153, 154, 150], dtype=uint8), array([8.89809448])], [array([153, 152, 151, 152, 152, 152, 153, 152, 152, 154, 153, 152, 150,\n       151, 155, 152, 149, 147, 148, 148, 150, 154, 150, 150, 153, 152,\n       152, 151, 151, 147, 153, 151, 151, 152, 149, 152, 154, 150, 151,\n       151, 151, 150, 150, 150, 149, 152, 151, 151, 150, 153, 153, 152,\n       153, 154, 154, 154, 154, 152, 152, 152, 151, 154, 154, 152, 151,\n       148, 150, 150, 148, 144, 132, 118, 111, 107, 104, 116, 127, 133,\n       134, 138, 144, 143, 141, 146, 146, 148, 147, 150, 150, 150, 151,\n       152, 152, 150, 150, 150, 151, 150, 150, 149, 150, 151, 152, 151,\n       150, 150, 150, 151, 152, 154, 153, 152, 152, 150, 148, 151, 153,\n       152, 152, 152], dtype=uint8), array([4.7800506])], [array([153, 153, 152, 153, 155, 152, 155, 153, 153, 154, 153, 151, 151,\n       150, 151, 153, 152, 150, 154, 154, 151, 152, 151, 152, 151, 150,\n       155, 155, 152, 153, 152, 152, 155, 155, 154, 154, 154, 153, 152,\n       151, 151, 151, 152, 152, 155, 149, 152, 153, 154, 149, 155, 153,\n       155, 154, 155, 154, 155, 153, 153, 153, 154, 155, 154, 150, 150,\n       151, 148, 146, 140, 124, 107, 112, 108,  96, 108, 129, 136, 137,\n       139, 141, 139, 142, 144, 143, 145, 147, 147, 148, 151, 149, 147,\n       149, 152, 152, 152, 149, 150, 148, 144, 142, 138, 143, 144, 152,\n       151, 151, 149, 152, 155, 153, 152, 153, 152, 150, 150, 152, 152,\n       152, 154, 155], dtype=uint8), array([5.29939395])], [array([148, 147, 145, 146, 145, 145, 147, 149, 149, 147, 148, 148, 147,\n       148, 149, 148, 148, 148, 150, 150, 149, 150, 150, 149, 148, 150,\n       151, 149, 150, 150, 148, 148, 149, 148, 149, 151, 151, 150, 149,\n       151, 151, 149, 150, 150, 151, 149, 150, 150, 152, 149, 148, 151,\n       153, 152, 149, 150, 152, 152, 150, 152, 150, 150, 152, 150, 150,\n       147, 147, 148, 146, 144, 137, 122, 112, 108, 104, 118, 132, 134,\n       137, 138, 146, 142, 147, 143, 148, 151, 147, 150, 149, 151, 151,\n       151, 152, 152, 154, 152, 155, 155, 155, 154, 153, 152, 151, 152,\n       150, 152, 153, 154, 156, 152, 154, 156, 155, 154, 153, 152, 151,\n       153, 154, 151], dtype=uint8), array([5.08347615])], [array([149, 148, 147, 147, 148, 148, 147, 145, 149, 150, 148, 147, 150,\n       151, 148, 148, 149, 148, 148, 150, 150, 150, 152, 152, 150, 149,\n       149, 149, 150, 151, 150, 149, 149, 150, 150, 152, 152, 151, 150,\n       152, 152, 152, 149, 151, 150, 150, 150, 149, 150, 151, 150, 150,\n       149, 150, 152, 153, 151, 151, 152, 151, 150, 147, 148, 150, 149,\n       148, 146, 145, 143, 136, 123, 114, 114, 115, 120, 132, 135, 136,\n       137, 140, 141, 142, 143, 144, 146, 147, 148, 149, 148, 147, 151,\n       152, 151, 151, 151, 152, 154, 149, 150, 151, 152, 152, 152, 152,\n       153, 153, 152, 152, 152, 150, 149, 153, 153, 152, 150, 150, 152,\n       150, 153, 151], dtype=uint8), array([5.923182])], [array([149, 148, 150, 149, 143, 140, 140, 135, 130, 123, 119, 119, 120,\n       127, 127, 128, 126, 126, 127, 128, 129, 132, 129, 130, 133, 132,\n       133, 135, 135, 137, 137, 138, 140, 140, 142, 142, 141, 144, 144,\n       144, 145, 144, 146, 148, 145, 146, 149, 150, 150, 148, 149, 150,\n       150, 146, 148, 149, 149, 151, 152, 152, 151, 151, 148, 149, 151,\n       151, 151, 150, 147, 139, 130, 122, 114, 112, 118, 125, 126, 127,\n       130, 130, 133, 131, 135, 134, 138, 140, 141, 141, 145, 146, 146,\n       146, 147, 146, 148, 149, 149, 149, 148, 150, 148, 148, 150, 151,\n       152, 151, 149, 152, 151, 150, 151, 152, 149, 149, 152, 149, 151,\n       150, 148, 150], dtype=uint8), array([4.59109883])], [array([145, 144, 146, 148, 148, 149, 147, 147, 149, 151, 147, 150, 152,\n       149, 150, 150, 149, 149, 148, 149, 148, 145, 146, 149, 151, 150,\n       148, 147, 149, 148, 150, 150, 149, 147, 149, 150, 146, 146, 148,\n       147, 148, 147, 147, 148, 148, 151, 150, 147, 150, 150, 149, 149,\n       149, 148, 147, 148, 148, 148, 147, 144, 141, 138, 133, 126, 121,\n       119, 123, 128, 128, 127, 126, 128, 131, 131, 129, 132, 133, 135,\n       138, 134, 138, 139, 141, 142, 142, 141, 143, 143, 144, 146, 146,\n       146, 145, 149, 148, 146, 146, 147, 149, 151, 150, 151, 148, 147,\n       148, 150, 149, 149, 148, 148, 149, 151, 152, 150, 149, 151, 153,\n       150, 151, 150], dtype=uint8), array([4.34090199])], [array([147, 147, 147, 147, 147, 147, 148, 148, 151, 152, 148, 145, 149,\n       149, 146, 148, 147, 147, 148, 146, 148, 148, 151, 149, 147, 148,\n       146, 146, 148, 146, 146, 146, 144, 145, 145, 143, 143, 144, 140,\n       139, 136, 139, 138, 138, 135, 133, 127, 119, 104,  99, 104, 102,\n        90,  72,  75,  89,  99,  99,  99,  99, 101, 101, 105, 106, 109,\n       112, 114, 113, 121, 122, 124, 127, 130, 131, 133, 135, 138, 139,\n       138, 143, 142, 142, 145, 145, 146, 145, 145, 149, 150, 148, 149,\n       148, 149, 150, 148, 149, 148, 148, 150, 148, 149, 146, 147, 148,\n       149, 146, 147, 148, 146, 146, 146, 144, 143, 147, 146, 145, 146,\n       147, 147, 146], dtype=uint8), array([8.52101685])], [array([149, 148, 149, 149, 148, 149, 148, 150, 148, 148, 149, 149, 147,\n       149, 151, 150, 151, 151, 149, 149, 150, 152, 150, 148, 149, 151,\n       150, 147, 148, 148, 149, 149, 151, 151, 151, 148, 147, 148, 146,\n       146, 145, 144, 145, 142, 141, 139, 138, 137, 132, 116, 102, 105,\n       115, 114,  96,  81,  83,  96, 102, 102,  98,  99, 101, 101, 102,\n       105, 107, 109, 112, 117, 119, 120, 125, 126, 126, 126, 131, 133,\n       134, 135, 137, 139, 140, 140, 142, 142, 143, 144, 145, 147, 146,\n       147, 145, 148, 148, 148, 147, 149, 150, 145, 150, 149, 150, 148,\n       149, 147, 150, 148, 148, 148, 149, 147, 147, 149, 148, 148, 149,\n       150, 149, 148], dtype=uint8), array([8.73503977])], [array([148, 148, 147, 147, 147, 148, 148, 148, 146, 149, 148, 147, 148,\n       147, 147, 146, 148, 148, 148, 150, 148, 149, 150, 148, 148, 147,\n       146, 147, 148, 148, 146, 148, 148, 150, 148, 149, 149, 145, 148,\n       147, 147, 149, 150, 149, 147, 148, 149, 148, 146, 147, 148, 148,\n       150, 150, 149, 146, 146, 143, 137, 129, 121, 116, 111, 115, 122,\n       123, 125, 123, 123, 122, 123, 126, 129, 130, 132, 133, 135, 138,\n       140, 138, 141, 144, 146, 146, 146, 146, 146, 145, 146, 150, 148,\n       151, 150, 146, 151, 147, 147, 144, 142, 136, 128, 120, 124, 127,\n       129, 128, 128, 127, 128, 132, 132, 132, 135, 136, 138, 139, 142,\n       145, 140, 142], dtype=uint8), array([4.18356936])], [array([149, 149, 148, 147, 145, 148, 149, 147, 147, 148, 146, 146, 149,\n       151, 149, 148, 147, 147, 148, 148, 148, 151, 151, 149, 149, 149,\n       149, 149, 150, 145, 148, 149, 150, 148, 149, 147, 147, 147, 147,\n       147, 148, 147, 147, 151, 150, 146, 148, 151, 151, 149, 147, 149,\n       150, 150, 150, 148, 150, 150, 149, 149, 146, 144, 139, 132, 123,\n       118, 121, 127, 128, 127, 128, 127, 126, 128, 129, 128, 130, 133,\n       133, 135, 138, 139, 140, 141, 144, 141, 146, 146, 147, 146, 146,\n       146, 146, 147, 147, 150, 151, 149, 149, 149, 150, 148, 147, 149,\n       150, 151, 151, 149, 151, 148, 144, 145, 144, 143, 141, 143, 144,\n       141, 141, 143], dtype=uint8), array([4.35067225])], [array([133, 135, 131, 131, 131, 132, 133, 133, 134, 134, 135, 136, 136,\n       135, 136, 133, 130, 132, 132, 134, 133, 133, 133, 135, 133, 134,\n       133, 134, 135, 135, 134, 134, 135, 134, 134, 136, 136, 134, 134,\n       133, 132, 132, 136, 134, 134, 133, 131, 134, 135, 133, 133, 134,\n       134, 134, 136, 135, 134, 131, 133, 132, 134, 134, 134, 134, 133,\n       133, 132, 132, 134, 132, 129, 130, 133, 133, 131, 127, 128, 131,\n       130, 131, 132, 132, 131, 131, 132, 131, 131, 134, 132, 130, 131,\n       131, 130, 131, 131, 131, 130, 131, 130, 129, 129, 128, 130, 132,\n       131, 129, 131, 131, 130, 132, 132, 130, 131, 131, 128, 130, 128,\n       125, 129, 130], dtype=uint8), array([0.])], [array([140, 143, 142, 140, 141, 141, 142, 139, 140, 140, 140, 140, 142,\n       142, 140, 141, 139, 139, 137, 140, 141, 143, 139, 140, 140, 141,\n       140, 142, 142, 141, 140, 140, 140, 142, 142, 144, 144, 140, 139,\n       138, 141, 139, 141, 140, 138, 139, 137, 138, 140, 141, 137, 139,\n       139, 140, 140, 140, 140, 139, 140, 141, 137, 140, 140, 142, 141,\n       143, 141, 143, 143, 142, 141, 140, 137, 129, 118, 109, 102,  96,\n       100, 110, 116, 118, 119, 118, 117, 117, 117, 118, 116, 119, 120,\n       121, 122, 126, 126, 129, 127, 128, 131, 133, 135, 134, 136, 135,\n       137, 137, 136, 137, 136, 139, 140, 141, 140, 140, 140, 141, 140,\n       142, 140, 141], dtype=uint8), array([4.75818342])], [array([140, 142, 142, 141, 139, 141, 144, 143, 143, 140, 139, 140, 139,\n       139, 139, 141, 140, 140, 140, 141, 141, 139, 138, 139, 139, 138,\n       136, 141, 138, 137, 135, 134, 133, 133, 133, 131, 131, 129, 127,\n       124, 125, 123, 123, 122, 122, 120, 122, 122, 120, 120, 121, 120,\n       121, 123, 123, 121, 120, 116, 113, 119, 127, 134, 138, 142, 141,\n       140, 140, 142, 141, 142, 141, 141, 141, 139, 142, 140, 140, 141,\n       142, 139, 140, 141, 140, 140, 141, 141, 141, 137, 139, 140, 138,\n       138, 139, 138, 137, 136, 136, 135, 134, 134, 136, 136, 136, 137,\n       137, 135, 137, 136, 135, 137, 138, 139, 136, 139, 139, 136, 139,\n       140, 140, 141], dtype=uint8), array([3.84824603])], [array([140, 137, 140, 140, 140, 140, 140, 139, 140, 139, 138, 138, 138,\n       138, 138, 138, 139, 139, 135, 137, 137, 136, 136, 136, 137, 135,\n       137, 136, 136, 138, 134, 133, 135, 135, 134, 134, 135, 135, 135,\n       132, 133, 135, 133, 135, 132, 133, 129, 129, 128, 126, 127, 124,\n       123, 122, 123, 120, 120, 120, 118, 116, 115, 114, 113, 113, 112,\n       112, 115, 111, 105,  95,  91,  94, 101, 106, 115, 125, 131, 132,\n       133, 132, 135, 134, 135, 134, 134, 135, 134, 136, 136, 135, 135,\n       133, 133, 131, 132, 132, 130, 131, 127, 125, 122, 117, 113, 111,\n       109, 110, 113, 120, 124, 126, 130, 133, 132, 134, 131, 133, 135,\n       134, 136, 135], dtype=uint8), array([5.52762087])], [array([138, 140, 139, 139, 140, 138, 137, 139, 141, 142, 140, 138, 142,\n       141, 138, 136, 136, 138, 140, 136, 138, 136, 136, 136, 135, 136,\n       134, 134, 132, 131, 133, 133, 127, 127, 123, 123, 119, 121, 124,\n       118, 115, 114, 113, 115, 111, 107, 108, 108, 107, 108, 111, 113,\n       113, 113, 113, 109, 101,  98, 104, 113, 118, 124, 132, 137, 139,\n       141, 140, 137, 139, 141, 139, 138, 139, 139, 138, 139, 138, 137,\n       137, 138, 137, 134, 135, 135, 137, 137, 136, 135, 134, 135, 134,\n       134, 136, 134, 135, 138, 135, 134, 136, 134, 134, 135, 133, 136,\n       135, 135, 134, 132, 134, 132, 130, 131, 132, 130, 129, 130, 129,\n       128, 128, 127], dtype=uint8), array([5.24173503])], [array([134, 135, 134, 134, 135, 135, 134, 136, 132, 132, 132, 132, 132,\n       132, 131, 133, 132, 130, 130, 132, 130, 129, 126, 128, 127, 126,\n       126, 128, 124, 123, 120, 122, 116, 113, 115, 117, 114, 114, 116,\n       111, 112, 113, 110, 112, 109, 114, 113, 117, 117, 115, 117, 115,\n       116, 114, 110, 107, 109, 118, 125, 132, 135, 135, 133, 134, 134,\n       130, 131, 131, 130, 128, 131, 130, 130, 129, 128, 128, 128, 131,\n       132, 131, 130, 132, 131, 127, 127, 127, 128, 130, 129, 128, 131,\n       131, 128, 128, 127, 128, 128, 127, 129, 129, 130, 129, 127, 127,\n       127, 129, 131, 130, 130, 130, 131, 131, 131, 130, 131, 131, 130,\n       129, 128, 129], dtype=uint8), array([3.48806279])], [array([128, 130, 132, 129, 130, 129, 127, 128, 132, 131, 130, 131, 129,\n       128, 130, 129, 126, 129, 128, 127, 129, 130, 130, 128, 128, 129,\n       128, 129, 129, 131, 129, 127, 129, 131, 128, 131, 131, 130, 128,\n       129, 129, 127, 128, 127, 128, 126, 127, 130, 129, 131, 130, 129,\n       125, 126, 127, 129, 128, 127, 126, 124, 126, 126, 125, 122, 122,\n       123, 124, 123, 121, 122, 121, 122, 119, 117, 115, 107,  98,  95,\n        89,  88,  98, 109, 109, 111, 110, 112, 111, 112, 110, 111, 111,\n       110, 113, 114, 115, 113, 114, 114, 111, 113, 111, 114, 112, 112,\n       111, 110, 111, 111, 112, 111, 112, 109, 111, 111, 111, 110, 110,\n       105,  95,  88], dtype=uint8), array([4.68352392])], [array([131, 129, 129, 128, 130, 129, 128, 128, 129, 129, 130, 131, 129,\n       131, 129, 128, 129, 129, 126, 126, 126, 125, 125, 126, 124, 126,\n       124, 123, 123, 122, 122, 120, 117, 116, 116, 116, 114, 114, 114,\n       110, 100,  91,  89,  92,  94, 100, 109, 115, 115, 115, 117, 118,\n       118, 116, 115, 116, 117, 116, 115, 118, 118, 115, 117, 115, 118,\n       117, 118, 117, 116, 115, 116, 109,  99,  94,  92,  98, 106, 115,\n       122, 123, 123, 124, 126, 125, 127, 129, 131, 129, 129, 132, 130,\n       129, 128, 130, 128, 129, 128, 128, 128, 129, 130, 129, 128, 129,\n       127, 127, 129, 128, 128, 127, 127, 129, 129, 129, 129, 129, 129,\n       130, 129, 129], dtype=uint8), array([4.45399496])], [array([143, 143, 141, 142, 143, 142, 140, 140, 140, 141, 141, 140, 142,\n       141, 141, 144, 142, 141, 144, 144, 142, 143, 143, 141, 142, 139,\n       139, 141, 140, 140, 141, 142, 143, 144, 141, 141, 142, 140, 140,\n       141, 140, 140, 139, 136, 139, 142, 139, 138, 141, 142, 142, 141,\n       139, 139, 139, 142, 140, 138, 140, 140, 139, 137, 140, 138, 141,\n       141, 140, 140, 142, 139, 139, 141, 139, 138, 140, 140, 141, 139,\n       138, 140, 140, 139, 140, 141, 140, 141, 141, 139, 139, 140, 141,\n       139, 137, 139, 141, 141, 138, 136, 137, 139, 141, 139, 139, 140,\n       137, 140, 142, 141, 139, 140, 139, 141, 137, 137, 138, 140, 138,\n       138, 140, 140], dtype=uint8), array([0.])], [array([151, 152, 153, 152, 150, 151, 153, 154, 151, 154, 152, 153, 153,\n       150, 152, 153, 153, 151, 150, 152, 152, 154, 152, 149, 151, 153,\n       150, 152, 153, 152, 154, 152, 150, 153, 152, 149, 148, 151, 152,\n       152, 152, 156, 153, 155, 151, 151, 151, 152, 152, 153, 154, 151,\n       150, 146, 145, 144, 145, 145, 143, 139, 139, 139, 137, 133, 125,\n       113, 102,  98,  99,  97,  87,  82,  87,  98, 106, 108, 108, 113,\n       118, 120, 124, 124, 128, 132, 134, 137, 139, 141, 143, 145, 142,\n       146, 147, 147, 150, 149, 149, 149, 150, 151, 151, 150, 151, 150,\n       151, 153, 152, 151, 153, 152, 151, 150, 152, 150, 151, 153, 153,\n       153, 150, 154], dtype=uint8), array([8.71474618])], [array([152, 153, 153, 151, 154, 152, 151, 155, 153, 154, 159, 153, 153,\n       150, 153, 153, 153, 152, 152, 154, 154, 152, 152, 152, 151, 152,\n       152, 153, 152, 152, 151, 153, 152, 152, 155, 154, 152, 152, 149,\n       152, 152, 150, 147, 149, 150, 150, 151, 152, 149, 152, 150, 147,\n       146, 148, 147, 145, 146, 144, 143, 144, 142, 139, 138, 136, 132,\n       126, 113,  95,  77,  72,  82,  97, 101,  93,  91,  99, 112, 119,\n       120, 123, 125, 127, 128, 130, 136, 136, 138, 140, 142, 141, 142,\n       144, 148, 148, 146, 147, 147, 150, 149, 150, 150, 151, 151, 150,\n       150, 149, 149, 150, 151, 149, 148, 152, 152, 154, 151, 152, 155,\n       152, 151, 152], dtype=uint8), array([9.02551505])], [array([125, 125, 129, 130, 132, 132, 134, 132, 133, 132, 134, 136, 136,\n       139, 138, 141, 142, 140, 140, 140, 141, 143, 143, 146, 145, 145,\n       148, 146, 148, 150, 147, 146, 147, 147, 146, 147, 145, 148, 148,\n       148, 147, 147, 148, 141, 141, 135, 120, 104,  96,  93,  85,  79,\n        83,  93, 100, 104, 104, 108, 112, 115, 119, 122, 126, 128, 130,\n       133, 139, 138, 139, 139, 142, 145, 145, 149, 145, 146, 152, 151,\n       149, 151, 151, 150, 149, 150, 154, 153, 151, 152, 152, 152, 152,\n       150, 153, 153, 151, 151, 152, 150, 150, 147, 153, 152, 151, 151,\n       152, 152, 155, 154, 153, 151, 150, 152, 150, 151, 152, 151, 150,\n       150, 153, 151], dtype=uint8), array([7.32964192])], [array([154, 152, 153, 151, 154, 157, 154, 154, 156, 154, 154, 154, 154,\n       152, 155, 157, 154, 154, 155, 154, 156, 155, 156, 155, 155, 155,\n       152, 156, 152, 153, 154, 155, 154, 153, 150, 150, 148, 142, 143,\n       144, 144, 146, 150, 149, 150, 150, 152, 153, 153, 151, 151, 151,\n       150, 150, 147, 148, 149, 149, 145, 144, 142, 141, 133, 122, 115,\n       112, 109, 112, 121, 126, 128, 133, 133, 138, 140, 140, 141, 144,\n       145, 145, 148, 149, 150, 154, 155, 155, 154, 154, 155, 153, 153,\n       152, 153, 153, 156, 153, 157, 149, 152, 153, 155, 154, 153, 155,\n       155, 154, 155, 155, 158, 155, 154, 153, 154, 151, 153, 155, 155,\n       154, 153, 154], dtype=uint8), array([4.88385177])], [array([152, 151, 150, 151, 150, 153, 150, 150, 153, 150, 152, 151, 151,\n       149, 149, 150, 151, 154, 150, 150, 151, 151, 151, 153, 152, 153,\n       152, 152, 153, 151, 149, 151, 151, 150, 149, 146, 148, 144, 144,\n       138, 135, 137, 139, 142, 147, 149, 149, 148, 148, 144, 146, 146,\n       146, 142, 138, 138, 134, 131, 130, 131, 131, 134, 132, 131, 126,\n       126, 125, 123, 119, 105,  85,  81,  88,  93,  96, 102, 125, 136,\n       138, 139, 141, 144, 144, 146, 148, 149, 149, 146, 146, 151, 149,\n       149, 150, 149, 150, 153, 154, 151, 152, 151, 149, 151, 152, 154,\n       153, 152, 149, 151, 151, 151, 152, 153, 154, 153, 153, 152, 153,\n       153, 153, 153], dtype=uint8), array([6.54541434])], [array([147, 146, 145, 144, 144, 140, 140, 141, 139, 139, 139, 140, 140,\n       135, 133, 133, 130, 127, 123, 115, 110, 105, 106, 111, 121, 129,\n       132, 134, 135, 134, 130, 120, 112, 106, 103, 109, 114, 119, 121,\n       121, 121, 125, 127, 133, 137, 144, 147, 145, 147, 147, 148, 149,\n       148, 148, 149, 149, 147, 147, 148, 145, 144, 144, 141, 141, 140,\n       137, 137, 135, 130, 121, 103,  91,  95,  99,  94,  97, 112, 129,\n       137, 138, 142, 144, 145, 147, 147, 148, 148, 149, 149, 152, 150,\n       154, 153, 154, 153, 151, 153, 151, 153, 155, 157, 154, 153, 155,\n       152, 153, 152, 153, 151, 151, 153, 152, 152, 153, 152, 150, 147,\n       150, 154, 153], dtype=uint8), array([7.03218657])], [array([139, 139, 140, 139, 135, 135, 134, 128, 120, 114, 103, 100, 101,\n       102,  99,  97, 102, 111, 118, 124, 130, 136, 139, 140, 143, 141,\n       142, 142, 142, 145, 142, 146, 145, 145, 146, 148, 150, 149, 149,\n       151, 152, 149, 147, 150, 150, 151, 148, 147, 147, 147, 149, 146,\n       146, 144, 143, 140, 139, 139, 135, 131, 127, 126, 124, 120, 121,\n       120, 119, 115, 105,  91,  90,  95, 100,  95, 103, 121, 134, 140,\n       139, 143, 145, 145, 146, 148, 150, 150, 151, 150, 151, 152, 153,\n       153, 151, 154, 154, 155, 157, 156, 156, 152, 154, 154, 153, 154,\n       154, 153, 152, 153, 152, 153, 154, 153, 154, 153, 154, 151, 150,\n       153, 152, 152], dtype=uint8), array([6.38074043])], [array([146, 141, 143, 146, 145, 143, 146, 146, 145, 145, 145, 146, 144,\n       145, 148, 149, 148, 147, 148, 149, 148, 148, 148, 149, 149, 150,\n       149, 149, 149, 146, 147, 148, 147, 147, 147, 148, 150, 152, 151,\n       150, 152, 152, 149, 148, 147, 148, 147, 146, 151, 150, 150, 147,\n       147, 148, 148, 144, 145, 147, 145, 143, 143, 139, 134, 133, 137,\n       141, 143, 143, 142, 143, 145, 140, 138, 135, 126, 111, 103, 105,\n       108, 114, 125, 138, 147, 146, 151, 149, 150, 149, 146, 150, 149,\n       149, 150, 152, 151, 151, 153, 153, 152, 150, 151, 153, 155, 154,\n       152, 153, 153, 153, 152, 150, 151, 152, 152, 152, 152, 153, 152,\n       152, 152, 152], dtype=uint8), array([5.54238319])], [array([154, 153, 154, 153, 152, 154, 154, 152, 153, 154, 155, 155, 154,\n       157, 156, 154, 152, 154, 155, 155, 152, 153, 153, 154, 152, 151,\n       148, 150, 154, 150, 149, 149, 148, 149, 150, 148, 146, 147, 144,\n       142, 141, 139, 140, 136, 135, 136, 135, 137, 136, 133, 130, 132,\n       135, 140, 143, 148, 146, 143, 145, 146, 147, 148, 149, 148, 146,\n       145, 144, 143, 142, 141, 139, 138, 136, 133, 130, 125, 123, 120,\n       119, 121, 125, 134, 145, 149, 151, 150, 150, 152, 151, 153, 153,\n       153, 149, 150, 151, 149, 146, 148, 144, 143, 145, 146, 141, 143,\n       145, 145, 148, 147, 146, 148, 151, 152, 150, 153, 152, 150, 152,\n       154, 153, 153], dtype=uint8), array([4.58639866])], [array([154, 154, 157, 156, 156, 154, 152, 157, 156, 156, 156, 156, 157,\n       155, 155, 156, 156, 156, 155, 154, 155, 155, 155, 155, 155, 154,\n       155, 155, 154, 155, 154, 154, 152, 154, 155, 155, 155, 154, 154,\n       153, 156, 155, 154, 154, 153, 151, 151, 151, 150, 149, 146, 140,\n       134, 127, 118, 106,  98, 101, 111, 123, 123, 124, 124, 127, 124,\n       128, 132, 136, 138, 140, 141, 144, 149, 149, 149, 151, 150, 150,\n       153, 155, 154, 155, 156, 157, 156, 157, 157, 154, 156, 156, 157,\n       155, 157, 158, 156, 155, 156, 157, 157, 155, 155, 156, 156, 156,\n       157, 158, 158, 158, 156, 156, 155, 156, 155, 155, 155, 157, 152,\n       152, 154, 155], dtype=uint8), array([5.4984222])], [array([143, 142, 140, 136, 141, 138, 135, 125, 110,  99,  89,  85,  79,\n        79,  81,  84,  93, 101, 109, 116, 120, 124, 126, 124, 124, 129,\n       133, 136, 139, 143, 143, 144, 144, 144, 142, 145, 147, 146, 145,\n       145, 145, 147, 144, 147, 150, 145, 146, 147, 148, 148, 148, 148,\n       148, 149, 148, 147, 146, 145, 147, 146, 145, 146, 146, 144, 140,\n       134, 124, 112, 108, 109, 106,  95,  85,  84,  91, 101, 104, 107,\n       108, 112, 114, 117, 121, 123, 127, 130, 133, 135, 139, 141, 141,\n       141, 144, 145, 149, 151, 149, 151, 151, 151, 150, 149, 151, 151,\n       149, 149, 150, 152, 152, 155, 154, 154, 152, 153, 151, 154, 152,\n       151, 152, 151], dtype=uint8), array([8.81468908])], [array([155, 154, 152, 152, 152, 153, 154, 154, 153, 150, 152, 153, 152,\n       153, 152, 152, 152, 153, 152, 152, 153, 154, 151, 151, 153, 153,\n       153, 155, 154, 153, 153, 153, 153, 153, 152, 151, 150, 153, 154,\n       152, 153, 152, 155, 155, 155, 155, 151, 150, 152, 150, 152, 153,\n       150, 152, 152, 151, 152, 148, 149, 150, 148, 149, 148, 148, 145,\n       146, 144, 147, 144, 143, 143, 142, 142, 140, 135, 127, 108,  83,\n        76,  76,  83, 105, 130, 137, 142, 144, 145, 146, 148, 148, 148,\n       149, 150, 150, 154, 152, 150, 152, 152, 151, 154, 152, 153, 153,\n       153, 151, 153, 152, 155, 151, 151, 149, 152, 153, 152, 153, 149,\n       151, 155, 153], dtype=uint8), array([5.09065576])], [array([132, 133, 132, 133, 134, 131, 131, 134, 134, 132, 132, 131, 134,\n       135, 133, 134, 133, 133, 131, 132, 131, 135, 133, 133, 134, 136,\n       136, 135, 133, 133, 134, 133, 132, 132, 134, 134, 132, 135, 134,\n       135, 134, 134, 136, 135, 133, 133, 136, 134, 134, 131, 132, 132,\n       132, 136, 132, 131, 134, 134, 132, 135, 136, 134, 135, 137, 135,\n       136, 136, 135, 135, 139, 136, 136, 138, 137, 137, 138, 137, 136,\n       136, 137, 137, 136, 136, 136, 135, 137, 137, 136, 137, 134, 135,\n       134, 134, 133, 135, 132, 133, 133, 134, 136, 137, 135, 133, 137,\n       137, 135, 134, 135, 135, 135, 135, 135, 135, 136, 136, 136, 137,\n       136, 136, 135], dtype=uint8), array([0.])], [array([148, 149, 149, 149, 149, 148, 149, 149, 149, 149, 150, 150, 148,\n       148, 148, 148, 150, 150, 147, 147, 148, 146, 148, 148, 149, 145,\n       146, 148, 149, 150, 148, 149, 149, 151, 151, 150, 149, 146, 148,\n       148, 152, 149, 146, 146, 147, 147, 148, 150, 150, 152, 151, 150,\n       147, 149, 149, 148, 148, 148, 149, 146, 144, 146, 141, 127, 114,\n       103,  93,  90,  99, 114, 121, 123, 124, 126, 125, 127, 128, 131,\n       133, 135, 136, 136, 137, 139, 141, 143, 144, 143, 144, 144, 146,\n       147, 146, 147, 149, 147, 148, 148, 145, 147, 147, 147, 148, 149,\n       147, 147, 147, 152, 148, 147, 148, 146, 145, 140, 137, 131, 124,\n       115, 114, 122], dtype=uint8), array([4.42544194])], [array([146, 147, 148, 147, 149, 147, 148, 149, 148, 150, 149, 148, 147,\n       149, 149, 148, 148, 149, 148, 148, 148, 150, 150, 148, 146, 149,\n       151, 151, 149, 150, 151, 148, 149, 148, 151, 150, 150, 149, 150,\n       149, 148, 149, 148, 148, 147, 144, 141, 135, 125, 119, 114, 109,\n       111, 120, 130, 132, 134, 137, 140, 141, 144, 143, 144, 147, 146,\n       145, 146, 148, 146, 145, 141, 135, 126, 114, 100,  98, 107, 120,\n       124, 124, 123, 122, 124, 125, 126, 129, 129, 132, 132, 137, 138,\n       138, 142, 143, 145, 146, 145, 143, 144, 144, 150, 147, 146, 146,\n       150, 149, 150, 151, 151, 150, 150, 150, 149, 148, 149, 150, 150,\n       149, 149, 149], dtype=uint8), array([4.45399496])], [array([130, 131, 132, 133, 134, 134, 134, 133, 135, 135, 135, 138, 136,\n       137, 134, 138, 138, 142, 140, 141, 142, 145, 144, 143, 143, 144,\n       144, 142, 143, 143, 145, 145, 145, 146, 146, 147, 149, 147, 150,\n       150, 146, 147, 147, 147, 147, 147, 147, 147, 147, 147, 147, 148,\n       148, 149, 149, 148, 149, 150, 149, 149, 151, 149, 147, 146, 148,\n       148, 148, 149, 148, 150, 148, 148, 148, 145, 145, 142, 130, 118,\n       108,  95,  92, 107, 120, 123, 125, 130, 131, 131, 132, 134, 137,\n       140, 140, 141, 142, 142, 144, 147, 146, 146, 145, 146, 147, 147,\n       148, 150, 149, 148, 148, 148, 147, 149, 149, 148, 143, 131, 117,\n       106,  96,  87], dtype=uint8), array([4.68352392])], [array([148, 148, 148, 147, 147, 149, 151, 149, 148, 147, 147, 148, 147,\n       147, 146, 147, 148, 149, 148, 148, 148, 145, 143, 147, 147, 147,\n       147, 151, 149, 146, 146, 142, 139, 145, 146, 147, 148, 151, 151,\n       147, 147, 149, 151, 148, 145, 145, 144, 145, 144, 143, 140, 133,\n       122, 113, 111, 116, 127, 134, 135, 134, 133, 133, 135, 136, 136,\n       136, 135, 133, 132, 132, 137, 137, 138, 139, 140, 139, 141, 140,\n       140, 144, 143, 143, 146, 146, 145, 146, 146, 145, 147, 148, 146,\n       147, 145, 146, 145, 148, 150, 150, 146, 150, 150, 149, 150, 149,\n       147, 148, 150, 148, 147, 149, 149, 148, 147, 149, 152, 149, 147,\n       145, 148, 147], dtype=uint8), array([3.48806279])], [array([136, 137, 136, 139, 145, 143, 141, 145, 146, 144, 143, 144, 145,\n       148, 145, 147, 149, 148, 148, 144, 147, 149, 150, 149, 147, 147,\n       149, 149, 148, 148, 146, 146, 147, 147, 151, 147, 149, 147, 147,\n       148, 149, 148, 147, 148, 150, 149, 147, 147, 146, 148, 149, 149,\n       147, 149, 147, 146, 148, 147, 150, 147, 147, 146, 146, 148, 148,\n       146, 148, 147, 151, 148, 146, 146, 140, 129, 114, 106,  94,  89,\n        99, 112, 119, 118, 117, 119, 121, 120, 124, 125, 127, 130, 133,\n       134, 135, 138, 139, 140, 143, 142, 143, 143, 144, 147, 147, 146,\n       147, 148, 147, 150, 146, 148, 149, 151, 149, 147, 147, 144, 150,\n       152, 148, 149], dtype=uint8), array([5.52762087])], [array([147, 145, 144, 146, 146, 146, 146, 148, 148, 148, 147, 146, 147,\n       148, 150, 148, 147, 145, 145, 146, 146, 146, 146, 146, 146, 147,\n       147, 147, 146, 146, 147, 148, 147, 146, 146, 146, 145, 146, 145,\n       139, 130, 122, 117, 122, 131, 138, 141, 142, 144, 146, 147, 144,\n       145, 143, 138, 128, 118, 116, 112, 101,  95, 102, 110, 113, 110,\n       109, 111, 111, 111, 113, 116, 120, 123, 124, 127, 130, 131, 134,\n       136, 138, 137, 137, 140, 142, 143, 145, 144, 145, 146, 146, 145,\n       145, 148, 148, 147, 144, 145, 147, 147, 148, 147, 146, 147, 146,\n       145, 146, 148, 148, 147, 148, 148, 146, 149, 147, 147, 149, 146,\n       146, 147, 147], dtype=uint8), array([5.24173503])], [array([148, 147, 146, 146, 149, 146, 148, 146, 148, 146, 149, 147, 147,\n       145, 145, 142, 147, 147, 147, 147, 143, 144, 144, 141, 143, 143,\n       141, 136, 131, 133, 137, 138, 140, 143, 145, 144, 146, 146, 144,\n       145, 145, 144, 146, 147, 147, 146, 144, 143, 144, 144, 142, 143,\n       146, 144, 141, 140, 139, 142, 137, 134, 136, 133, 130, 129, 127,\n       126, 126, 126, 125, 122, 123, 121, 119, 120, 118, 104,  97,  98,\n       100, 108, 124, 136, 140, 141, 142, 145, 144, 144, 147, 145, 147,\n       145, 143, 146, 144, 147, 146, 145, 145, 148, 146, 144, 144, 147,\n       147, 147, 146, 147, 148, 147, 149, 149, 146, 149, 145, 145, 145,\n       145, 145, 146], dtype=uint8), array([4.75818342])], [array([143, 143, 143, 143, 145, 145, 144, 143, 143, 141, 142, 144, 143,\n       143, 146, 145, 144, 144, 145, 145, 144, 143, 144, 142, 144, 148,\n       145, 147, 145, 145, 144, 147, 146, 146, 144, 140, 141, 143, 142,\n       145, 142, 144, 145, 143, 148, 145, 144, 143, 146, 148, 146, 146,\n       146, 146, 142, 139, 134, 121, 110, 107, 113, 118, 118, 121, 121,\n       122, 122, 121, 120, 122, 124, 125, 126, 129, 132, 134, 135, 136,\n       137, 139, 141, 142, 143, 144, 144, 144, 143, 143, 144, 145, 144,\n       147, 147, 146, 150, 148, 147, 147, 146, 145, 144, 148, 150, 147,\n       145, 145, 144, 144, 148, 147, 145, 139, 139, 139, 137, 136, 135,\n       133, 133, 136], dtype=uint8), array([3.84824603])], [array([139, 141, 141, 140, 140, 142, 140, 139, 139, 138, 136, 138, 137,\n       136, 138, 138, 138, 137, 138, 137, 138, 138, 137, 137, 138, 137,\n       137, 138, 141, 139, 138, 140, 140, 138, 137, 139, 139, 139, 139,\n       141, 138, 140, 141, 139, 142, 142, 140, 143, 141, 143, 141, 142,\n       142, 143, 144, 144, 142, 140, 140, 138, 139, 136, 128, 119, 116,\n       116, 109,  99,  97, 104, 107, 106, 102, 100,  97,  96,  97,  98,\n       102, 103, 106, 109, 111, 115, 116, 115, 118, 122, 124, 126, 127,\n       130, 130, 133, 135, 137, 136, 136, 139, 139, 138, 142, 139, 142,\n       142, 142, 141, 142, 141, 140, 143, 142, 139, 141, 143, 142, 144,\n       143, 145, 144], dtype=uint8), array([6.3266849])], [array([114, 115, 119, 120, 122, 124, 125, 122, 124, 125, 127, 128, 126,\n       127, 131, 129, 129, 130, 131, 132, 133, 135, 134, 137, 136, 138,\n       135, 138, 139, 139, 139, 140, 141, 141, 137, 139, 139, 139, 139,\n       142, 142, 142, 140, 139, 139, 138, 140, 140, 141, 141, 140, 140,\n       138, 137, 137, 137, 137, 134, 126, 119, 115, 116, 118, 125, 130,\n       131, 129, 128, 127, 127, 127, 125, 124, 115, 104,  94,  92,  84,\n        78,  86, 100, 106, 108, 110, 111, 113, 116, 118, 122, 124, 125,\n       129, 128, 131, 130, 133, 135, 137, 136, 137, 139, 140, 140, 139,\n       142, 142, 142, 143, 142, 142, 144, 147, 144, 143, 143, 144, 143,\n       142, 145, 145], dtype=uint8), array([5.48232787])], [array([116, 117, 120, 117, 118, 121, 121, 122, 121, 125, 125, 123, 124,\n       124, 126, 126, 129, 130, 129, 131, 129, 130, 131, 131, 130, 133,\n       134, 130, 132, 133, 132, 138, 137, 135, 137, 134, 134, 129, 132,\n       134, 137, 135, 138, 139, 136, 135, 139, 137, 137, 135, 135, 136,\n       139, 134, 134, 136, 137, 140, 139, 138, 141, 141, 140, 138, 140,\n       137, 143, 141, 141, 143, 142, 140, 143, 140, 136, 128, 117, 106,\n        97,  91, 100, 107, 110, 108, 112, 112, 108, 111, 111, 111, 115,\n       116, 115, 119, 117, 125, 121, 125, 126, 124, 127, 129, 130, 135,\n       133, 138, 138, 137, 139, 136, 136, 139, 138, 140, 140, 142, 138,\n       138, 142, 141], dtype=uint8), array([4.22418291])], [array([148, 148, 151, 151, 149, 148, 151, 151, 149, 148, 150, 149, 148,\n       150, 148, 149, 149, 148, 145, 146, 150, 149, 146, 147, 146, 147,\n       148, 149, 149, 152, 150, 149, 149, 150, 149, 148, 149, 146, 148,\n       149, 150, 148, 147, 148, 148, 149, 149, 150, 148, 148, 149, 148,\n       150, 150, 148, 149, 150, 150, 150, 148, 149, 148, 149, 149, 148,\n       147, 150, 150, 150, 152, 151, 148, 149, 148, 149, 150, 150, 148,\n       149, 148, 151, 151, 149, 152, 149, 146, 150, 150, 150, 150, 151,\n       149, 149, 146, 149, 149, 150, 149, 150, 150, 152, 149, 151, 147,\n       145, 146, 148, 148, 146, 146, 149, 147, 147, 153, 148, 147, 149,\n       148, 149, 148], dtype=uint8), array([0.])], [array([145, 144, 146, 147, 147, 145, 145, 142, 145, 147, 147, 146, 146,\n       145, 146, 146, 146, 145, 145, 145, 146, 146, 145, 147, 148, 146,\n       146, 148, 147, 145, 145, 146, 147, 145, 146, 144, 143, 145, 147,\n       148, 146, 145, 144, 146, 146, 146, 144, 144, 145, 146, 147, 147,\n       147, 148, 148, 147, 146, 148, 144, 146, 146, 146, 145, 145, 143,\n       137, 128, 118, 111, 113, 118, 124, 123, 123, 123, 124, 125, 122,\n       125, 129, 129, 128, 132, 133, 134, 139, 140, 139, 142, 143, 143,\n       143, 143, 143, 145, 148, 145, 144, 146, 152, 148, 146, 146, 148,\n       147, 146, 148, 146, 149, 147, 150, 149, 148, 148, 148, 147, 148,\n       146, 148, 148], dtype=uint8), array([3.71157107])], [array([144, 145, 144, 144, 148, 146, 145, 148, 146, 147, 148, 145, 146,\n       146, 144, 148, 146, 145, 145, 143, 146, 148, 148, 144, 146, 143,\n       146, 147, 145, 144, 145, 145, 146, 148, 146, 144, 145, 144, 145,\n       144, 141, 142, 139, 139, 139, 136, 135, 137, 138, 143, 144, 144,\n       145, 143, 145, 144, 145, 144, 146, 145, 144, 145, 145, 142, 141,\n       144, 140, 138, 141, 139, 137, 131, 126, 113, 101, 102,  97,  98,\n       113, 122, 123, 126, 126, 126, 130, 130, 129, 133, 135, 137, 137,\n       138, 140, 144, 143, 144, 145, 146, 145, 143, 142, 145, 145, 146,\n       145, 144, 144, 146, 148, 147, 147, 149, 147, 148, 149, 149, 147,\n       146, 146, 145], dtype=uint8), array([4.08382213])], [array([150, 149, 148, 147, 147, 149, 147, 149, 148, 144, 145, 147, 146,\n       146, 149, 148, 147, 149, 149, 149, 147, 149, 147, 146, 148, 148,\n       147, 147, 146, 148, 145, 146, 144, 144, 147, 148, 145, 143, 143,\n       145, 143, 138, 137, 136, 135, 131, 127, 112, 102,  99, 106, 123,\n       135, 137, 140, 142, 143, 146, 146, 147, 149, 149, 148, 148, 147,\n       146, 147, 147, 146, 148, 150, 148, 146, 147, 148, 147, 144, 148,\n       144, 148, 149, 149, 150, 151, 149, 148, 147, 147, 148, 150, 149,\n       146, 146, 147, 149, 147, 149, 147, 146, 145, 147, 149, 147, 145,\n       143, 143, 142, 142, 140, 142, 138, 135, 133, 128, 122, 117, 112,\n       111, 112, 117], dtype=uint8), array([3.69767209])], [array([141, 142, 142, 143, 143, 143, 141, 141, 141, 143, 143, 143, 144,\n       141, 143, 143, 142, 142, 141, 134, 125, 121, 118, 118, 123, 127,\n       127, 130, 130, 125, 123, 122, 119, 118, 113, 110, 110, 106, 107,\n       102,  99,  98,  99, 102, 107, 112, 117, 121, 125, 127, 127, 126,\n       128, 130, 130, 129, 130, 129, 132, 134, 136, 134, 136, 135, 134,\n       136, 137, 139, 140, 129, 119, 110,  97,  95, 103, 111, 115, 114,\n       114, 113, 114, 110, 110, 112, 114, 116, 115, 120, 120, 122, 122,\n       126, 126, 127, 128, 130, 134, 133, 136, 137, 137, 140, 140, 139,\n       139, 141, 143, 141, 142, 141, 144, 144, 141, 141, 142, 142, 142,\n       144, 144, 139], dtype=uint8), array([4.18255064])], [array([148, 145, 145, 145, 145, 146, 146, 145, 148, 147, 147, 146, 147,\n       145, 147, 148, 146, 148, 145, 144, 144, 148, 148, 149, 147, 145,\n       144, 144, 146, 147, 146, 145, 148, 146, 145, 146, 144, 145, 145,\n       144, 147, 146, 145, 138, 141, 143, 142, 142, 141, 138, 138, 135,\n       133, 132, 130, 130, 130, 128, 128, 125, 122, 121, 116, 113, 113,\n       112, 110, 111, 108, 103,  84,  71,  73,  79,  76,  74,  90, 113,\n       126, 126, 128, 133, 132, 134, 136, 140, 140, 140, 138, 141, 145,\n       146, 145, 143, 147, 149, 147, 146, 148, 145, 146, 146, 145, 146,\n       146, 144, 146, 144, 145, 144, 144, 145, 145, 145, 144, 144, 146,\n       144, 144, 143], dtype=uint8), array([9.01671984])], [array([115, 117, 124, 124, 126, 127, 126, 127, 128, 127, 127, 127, 127,\n       126, 124, 125, 128, 126, 126, 128, 125, 125, 125, 125, 125, 123,\n       123, 119, 118, 119, 121, 122, 123, 120, 119, 122, 121, 121, 120,\n       120, 119, 117, 114, 112, 107, 102, 102, 101, 107, 111, 115, 118,\n       119, 121, 124, 127, 127, 126, 127, 126, 127, 128, 126, 121, 115,\n       112, 116, 110, 110, 121, 132, 137, 138, 140, 139, 141, 142, 144,\n       141, 143, 142, 142, 144, 145, 143, 146, 143, 141, 142, 141, 141,\n       140, 141, 141, 142, 142, 142, 141, 138, 137, 141, 141, 143, 143,\n       142, 143, 146, 144, 139, 140, 140, 142, 144, 141, 141, 146, 143,\n       141, 142, 140], dtype=uint8), array([6.47364817])], [array([140, 143, 144, 143, 142, 141, 143, 143, 142, 141, 140, 141, 142,\n       143, 140, 141, 140, 142, 144, 142, 142, 143, 141, 139, 141, 141,\n       142, 141, 142, 142, 141, 143, 142, 143, 142, 142, 143, 141, 141,\n       141, 144, 145, 144, 144, 144, 141, 144, 143, 141, 142, 144, 143,\n       143, 142, 141, 142, 144, 144, 144, 145, 144, 143, 143, 145, 145,\n       143, 146, 145, 145, 144, 143, 144, 138, 133, 120, 111, 102, 103,\n       113, 119, 118, 120, 124, 123, 123, 124, 123, 124, 124, 126, 124,\n       126, 128, 129, 129, 134, 133, 133, 136, 136, 136, 137, 138, 138,\n       139, 141, 141, 141, 140, 141, 141, 142, 139, 141, 142, 141, 142,\n       144, 143, 145], dtype=uint8), array([4.51710674])], [array([151, 149, 149, 150, 150, 151, 150, 147, 149, 148, 150, 150, 150,\n       148, 148, 146, 148, 152, 148, 147, 146, 146, 145, 144, 144, 145,\n       147, 148, 148, 147, 147, 148, 146, 146, 148, 148, 149, 148, 150,\n       150, 149, 146, 149, 148, 150, 149, 155, 151, 150, 147, 145, 147,\n       147, 148, 146, 149, 149, 150, 148, 147, 150, 149, 146, 146, 147,\n       149, 149, 148, 148, 148, 148, 148, 147, 146, 145, 142, 136, 131,\n       133, 134, 137, 135, 135, 136, 137, 138, 137, 136, 138, 141, 141,\n       145, 143, 143, 145, 146, 144, 146, 145, 145, 146, 147, 148, 149,\n       147, 149, 150, 149, 148, 147, 149, 148, 146, 148, 150, 148, 145,\n       147, 148, 147], dtype=uint8), array([4.88037655])], [array([145, 146, 147, 148, 149, 149, 148, 149, 150, 147, 147, 148, 147,\n       147, 147, 146, 145, 147, 147, 146, 146, 146, 147, 149, 148, 149,\n       146, 149, 146, 148, 147, 146, 146, 145, 146, 147, 148, 151, 148,\n       148, 147, 146, 149, 147, 147, 146, 147, 147, 148, 146, 146, 145,\n       145, 144, 144, 146, 147, 145, 144, 146, 145, 143, 144, 144, 143,\n       146, 146, 143, 145, 146, 145, 143, 141, 141, 143, 145, 144, 143,\n       143, 145, 146, 145, 144, 144, 144, 143, 143, 142, 140, 139, 140,\n       142, 144, 146, 148, 146, 147, 148, 149, 149, 148, 148, 148, 145,\n       146, 148, 148, 150, 149, 147, 146, 146, 145, 145, 142, 144, 146,\n       146, 147, 146], dtype=uint8), array([4.75318777])], [array([145, 145, 145, 147, 146, 145, 146, 147, 146, 146, 146, 143, 145,\n       147, 144, 143, 143, 143, 142, 142, 142, 141, 140, 138, 136, 137,\n       133, 133, 132, 132, 129, 128, 125, 124, 123, 120, 121, 120, 120,\n       120, 120, 120, 119, 121, 119, 110,  98,  96, 104, 114, 123, 136,\n       142, 143, 143, 141, 143, 145, 143, 146, 141, 144, 149, 147, 145,\n       145, 146, 145, 144, 146, 145, 146, 147, 147, 146, 144, 145, 145,\n       146, 148, 145, 146, 146, 145, 145, 146, 143, 145, 144, 145, 145,\n       146, 145, 145, 148, 147, 145, 144, 145, 144, 144, 148, 145, 143,\n       144, 143, 143, 142, 143, 144, 143, 144, 142, 145, 147, 148, 146,\n       145, 145, 144], dtype=uint8), array([4.67930649])], [array([146, 146, 144, 144, 145, 144, 147, 145, 145, 148, 147, 147, 146,\n       145, 143, 145, 145, 143, 145, 146, 146, 145, 146, 145, 145, 145,\n       147, 147, 146, 148, 143, 144, 144, 144, 143, 144, 143, 142, 141,\n       143, 143, 141, 144, 144, 143, 143, 143, 146, 145, 144, 144, 145,\n       143, 143, 142, 144, 142, 140, 140, 138, 140, 139, 136, 136, 136,\n       133, 133, 125, 120, 118, 119, 126, 129, 132, 130, 134, 134, 134,\n       132, 133, 135, 135, 139, 138, 138, 141, 141, 142, 142, 145, 144,\n       143, 144, 146, 142, 141, 142, 144, 142, 143, 145, 146, 145, 145,\n       145, 145, 147, 150, 147, 144, 144, 145, 144, 145, 144, 146, 144,\n       147, 146, 143], dtype=uint8), array([3.66342182])], [array([129, 130, 129, 133, 130, 131, 129, 128, 130, 130, 130, 130, 129,\n       128, 129, 130, 131, 130, 129, 130, 131, 130, 127, 128, 129, 131,\n       129, 128, 132, 132, 131, 131, 128, 130, 130, 130, 132, 131, 129,\n       130, 131, 129, 128, 126, 130, 131, 128, 128, 130, 128, 129, 130,\n       128, 127, 129, 129, 130, 131, 129, 126, 126, 128, 128, 126, 125,\n       124, 124, 123, 121, 121, 118, 114, 111, 103,  95,  96, 102,  99,\n        83,  66,  65,  71,  67,  65,  68,  72,  78,  78,  80,  81,  82,\n        84,  84,  86,  91,  92,  95,  99, 102, 105, 106, 107, 108, 107,\n       110, 111, 113, 116, 117, 118, 118, 120, 121, 123, 124, 126, 126,\n       125, 127, 127], dtype=uint8), array([11.24816955])], [array([131, 134, 133, 136, 136, 134, 132, 135, 135, 135, 134, 132, 132,\n       134, 134, 131, 131, 131, 130, 130, 126, 125, 124, 122, 123, 123,\n       121, 119, 119, 118, 116, 117, 115, 114, 112, 110, 111, 111, 112,\n       112, 112, 113, 114, 116, 118, 116, 115, 113, 103,  96, 105, 116,\n       122, 129, 139, 138, 140, 141, 138, 138, 138, 137, 136, 137, 135,\n       137, 136, 136, 133, 133, 132, 132, 133, 134, 134, 134, 134, 133,\n       132, 132, 132, 132, 132, 134, 132, 132, 132, 133, 132, 132, 134,\n       131, 131, 130, 129, 130, 131, 131, 133, 134, 133, 136, 132, 131,\n       131, 131, 130, 131, 131, 131, 130, 133, 132, 131, 132, 131, 131,\n       132, 134, 131], dtype=uint8), array([5.29607184])], [array([135, 135, 135, 136, 134, 133, 132, 133, 135, 136, 137, 135, 135,\n       135, 132, 133, 130, 129, 129, 132, 130, 131, 130, 132, 128, 128,\n       124, 123, 125, 124, 121, 118, 118, 118, 117, 115, 112, 110, 109,\n       109, 107, 103, 104, 104, 103, 103, 105, 104, 104, 104, 101,  97,\n        88,  84,  90, 103, 116, 127, 137, 137, 136, 135, 136, 137, 136,\n       138, 138, 136, 136, 135, 136, 138, 135, 133, 134, 134, 135, 134,\n       136, 137, 131, 135, 133, 135, 135, 134, 134, 131, 132, 134, 132,\n       131, 131, 133, 131, 128, 128, 126, 127, 126, 126, 123, 125, 128,\n       127, 126, 127, 125, 128, 129, 131, 131, 131, 132, 133, 131, 132,\n       132, 130, 130], dtype=uint8), array([5.46791157])], [array([135, 133, 134, 135, 134, 133, 133, 132, 135, 135, 134, 133, 135,\n       135, 135, 134, 134, 132, 133, 132, 130, 130, 129, 131, 130, 128,\n       128, 127, 125, 125, 123, 122, 121, 120, 120, 117, 114, 114, 113,\n       113, 112, 110, 109, 108, 107, 107, 105, 104, 105, 108, 108, 109,\n       109, 110, 111, 103,  94,  91,  96, 108, 119, 130, 135, 135, 135,\n       136, 134, 135, 135, 134, 136, 136, 134, 133, 136, 135, 137, 135,\n       135, 135, 134, 135, 135, 133, 134, 134, 134, 134, 136, 134, 133,\n       134, 135, 136, 135, 134, 137, 136, 133, 135, 134, 134, 133, 132,\n       133, 133, 134, 133, 133, 134, 135, 134, 133, 134, 135, 134, 133,\n       131, 130, 125], dtype=uint8), array([5.45620238])], [array([143, 147, 149, 149, 146, 147, 147, 144, 144, 145, 145, 146, 146,\n       144, 145, 144, 144, 145, 144, 144, 145, 146, 146, 148, 150, 148,\n       149, 151, 150, 147, 147, 145, 144, 147, 148, 148, 147, 146, 144,\n       144, 144, 144, 144, 143, 144, 144, 145, 147, 147, 146, 147, 148,\n       147, 147, 148, 148, 147, 150, 150, 148, 150, 148, 148, 150, 148,\n       148, 149, 149, 149, 147, 149, 150, 149, 148, 148, 147, 145, 144,\n       145, 148, 149, 149, 150, 149, 147, 148, 148, 148, 149, 148, 148,\n       148, 149, 148, 147, 147, 148, 147, 147, 147, 148, 148, 148, 148,\n       147, 147, 148, 148, 148, 148, 146, 146, 148, 149, 149, 149, 147,\n       147, 147, 147], dtype=uint8), array([0.])], [array([110, 119, 129, 136, 136, 137, 139, 142, 143, 145, 145, 145, 146,\n       146, 148, 148, 147, 147, 149, 149, 148, 150, 150, 149, 151, 151,\n       149, 150, 151, 148, 150, 149, 150, 152, 150, 150, 148, 151, 152,\n       151, 151, 152, 152, 151, 150, 151, 150, 150, 153, 151, 149, 151,\n       151, 151, 151, 150, 151, 150, 148, 150, 151, 150, 147, 146, 146,\n       147, 147, 146, 144, 143, 139, 122, 101,  85,  82,  78,  68,  54,\n        48,  52,  58,  64,  71,  78,  83,  88,  93,  93,  97, 102, 107,\n       107, 108, 111, 116, 118, 121, 122, 126, 130, 132, 132, 137, 139,\n       139, 138, 142, 143, 142, 145, 147, 146, 144, 146, 147, 148, 147,\n       148, 148, 150], dtype=uint8), array([11.65322989])], [array([149, 149, 148, 149, 148, 148, 152, 148, 152, 150, 148, 151, 149,\n       149, 153, 151, 148, 150, 148, 149, 148, 149, 147, 147, 147, 148,\n       147, 148, 148, 152, 151, 150, 149, 151, 148, 152, 148, 150, 151,\n       150, 148, 147, 148, 145, 148, 146, 148, 149, 147, 150, 149, 150,\n       151, 152, 151, 150, 149, 149, 149, 148, 149, 146, 146, 145, 143,\n       142, 143, 136, 135, 128, 125, 116, 109,  94,  74,  60,  55,  52,\n        48,  56,  67,  80,  93, 100, 102, 103, 107, 114, 115, 118, 121,\n       124, 125, 127, 129, 129, 132, 133, 138, 139, 140, 139, 143, 146,\n       146, 147, 150, 148, 147, 149, 147, 148, 147, 148, 150, 150, 150,\n       149, 151, 151], dtype=uint8), array([11.24816955])], [array([150, 151, 149, 150, 149, 148, 149, 151, 149, 151, 152, 148, 146,\n       149, 146, 147, 149, 150, 153, 152, 150, 149, 151, 148, 148, 149,\n       149, 149, 148, 149, 149, 150, 149, 149, 148, 148, 149, 148, 148,\n       148, 150, 148, 148, 149, 148, 146, 147, 149, 146, 146, 144, 142,\n       143, 142, 138, 139, 136, 135, 132, 131, 123, 110,  99, 100, 103,\n       106, 110, 105,  91,  85, 101, 110, 123, 135, 141, 141, 144, 144,\n       149, 147, 146, 146, 148, 148, 145, 145, 143, 149, 147, 147, 149,\n       149, 147, 148, 147, 151, 148, 148, 149, 148, 149, 148, 148, 148,\n       149, 149, 149, 150, 149, 149, 146, 147, 148, 148, 148, 147, 146,\n       146, 148, 146], dtype=uint8), array([5.29607184])], [array([152, 155, 155, 154, 151, 151, 150, 152, 150, 149, 149, 150, 150,\n       152, 151, 151, 152, 151, 150, 152, 152, 151, 152, 151, 153, 153,\n       151, 150, 149, 151, 153, 155, 154, 152, 153, 150, 154, 152, 152,\n       152, 150, 150, 153, 150, 150, 153, 148, 147, 147, 143, 133, 113,\n       103,  90,  85, 100, 114, 119, 122, 122, 123, 126, 129, 131, 135,\n       138, 139, 140, 142, 144, 145, 147, 148, 148, 149, 152, 153, 147,\n       150, 152, 151, 154, 152, 150, 148, 152, 149, 151, 151, 152, 153,\n       150, 149, 148, 147, 149, 150, 149, 147, 148, 148, 147, 148, 149,\n       147, 148, 150, 150, 150, 151, 151, 152, 150, 150, 149, 151, 154,\n       153, 156, 152], dtype=uint8), array([5.46791157])], [array([150, 149, 148, 149, 149, 149, 151, 151, 151, 152, 150, 151, 150,\n       150, 150, 151, 152, 152, 152, 150, 150, 150, 149, 148, 148, 149,\n       147, 148, 149, 149, 144, 145, 146, 143, 146, 147, 149, 150, 150,\n       151, 153, 152, 150, 151, 151, 151, 151, 150, 150, 150, 148, 147,\n       145, 139, 125, 111,  98,  86,  78,  93, 109, 111, 115, 119, 121,\n       123, 128, 130, 128, 132, 132, 136, 139, 142, 141, 145, 145, 147,\n       148, 151, 149, 149, 148, 151, 150, 148, 148, 151, 152, 149, 147,\n       145, 149, 151, 150, 151, 150, 151, 153, 152, 152, 151, 150, 149,\n       152, 151, 152, 151, 150, 153, 149, 153, 150, 151, 150, 148, 149,\n       151, 152, 150], dtype=uint8), array([5.45620238])], [array([153, 153, 152, 152, 153, 151, 151, 151, 154, 154, 153, 151, 151,\n       152, 153, 155, 152, 152, 152, 152, 153, 152, 152, 153, 153, 153,\n       151, 153, 152, 152, 151, 152, 151, 150, 149, 151, 150, 150, 153,\n       152, 148, 149, 148, 152, 153, 148, 151, 152, 154, 150, 153, 150,\n       157, 153, 154, 151, 150, 150, 154, 154, 153, 150, 152, 150, 150,\n       150, 150, 147, 149, 153, 153, 152, 152, 154, 151, 148, 146, 146,\n       145, 147, 148, 148, 149, 150, 150, 152, 151, 150, 150, 153, 153,\n       154, 153, 150, 150, 150, 153, 153, 152, 154, 154, 154, 153, 149,\n       152, 151, 152, 153, 154, 151, 158, 154, 153, 155, 153, 150, 152,\n       152, 153, 151], dtype=uint8), array([3.54463004])], [array([135, 135, 136, 134, 136, 137, 136, 136, 135, 136, 137, 137, 136,\n       136, 137, 137, 139, 140, 138, 137, 138, 139, 140, 140, 137, 138,\n       136, 138, 138, 139, 138, 138, 138, 141, 137, 139, 137, 136, 137,\n       139, 136, 139, 140, 140, 139, 138, 139, 138, 138, 136, 136, 136,\n       139, 138, 134, 132, 132, 133, 130, 127, 125, 125, 123, 122, 120,\n       117, 115, 112, 110, 109, 107, 105, 103, 104, 102, 102, 100,  87,\n        78,  92, 111, 123, 135, 140, 139, 142, 142, 138, 140, 142, 142,\n       139, 136, 136, 137, 135, 135, 136, 135, 136, 136, 135, 135, 134,\n       132, 131, 132, 132, 133, 132, 131, 130, 130, 129, 129, 128, 126,\n       129, 127, 127], dtype=uint8), array([4.51179147])], [array([146, 148, 147, 149, 147, 146, 148, 150, 146, 146, 148, 147, 149,\n       148, 146, 146, 147, 147, 145, 147, 144, 148, 146, 146, 146, 147,\n       145, 147, 145, 144, 144, 143, 141, 144, 143, 141, 140, 138, 140,\n       139, 135, 134, 135, 136, 135, 134, 136, 136, 131, 131, 130, 131,\n       130, 131, 130, 126, 126, 126, 126, 123, 116, 110, 107, 107, 120,\n       128, 138, 146, 146, 145, 148, 149, 148, 146, 145, 144, 140, 141,\n       143, 142, 140, 141, 140, 139, 139, 139, 139, 141, 143, 141, 141,\n       138, 136, 138, 139, 137, 138, 137, 136, 136, 136, 137, 137, 137,\n       136, 134, 136, 135, 135, 137, 136, 137, 135, 136, 139, 137, 138,\n       139, 138, 137], dtype=uint8), array([4.37560143])], [array([146, 149, 149, 146, 146, 144, 144, 146, 146, 146, 144, 143, 141,\n       143, 141, 140, 142, 141, 140, 142, 142, 143, 143, 143, 144, 145,\n       143, 142, 140, 143, 142, 142, 142, 143, 143, 142, 141, 142, 143,\n       140, 141, 138, 139, 141, 142, 139, 139, 138, 137, 138, 140, 137,\n       137, 137, 135, 135, 134, 131, 132, 130, 129, 130, 125, 124, 125,\n       124, 121, 121, 118, 113, 110, 112, 116, 118, 113, 111, 105,  90,\n        84,  91, 106, 122, 134, 140, 139, 141, 140, 139, 136, 141, 139,\n       138, 139, 137, 137, 135, 135, 134, 133, 132, 135, 133, 129, 133,\n       131, 129, 133, 134, 134, 132, 132, 134, 131, 132, 133, 135, 137,\n       132, 135, 135], dtype=uint8), array([3.95002995])], [array([139, 139, 139, 137, 133, 137, 139, 139, 137, 135, 136, 136, 136,\n       138, 137, 138, 136, 135, 136, 136, 135, 136, 134, 134, 138, 134,\n       139, 136, 135, 135, 134, 137, 137, 134, 136, 137, 134, 135, 137,\n       135, 135, 136, 135, 135, 135, 136, 137, 138, 134, 135, 135, 135,\n       135, 131, 133, 132, 131, 130, 130, 127, 124, 123, 120, 118, 117,\n       116, 119, 119, 116, 113, 110, 111, 111, 110, 106,  98,  93, 100,\n       114, 128, 134, 139, 141, 141, 138, 137, 137, 135, 134, 137, 127,\n       131, 129, 125, 126, 126, 123, 121, 119, 118, 116, 117, 118, 120,\n       121, 123, 126, 129, 130, 128, 126, 128, 130, 128, 127, 126, 122,\n       122, 123, 125], dtype=uint8), array([3.53048839])], [array([119, 119, 120, 119, 119, 116, 117, 114, 115, 114, 112, 112, 113,\n       110, 109, 110, 112, 112, 111, 111, 111, 110, 108, 109, 106, 107,\n       106, 108, 105, 104, 106, 105, 103, 104, 105, 107, 110, 114, 113,\n       117, 119, 120, 120, 118, 116, 113, 115, 114, 115, 115, 117, 117,\n       120, 121, 122, 123, 123, 123, 121, 119, 116, 112, 107, 106, 112,\n       120, 129, 136, 137, 140, 139, 141, 142, 140, 140, 139, 142, 140,\n       139, 142, 140, 141, 138, 139, 136, 136, 136, 137, 138, 136, 135,\n       140, 140, 138, 139, 135, 130, 132, 133, 134, 133, 135, 136, 137,\n       138, 137, 135, 138, 133, 134, 129, 124, 122, 116, 113, 115, 123,\n       129, 132, 133], dtype=uint8), array([3.67640104])], [array([133, 133, 132, 133, 133, 132, 133, 133, 133, 132, 133, 130, 131,\n       133, 131, 130, 131, 132, 133, 132, 132, 132, 131, 132, 133, 132,\n       132, 130, 130, 132, 133, 131, 131, 130, 130, 130, 131, 131, 126,\n       126, 125, 122, 122, 119, 118, 117, 115, 109, 106, 105, 104, 100,\n        99,  95,  97,  97,  92,  89,  85,  84,  81,  76,  72,  69,  66,\n        65,  62,  63,  68,  76,  87, 100, 111, 114, 119, 128, 140, 146,\n       148, 150, 150, 150, 148, 147, 146, 146, 148, 145, 146, 143, 142,\n       142, 140, 137, 138, 136, 134, 138, 134, 132, 133, 131, 129, 130,\n       126, 128, 127, 129, 125, 125, 127, 126, 125, 123, 126, 129, 128,\n       127, 126, 126], dtype=uint8), array([8.97995119])], [array([138, 136, 136, 138, 138, 137, 136, 133, 135, 135, 133, 133, 131,\n       133, 133, 134, 134, 131, 130, 133, 131, 131, 130, 132, 132, 132,\n       132, 130, 130, 128, 126, 129, 128, 130, 131, 127, 125, 130, 129,\n       128, 127, 130, 128, 127, 129, 125, 120, 114, 102,  92,  86,  82,\n        88, 100, 108, 110, 113, 114, 115, 116, 117, 118, 120, 121, 122,\n       123, 122, 127, 128, 128, 127, 127, 127, 128, 128, 127, 129, 130,\n       130, 130, 131, 130, 129, 129, 130, 127, 129, 131, 131, 128, 130,\n       130, 131, 131, 130, 128, 130, 130, 130, 131, 130, 130, 129, 128,\n       129, 129, 130, 128, 130, 129, 129, 130, 131, 129, 130, 132, 130,\n       131, 131, 127], dtype=uint8), array([5.35827466])], [array([133, 133, 132, 134, 132, 137, 135, 136, 136, 136, 139, 138, 137,\n       137, 137, 139, 138, 141, 140, 138, 140, 141, 143, 141, 139, 141,\n       140, 140, 138, 139, 141, 139, 141, 141, 140, 134, 130, 127, 131,\n       133, 134, 134, 135, 136, 137, 137, 137, 137, 140, 141, 142, 141,\n       142, 141, 142, 141, 141, 141, 141, 139, 137, 137, 136, 136, 135,\n       133, 129, 131, 130, 116, 100,  88,  94,  95,  91,  83,  83,  84,\n        86,  89,  90,  92,  91,  93,  95,  96,  97,  99, 101, 101, 102,\n       102, 105, 105, 106, 106, 106, 108, 108, 107, 108, 109, 109, 108,\n       110, 109, 110, 112, 112, 110, 110, 111, 111, 112, 112, 113, 113,\n       112, 112, 114], dtype=uint8), array([8.97995119])], [array([110, 111, 109, 112, 115, 113, 115, 115, 116, 116, 117, 119, 118,\n       119, 118, 119, 118, 118, 115, 116, 119, 119, 117, 115, 118, 118,\n       116, 115, 117, 117, 113, 111, 112, 112, 112, 110, 109, 112, 112,\n       112, 110, 109, 110, 111, 111, 111, 105,  91,  86,  95, 104, 113,\n       124, 135, 139, 143, 145, 143, 141, 138, 140, 141, 142, 139, 138,\n       138, 138, 136, 137, 138, 137, 138, 136, 138, 138, 136, 139, 139,\n       138, 139, 139, 136, 135, 136, 138, 138, 137, 138, 137, 136, 136,\n       136, 137, 137, 138, 139, 139, 139, 138, 140, 138, 138, 137, 138,\n       140, 138, 136, 137, 137, 135, 134, 134, 133, 127, 116, 109, 110,\n       114, 125, 134], dtype=uint8), array([5.35827466])], [array([139, 141, 142, 143, 144, 144, 143, 142, 142, 141, 142, 142, 143,\n       140, 144, 144, 142, 142, 142, 140, 141, 141, 140, 141, 141, 139,\n       138, 140, 140, 140, 142, 140, 140, 142, 139, 144, 142, 140, 143,\n       142, 142, 141, 141, 141, 139, 139, 137, 138, 136, 136, 137, 137,\n       137, 138, 138, 136, 136, 135, 135, 134, 132, 134, 132, 131, 133,\n       133, 134, 136, 135, 136, 136, 132, 132, 133, 123, 115, 106,  98,\n        95, 104, 112, 116, 117, 115, 115, 116, 114, 113, 115, 114, 114,\n       114, 111, 111, 114, 113, 111, 111, 111, 111, 109, 110, 110, 109,\n       110, 110, 109, 109, 109, 109, 109, 108, 107, 109, 110, 109, 109,\n       111, 111, 111], dtype=uint8), array([3.76287851])], [array([143, 143, 145, 144, 145, 146, 145, 144, 146, 145, 142, 145, 143,\n       144, 145, 144, 144, 145, 143, 143, 143, 147, 146, 146, 146, 145,\n       143, 142, 137, 136, 138, 139, 141, 140, 138, 138, 139, 138, 136,\n       135, 132, 129, 127, 127, 131, 132, 135, 136, 139, 139, 139, 138,\n       137, 143, 141, 141, 143, 144, 146, 145, 142, 142, 144, 145, 147,\n       143, 146, 148, 148, 146, 145, 146, 147, 142, 137, 135, 134, 136,\n       136, 135, 131, 134, 131, 133, 130, 131, 132, 133, 136, 136, 135,\n       138, 140, 140, 140, 140, 141, 142, 144, 145, 144, 142, 143, 143,\n       144, 144, 143, 145, 142, 144, 143, 145, 145, 145, 145, 147, 147,\n       148, 145, 146], dtype=uint8), array([3.04808728])], [array([139, 142, 142, 144, 146, 146, 144, 145, 142, 147, 147, 147, 144,\n       143, 144, 143, 145, 147, 146, 146, 146, 147, 148, 146, 147, 147,\n       147, 147, 150, 147, 149, 148, 148, 147, 148, 148, 146, 146, 147,\n       147, 144, 146, 147, 148, 145, 146, 147, 148, 149, 147, 148, 148,\n       148, 148, 148, 145, 146, 147, 149, 149, 148, 148, 146, 149, 147,\n       147, 148, 147, 144, 145, 146, 141, 141, 137, 127, 119, 110, 106,\n       115, 121, 125, 123, 126, 127, 127, 128, 128, 128, 132, 131, 129,\n       129, 130, 133, 133, 132, 132, 132, 133, 133, 132, 133, 131, 130,\n       134, 135, 136, 133, 132, 134, 132, 133, 132, 132, 133, 133, 131,\n       130, 129, 127], dtype=uint8), array([3.04562947])], [array([150, 148, 149, 152, 152, 150, 148, 150, 151, 152, 150, 149, 150,\n       150, 148, 148, 149, 149, 148, 150, 150, 152, 151, 152, 151, 151,\n       148, 150, 152, 148, 148, 149, 151, 151, 149, 148, 147, 149, 148,\n       151, 149, 148, 149, 150, 148, 151, 150, 150, 149, 148, 148, 148,\n       147, 146, 150, 150, 150, 150, 150, 148, 147, 148, 150, 149, 146,\n       147, 145, 143, 144, 143, 140, 134, 125, 108,  95,  98, 114, 128,\n       137, 140, 143, 145, 144, 143, 140, 139, 140, 141, 140, 141, 140,\n       139, 138, 136, 136, 135, 133, 133, 132, 130, 131, 132, 131, 132,\n       131, 131, 132, 130, 130, 130, 126, 121, 116, 110, 105, 102,  99,\n        88,  84,  83], dtype=uint8), array([3.06895321])], [array([146, 146, 146, 147, 147, 148, 146, 147, 146, 143, 145, 143, 142,\n       140, 137, 134, 130, 126, 119, 113, 111, 106, 100, 103, 108, 110,\n       106, 105, 108, 108, 118, 123, 124, 126, 128, 132, 133, 134, 134,\n       135, 137, 140, 140, 140, 141, 143, 142, 141, 139, 137, 133, 130,\n       119, 115, 121, 127, 136, 139, 143, 144, 143, 142, 140, 140, 143,\n       145, 143, 141, 143, 147, 147, 147, 145, 147, 144, 144, 151, 147,\n       149, 147, 144, 143, 147, 147, 147, 148, 148, 149, 148, 149, 150,\n       150, 149, 149, 150, 146, 148, 148, 147, 146, 147, 146, 146, 146,\n       146, 144, 146, 146, 144, 143, 142, 140, 139, 137, 137, 138, 134,\n       132, 131, 126], dtype=uint8), array([2.85702873])], [array([130, 129, 130, 130, 133, 133, 132, 131, 131, 130, 132, 133, 133,\n       133, 133, 131, 130, 132, 133, 130, 131, 133, 131, 133, 133, 131,\n       134, 133, 133, 133, 131, 131, 132, 131, 133, 135, 132, 130, 129,\n       132, 132, 133, 131, 133, 132, 134, 130, 133, 133, 133, 130, 130,\n       131, 132, 132, 133, 134, 133, 132, 133, 131, 133, 133, 135, 134,\n       133, 133, 133, 133, 134, 136, 137, 138, 138, 137, 138, 139, 139,\n       138, 133, 126, 114, 103, 100, 105, 110, 111, 113, 112, 112, 112,\n       110, 109, 108, 111, 110, 114, 114, 114, 116, 120, 119, 120, 121,\n       122, 125, 126, 127, 126, 128, 126, 133, 133, 135, 132, 133, 131,\n       131, 131, 135], dtype=uint8), array([4.51179147])], [array([141, 140, 139, 143, 142, 144, 141, 141, 141, 140, 140, 140, 140,\n       139, 138, 135, 132, 134, 137, 138, 133, 132, 130, 127, 126, 122,\n       119, 117, 115, 111, 103,  96,  94,  93,  94,  96,  97,  98, 103,\n       105, 107, 109, 112, 112, 114, 116, 115, 115, 118, 116, 117, 119,\n       118, 120, 118, 119, 116, 118, 115, 104,  95,  93,  92,  93, 101,\n       110, 110, 110, 108, 107, 105, 105, 105, 103, 103, 103, 105, 103,\n       106, 106, 107, 107, 106, 107, 108, 112, 109, 112, 114, 113, 115,\n       115, 117, 118, 117, 118, 118, 119, 123, 124, 122, 124, 125, 124,\n       125, 125, 127, 126, 129, 130, 129, 129, 130, 132, 131, 130, 132,\n       132, 133, 133], dtype=uint8), array([4.37560143])], [array([117, 113, 110, 109, 108, 105, 104, 105, 102, 103, 104, 105, 106,\n       104, 106, 106, 107, 107, 107, 107, 106, 107, 108, 109, 110, 111,\n       112, 113, 113, 113, 113, 114, 116, 115, 113, 115, 118, 117, 115,\n       118, 120, 121, 123, 122, 123, 122, 122, 125, 126, 124, 125, 127,\n       128, 126, 126, 126, 128, 125, 125, 127, 129, 130, 130, 129, 131,\n       132, 132, 134, 133, 133, 135, 135, 134, 138, 140, 140, 138, 138,\n       135, 130, 119, 104,  93,  92, 102, 109, 111, 110, 111, 111, 112,\n       111, 112, 114, 114, 116, 117, 119, 123, 123, 123, 126, 128, 130,\n       127, 131, 132, 134, 135, 134, 133, 135, 135, 137, 138, 134, 135,\n       138, 138, 136], dtype=uint8), array([3.95002995])], [array([127, 127, 129, 128, 130, 132, 133, 133, 134, 133, 136, 136, 136,\n       135, 136, 136, 137, 138, 138, 139, 137, 138, 137, 142, 142, 139,\n       140, 139, 139, 139, 140, 138, 140, 139, 139, 141, 140, 140, 141,\n       142, 142, 142, 141, 142, 142, 141, 141, 144, 142, 142, 140, 140,\n       140, 140, 141, 141, 143, 143, 140, 142, 144, 143, 141, 141, 142,\n       141, 135, 135, 142, 139, 142, 142, 142, 144, 141, 139, 139, 136,\n       132, 126, 118, 119, 123, 127, 128, 128, 127, 125, 127, 125, 126,\n       124, 125, 124, 126, 129, 131, 131, 133, 136, 135, 137, 140, 138,\n       137, 138, 134, 133, 132, 129, 129, 129, 130, 131, 133, 132, 133,\n       135, 132, 129], dtype=uint8), array([3.53048839])], [array([143, 142, 144, 144, 145, 146, 146, 143, 142, 145, 148, 146, 144,\n       143, 145, 146, 144, 143, 144, 143, 143, 143, 142, 143, 142, 143,\n       144, 143, 144, 145, 144, 140, 139, 134, 134, 137, 140, 143, 142,\n       144, 140, 145, 145, 145, 144, 145, 146, 144, 145, 145, 145, 145,\n       145, 147, 147, 142, 140, 141, 140, 138, 134, 126, 117, 112, 108,\n       118, 127, 128, 129, 133, 135, 135, 134, 135, 136, 136, 136, 137,\n       138, 137, 136, 134, 134, 134, 134, 135, 136, 134, 133, 133, 135,\n       136, 135, 134, 132, 128, 123, 125, 127, 130, 132, 133, 136, 137,\n       135, 138, 138, 137, 139, 141, 139, 141, 142, 142, 139, 140, 141,\n       142, 142, 142], dtype=uint8), array([3.67640104])], [array([138, 139, 138, 138, 138, 137, 137, 138, 137, 138, 137, 134, 139,\n       137, 136, 136, 134, 133, 133, 134, 135, 134, 136, 135, 132, 132,\n       133, 130, 135, 134, 135, 133, 133, 133, 132, 133, 133, 133, 132,\n       131, 131, 131, 128, 129, 127, 126, 126, 130, 128, 126, 126, 126,\n       127, 125, 125, 127, 129, 130, 125, 123, 105,  91,  89,  88,  94,\n       110, 118, 120, 122, 125, 124, 124, 126, 128, 128, 130, 132, 133,\n       133, 133, 133, 129, 125, 116, 110, 113, 122, 130, 133, 137, 136,\n       137, 138, 139, 138, 139, 139, 138, 138, 138, 136, 138, 135, 138,\n       139, 139, 140, 140, 143, 143, 141, 142, 139, 140, 141, 143, 140,\n       141, 140, 139], dtype=uint8), array([5.21064103])], [array([145, 146, 147, 146, 145, 146, 147, 148, 147, 149, 147, 149, 148,\n       145, 147, 147, 146, 147, 148, 149, 148, 150, 148, 150, 148, 145,\n       143, 143, 145, 146, 147, 147, 147, 146, 145, 146, 147, 147, 146,\n       145, 146, 146, 142, 143, 144, 144, 141, 139, 139, 135, 131, 128,\n       121, 112, 115, 119, 122, 125, 127, 126, 125, 124, 125, 123, 121,\n       120, 117, 113, 103,  88,  84,  91,  91,  81,  81,  98, 106, 109,\n       111, 116, 119, 122, 124, 125, 124, 122, 121, 119, 118, 121, 128,\n       131, 132, 133, 133, 135, 138, 138, 140, 142, 141, 140, 142, 141,\n       143, 142, 142, 143, 143, 144, 144, 143, 146, 145, 142, 144, 143,\n       145, 141, 143], dtype=uint8), array([7.26221294])], [array([146, 145, 142, 144, 145, 145, 143, 143, 144, 145, 144, 144, 145,\n       146, 146, 149, 147, 146, 147, 147, 146, 146, 146, 148, 144, 146,\n       146, 147, 146, 144, 148, 147, 147, 149, 148, 149, 146, 146, 147,\n       147, 147, 148, 147, 145, 146, 146, 144, 144, 146, 149, 145, 147,\n       146, 150, 148, 148, 149, 149, 150, 152, 152, 153, 156, 156, 158,\n       158, 154, 153, 157, 156, 146, 136, 124, 107,  94,  97, 108, 116,\n       115, 115, 114, 112, 114, 116, 118, 118, 117, 121, 122, 123, 127,\n       129, 130, 133, 135, 136, 138, 142, 144, 144, 145, 146, 149, 149,\n       148, 148, 150, 149, 150, 150, 150, 153, 154, 154, 153, 152, 152,\n       153, 153, 150], dtype=uint8), array([5.93755418])], [array([149, 145, 147, 146, 151, 145, 144, 144, 146, 147, 146, 144, 145,\n       145, 146, 146, 147, 147, 147, 147, 148, 149, 147, 147, 146, 148,\n       148, 148, 147, 147, 147, 148, 149, 148, 147, 149, 150, 150, 148,\n       151, 150, 151, 151, 150, 153, 152, 151, 151, 150, 150, 151, 150,\n       153, 152, 151, 151, 151, 154, 153, 154, 154, 151, 155, 157, 157,\n       157, 159, 159, 159, 155, 148, 137, 128, 113, 105, 112, 123, 122,\n       121, 122, 118, 114, 118, 118, 119, 120, 124, 124, 125, 126, 127,\n       133, 133, 135, 132, 135, 139, 141, 142, 145, 147, 149, 150, 151,\n       151, 148, 150, 151, 152, 153, 154, 153, 152, 153, 152, 152, 153,\n       152, 154, 155], dtype=uint8), array([5.5774322])], [array([155, 157, 157, 159, 158, 156, 155, 154, 154, 155, 156, 155, 156,\n       157, 155, 154, 151, 154, 155, 154, 156, 155, 151, 155, 155, 155,\n       153, 157, 158, 156, 156, 156, 160, 157, 157, 156, 156, 157, 158,\n       154, 156, 157, 157, 157, 156, 155, 158, 155, 153, 151, 154, 151,\n       147, 150, 150, 148, 147, 146, 146, 144, 144, 144, 140, 141, 138,\n       135, 132, 119, 106, 103, 104, 111, 127, 136, 140, 140, 143, 146,\n       145, 147, 146, 147, 148, 152, 149, 149, 149, 151, 153, 154, 153,\n       154, 153, 153, 156, 156, 153, 153, 153, 157, 157, 156, 154, 153,\n       154, 156, 154, 153, 153, 151, 152, 152, 154, 153, 157, 157, 153,\n       155, 152, 152], dtype=uint8), array([4.19787153])], [array([154, 154, 155, 156, 154, 157, 154, 156, 157, 157, 157, 157, 158,\n       154, 159, 159, 157, 156, 156, 156, 156, 156, 157, 156, 157, 157,\n       159, 159, 158, 157, 155, 158, 158, 158, 158, 156, 158, 157, 158,\n       157, 156, 155, 155, 153, 154, 158, 158, 155, 156, 155, 153, 153,\n       152, 152, 150, 149, 148, 147, 146, 148, 147, 150, 153, 155, 152,\n       148, 149, 147, 143, 140, 126, 117, 107, 106, 116, 126, 131, 134,\n       138, 139, 139, 142, 144, 146, 149, 147, 151, 151, 152, 155, 153,\n       154, 156, 158, 159, 156, 154, 158, 160, 158, 157, 159, 159, 157,\n       161, 161, 160, 159, 156, 158, 158, 158, 158, 160, 157, 157, 158,\n       157, 156, 156], dtype=uint8), array([3.7441611])], [array([143, 143, 141, 141, 141, 141, 143, 143, 141, 142, 143, 143, 140,\n       140, 141, 144, 141, 139, 140, 136, 136, 135, 135, 137, 136, 136,\n       136, 139, 141, 143, 142, 141, 142, 143, 144, 144, 144, 144, 141,\n       143, 143, 141, 144, 144, 142, 143, 144, 144, 144, 146, 141, 144,\n       144, 143, 143, 143, 144, 146, 148, 146, 147, 147, 149, 147, 147,\n       151, 152, 152, 152, 148, 142, 132, 117, 101,  97, 108, 118, 121,\n       121, 118, 116, 116, 117, 120, 121, 120, 123, 127, 127, 130, 131,\n       131, 134, 136, 135, 136, 141, 140, 140, 144, 146, 145, 143, 143,\n       142, 145, 143, 143, 145, 141, 142, 145, 145, 145, 144, 145, 145,\n       144, 146, 147], dtype=uint8), array([5.20109506])], [array([135, 133, 133, 135, 133, 132, 134, 135, 134, 135, 136, 137, 136,\n       137, 138, 137, 138, 137, 136, 137, 136, 136, 138, 139, 138, 138,\n       138, 137, 139, 142, 139, 138, 137, 139, 139, 138, 139, 136, 138,\n       138, 135, 138, 137, 137, 134, 139, 139, 139, 139, 137, 137, 138,\n       139, 141, 139, 139, 140, 139, 139, 140, 141, 143, 145, 146, 147,\n       148, 149, 150, 151, 150, 147, 141, 131, 117, 100,  90,  98, 109,\n       114, 115, 112, 111, 110, 109, 111, 112, 115, 116, 116, 117, 121,\n       121, 124, 125, 125, 127, 127, 129, 130, 130, 134, 133, 132, 131,\n       131, 132, 132, 134, 130, 131, 131, 130, 132, 131, 133, 132, 131,\n       131, 130, 130], dtype=uint8), array([4.87914297])], [array([162, 160, 162, 163, 165, 167, 169, 168, 168, 169, 168, 167, 166,\n       164, 164, 163, 161, 161, 162, 163, 163, 165, 167, 169, 164, 164,\n       167, 167, 165, 168, 168, 164, 165, 165, 167, 165, 167, 166, 166,\n       165, 164, 164, 165, 166, 166, 167, 166, 165, 165, 163, 166, 165,\n       166, 165, 167, 163, 163, 165, 168, 167, 164, 165, 162, 163, 166,\n       164, 165, 165, 164, 162, 166, 168, 166, 166, 165, 166, 166, 166,\n       164, 166, 170, 168, 165, 164, 165, 168, 168, 167, 164, 166, 167,\n       169, 164, 164, 164, 165, 165, 166, 166, 166, 168, 166, 167, 165,\n       165, 166, 166, 165, 165, 166, 165, 165, 166, 166, 165, 166, 163,\n       162, 162, 166], dtype=uint8), array([0.])], [array([154, 154, 155, 155, 156, 155, 154, 151, 150, 149, 151, 151, 151,\n       149, 150, 151, 151, 151, 151, 153, 151, 150, 152, 150, 153, 152,\n       152, 151, 152, 152, 155, 151, 155, 154, 155, 156, 157, 154, 154,\n       152, 156, 154, 152, 154, 155, 155, 156, 155, 155, 155, 157, 157,\n       155, 155, 156, 158, 160, 159, 158, 159, 156, 159, 158, 158, 157,\n       157, 154, 145, 133, 118, 115, 118, 113, 101, 100, 102, 104, 103,\n       103, 103, 100,  98, 100, 103, 106, 105, 108, 110, 112, 112, 113,\n       115, 116, 120, 123, 125, 129, 131, 134, 135, 137, 138, 137, 139,\n       140, 143, 144, 146, 149, 151, 149, 152, 153, 154, 155, 156, 157,\n       155, 158, 156], dtype=uint8), array([8.52101685])], [array([149, 151, 149, 151, 149, 151, 149, 150, 149, 150, 152, 151, 152,\n       151, 152, 151, 151, 151, 152, 152, 153, 153, 151, 151, 152, 151,\n       154, 157, 154, 150, 151, 154, 153, 156, 158, 155, 153, 153, 155,\n       156, 154, 157, 156, 155, 155, 154, 155, 157, 157, 158, 156, 153,\n       156, 157, 160, 160, 160, 159, 159, 158, 159, 160, 161, 161, 164,\n       155, 144, 130, 121, 122, 126, 121, 106,  97,  93,  97,  96,  97,\n       100,  99,  99, 100,  99,  99, 103, 101, 105, 109, 108, 112, 117,\n       115, 118, 122, 125, 125, 126, 129, 132, 135, 135, 135, 141, 143,\n       142, 143, 145, 148, 150, 149, 150, 151, 153, 154, 153, 152, 153,\n       156, 156, 155], dtype=uint8), array([8.73503977])], [array([126, 125, 125, 127, 125, 118, 112, 116, 120, 126, 132, 137, 143,\n       143, 149, 151, 151, 153, 155, 151, 151, 153, 152, 151, 152, 152,\n       150, 149, 151, 152, 152, 150, 150, 152, 151, 152, 151, 150, 151,\n       152, 151, 149, 149, 148, 146, 149, 150, 146, 143, 146, 146, 147,\n       146, 146, 142, 142, 141, 140, 140, 139, 138, 138, 137, 136, 135,\n       134, 133, 134, 135, 135, 130, 120, 117, 115, 113, 120, 131, 132,\n       135, 135, 135, 137, 139, 141, 141, 140, 142, 145, 145, 145, 145,\n       147, 145, 147, 147, 146, 147, 150, 146, 148, 147, 149, 150, 153,\n       150, 147, 147, 149, 147, 147, 147, 148, 148, 147, 148, 149, 147,\n       144, 147, 147], dtype=uint8), array([4.59109883])], [array([152, 152, 152, 153, 152, 152, 153, 153, 154, 153, 152, 152, 152,\n       152, 154, 153, 154, 153, 153, 150, 153, 154, 153, 152, 153, 153,\n       152, 152, 150, 149, 150, 151, 149, 147, 148, 148, 147, 148, 145,\n       145, 144, 145, 142, 137, 135, 135, 134, 133, 130, 129, 132, 130,\n       126, 125, 126, 129, 128, 129, 130, 130, 127, 114, 104, 114, 126,\n       136, 144, 150, 152, 155, 153, 151, 148, 152, 153, 152, 152, 150,\n       154, 151, 152, 152, 151, 150, 149, 148, 149, 148, 151, 150, 149,\n       149, 148, 148, 147, 145, 146, 147, 145, 144, 147, 146, 143, 142,\n       143, 143, 139, 142, 142, 142, 141, 142, 144, 142, 140, 137, 138,\n       138, 137, 137], dtype=uint8), array([4.34090199])], [array([150, 152, 151, 150, 151, 150, 150, 148, 151, 148, 148, 148, 148,\n       148, 150, 149, 147, 145, 150, 150, 151, 151, 150, 149, 150, 153,\n       149, 142, 149, 148, 148, 147, 144, 145, 144, 143, 142, 142, 144,\n       141, 144, 143, 140, 137, 135, 134, 134, 133, 131, 132, 133, 130,\n       130, 132, 132, 133, 132, 132, 132, 132, 132, 121, 116, 119, 127,\n       142, 149, 150, 150, 148, 149, 149, 147, 146, 141, 142, 141, 144,\n       143, 143, 143, 142, 139, 140, 142, 143, 141, 144, 144, 143, 142,\n       146, 145, 144, 144, 143, 143, 146, 144, 146, 145, 146, 148, 147,\n       146, 147, 148, 147, 146, 145, 144, 148, 147, 145, 142, 140, 141,\n       138, 141, 143], dtype=uint8), array([4.35067225])], [array([148, 150, 152, 153, 152, 152, 152, 149, 148, 149, 150, 151, 151,\n       151, 150, 149, 149, 151, 152, 152, 151, 149, 150, 150, 150, 148,\n       149, 150, 150, 149, 148, 147, 146, 144, 143, 139, 139, 140, 137,\n       134, 133, 135, 133, 132, 128, 128, 128, 129, 127, 124, 125, 127,\n       129, 128, 128, 129, 128, 127, 123, 112, 111, 119, 132, 141, 147,\n       149, 150, 150, 150, 148, 147, 148, 146, 146, 142, 142, 141, 140,\n       138, 137, 136, 136, 136, 133, 133, 132, 132, 133, 131, 128, 129,\n       121, 114, 119, 137, 140, 144, 147, 147, 147, 148, 143, 139, 137,\n       135, 137, 139, 141, 142, 142, 142, 143, 143, 142, 141, 140, 139,\n       138, 138, 138], dtype=uint8), array([4.18356936])], [array([140, 142, 141, 139, 139, 136, 137, 137, 140, 139, 137, 134, 137,\n       140, 140, 137, 138, 138, 137, 138, 138, 137, 140, 139, 139, 138,\n       135, 137, 138, 137, 137, 138, 136, 137, 136, 135, 137, 137, 137,\n       137, 135, 137, 138, 138, 139, 139, 137, 139, 138, 139, 138, 137,\n       137, 138, 138, 138, 137, 137, 137, 139, 139, 139, 141, 141, 139,\n       136, 138, 138, 138, 137, 136, 132, 122, 117, 115, 115, 116, 121,\n       126, 126, 125, 122, 120, 118, 118, 116, 116, 117, 118, 119, 120,\n       121, 121, 123, 126, 128, 128, 130, 132, 131, 131, 133, 136, 138,\n       133, 136, 135, 136, 139, 138, 138, 139, 140, 139, 136, 138, 138,\n       139, 139, 139], dtype=uint8), array([5.923182])], [array([142, 144, 142, 140, 141, 140, 141, 140, 141, 142, 142, 140, 140,\n       141, 144, 142, 140, 139, 136, 132, 128, 126, 128, 130, 132, 133,\n       135, 139, 141, 137, 138, 133, 127, 119, 114, 117, 121, 128, 132,\n       134, 136, 135, 137, 139, 141, 142, 143, 141, 144, 146, 145, 144,\n       141, 142, 139, 146, 146, 150, 151, 154, 156, 158, 157, 154, 149,\n       142, 130, 127, 126, 117, 104,  91,  86,  86,  85,  83,  85,  85,\n        88,  90,  92,  92,  92,  93,  95,  97,  99, 100, 103, 103, 106,\n       111, 113, 114, 117, 121, 121, 125, 126, 128, 129, 135, 133, 133,\n       134, 136, 136, 138, 143, 141, 141, 143, 144, 145, 145, 143, 143,\n       145, 146, 147], dtype=uint8), array([8.89809448])], [array([138, 139, 140, 137, 139, 139, 141, 138, 139, 139, 133, 133, 137,\n       141, 139, 141, 139, 140, 141, 141, 140, 140, 142, 143, 143, 140,\n       139, 140, 142, 139, 144, 143, 143, 144, 139, 139, 137, 140, 141,\n       141, 141, 142, 139, 141, 139, 139, 140, 140, 140, 142, 139, 138,\n       136, 138, 138, 136, 134, 135, 134, 135, 134, 132, 132, 132, 133,\n       131, 128, 126, 125, 124, 122, 115, 102,  96,  97,  96,  95, 103,\n       116, 124, 126, 127, 128, 127, 128, 132, 133, 132, 133, 134, 136,\n       137, 138, 139, 139, 142, 141, 142, 140, 140, 142, 143, 142, 141,\n       140, 139, 138, 130, 129, 124, 124, 127, 124, 125, 133, 132, 138,\n       142, 141, 142], dtype=uint8), array([4.7800506])], [array([142, 140, 141, 139, 142, 140, 141, 140, 141, 140, 140, 141, 140,\n       141, 144, 142, 140, 139, 140, 141, 141, 140, 139, 140, 141, 141,\n       142, 141, 141, 140, 141, 140, 139, 140, 139, 140, 142, 138, 140,\n       137, 141, 137, 133, 138, 136, 136, 136, 136, 134, 132, 129, 130,\n       131, 127, 126, 126, 126, 124, 122, 121, 121, 120, 119, 118, 119,\n       119, 121, 121, 119, 119, 115, 102,  97, 102, 103, 108, 121, 127,\n       130, 128, 129, 130, 132, 131, 130, 129, 131, 136, 136, 135, 135,\n       135, 135, 135, 137, 137, 138, 138, 136, 137, 138, 139, 138, 138,\n       137, 136, 135, 138, 138, 139, 140, 139, 140, 140, 141, 140, 139,\n       140, 138, 138], dtype=uint8), array([5.29939395])], [array([142, 140, 141, 142, 142, 138, 143, 138, 140, 139, 143, 142, 144,\n       143, 141, 139, 138, 141, 140, 137, 139, 140, 137, 138, 140, 140,\n       135, 136, 138, 140, 142, 139, 138, 136, 140, 138, 135, 138, 141,\n       137, 138, 136, 137, 141, 138, 133, 136, 136, 136, 134, 138, 132,\n       132, 137, 133, 131, 133, 128, 133, 129, 128, 129, 131, 130, 131,\n       128, 129, 128, 127, 122, 122, 114, 106, 101, 106, 102, 116, 121,\n       126, 122, 125, 121, 127, 127, 125, 127, 127, 125, 130, 128, 129,\n       131, 135, 129, 133, 135, 134, 134, 138, 133, 136, 139, 137, 138,\n       136, 138, 133, 138, 139, 135, 139, 138, 139, 135, 137, 139, 139,\n       138, 135, 138], dtype=uint8), array([5.08347615])], [array([172, 173, 173, 173, 171, 174, 174, 173, 174, 173, 174, 169, 173,\n       174, 172, 168, 169, 170, 171, 172, 169, 172, 172, 172, 172, 174,\n       172, 172, 174, 175, 172, 171, 172, 174, 171, 172, 174, 170, 173,\n       170, 169, 171, 169, 165, 166, 165, 161, 160, 159, 147, 124, 107,\n       117, 131, 118,  90,  81,  97, 115, 118, 120, 122, 125, 128, 132,\n       137, 139, 141, 145, 146, 152, 153, 155, 158, 160, 162, 164, 165,\n       165, 167, 168, 169, 169, 167, 168, 168, 167, 171, 170, 171, 171,\n       173, 172, 172, 172, 174, 173, 174, 172, 173, 174, 174, 175, 175,\n       172, 172, 173, 174, 176, 176, 174, 174, 173, 172, 174, 174, 173,\n       172, 173, 172], dtype=uint8), array([8.36581426])], [array([173, 172, 173, 170, 172, 175, 174, 171, 171, 170, 169, 165, 164,\n       165, 165, 163, 162, 162, 158, 157, 157, 156, 151, 145, 138, 136,\n       142, 148, 153, 161, 166, 166, 165, 166, 166, 166, 164, 165, 165,\n       165, 164, 165, 164, 163, 164, 162, 161, 160, 156, 155, 152, 148,\n       142, 138, 135, 134, 130, 126, 123, 125, 129, 131, 132, 128, 111,\n        90,  91, 103, 108, 102,  99, 119, 143, 155, 160, 162, 159, 163,\n       166, 165, 166, 169, 168, 169, 168, 170, 171, 171, 171, 172, 172,\n       171, 178, 172, 170, 172, 175, 177, 175, 175, 172, 174, 169, 169,\n       172, 171, 174, 176, 173, 172, 172, 175, 170, 173, 172, 171, 173,\n       175, 173, 170], dtype=uint8), array([8.89809448])], [array([174, 175, 172, 173, 173, 172, 173, 173, 171, 172, 173, 172, 170,\n       171, 170, 173, 168, 167, 168, 167, 171, 170, 171, 171, 172, 170,\n       170, 172, 174, 170, 169, 170, 170, 172, 170, 170, 169, 171, 172,\n       168, 173, 175, 174, 170, 168, 172, 171, 171, 171, 173, 171, 172,\n       173, 173, 173, 175, 173, 172, 173, 171, 172, 172, 171, 170, 170,\n       169, 168, 166, 166, 162, 155, 141, 127, 121, 118, 123, 140, 150,\n       154, 155, 157, 158, 165, 163, 165, 164, 165, 167, 167, 170, 168,\n       169, 170, 170, 170, 171, 173, 171, 170, 170, 173, 171, 170, 170,\n       171, 172, 171, 172, 172, 171, 171, 171, 171, 170, 168, 170, 170,\n       168, 170, 172], dtype=uint8), array([4.7800506])], [array([173, 171, 171, 173, 173, 175, 172, 173, 173, 173, 172, 170, 170,\n       171, 170, 171, 173, 172, 174, 175, 171, 172, 172, 173, 170, 172,\n       171, 173, 172, 175, 172, 172, 172, 171, 173, 171, 172, 172, 170,\n       172, 172, 173, 173, 170, 171, 171, 170, 172, 170, 170, 173, 175,\n       176, 172, 175, 172, 176, 172, 172, 171, 171, 173, 174, 171, 168,\n       169, 168, 167, 163, 150, 130, 121, 121, 109, 110, 135, 149, 151,\n       152, 157, 158, 159, 162, 162, 161, 165, 166, 168, 169, 169, 169,\n       169, 170, 170, 169, 169, 168, 162, 153, 143, 139, 143, 153, 165,\n       168, 169, 168, 170, 173, 173, 176, 172, 169, 170, 170, 171, 172,\n       173, 174, 176], dtype=uint8), array([5.29939395])], [array([165, 166, 165, 164, 165, 167, 167, 167, 167, 166, 167, 167, 170,\n       172, 169, 168, 169, 169, 168, 168, 167, 169, 170, 170, 170, 171,\n       170, 170, 170, 169, 169, 170, 168, 168, 168, 168, 169, 169, 169,\n       169, 172, 170, 170, 171, 170, 168, 171, 170, 169, 170, 171, 170,\n       168, 170, 168, 168, 171, 171, 168, 170, 171, 171, 170, 170, 170,\n       167, 170, 169, 166, 163, 162, 152, 135, 127, 122, 124, 139, 149,\n       153, 161, 161, 166, 164, 163, 165, 171, 171, 169, 171, 172, 172,\n       171, 171, 173, 171, 171, 174, 173, 171, 173, 173, 171, 174, 172,\n       175, 174, 175, 175, 174, 173, 175, 175, 171, 171, 172, 172, 173,\n       171, 173, 175], dtype=uint8), array([5.08347615])], [array([168, 168, 170, 170, 168, 167, 167, 166, 168, 169, 166, 169, 169,\n       170, 170, 169, 171, 168, 167, 168, 170, 172, 170, 169, 168, 171,\n       170, 169, 174, 169, 170, 168, 169, 172, 172, 169, 170, 171, 168,\n       171, 173, 169, 172, 170, 167, 172, 170, 172, 166, 167, 168, 171,\n       172, 172, 173, 173, 171, 172, 170, 169, 166, 166, 169, 167, 167,\n       168, 168, 165, 163, 159, 149, 137, 129, 128, 131, 140, 148, 152,\n       153, 157, 157, 162, 162, 162, 164, 166, 168, 169, 169, 168, 169,\n       170, 170, 171, 171, 170, 174, 170, 171, 170, 173, 174, 172, 172,\n       173, 172, 168, 170, 173, 173, 173, 171, 172, 170, 168, 169, 169,\n       170, 169, 167], dtype=uint8), array([5.923182])], [array([168, 168, 166, 165, 161, 156, 153, 149, 145, 141, 139, 136, 141,\n       145, 143, 144, 143, 143, 144, 147, 148, 146, 148, 147, 147, 151,\n       154, 154, 154, 157, 158, 156, 157, 158, 160, 160, 164, 162, 166,\n       168, 165, 166, 166, 165, 168, 169, 169, 169, 169, 169, 171, 171,\n       168, 169, 170, 169, 169, 172, 170, 170, 169, 171, 169, 169, 170,\n       169, 167, 166, 167, 157, 146, 134, 127, 122, 129, 140, 144, 145,\n       147, 147, 150, 149, 146, 153, 154, 153, 159, 163, 165, 164, 165,\n       167, 165, 165, 167, 169, 166, 168, 168, 170, 166, 167, 169, 168,\n       169, 170, 169, 171, 173, 172, 170, 169, 171, 172, 172, 169, 169,\n       169, 169, 166], dtype=uint8), array([4.59109883])], [array([162, 163, 165, 165, 166, 167, 167, 165, 172, 169, 168, 169, 169,\n       167, 168, 168, 167, 167, 167, 167, 167, 167, 165, 170, 171, 171,\n       167, 170, 168, 170, 169, 166, 166, 168, 168, 168, 167, 168, 168,\n       168, 167, 168, 166, 169, 166, 170, 170, 170, 170, 168, 168, 169,\n       168, 169, 169, 169, 169, 168, 166, 161, 160, 153, 146, 142, 136,\n       140, 144, 146, 144, 144, 146, 148, 147, 147, 148, 149, 150, 153,\n       150, 156, 154, 156, 157, 159, 161, 160, 159, 161, 165, 165, 163,\n       165, 167, 169, 169, 170, 169, 169, 168, 168, 169, 169, 170, 169,\n       169, 168, 169, 168, 168, 169, 170, 172, 169, 167, 167, 167, 169,\n       166, 168, 167], dtype=uint8), array([4.34090199])], [array([170, 167, 167, 167, 165, 167, 168, 164, 169, 170, 168, 166, 168,\n       166, 169, 166, 166, 169, 167, 169, 167, 166, 166, 168, 166, 163,\n       167, 168, 166, 166, 165, 166, 166, 169, 168, 162, 162, 162, 158,\n       155, 153, 155, 152, 149, 146, 144, 131, 112,  99, 102,  96,  79,\n        70,  82,  99, 112, 110, 110, 111, 113, 114, 117, 119, 125, 125,\n       127, 131, 136, 137, 142, 143, 147, 150, 152, 152, 155, 157, 157,\n       159, 161, 161, 162, 163, 164, 166, 167, 164, 165, 166, 167, 170,\n       167, 168, 168, 169, 169, 167, 170, 167, 166, 167, 169, 167, 167,\n       166, 164, 165, 168, 165, 162, 165, 165, 164, 163, 164, 165, 165,\n       164, 165, 163], dtype=uint8), array([8.52101685])], [array([167, 166, 167, 169, 167, 168, 166, 168, 169, 169, 170, 168, 168,\n       168, 168, 168, 169, 170, 168, 170, 171, 171, 171, 166, 168, 170,\n       170, 169, 168, 169, 173, 169, 168, 169, 167, 166, 166, 168, 168,\n       163, 161, 159, 159, 159, 158, 156, 152, 144, 130, 116, 116, 126,\n       127, 107,  89,  94, 107, 114, 113, 110, 111, 111, 114, 118, 119,\n       121, 125, 129, 132, 133, 137, 138, 138, 142, 144, 149, 149, 151,\n       155, 157, 157, 160, 161, 162, 162, 164, 163, 165, 166, 166, 166,\n       168, 165, 169, 168, 167, 165, 167, 167, 168, 168, 168, 167, 165,\n       166, 166, 165, 169, 165, 167, 168, 168, 167, 169, 166, 166, 166,\n       168, 167, 169], dtype=uint8), array([8.73503977])], [array([167, 167, 167, 166, 167, 168, 170, 168, 170, 167, 165, 164, 167,\n       167, 169, 169, 168, 166, 168, 167, 168, 168, 167, 165, 165, 166,\n       169, 167, 168, 165, 163, 166, 166, 165, 167, 166, 167, 167, 166,\n       167, 168, 168, 165, 167, 169, 167, 167, 170, 169, 167, 166, 167,\n       169, 167, 167, 164, 162, 156, 146, 138, 132, 127, 128, 137, 142,\n       140, 139, 139, 139, 140, 142, 143, 146, 147, 150, 152, 155, 157,\n       157, 159, 161, 162, 163, 165, 165, 166, 167, 167, 167, 167, 166,\n       170, 170, 170, 168, 166, 166, 161, 158, 148, 139, 136, 141, 145,\n       144, 145, 145, 146, 148, 149, 150, 150, 151, 154, 156, 159, 159,\n       163, 160, 161], dtype=uint8), array([4.18356936])], [array([167, 166, 165, 168, 167, 167, 168, 169, 169, 168, 169, 169, 168,\n       168, 170, 169, 169, 168, 166, 166, 168, 165, 165, 164, 165, 166,\n       167, 167, 171, 165, 166, 167, 169, 167, 168, 169, 170, 169, 165,\n       165, 168, 170, 167, 167, 167, 165, 166, 168, 165, 168, 166, 167,\n       168, 168, 169, 167, 169, 172, 167, 167, 166, 160, 153, 145, 137,\n       138, 141, 145, 142, 142, 142, 143, 144, 145, 145, 147, 149, 152,\n       153, 155, 156, 159, 161, 160, 161, 163, 161, 163, 164, 165, 165,\n       167, 167, 166, 166, 169, 170, 167, 171, 172, 168, 169, 168, 166,\n       170, 170, 172, 170, 169, 168, 164, 162, 161, 160, 161, 160, 159,\n       158, 159, 161], dtype=uint8), array([4.35067225])], [array([150, 152, 149, 148, 150, 152, 152, 150, 151, 152, 154, 154, 153,\n       151, 150, 152, 149, 150, 147, 152, 150, 150, 153, 152, 153, 150,\n       151, 151, 151, 151, 153, 154, 153, 152, 154, 151, 153, 152, 150,\n       151, 148, 153, 156, 150, 148, 148, 150, 150, 150, 151, 151, 151,\n       151, 152, 154, 153, 151, 153, 153, 152, 153, 151, 151, 151, 149,\n       149, 150, 150, 150, 148, 148, 147, 149, 148, 149, 148, 148, 147,\n       148, 147, 149, 149, 149, 149, 148, 151, 147, 148, 149, 149, 147,\n       145, 147, 146, 145, 145, 147, 147, 146, 147, 145, 147, 146, 147,\n       145, 145, 148, 147, 146, 149, 151, 147, 147, 149, 146, 146, 146,\n       146, 147, 147], dtype=uint8), array([0.])], [array([159, 158, 160, 160, 159, 159, 162, 160, 160, 158, 158, 156, 159,\n       160, 159, 158, 159, 160, 160, 158, 159, 157, 158, 160, 160, 159,\n       159, 161, 158, 157, 160, 161, 160, 159, 161, 158, 160, 160, 158,\n       157, 158, 157, 157, 157, 156, 161, 158, 157, 156, 156, 155, 159,\n       159, 158, 156, 155, 158, 159, 160, 160, 161, 159, 158, 161, 161,\n       163, 161, 160, 162, 160, 162, 161, 157, 146, 132, 120, 115, 105,\n       106, 124, 132, 133, 134, 136, 135, 135, 133, 133, 135, 135, 138,\n       139, 139, 142, 143, 143, 145, 147, 147, 147, 152, 152, 154, 154,\n       154, 153, 151, 151, 154, 153, 156, 159, 159, 160, 161, 160, 160,\n       159, 160, 159], dtype=uint8), array([4.75818342])], [array([161, 160, 160, 160, 160, 159, 158, 159, 159, 159, 159, 159, 161,\n       159, 158, 158, 158, 160, 159, 159, 159, 160, 157, 158, 157, 155,\n       158, 158, 158, 156, 153, 151, 155, 150, 150, 146, 144, 143, 143,\n       143, 141, 141, 139, 140, 139, 138, 137, 138, 139, 139, 138, 137,\n       138, 139, 139, 140, 139, 132, 126, 129, 138, 148, 156, 160, 159,\n       161, 160, 161, 158, 158, 157, 158, 159, 158, 159, 159, 160, 157,\n       158, 161, 158, 159, 158, 158, 157, 159, 158, 158, 158, 157, 157,\n       155, 156, 157, 156, 155, 154, 153, 153, 152, 151, 153, 154, 154,\n       154, 156, 156, 154, 154, 157, 158, 158, 158, 158, 156, 158, 157,\n       159, 160, 158], dtype=uint8), array([3.84824603])], [array([157, 159, 159, 160, 159, 157, 157, 158, 159, 157, 156, 157, 156,\n       154, 157, 157, 156, 154, 151, 153, 154, 156, 156, 155, 155, 156,\n       153, 152, 156, 157, 155, 155, 153, 153, 154, 152, 150, 153, 152,\n       152, 152, 151, 152, 153, 150, 149, 148, 147, 147, 144, 144, 141,\n       141, 139, 137, 137, 135, 135, 132, 132, 131, 132, 130, 129, 127,\n       128, 128, 128, 128, 116, 104, 106, 114, 121, 126, 136, 144, 147,\n       148, 152, 152, 152, 152, 152, 153, 153, 153, 153, 152, 153, 153,\n       152, 151, 150, 148, 147, 147, 147, 146, 142, 139, 132, 127, 126,\n       126, 124, 128, 133, 139, 142, 146, 147, 149, 147, 150, 152, 153,\n       153, 152, 154], dtype=uint8), array([5.52762087])], [array([156, 160, 162, 158, 157, 158, 157, 156, 156, 156, 157, 157, 159,\n       159, 156, 155, 156, 156, 156, 157, 156, 155, 154, 155, 154, 153,\n       153, 152, 149, 149, 148, 143, 146, 141, 140, 140, 137, 137, 137,\n       135, 134, 131, 129, 125, 126, 123, 121, 119, 122, 125, 126, 125,\n       130, 127, 128, 126, 115, 107, 114, 124, 130, 140, 151, 155, 157,\n       160, 158, 156, 156, 156, 158, 157, 156, 156, 155, 154, 154, 154,\n       153, 154, 157, 157, 154, 153, 153, 154, 152, 151, 153, 154, 153,\n       152, 152, 153, 153, 152, 154, 157, 152, 151, 152, 153, 153, 152,\n       149, 150, 152, 150, 151, 150, 149, 147, 151, 149, 151, 148, 147,\n       147, 146, 146], dtype=uint8), array([5.24173503])], [array([150, 151, 151, 151, 151, 153, 152, 154, 152, 152, 152, 149, 147,\n       146, 150, 150, 150, 151, 149, 146, 147, 150, 145, 144, 147, 145,\n       143, 142, 142, 142, 138, 134, 132, 130, 126, 128, 131, 128, 126,\n       128, 125, 126, 127, 125, 126, 128, 131, 132, 131, 133, 134, 133,\n       133, 131, 126, 118, 119, 132, 140, 151, 149, 150, 150, 151, 151,\n       150, 149, 148, 145, 148, 146, 147, 148, 147, 146, 147, 146, 147,\n       147, 149, 147, 146, 146, 143, 143, 145, 146, 146, 146, 145, 147,\n       147, 145, 144, 145, 143, 142, 145, 146, 146, 146, 146, 147, 146,\n       145, 148, 147, 147, 146, 146, 147, 147, 145, 146, 148, 146, 146,\n       146, 146, 145], dtype=uint8), array([3.48806279])], [array([148, 150, 150, 147, 148, 150, 146, 147, 147, 148, 146, 148, 147,\n       148, 147, 146, 145, 146, 144, 145, 147, 145, 148, 144, 145, 146,\n       147, 145, 146, 146, 145, 145, 145, 149, 147, 145, 147, 148, 147,\n       145, 147, 145, 146, 147, 145, 144, 147, 146, 144, 145, 144, 145,\n       145, 148, 144, 145, 144, 144, 142, 141, 142, 142, 140, 139, 139,\n       141, 140, 142, 139, 141, 138, 139, 138, 135, 134, 126, 114, 109,\n       104, 100, 108, 121, 124, 126, 125, 125, 126, 127, 124, 126, 127,\n       128, 128, 128, 127, 128, 126, 129, 128, 130, 128, 128, 124, 126,\n       126, 125, 126, 127, 126, 125, 126, 124, 125, 126, 123, 123, 125,\n       121, 116, 105], dtype=uint8), array([4.68352392])], [array([146, 148, 146, 147, 147, 147, 145, 144, 146, 144, 144, 146, 149,\n       143, 146, 144, 145, 144, 144, 144, 144, 140, 141, 142, 141, 141,\n       137, 137, 140, 142, 139, 137, 138, 141, 135, 134, 133, 130, 128,\n       127, 120, 107, 104, 105, 107, 110, 122, 127, 130, 129, 130, 130,\n       131, 131, 132, 133, 131, 128, 130, 132, 132, 128, 132, 132, 132,\n       131, 131, 133, 134, 131, 133, 128, 117, 111, 106, 105, 114, 126,\n       135, 137, 138, 140, 142, 143, 144, 145, 143, 144, 144, 144, 146,\n       145, 143, 144, 145, 146, 146, 146, 147, 145, 146, 146, 145, 145,\n       145, 146, 145, 145, 145, 149, 146, 147, 146, 145, 144, 144, 145,\n       144, 143, 146], dtype=uint8), array([4.45399496])], [array([162, 160, 159, 159, 158, 159, 159, 160, 158, 158, 160, 160, 159,\n       157, 157, 159, 160, 160, 163, 163, 161, 161, 160, 156, 155, 156,\n       158, 161, 156, 160, 159, 160, 159, 161, 161, 161, 160, 157, 157,\n       157, 158, 159, 159, 156, 156, 160, 159, 158, 160, 159, 159, 159,\n       160, 159, 158, 159, 161, 156, 160, 160, 161, 158, 160, 155, 156,\n       157, 158, 159, 156, 157, 159, 159, 155, 157, 156, 158, 157, 158,\n       156, 158, 159, 159, 156, 156, 158, 159, 158, 158, 157, 159, 159,\n       157, 158, 158, 157, 157, 157, 158, 156, 156, 157, 159, 158, 158,\n       159, 157, 160, 158, 161, 156, 154, 156, 157, 156, 154, 157, 157,\n       159, 155, 155], dtype=uint8), array([0.])], [array([171, 172, 174, 171, 171, 171, 169, 170, 174, 174, 174, 171, 171,\n       170, 169, 176, 173, 170, 171, 170, 172, 171, 173, 173, 172, 172,\n       173, 169, 171, 172, 172, 172, 171, 169, 170, 171, 170, 169, 171,\n       169, 170, 172, 172, 174, 171, 172, 168, 166, 168, 170, 171, 169,\n       170, 165, 165, 166, 164, 162, 161, 159, 159, 160, 154, 154, 149,\n       134, 111, 104, 109, 107,  90,  82,  95, 111, 120, 122, 126, 126,\n       129, 133, 137, 141, 143, 146, 148, 153, 156, 158, 158, 162, 164,\n       164, 165, 168, 169, 170, 168, 171, 170, 171, 171, 171, 170, 168,\n       168, 170, 169, 171, 171, 170, 171, 169, 170, 171, 171, 172, 172,\n       170, 170, 170], dtype=uint8), array([8.71474618])], [array([174, 175, 173, 173, 170, 172, 174, 170, 172, 173, 173, 171, 173,\n       173, 172, 172, 172, 171, 173, 172, 171, 174, 173, 172, 170, 170,\n       171, 171, 171, 171, 173, 175, 174, 172, 175, 171, 169, 172, 170,\n       171, 170, 165, 169, 169, 170, 169, 170, 173, 175, 170, 170, 170,\n       167, 168, 169, 166, 165, 166, 163, 163, 160, 159, 153, 155, 150,\n       149, 137, 116,  90,  74,  87, 109, 116, 110, 102, 108, 124, 135,\n       136, 137, 139, 142, 146, 149, 149, 153, 153, 157, 158, 159, 158,\n       162, 165, 166, 165, 167, 168, 168, 168, 168, 168, 166, 170, 172,\n       169, 169, 169, 173, 171, 170, 170, 172, 172, 173, 171, 172, 172,\n       172, 172, 170], dtype=uint8), array([9.02551505])], [array([137, 139, 145, 146, 146, 145, 146, 148, 151, 151, 152, 154, 153,\n       154, 157, 156, 157, 159, 161, 159, 158, 159, 161, 163, 162, 163,\n       165, 165, 162, 164, 165, 166, 169, 167, 166, 167, 166, 164, 167,\n       165, 167, 167, 167, 164, 161, 155, 144, 123, 115, 125, 123, 104,\n       101, 109, 116, 117, 120, 121, 124, 130, 133, 137, 140, 142, 145,\n       152, 152, 153, 155, 159, 160, 162, 163, 166, 168, 167, 168, 168,\n       166, 169, 168, 168, 169, 169, 171, 170, 172, 173, 172, 171, 170,\n       172, 169, 171, 170, 171, 172, 171, 169, 170, 171, 170, 172, 170,\n       169, 171, 173, 171, 171, 171, 170, 170, 170, 173, 171, 170, 171,\n       171, 172, 169], dtype=uint8), array([7.32964192])], [array([173, 174, 171, 173, 173, 173, 173, 173, 172, 173, 171, 173, 177,\n       173, 176, 173, 172, 172, 174, 175, 174, 173, 173, 173, 174, 176,\n       175, 172, 175, 174, 172, 170, 173, 171, 169, 170, 167, 164, 159,\n       161, 159, 162, 168, 167, 168, 169, 170, 171, 173, 173, 172, 171,\n       171, 170, 167, 168, 167, 170, 170, 165, 163, 162, 157, 143, 131,\n       126, 118, 120, 131, 140, 144, 144, 149, 153, 158, 161, 161, 163,\n       164, 165, 169, 170, 168, 173, 172, 172, 171, 171, 172, 174, 174,\n       174, 173, 172, 172, 172, 175, 165, 176, 174, 175, 174, 174, 175,\n       174, 173, 174, 174, 175, 176, 173, 173, 172, 174, 173, 172, 172,\n       173, 173, 172], dtype=uint8), array([4.88385177])], [array([168, 169, 171, 171, 172, 170, 170, 170, 172, 171, 170, 171, 171,\n       169, 168, 167, 172, 172, 169, 169, 169, 169, 170, 171, 172, 170,\n       172, 171, 173, 173, 170, 170, 170, 169, 168, 165, 163, 162, 165,\n       159, 156, 155, 158, 163, 165, 166, 167, 168, 166, 165, 167, 167,\n       162, 158, 155, 153, 150, 148, 148, 147, 150, 149, 148, 150, 142,\n       139, 137, 139, 132, 113,  94,  94, 104, 106, 103, 117, 144, 155,\n       158, 161, 161, 165, 165, 166, 168, 169, 169, 164, 167, 165, 171,\n       172, 170, 171, 169, 169, 171, 172, 172, 171, 170, 171, 173, 171,\n       173, 174, 172, 172, 171, 172, 171, 173, 175, 174, 175, 174, 174,\n       171, 172, 173], dtype=uint8), array([6.54541434])], [array([167, 164, 161, 160, 160, 160, 157, 157, 159, 157, 158, 157, 155,\n       154, 151, 150, 148, 147, 137, 127, 120, 119, 124, 132, 141, 148,\n       152, 155, 153, 152, 149, 140, 128, 119, 115, 123, 128, 135, 139,\n       137, 136, 137, 140, 149, 154, 162, 161, 163, 166, 166, 165, 167,\n       169, 167, 168, 166, 168, 168, 168, 165, 161, 162, 159, 155, 156,\n       154, 153, 153, 150, 135, 112, 100, 111, 117, 106, 109, 127, 149,\n       152, 160, 161, 161, 163, 167, 166, 166, 168, 170, 168, 169, 169,\n       173, 175, 171, 171, 172, 174, 174, 172, 174, 174, 173, 174, 173,\n       172, 169, 172, 172, 173, 174, 172, 174, 171, 172, 172, 167, 165,\n       169, 171, 173], dtype=uint8), array([7.03218657])], [array([162, 159, 159, 158, 155, 152, 148, 145, 135, 129, 109, 104, 106,\n       109, 112, 114, 116, 122, 134, 145, 153, 155, 157, 157, 161, 160,\n       157, 160, 161, 163, 163, 163, 164, 164, 166, 168, 165, 170, 172,\n       171, 168, 168, 168, 170, 174, 171, 168, 165, 165, 167, 167, 164,\n       164, 161, 159, 158, 156, 155, 149, 148, 145, 142, 138, 135, 134,\n       136, 134, 128, 115,  99,  97, 109, 110, 107, 118, 139, 153, 157,\n       156, 162, 162, 163, 164, 164, 164, 168, 168, 168, 169, 170, 170,\n       171, 171, 172, 173, 172, 175, 174, 175, 172, 171, 176, 174, 173,\n       174, 175, 174, 175, 174, 173, 172, 171, 171, 172, 171, 170, 170,\n       170, 170, 172], dtype=uint8), array([6.38074043])], [array([165, 162, 163, 163, 164, 162, 160, 161, 163, 163, 163, 166, 165,\n       163, 164, 167, 165, 170, 166, 170, 167, 169, 169, 170, 169, 168,\n       168, 169, 167, 167, 166, 165, 161, 168, 171, 166, 169, 170, 170,\n       168, 169, 169, 168, 168, 166, 167, 168, 168, 166, 165, 168, 163,\n       166, 166, 163, 165, 164, 163, 164, 165, 163, 161, 157, 154, 155,\n       158, 159, 160, 160, 164, 159, 160, 156, 150, 144, 128, 115, 120,\n       127, 129, 136, 153, 163, 164, 169, 167, 170, 170, 168, 169, 169,\n       170, 172, 172, 170, 169, 169, 170, 169, 170, 174, 170, 174, 173,\n       170, 169, 170, 170, 170, 170, 170, 169, 172, 171, 170, 173, 170,\n       173, 176, 174], dtype=uint8), array([5.54238319])], [array([171, 170, 171, 173, 172, 172, 173, 175, 177, 176, 176, 174, 173,\n       173, 170, 174, 173, 173, 173, 173, 174, 176, 174, 172, 169, 172,\n       171, 170, 169, 167, 170, 167, 166, 168, 169, 166, 167, 167, 163,\n       164, 158, 156, 154, 154, 151, 153, 153, 152, 152, 150, 148, 148,\n       154, 160, 160, 163, 164, 163, 164, 167, 168, 167, 166, 165, 165,\n       164, 165, 163, 160, 159, 159, 156, 153, 150, 146, 145, 141, 135,\n       135, 140, 145, 152, 163, 169, 169, 171, 169, 169, 170, 171, 170,\n       170, 172, 170, 169, 171, 173, 172, 167, 163, 165, 167, 162, 162,\n       163, 163, 166, 165, 162, 167, 170, 168, 171, 170, 169, 171, 174,\n       172, 173, 170], dtype=uint8), array([4.58639866])], [array([175, 175, 178, 173, 174, 175, 173, 174, 174, 178, 178, 176, 176,\n       179, 175, 173, 176, 173, 173, 173, 173, 173, 174, 176, 176, 173,\n       171, 172, 173, 173, 174, 172, 172, 173, 176, 175, 175, 175, 175,\n       174, 175, 174, 173, 172, 174, 172, 170, 169, 169, 167, 166, 164,\n       156, 145, 135, 123, 109, 109, 124, 138, 142, 138, 140, 142, 141,\n       142, 147, 149, 155, 158, 159, 162, 164, 168, 169, 169, 169, 170,\n       172, 174, 176, 177, 175, 173, 174, 176, 179, 174, 172, 175, 175,\n       175, 175, 179, 176, 175, 174, 177, 176, 176, 177, 177, 174, 174,\n       177, 176, 174, 175, 177, 175, 173, 175, 177, 177, 176, 174, 173,\n       173, 174, 178], dtype=uint8), array([5.4984222])], [array([163, 161, 158, 157, 160, 157, 152, 145, 136, 122, 109,  99,  96,\n       100, 107, 110, 117, 120, 126, 128, 130, 131, 135, 134, 141, 145,\n       150, 152, 155, 161, 161, 161, 164, 164, 162, 164, 164, 163, 162,\n       164, 167, 166, 163, 166, 168, 167, 167, 165, 166, 167, 167, 168,\n       168, 168, 164, 162, 162, 163, 166, 166, 164, 165, 164, 162, 159,\n       156, 146, 127, 117, 123, 128, 117,  96,  91, 102, 111, 117, 120,\n       122, 125, 128, 132, 135, 138, 141, 145, 146, 153, 157, 158, 161,\n       162, 160, 163, 165, 170, 170, 169, 168, 172, 171, 170, 169, 169,\n       168, 171, 169, 171, 173, 175, 173, 172, 172, 172, 173, 173, 172,\n       172, 173, 175], dtype=uint8), array([8.81468908])], [array([173, 173, 171, 172, 172, 172, 174, 173, 171, 170, 172, 173, 170,\n       169, 171, 171, 168, 169, 172, 173, 172, 172, 171, 169, 172, 173,\n       171, 171, 173, 173, 172, 174, 174, 173, 173, 172, 172, 173, 170,\n       172, 175, 174, 175, 175, 172, 171, 173, 174, 172, 171, 171, 170,\n       170, 173, 172, 169, 172, 168, 167, 164, 167, 168, 166, 166, 163,\n       163, 164, 162, 162, 162, 160, 162, 160, 156, 154, 141, 124,  96,\n        90,  89,  94, 118, 141, 155, 159, 162, 163, 163, 167, 166, 168,\n       170, 167, 168, 172, 174, 167, 170, 172, 173, 171, 173, 175, 174,\n       172, 173, 171, 175, 171, 171, 170, 173, 172, 170, 174, 176, 170,\n       173, 172, 176], dtype=uint8), array([5.09065576])], [array([147, 150, 150, 150, 150, 147, 149, 152, 151, 148, 149, 148, 151,\n       151, 152, 153, 151, 147, 148, 149, 150, 151, 153, 152, 151, 153,\n       153, 152, 150, 151, 152, 153, 151, 151, 150, 152, 151, 152, 151,\n       151, 151, 149, 150, 152, 153, 153, 155, 153, 153, 151, 152, 154,\n       152, 153, 151, 151, 151, 152, 154, 152, 150, 152, 153, 150, 154,\n       154, 154, 155, 153, 152, 157, 158, 157, 155, 156, 155, 154, 154,\n       153, 157, 156, 152, 152, 154, 156, 151, 152, 156, 157, 155, 153,\n       152, 154, 152, 152, 154, 152, 152, 154, 153, 155, 152, 152, 151,\n       153, 154, 151, 150, 152, 154, 154, 154, 151, 151, 153, 153, 153,\n       152, 152, 153], dtype=uint8), array([0.])], [array([171, 170, 168, 167, 171, 170, 167, 167, 168, 169, 169, 170, 168,\n       169, 168, 169, 171, 168, 167, 167, 168, 169, 170, 169, 164, 167,\n       166, 167, 168, 170, 169, 169, 167, 167, 168, 167, 167, 167, 168,\n       166, 168, 167, 166, 167, 167, 168, 170, 170, 168, 170, 171, 172,\n       168, 169, 167, 167, 168, 167, 169, 166, 164, 164, 159, 148, 130,\n       116, 107, 108, 116, 131, 138, 138, 142, 143, 142, 144, 144, 146,\n       148, 151, 153, 154, 157, 159, 161, 161, 162, 162, 161, 159, 164,\n       166, 167, 167, 168, 166, 168, 165, 169, 169, 169, 169, 170, 170,\n       168, 168, 169, 170, 170, 169, 167, 167, 167, 161, 154, 146, 137,\n       129, 131, 139], dtype=uint8), array([4.42544194])], [array([166, 168, 167, 164, 167, 166, 163, 167, 167, 165, 167, 166, 169,\n       167, 167, 169, 166, 167, 169, 168, 166, 167, 171, 169, 168, 170,\n       169, 168, 169, 168, 166, 168, 169, 170, 166, 167, 169, 166, 168,\n       166, 167, 167, 167, 165, 166, 164, 163, 158, 147, 141, 134, 126,\n       122, 126, 139, 142, 151, 153, 156, 160, 162, 161, 164, 165, 164,\n       164, 163, 165, 166, 167, 163, 155, 148, 137, 121, 112, 117, 131,\n       137, 139, 138, 137, 139, 141, 144, 145, 145, 148, 152, 152, 155,\n       157, 161, 160, 162, 162, 163, 163, 164, 165, 166, 166, 166, 166,\n       166, 167, 168, 171, 168, 167, 170, 166, 167, 168, 167, 168, 167,\n       167, 165, 165], dtype=uint8), array([4.45399496])], [array([143, 144, 146, 149, 150, 153, 150, 152, 154, 156, 154, 154, 158,\n       155, 159, 158, 153, 157, 157, 162, 162, 162, 160, 158, 159, 161,\n       163, 165, 165, 162, 163, 165, 164, 166, 166, 163, 165, 165, 167,\n       167, 167, 168, 167, 167, 165, 165, 167, 165, 168, 166, 167, 167,\n       168, 168, 167, 167, 167, 167, 168, 169, 169, 169, 169, 168, 170,\n       170, 168, 169, 168, 168, 167, 166, 165, 165, 165, 164, 158, 146,\n       132, 119, 109, 109, 124, 136, 141, 147, 148, 148, 150, 153, 154,\n       155, 156, 158, 159, 162, 164, 165, 164, 164, 166, 167, 167, 165,\n       166, 169, 168, 167, 167, 169, 171, 171, 171, 168, 163, 153, 141,\n       126, 113, 105], dtype=uint8), array([4.68352392])], [array([166, 170, 170, 167, 166, 167, 167, 167, 169, 168, 166, 165, 166,\n       168, 167, 167, 166, 168, 169, 166, 165, 162, 164, 165, 167, 167,\n       165, 170, 166, 166, 163, 165, 164, 161, 165, 165, 169, 168, 167,\n       169, 167, 166, 167, 165, 167, 165, 162, 160, 160, 154, 148, 138,\n       131, 130, 134, 141, 148, 150, 151, 152, 152, 153, 153, 151, 153,\n       154, 151, 151, 152, 152, 153, 153, 155, 156, 159, 161, 157, 161,\n       161, 163, 161, 161, 164, 165, 164, 164, 164, 165, 168, 163, 162,\n       163, 165, 166, 168, 168, 168, 167, 165, 169, 169, 168, 167, 168,\n       168, 167, 169, 169, 167, 167, 168, 168, 169, 169, 168, 168, 166,\n       169, 169, 165], dtype=uint8), array([3.48806279])], [array([153, 151, 152, 155, 157, 159, 163, 163, 163, 163, 165, 164, 169,\n       165, 163, 165, 166, 165, 164, 167, 166, 168, 166, 165, 165, 166,\n       167, 166, 165, 166, 168, 167, 167, 168, 170, 166, 170, 167, 167,\n       165, 165, 168, 168, 167, 168, 167, 168, 168, 167, 165, 165, 169,\n       167, 167, 166, 165, 167, 168, 165, 169, 168, 168, 167, 168, 168,\n       167, 166, 170, 167, 168, 166, 166, 164, 152, 140, 130, 116, 103,\n       105, 121, 131, 133, 134, 133, 137, 137, 138, 140, 143, 145, 143,\n       148, 151, 154, 156, 157, 159, 159, 159, 161, 162, 164, 164, 163,\n       165, 165, 165, 167, 167, 167, 168, 168, 169, 169, 171, 169, 170,\n       167, 165, 167], dtype=uint8), array([5.52762087])], [array([166, 166, 167, 168, 167, 164, 165, 166, 166, 168, 170, 168, 167,\n       168, 168, 167, 167, 167, 166, 166, 165, 165, 165, 166, 165, 166,\n       167, 168, 167, 166, 167, 166, 166, 165, 166, 166, 165, 165, 162,\n       156, 148, 141, 141, 148, 156, 161, 162, 162, 164, 165, 167, 166,\n       163, 159, 151, 141, 134, 130, 121, 111, 112, 120, 124, 127, 128,\n       125, 123, 124, 126, 129, 132, 136, 139, 142, 146, 147, 149, 151,\n       152, 155, 154, 157, 159, 159, 160, 162, 163, 163, 163, 164, 164,\n       166, 167, 167, 165, 163, 163, 164, 165, 166, 166, 165, 165, 165,\n       165, 167, 167, 167, 167, 167, 166, 166, 166, 165, 166, 166, 165,\n       168, 168, 168], dtype=uint8), array([5.24173503])], [array([164, 164, 166, 166, 168, 166, 165, 164, 167, 164, 163, 165, 165,\n       165, 165, 165, 166, 166, 166, 166, 162, 165, 166, 166, 161, 159,\n       159, 155, 151, 148, 148, 153, 156, 160, 164, 163, 162, 164, 164,\n       163, 164, 167, 165, 164, 166, 166, 163, 164, 164, 164, 168, 163,\n       162, 161, 162, 161, 159, 156, 157, 155, 155, 153, 149, 150, 147,\n       145, 143, 141, 139, 137, 139, 136, 134, 134, 135, 129, 119, 112,\n       114, 117, 125, 141, 152, 157, 159, 160, 162, 163, 165, 163, 162,\n       162, 163, 162, 165, 163, 165, 165, 166, 165, 165, 162, 163, 164,\n       163, 163, 167, 169, 167, 167, 167, 164, 165, 166, 164, 165, 164,\n       166, 164, 166], dtype=uint8), array([4.75818342])], [array([158, 159, 161, 162, 163, 163, 161, 162, 163, 162, 161, 162, 164,\n       163, 163, 163, 162, 161, 162, 163, 162, 160, 161, 165, 164, 166,\n       167, 163, 161, 163, 162, 162, 165, 163, 161, 159, 161, 160, 162,\n       162, 166, 163, 164, 165, 166, 169, 167, 165, 167, 166, 167, 166,\n       166, 164, 161, 155, 143, 131, 124, 127, 134, 136, 138, 141, 141,\n       136, 134, 135, 136, 137, 138, 140, 143, 146, 149, 152, 154, 155,\n       158, 159, 159, 159, 162, 163, 161, 160, 161, 163, 166, 162, 162,\n       164, 164, 164, 168, 168, 166, 167, 164, 167, 161, 165, 168, 164,\n       163, 162, 163, 164, 166, 163, 160, 157, 156, 157, 154, 152, 152,\n       152, 151, 153], dtype=uint8), array([3.84824603])], [array([157, 157, 156, 156, 159, 159, 158, 157, 157, 158, 157, 154, 155,\n       155, 154, 155, 156, 158, 157, 156, 155, 157, 154, 155, 157, 157,\n       156, 156, 157, 157, 156, 156, 159, 158, 158, 159, 160, 160, 158,\n       157, 155, 159, 160, 162, 161, 161, 161, 162, 162, 162, 163, 162,\n       161, 162, 162, 161, 159, 157, 155, 154, 151, 149, 140, 134, 133,\n       126, 116, 109, 113, 118, 121, 120, 113, 108, 108, 109, 110, 112,\n       116, 116, 121, 122, 124, 126, 129, 130, 134, 138, 140, 142, 143,\n       147, 150, 151, 152, 152, 154, 155, 157, 157, 159, 158, 159, 160,\n       159, 158, 158, 160, 157, 159, 159, 159, 159, 159, 158, 160, 162,\n       163, 163, 163], dtype=uint8), array([6.3266849])], [array([129, 130, 132, 134, 134, 133, 137, 140, 141, 139, 138, 140, 143,\n       145, 146, 144, 147, 146, 146, 148, 150, 153, 154, 154, 154, 154,\n       153, 155, 155, 156, 157, 157, 160, 159, 157, 157, 158, 156, 156,\n       157, 158, 161, 157, 160, 158, 159, 161, 160, 159, 158, 158, 158,\n       160, 160, 156, 159, 155, 153, 145, 140, 134, 129, 129, 136, 142,\n       147, 146, 148, 144, 142, 142, 143, 143, 139, 132, 117, 106, 101,\n        93,  90, 100, 111, 119, 122, 127, 130, 129, 131, 135, 138, 139,\n       140, 143, 146, 142, 146, 150, 153, 152, 154, 156, 157, 158, 161,\n       159, 162, 160, 160, 161, 161, 162, 163, 161, 161, 163, 162, 163,\n       161, 161, 163], dtype=uint8), array([5.48232787])], [array([133, 134, 132, 136, 134, 138, 140, 135, 138, 140, 140, 141, 140,\n       141, 143, 147, 143, 146, 146, 148, 149, 144, 150, 150, 153, 151,\n       148, 154, 152, 151, 150, 154, 151, 153, 152, 154, 150, 151, 150,\n       150, 153, 156, 156, 158, 151, 156, 153, 155, 155, 156, 156, 156,\n       158, 154, 156, 157, 155, 154, 157, 154, 157, 156, 158, 157, 159,\n       159, 158, 161, 158, 162, 160, 161, 162, 160, 155, 147, 138, 121,\n       111, 105, 108, 112, 118, 121, 122, 125, 125, 124, 125, 126, 126,\n       131, 130, 131, 135, 134, 137, 140, 137, 139, 145, 146, 150, 151,\n       152, 149, 155, 154, 154, 154, 152, 161, 157, 159, 158, 159, 159,\n       161, 160, 159], dtype=uint8), array([4.22418291])], [array([168, 169, 167, 170, 169, 170, 171, 169, 168, 168, 168, 165, 170,\n       167, 169, 171, 168, 166, 165, 166, 169, 168, 167, 165, 165, 166,\n       166, 167, 169, 169, 168, 169, 168, 169, 170, 168, 166, 167, 166,\n       167, 166, 167, 167, 168, 169, 168, 167, 167, 171, 170, 170, 168,\n       168, 169, 167, 170, 170, 170, 169, 169, 169, 170, 171, 170, 169,\n       167, 168, 168, 169, 168, 167, 168, 167, 165, 167, 169, 167, 169,\n       167, 169, 168, 167, 168, 168, 170, 170, 167, 167, 169, 170, 170,\n       168, 169, 167, 170, 170, 169, 171, 169, 167, 170, 167, 168, 170,\n       167, 168, 168, 168, 165, 165, 169, 167, 165, 168, 166, 165, 168,\n       168, 167, 167], dtype=uint8), array([0.])], [array([163, 162, 165, 164, 165, 162, 162, 163, 163, 164, 165, 164, 164,\n       165, 163, 162, 162, 164, 165, 166, 165, 163, 165, 165, 168, 164,\n       164, 166, 167, 166, 164, 168, 167, 164, 165, 165, 165, 167, 167,\n       167, 165, 165, 166, 165, 166, 166, 165, 166, 168, 166, 167, 167,\n       166, 167, 167, 167, 166, 166, 165, 168, 166, 166, 167, 164, 159,\n       154, 143, 130, 122, 126, 133, 139, 139, 139, 139, 141, 139, 141,\n       144, 146, 149, 149, 152, 150, 153, 154, 159, 158, 158, 159, 163,\n       164, 163, 164, 164, 164, 165, 165, 166, 165, 166, 167, 167, 167,\n       166, 166, 166, 166, 168, 167, 167, 167, 169, 168, 163, 166, 168,\n       165, 166, 166], dtype=uint8), array([3.71157107])], [array([166, 163, 163, 163, 165, 165, 164, 166, 167, 165, 165, 165, 166,\n       166, 167, 166, 166, 167, 165, 163, 165, 166, 165, 165, 165, 164,\n       168, 167, 168, 166, 165, 166, 165, 167, 165, 164, 166, 163, 165,\n       163, 161, 162, 160, 156, 157, 156, 154, 154, 154, 158, 158, 160,\n       162, 163, 162, 163, 164, 164, 167, 167, 167, 167, 161, 163, 162,\n       164, 163, 161, 158, 156, 155, 151, 150, 144, 129, 117, 113, 110,\n       114, 129, 139, 140, 141, 141, 144, 146, 147, 148, 150, 152, 153,\n       154, 156, 159, 162, 164, 162, 164, 163, 162, 165, 167, 166, 167,\n       166, 168, 165, 165, 165, 164, 165, 165, 165, 163, 165, 166, 167,\n       165, 165, 166], dtype=uint8), array([4.08382213])], [array([168, 167, 166, 164, 165, 167, 164, 165, 167, 168, 166, 167, 169,\n       167, 166, 167, 167, 166, 168, 168, 168, 165, 164, 164, 164, 168,\n       166, 165, 167, 167, 166, 166, 164, 166, 168, 164, 165, 164, 161,\n       160, 158, 156, 157, 153, 149, 141, 129, 119, 115, 119, 135, 150,\n       155, 160, 164, 161, 162, 164, 166, 166, 168, 166, 165, 168, 169,\n       163, 167, 165, 165, 167, 170, 165, 168, 168, 168, 165, 166, 166,\n       167, 166, 168, 169, 170, 167, 169, 169, 169, 167, 167, 169, 166,\n       166, 167, 168, 168, 166, 164, 163, 165, 164, 166, 167, 165, 162,\n       161, 160, 160, 160, 156, 153, 150, 148, 145, 137, 128, 126, 126,\n       127, 132, 136], dtype=uint8), array([3.69767209])], [array([158, 159, 158, 160, 161, 161, 159, 156, 161, 161, 162, 161, 161,\n       163, 165, 162, 163, 163, 159, 152, 144, 136, 133, 135, 139, 144,\n       147, 146, 145, 144, 144, 144, 143, 142, 137, 134, 133, 131, 128,\n       126, 123, 118, 117, 114, 114, 117, 127, 133, 137, 140, 142, 143,\n       146, 146, 146, 146, 148, 145, 147, 150, 151, 151, 153, 153, 150,\n       151, 155, 159, 157, 150, 142, 129, 117, 110, 114, 122, 131, 131,\n       132, 131, 130, 127, 125, 126, 128, 128, 132, 133, 135, 137, 140,\n       142, 142, 143, 146, 146, 150, 151, 153, 154, 154, 153, 157, 158,\n       157, 159, 159, 161, 160, 160, 161, 158, 159, 160, 161, 164, 160,\n       159, 161, 159], dtype=uint8), array([4.18255064])], [array([165, 165, 165, 167, 164, 161, 164, 165, 163, 168, 169, 166, 165,\n       163, 164, 167, 167, 165, 165, 163, 165, 166, 165, 166, 166, 164,\n       164, 166, 165, 165, 164, 161, 163, 163, 164, 163, 163, 165, 165,\n       163, 163, 163, 163, 163, 163, 160, 157, 159, 159, 156, 155, 155,\n       152, 149, 147, 146, 146, 144, 143, 140, 140, 136, 132, 129, 130,\n       130, 130, 128, 127, 122, 102,  84,  94, 106,  96,  85,  95, 121,\n       138, 145, 145, 149, 149, 151, 154, 154, 153, 157, 159, 161, 162,\n       163, 165, 163, 163, 165, 163, 164, 167, 164, 164, 167, 166, 164,\n       165, 164, 166, 163, 163, 165, 164, 165, 165, 164, 163, 162, 164,\n       163, 166, 161], dtype=uint8), array([9.01671984])], [array([119, 126, 132, 137, 139, 142, 144, 145, 144, 143, 143, 145, 146,\n       142, 141, 143, 141, 144, 142, 143, 143, 143, 143, 141, 140, 139,\n       139, 135, 135, 136, 139, 139, 140, 141, 143, 137, 135, 131, 132,\n       134, 132, 126, 123, 121, 119, 116, 112, 117, 124, 132, 137, 139,\n       139, 142, 145, 145, 143, 144, 143, 145, 147, 149, 150, 141, 130,\n       126, 133, 127, 127, 135, 147, 155, 155, 155, 158, 160, 163, 162,\n       159, 158, 161, 162, 162, 162, 165, 163, 161, 163, 163, 162, 160,\n       160, 162, 162, 159, 160, 160, 160, 158, 159, 158, 159, 161, 160,\n       161, 161, 160, 159, 159, 161, 159, 162, 163, 161, 159, 160, 161,\n       163, 161, 160], dtype=uint8), array([6.47364817])], [array([165, 162, 161, 161, 162, 159, 160, 159, 161, 163, 159, 157, 159,\n       159, 160, 159, 157, 160, 162, 159, 159, 161, 163, 158, 160, 163,\n       160, 157, 158, 159, 160, 161, 159, 161, 160, 159, 160, 162, 159,\n       160, 161, 159, 159, 160, 160, 163, 161, 159, 160, 158, 162, 164,\n       164, 163, 164, 162, 163, 164, 163, 164, 164, 165, 161, 163, 164,\n       165, 163, 162, 162, 162, 164, 165, 160, 153, 141, 129, 122, 118,\n       121, 136, 135, 136, 137, 137, 139, 140, 140, 142, 142, 140, 141,\n       141, 143, 146, 145, 147, 148, 151, 149, 151, 151, 154, 157, 155,\n       161, 159, 159, 158, 158, 157, 158, 159, 162, 161, 162, 162, 162,\n       162, 161, 161], dtype=uint8), array([4.51710674])], [array([168, 171, 167, 167, 165, 170, 169, 165, 167, 165, 168, 168, 166,\n       168, 167, 167, 166, 168, 167, 167, 166, 164, 163, 164, 163, 165,\n       166, 166, 168, 168, 167, 168, 166, 167, 167, 164, 167, 167, 166,\n       166, 166, 166, 167, 169, 168, 167, 170, 167, 170, 166, 168, 166,\n       169, 167, 166, 167, 169, 169, 168, 166, 164, 168, 169, 165, 166,\n       169, 169, 169, 169, 166, 166, 168, 166, 165, 166, 163, 158, 154,\n       148, 151, 153, 155, 154, 155, 156, 155, 156, 156, 158, 160, 162,\n       162, 159, 159, 160, 163, 162, 166, 165, 161, 165, 167, 165, 167,\n       166, 166, 167, 166, 166, 166, 167, 168, 166, 167, 165, 163, 164,\n       167, 166, 166], dtype=uint8), array([4.88037655])], [array([166, 168, 168, 167, 171, 170, 167, 166, 168, 166, 168, 166, 167,\n       168, 170, 167, 166, 169, 170, 169, 167, 167, 165, 165, 169, 168,\n       167, 167, 168, 167, 165, 165, 165, 165, 165, 165, 166, 168, 166,\n       168, 169, 169, 166, 165, 166, 168, 167, 164, 166, 164, 166, 167,\n       166, 164, 163, 164, 164, 163, 165, 164, 166, 162, 161, 164, 162,\n       163, 162, 165, 164, 161, 160, 158, 157, 159, 160, 160, 162, 166,\n       167, 162, 163, 160, 161, 164, 164, 162, 163, 162, 158, 158, 159,\n       161, 165, 166, 166, 166, 165, 165, 170, 168, 168, 167, 166, 164,\n       166, 165, 165, 165, 165, 167, 168, 165, 164, 162, 162, 163, 164,\n       165, 168, 165], dtype=uint8), array([4.75318777])], [array([164, 167, 165, 164, 165, 166, 167, 162, 163, 164, 163, 165, 166,\n       164, 161, 162, 161, 161, 160, 159, 158, 158, 158, 156, 155, 153,\n       150, 147, 146, 146, 144, 145, 143, 140, 138, 137, 138, 135, 134,\n       136, 133, 134, 134, 133, 133, 122, 109, 113, 123, 136, 151, 159,\n       163, 162, 159, 160, 163, 166, 162, 160, 160, 162, 168, 165, 165,\n       165, 167, 168, 166, 164, 166, 164, 163, 165, 166, 167, 165, 164,\n       166, 161, 163, 164, 166, 166, 164, 164, 164, 164, 164, 162, 165,\n       165, 164, 163, 164, 163, 163, 164, 164, 163, 164, 163, 165, 167,\n       164, 162, 161, 163, 163, 160, 162, 163, 160, 163, 164, 165, 164,\n       165, 163, 160], dtype=uint8), array([4.67930649])], [array([164, 165, 162, 163, 163, 165, 166, 164, 162, 161, 165, 169, 167,\n       165, 160, 164, 167, 162, 164, 165, 164, 164, 165, 163, 165, 168,\n       165, 163, 164, 163, 162, 165, 166, 164, 164, 162, 161, 161, 158,\n       161, 162, 163, 162, 161, 161, 162, 162, 164, 164, 162, 159, 159,\n       160, 161, 160, 162, 160, 158, 157, 154, 153, 156, 154, 152, 152,\n       150, 151, 143, 137, 133, 137, 142, 144, 145, 151, 149, 151, 151,\n       152, 152, 153, 153, 153, 155, 158, 160, 158, 158, 160, 160, 160,\n       161, 162, 161, 163, 159, 161, 162, 163, 164, 165, 166, 165, 164,\n       165, 165, 165, 164, 164, 163, 167, 163, 163, 164, 164, 163, 164,\n       166, 167, 167], dtype=uint8), array([3.66342182])], [array([147, 149, 147, 146, 146, 146, 145, 147, 146, 147, 147, 147, 146,\n       147, 146, 147, 148, 148, 148, 148, 149, 147, 146, 147, 147, 147,\n       147, 148, 147, 148, 149, 147, 149, 150, 146, 147, 148, 144, 146,\n       149, 147, 146, 151, 147, 147, 146, 147, 147, 147, 147, 148, 145,\n       145, 145, 144, 145, 146, 146, 145, 143, 141, 142, 143, 144, 143,\n       145, 146, 139, 138, 137, 137, 134, 131, 120, 107,  97,  98, 104,\n        94,  75,  67,  75,  77,  76,  76,  82,  84,  88,  92,  92,  92,\n        95,  96,  96, 100, 106, 108, 112, 114, 116, 117, 119, 121, 120,\n       124, 126, 126, 129, 131, 132, 133, 135, 136, 138, 139, 141, 145,\n       145, 143, 143], dtype=uint8), array([11.24816955])], [array([153, 152, 152, 151, 152, 152, 151, 153, 153, 150, 150, 150, 149,\n       151, 150, 148, 148, 148, 147, 145, 145, 139, 141, 138, 136, 135,\n       135, 131, 132, 133, 131, 130, 129, 125, 125, 128, 127, 126, 126,\n       126, 126, 129, 130, 132, 131, 131, 131, 123, 111, 112, 124, 136,\n       144, 152, 157, 157, 155, 158, 156, 156, 156, 156, 156, 152, 155,\n       155, 151, 151, 151, 150, 152, 153, 153, 149, 153, 151, 149, 151,\n       149, 148, 147, 148, 148, 151, 151, 149, 148, 149, 149, 149, 147,\n       148, 149, 150, 148, 146, 147, 148, 147, 150, 150, 150, 149, 148,\n       149, 150, 151, 151, 150, 150, 150, 150, 151, 149, 148, 147, 148,\n       150, 149, 148], dtype=uint8), array([5.29607184])], [array([153, 153, 151, 150, 152, 153, 154, 153, 150, 150, 150, 149, 149,\n       149, 149, 146, 149, 148, 147, 147, 146, 150, 147, 146, 144, 143,\n       142, 141, 141, 140, 137, 136, 135, 132, 130, 128, 128, 127, 125,\n       123, 119, 120, 120, 118, 119, 121, 121, 120, 119, 119, 115, 108,\n        97,  94, 109, 125, 135, 146, 156, 157, 156, 154, 155, 156, 156,\n       154, 154, 154, 155, 156, 156, 152, 151, 151, 152, 151, 150, 153,\n       154, 151, 151, 152, 151, 151, 149, 151, 150, 147, 147, 149, 148,\n       149, 149, 148, 146, 145, 143, 142, 142, 142, 139, 142, 142, 142,\n       141, 145, 144, 141, 145, 148, 145, 147, 149, 150, 149, 149, 149,\n       147, 146, 148], dtype=uint8), array([5.46791157])], [array([152, 152, 151, 152, 152, 152, 150, 151, 151, 151, 152, 153, 150,\n       151, 151, 153, 152, 150, 150, 150, 147, 147, 149, 147, 145, 144,\n       142, 142, 140, 138, 139, 138, 136, 134, 131, 131, 131, 128, 127,\n       128, 127, 124, 122, 122, 121, 120, 118, 120, 119, 122, 122, 126,\n       126, 126, 125, 116, 103, 103, 112, 124, 138, 149, 155, 156, 154,\n       155, 152, 148, 151, 155, 153, 153, 153, 151, 152, 152, 154, 153,\n       150, 152, 152, 151, 151, 153, 153, 152, 152, 150, 152, 153, 152,\n       152, 154, 153, 153, 153, 154, 151, 152, 155, 153, 152, 150, 151,\n       151, 150, 151, 151, 152, 150, 152, 151, 152, 152, 152, 151, 149,\n       149, 149, 143], dtype=uint8), array([5.45620238])], [array([167, 165, 166, 162, 161, 164, 163, 164, 166, 166, 164, 164, 165,\n       164, 164, 165, 164, 165, 165, 163, 163, 165, 167, 166, 166, 167,\n       168, 167, 168, 168, 164, 166, 166, 167, 166, 166, 167, 167, 166,\n       163, 162, 163, 161, 162, 163, 163, 163, 164, 167, 166, 167, 169,\n       166, 166, 168, 170, 168, 166, 167, 167, 167, 168, 168, 168, 168,\n       167, 166, 168, 168, 167, 167, 168, 169, 168, 167, 166, 166, 165,\n       164, 167, 169, 169, 166, 165, 166, 166, 165, 165, 165, 166, 166,\n       164, 164, 167, 168, 168, 169, 168, 167, 167, 167, 167, 167, 168,\n       167, 165, 166, 167, 165, 166, 166, 166, 167, 166, 170, 169, 166,\n       165, 165, 167], dtype=uint8), array([0.])], [array([130, 136, 144, 152, 155, 157, 160, 164, 164, 164, 164, 165, 166,\n       167, 168, 166, 167, 167, 168, 166, 169, 166, 166, 168, 168, 170,\n       170, 169, 170, 171, 171, 169, 172, 170, 169, 171, 170, 170, 171,\n       169, 171, 169, 170, 168, 173, 171, 173, 170, 170, 170, 167, 170,\n       169, 171, 170, 171, 173, 169, 169, 171, 170, 168, 169, 167, 165,\n       166, 162, 162, 163, 163, 156, 143, 123, 104,  96,  98,  97,  88,\n        76,  73,  80,  79,  80,  84,  92,  99, 103, 107, 108, 113, 119,\n       121, 124, 124, 127, 131, 135, 140, 142, 145, 148, 150, 153, 152,\n       156, 158, 158, 163, 164, 163, 165, 164, 165, 167, 166, 168, 169,\n       168, 169, 169], dtype=uint8), array([11.65322989])], [array([168, 167, 168, 168, 169, 170, 171, 167, 165, 168, 171, 172, 168,\n       170, 171, 172, 167, 168, 169, 169, 170, 169, 168, 169, 169, 168,\n       168, 167, 170, 172, 169, 168, 170, 171, 168, 172, 172, 170, 168,\n       167, 167, 168, 168, 166, 169, 169, 169, 168, 168, 169, 168, 169,\n       169, 170, 171, 169, 166, 168, 168, 167, 167, 165, 163, 160, 160,\n       160, 159, 153, 151, 145, 145, 141, 129, 114,  98, 100, 108, 108,\n       104,  95,  89,  94, 103, 111, 115, 117, 121, 126, 128, 130, 136,\n       140, 141, 144, 145, 148, 148, 151, 153, 155, 156, 158, 159, 163,\n       165, 164, 163, 163, 166, 165, 166, 168, 168, 167, 168, 169, 171,\n       170, 169, 168], dtype=uint8), array([11.24816955])], [array([168, 170, 169, 169, 172, 169, 167, 170, 169, 170, 169, 170, 170,\n       169, 169, 170, 172, 170, 171, 171, 171, 169, 169, 167, 171, 170,\n       168, 167, 168, 169, 169, 170, 170, 169, 169, 169, 168, 167, 168,\n       167, 169, 169, 166, 165, 166, 166, 165, 165, 164, 165, 163, 163,\n       160, 155, 157, 154, 153, 154, 150, 146, 136, 125, 116, 117, 120,\n       123, 124, 116, 105, 104, 114, 129, 142, 151, 157, 163, 165, 161,\n       159, 163, 166, 165, 165, 167, 167, 167, 165, 165, 167, 166, 167,\n       168, 164, 164, 168, 169, 167, 164, 165, 165, 166, 168, 165, 166,\n       167, 170, 169, 168, 168, 166, 166, 168, 165, 166, 168, 168, 167,\n       167, 164, 168], dtype=uint8), array([5.29607184])], [array([170, 173, 173, 169, 169, 170, 171, 171, 170, 172, 171, 172, 170,\n       169, 170, 169, 169, 172, 173, 172, 170, 170, 173, 174, 170, 169,\n       171, 170, 171, 170, 170, 170, 172, 170, 172, 172, 174, 173, 170,\n       171, 171, 169, 172, 172, 171, 169, 168, 169, 165, 160, 149, 135,\n       118, 105,  98, 108, 124, 133, 135, 137, 141, 145, 146, 149, 149,\n       151, 156, 160, 161, 160, 163, 166, 167, 167, 166, 170, 170, 171,\n       170, 169, 170, 172, 173, 169, 167, 169, 168, 172, 171, 170, 172,\n       172, 170, 169, 172, 170, 170, 169, 167, 166, 165, 165, 167, 167,\n       167, 167, 166, 168, 169, 169, 168, 169, 170, 169, 170, 170, 169,\n       170, 173, 172], dtype=uint8), array([5.46791157])], [array([170, 169, 169, 169, 168, 168, 169, 169, 171, 172, 170, 170, 172,\n       170, 171, 173, 170, 167, 168, 169, 168, 170, 170, 169, 169, 170,\n       170, 166, 163, 164, 161, 160, 162, 164, 165, 166, 169, 171, 167,\n       170, 169, 175, 172, 168, 171, 171, 171, 168, 170, 170, 169, 168,\n       165, 160, 149, 133, 117, 104,  95, 100, 114, 128, 129, 131, 135,\n       139, 142, 144, 144, 146, 149, 150, 157, 159, 160, 159, 163, 167,\n       166, 167, 169, 167, 170, 171, 171, 170, 166, 168, 166, 166, 167,\n       166, 169, 170, 169, 169, 169, 168, 168, 171, 172, 170, 168, 169,\n       172, 171, 168, 172, 169, 170, 173, 171, 171, 172, 171, 170, 167,\n       170, 172, 172], dtype=uint8), array([5.45620238])], [array([175, 171, 171, 172, 173, 172, 172, 173, 172, 172, 172, 172, 170,\n       171, 172, 171, 172, 173, 172, 172, 172, 171, 172, 173, 173, 174,\n       174, 173, 170, 170, 169, 168, 171, 169, 170, 170, 169, 171, 172,\n       172, 171, 172, 170, 173, 174, 172, 171, 170, 171, 170, 175, 173,\n       175, 174, 172, 171, 170, 169, 169, 170, 171, 172, 172, 171, 173,\n       169, 171, 168, 169, 172, 170, 169, 172, 172, 172, 169, 166, 163,\n       166, 168, 168, 169, 168, 167, 170, 169, 167, 170, 170, 170, 171,\n       172, 174, 172, 171, 171, 172, 172, 171, 173, 173, 171, 176, 172,\n       173, 172, 173, 173, 176, 174, 175, 173, 176, 172, 172, 173, 170,\n       171, 175, 170], dtype=uint8), array([3.54463004])], [array([154, 153, 153, 152, 153, 154, 153, 152, 155, 154, 155, 156, 155,\n       155, 157, 156, 156, 156, 156, 157, 155, 154, 156, 157, 157, 156,\n       155, 157, 158, 155, 157, 155, 156, 156, 155, 154, 155, 155, 156,\n       153, 158, 157, 157, 157, 158, 156, 156, 157, 158, 156, 156, 156,\n       154, 155, 155, 153, 153, 152, 150, 149, 147, 144, 144, 143, 142,\n       139, 137, 134, 131, 127, 125, 123, 120, 121, 116, 117, 115, 117,\n       114,  99,  90, 103, 124, 136, 151, 155, 159, 161, 160, 159, 159,\n       159, 158, 157, 156, 156, 157, 156, 155, 154, 153, 152, 153, 152,\n       150, 151, 151, 151, 150, 150, 151, 151, 149, 148, 148, 148, 149,\n       149, 146, 144], dtype=uint8), array([4.51179147])], [array([146, 150, 155, 157, 159, 165, 164, 165, 164, 163, 165, 164, 164,\n       164, 164, 166, 167, 166, 163, 165, 165, 167, 167, 166, 164, 165,\n       166, 166, 164, 164, 165, 165, 161, 163, 162, 161, 161, 160, 162,\n       157, 156, 155, 155, 156, 155, 154, 155, 153, 151, 151, 151, 151,\n       152, 150, 150, 149, 148, 147, 143, 139, 135, 125, 113, 107, 108,\n       120, 140, 155, 163, 168, 168, 166, 166, 166, 164, 163, 158, 159,\n       161, 162, 160, 160, 162, 159, 159, 158, 157, 157, 159, 157, 156,\n       152, 154, 154, 155, 154, 154, 154, 154, 152, 153, 155, 154, 153,\n       154, 154, 153, 157, 157, 155, 156, 156, 155, 155, 155, 154, 157,\n       157, 156, 156], dtype=uint8), array([4.37560143])], [array([166, 168, 166, 168, 165, 169, 165, 163, 164, 164, 163, 162, 162,\n       160, 161, 158, 162, 159, 162, 161, 161, 161, 162, 164, 164, 163,\n       161, 163, 162, 162, 163, 160, 160, 160, 161, 162, 159, 160, 161,\n       161, 159, 160, 160, 158, 157, 156, 156, 160, 159, 157, 158, 159,\n       157, 158, 157, 152, 152, 154, 154, 153, 147, 147, 147, 146, 144,\n       142, 141, 139, 137, 136, 133, 127, 126, 125, 130, 132, 131, 129,\n       119, 102,  94, 105, 123, 140, 152, 158, 158, 159, 162, 159, 161,\n       162, 158, 157, 156, 154, 152, 154, 153, 153, 154, 152, 151, 151,\n       152, 150, 148, 150, 150, 151, 153, 151, 149, 148, 149, 154, 150,\n       152, 151, 148], dtype=uint8), array([3.95002995])], [array([159, 156, 155, 156, 155, 153, 155, 156, 156, 155, 154, 156, 157,\n       155, 154, 156, 157, 154, 153, 152, 153, 154, 154, 153, 153, 152,\n       156, 153, 150, 153, 154, 153, 154, 155, 154, 157, 155, 155, 156,\n       153, 151, 152, 150, 151, 155, 154, 151, 153, 154, 152, 152, 151,\n       151, 151, 152, 150, 150, 149, 145, 147, 146, 143, 141, 140, 137,\n       135, 134, 132, 133, 131, 129, 128, 127, 126, 123, 123, 119, 110,\n       111, 124, 141, 154, 156, 157, 153, 157, 159, 158, 157, 154, 153,\n       148, 149, 147, 147, 144, 143, 143, 139, 135, 131, 134, 136, 136,\n       135, 136, 141, 143, 145, 145, 145, 146, 148, 145, 145, 145, 145,\n       144, 142, 141], dtype=uint8), array([3.53048839])], [array([137, 136, 135, 135, 137, 137, 135, 133, 131, 131, 132, 130, 128,\n       129, 128, 126, 126, 125, 125, 124, 123, 122, 123, 123, 123, 123,\n       123, 122, 122, 123, 124, 120, 116, 114, 116, 121, 125, 126, 127,\n       127, 127, 127, 127, 129, 129, 130, 126, 125, 124, 127, 128, 131,\n       131, 134, 136, 137, 137, 139, 139, 137, 137, 134, 128, 123, 123,\n       130, 142, 150, 154, 158, 159, 157, 156, 155, 154, 156, 157, 155,\n       153, 154, 155, 155, 156, 155, 153, 153, 153, 152, 152, 154, 154,\n       156, 159, 157, 155, 155, 152, 151, 148, 149, 149, 147, 146, 152,\n       154, 157, 157, 156, 156, 155, 151, 152, 151, 147, 141, 141, 144,\n       146, 147, 150], dtype=uint8), array([3.67640104])], [array([151, 151, 150, 151, 151, 148, 147, 151, 151, 149, 149, 149, 149,\n       145, 150, 150, 150, 147, 151, 149, 152, 150, 150, 150, 152, 150,\n       151, 151, 149, 147, 150, 148, 147, 150, 148, 148, 147, 146, 145,\n       145, 146, 145, 140, 138, 136, 133, 133, 129, 128, 125, 122, 118,\n       115, 113, 111, 109, 107, 105, 103, 104,  97,  92,  85,  84,  80,\n        78,  75,  69,  66,  69,  81,  92, 102, 121, 130, 128, 133, 148,\n       162, 165, 165, 168, 168, 167, 167, 167, 167, 164, 165, 163, 162,\n       162, 162, 159, 158, 155, 154, 154, 152, 150, 151, 149, 148, 146,\n       141, 144, 144, 145, 142, 141, 138, 138, 138, 138, 142, 142, 143,\n       144, 142, 141], dtype=uint8), array([8.97995119])], [array([159, 156, 158, 157, 157, 156, 156, 154, 153, 152, 153, 154, 152,\n       149, 152, 155, 150, 150, 152, 151, 149, 150, 148, 149, 150, 148,\n       148, 148, 148, 146, 145, 144, 148, 149, 149, 147, 145, 145, 147,\n       147, 147, 146, 144, 144, 142, 134, 126, 114, 106,  97,  90,  98,\n       116, 122, 127, 129, 130, 130, 131, 130, 134, 138, 137, 136, 137,\n       139, 141, 141, 142, 147, 150, 144, 144, 145, 146, 146, 146, 145,\n       145, 147, 147, 147, 147, 147, 146, 147, 149, 148, 147, 147, 144,\n       147, 145, 146, 147, 147, 147, 147, 149, 148, 147, 147, 146, 146,\n       151, 147, 144, 149, 147, 147, 144, 143, 146, 147, 147, 145, 144,\n       145, 145, 145], dtype=uint8), array([5.35827466])], [array([148, 149, 150, 151, 151, 150, 151, 151, 154, 153, 152, 154, 155,\n       157, 156, 159, 155, 158, 159, 158, 156, 159, 158, 158, 159, 157,\n       160, 158, 156, 156, 158, 160, 160, 158, 155, 155, 150, 144, 147,\n       148, 149, 150, 152, 154, 154, 157, 156, 154, 155, 157, 158, 160,\n       159, 161, 160, 159, 163, 161, 158, 157, 157, 158, 159, 155, 152,\n       152, 152, 150, 144, 137, 125, 113, 121, 127, 123, 111, 101,  98,\n       101, 104, 103, 104, 103, 105, 106, 110, 110, 112, 112, 114, 117,\n       118, 118, 120, 121, 122, 121, 123, 122, 122, 121, 123, 124, 123,\n       124, 124, 126, 128, 128, 127, 129, 127, 129, 127, 126, 128, 129,\n       130, 131, 128], dtype=uint8), array([8.97995119])], [array([123, 122, 125, 125, 125, 128, 127, 128, 132, 132, 131, 134, 133,\n       134, 133, 134, 135, 132, 131, 131, 132, 130, 131, 133, 133, 132,\n       132, 128, 131, 130, 129, 129, 125, 125, 126, 126, 124, 124, 124,\n       123, 124, 123, 124, 124, 126, 127, 120, 108,  99, 106, 116, 128,\n       138, 147, 154, 158, 159, 162, 162, 158, 159, 160, 160, 158, 156,\n       155, 155, 153, 155, 154, 155, 157, 154, 153, 156, 154, 158, 156,\n       156, 156, 156, 157, 155, 156, 155, 154, 156, 157, 155, 153, 155,\n       155, 156, 154, 158, 158, 158, 156, 160, 159, 158, 157, 157, 157,\n       158, 155, 154, 154, 155, 155, 154, 152, 152, 150, 138, 128, 125,\n       132, 140, 147], dtype=uint8), array([5.35827466])], [array([158, 160, 160, 161, 160, 161, 161, 162, 163, 161, 160, 162, 161,\n       159, 163, 162, 160, 162, 162, 162, 160, 161, 160, 160, 159, 158,\n       159, 162, 160, 157, 161, 159, 160, 161, 164, 163, 159, 158, 159,\n       158, 159, 159, 157, 159, 156, 157, 156, 157, 160, 155, 154, 154,\n       156, 160, 155, 154, 155, 153, 153, 151, 150, 153, 150, 148, 149,\n       152, 150, 154, 154, 154, 152, 151, 149, 149, 145, 135, 124, 115,\n       107, 114, 127, 132, 131, 129, 130, 130, 129, 126, 126, 127, 126,\n       128, 127, 128, 127, 123, 125, 125, 124, 126, 128, 128, 126, 125,\n       125, 126, 126, 125, 124, 124, 125, 126, 125, 124, 123, 123, 122,\n       122, 125, 123], dtype=uint8), array([3.76287851])], [array([163, 163, 162, 160, 164, 162, 161, 163, 164, 162, 163, 164, 164,\n       164, 166, 164, 163, 165, 161, 165, 162, 165, 164, 164, 166, 164,\n       162, 161, 158, 159, 157, 158, 158, 159, 159, 157, 156, 155, 154,\n       152, 148, 145, 143, 143, 148, 153, 156, 154, 156, 155, 157, 157,\n       159, 160, 162, 164, 161, 163, 165, 165, 164, 164, 165, 160, 167,\n       166, 166, 165, 166, 166, 164, 165, 166, 161, 156, 153, 153, 152,\n       151, 152, 150, 151, 149, 148, 149, 149, 149, 151, 152, 153, 154,\n       154, 157, 159, 158, 157, 159, 161, 162, 168, 163, 165, 163, 163,\n       165, 163, 163, 163, 163, 163, 163, 163, 161, 164, 165, 162, 163,\n       164, 167, 165], dtype=uint8), array([3.04808728])], [array([161, 162, 162, 163, 163, 164, 164, 163, 162, 164, 164, 165, 161,\n       161, 160, 164, 166, 168, 167, 167, 166, 164, 167, 167, 166, 166,\n       165, 165, 167, 166, 167, 166, 168, 166, 166, 166, 166, 163, 164,\n       165, 163, 166, 165, 165, 165, 165, 165, 168, 169, 167, 166, 165,\n       167, 168, 169, 166, 166, 166, 167, 165, 168, 168, 167, 167, 168,\n       169, 166, 167, 165, 166, 163, 162, 161, 156, 148, 138, 127, 124,\n       125, 134, 141, 142, 143, 144, 145, 144, 146, 148, 145, 143, 145,\n       144, 143, 149, 150, 148, 148, 152, 153, 150, 151, 152, 152, 149,\n       150, 152, 149, 150, 149, 151, 152, 149, 149, 147, 146, 149, 148,\n       147, 147, 144], dtype=uint8), array([3.04562947])], [array([171, 170, 170, 170, 171, 171, 172, 171, 172, 168, 167, 168, 168,\n       169, 169, 170, 168, 167, 169, 169, 167, 171, 170, 168, 168, 168,\n       168, 169, 170, 169, 169, 167, 168, 170, 169, 168, 170, 169, 167,\n       169, 170, 168, 169, 167, 172, 168, 169, 167, 168, 168, 168, 168,\n       168, 166, 167, 170, 171, 169, 168, 166, 169, 170, 170, 168, 166,\n       165, 165, 165, 162, 160, 159, 154, 146, 130, 109, 108, 123, 142,\n       153, 158, 160, 163, 161, 164, 162, 158, 159, 158, 161, 160, 158,\n       157, 156, 154, 153, 154, 153, 152, 150, 149, 150, 149, 149, 150,\n       150, 150, 148, 149, 148, 147, 145, 144, 136, 128, 122, 117, 115,\n       103,  95,  93], dtype=uint8), array([3.06895321])], [array([166, 164, 168, 166, 166, 165, 166, 166, 169, 162, 165, 160, 159,\n       157, 156, 152, 150, 145, 140, 135, 131, 126, 119, 121, 127, 129,\n       127, 126, 123, 128, 135, 139, 136, 142, 144, 146, 149, 151, 149,\n       149, 151, 155, 158, 157, 157, 159, 161, 159, 158, 154, 151, 147,\n       142, 132, 131, 140, 152, 157, 157, 161, 163, 161, 160, 160, 163,\n       164, 163, 161, 160, 160, 161, 167, 166, 165, 165, 165, 166, 167,\n       164, 166, 165, 165, 167, 169, 169, 170, 168, 168, 168, 169, 169,\n       167, 168, 169, 167, 170, 169, 168, 167, 168, 165, 166, 168, 168,\n       165, 164, 164, 163, 163, 163, 159, 158, 157, 158, 156, 153, 153,\n       150, 148, 147], dtype=uint8), array([2.85702873])], [array([147, 148, 146, 146, 148, 150, 147, 149, 148, 149, 150, 150, 148,\n       149, 150, 147, 149, 151, 149, 148, 150, 150, 150, 149, 149, 151,\n       148, 148, 150, 149, 149, 152, 153, 150, 148, 149, 150, 148, 147,\n       150, 152, 150, 150, 149, 149, 148, 150, 151, 151, 150, 150, 148,\n       148, 146, 147, 149, 150, 149, 149, 149, 148, 147, 149, 151, 150,\n       149, 150, 151, 153, 153, 153, 153, 152, 156, 157, 156, 156, 157,\n       157, 151, 146, 132, 119, 115, 118, 125, 128, 128, 126, 127, 126,\n       124, 123, 122, 124, 124, 126, 127, 129, 129, 132, 134, 134, 137,\n       137, 137, 141, 144, 144, 145, 146, 148, 146, 149, 149, 148, 148,\n       148, 153, 150], dtype=uint8), array([4.51179147])], [array([159, 159, 160, 160, 161, 162, 160, 159, 159, 159, 160, 159, 157,\n       157, 157, 153, 150, 151, 152, 153, 151, 150, 149, 147, 146, 143,\n       137, 136, 134, 130, 121, 115, 111, 109, 108, 108, 107, 112, 115,\n       117, 119, 125, 128, 128, 129, 129, 132, 132, 132, 134, 134, 135,\n       137, 137, 135, 136, 133, 133, 132, 122, 108, 103, 103, 103, 110,\n       122, 123, 125, 123, 123, 121, 119, 117, 116, 115, 115, 118, 116,\n       119, 120, 121, 122, 121, 121, 123, 122, 126, 125, 129, 131, 130,\n       133, 135, 134, 133, 133, 136, 135, 137, 139, 139, 140, 140, 141,\n       141, 142, 143, 144, 146, 145, 143, 145, 147, 147, 145, 148, 145,\n       149, 148, 149], dtype=uint8), array([4.37560143])], [array([130, 127, 126, 123, 119, 120, 120, 119, 119, 120, 118, 119, 118,\n       119, 117, 119, 121, 120, 122, 122, 121, 122, 125, 125, 122, 124,\n       126, 127, 127, 126, 127, 127, 129, 128, 132, 131, 134, 132, 133,\n       135, 135, 136, 136, 135, 136, 139, 141, 142, 141, 138, 140, 142,\n       143, 145, 141, 142, 142, 143, 146, 144, 145, 147, 145, 146, 148,\n       148, 149, 151, 153, 152, 153, 154, 153, 154, 156, 157, 156, 154,\n       153, 149, 135, 118, 108, 108, 115, 124, 125, 127, 127, 126, 128,\n       126, 126, 128, 130, 132, 132, 134, 135, 136, 139, 139, 144, 146,\n       147, 147, 149, 153, 154, 152, 152, 153, 154, 156, 157, 156, 155,\n       155, 156, 159], dtype=uint8), array([3.95002995])], [array([140, 143, 146, 145, 147, 150, 150, 150, 150, 149, 153, 152, 151,\n       154, 154, 154, 154, 155, 156, 154, 159, 157, 157, 159, 159, 158,\n       156, 158, 159, 157, 159, 159, 158, 160, 156, 158, 158, 157, 159,\n       161, 160, 160, 159, 159, 160, 159, 158, 160, 160, 161, 159, 159,\n       158, 159, 162, 160, 160, 162, 160, 161, 162, 162, 158, 158, 158,\n       157, 155, 155, 158, 161, 161, 160, 161, 164, 165, 162, 157, 153,\n       148, 138, 134, 136, 140, 146, 142, 144, 145, 144, 143, 142, 142,\n       141, 139, 143, 143, 145, 146, 148, 149, 151, 152, 151, 156, 155,\n       154, 155, 153, 154, 150, 148, 149, 150, 150, 152, 153, 155, 154,\n       154, 152, 152], dtype=uint8), array([3.53048839])], [array([161, 160, 162, 162, 163, 164, 164, 163, 161, 164, 163, 162, 162,\n       164, 163, 162, 165, 166, 161, 165, 165, 164, 162, 159, 163, 161,\n       160, 164, 165, 162, 160, 162, 158, 152, 153, 154, 157, 158, 160,\n       163, 163, 164, 162, 162, 163, 164, 164, 165, 165, 165, 166, 166,\n       166, 166, 164, 164, 164, 163, 157, 155, 151, 145, 139, 132, 125,\n       130, 139, 144, 147, 152, 151, 152, 151, 151, 152, 155, 153, 156,\n       157, 153, 153, 154, 152, 153, 154, 153, 153, 153, 150, 152, 150,\n       151, 151, 152, 151, 146, 143, 140, 145, 150, 151, 151, 151, 152,\n       153, 155, 153, 155, 155, 158, 160, 157, 158, 157, 159, 158, 158,\n       159, 159, 158], dtype=uint8), array([3.67640104])], [array([158, 157, 156, 157, 156, 156, 153, 154, 155, 156, 154, 153, 153,\n       153, 151, 152, 153, 151, 150, 152, 152, 152, 151, 153, 151, 152,\n       150, 152, 152, 152, 152, 151, 150, 150, 150, 150, 149, 150, 151,\n       149, 148, 146, 145, 148, 146, 145, 147, 147, 145, 144, 144, 146,\n       143, 143, 141, 141, 144, 145, 142, 139, 129, 109, 101, 104, 106,\n       116, 133, 137, 136, 139, 142, 144, 143, 144, 144, 146, 146, 147,\n       150, 150, 151, 149, 144, 136, 124, 124, 132, 143, 152, 154, 155,\n       156, 156, 159, 161, 159, 160, 158, 157, 156, 154, 156, 152, 156,\n       155, 157, 156, 159, 157, 158, 159, 160, 159, 159, 159, 157, 159,\n       157, 156, 158], dtype=uint8), array([5.21064103])], [array([178, 180, 180, 181, 180, 181, 183, 179, 181, 185, 182, 182, 181,\n       181, 179, 180, 181, 184, 182, 182, 182, 178, 179, 177, 177, 176,\n       178, 178, 180, 179, 177, 180, 179, 181, 181, 180, 181, 181, 182,\n       179, 179, 178, 176, 175, 173, 173, 171, 170, 167, 160, 142, 125,\n       114, 117, 125, 141, 152, 154, 156, 156, 152, 152, 152, 148, 146,\n       145, 141, 130, 117, 110, 114, 114, 102, 102, 118, 132, 133, 137,\n       142, 146, 149, 153, 155, 155, 156, 152, 150, 150, 151, 158, 159,\n       162, 166, 169, 169, 168, 172, 174, 174, 174, 173, 173, 174, 177,\n       176, 176, 178, 174, 178, 180, 178, 177, 178, 178, 177, 175, 170,\n       173, 173, 176], dtype=uint8), array([7.26221294])], [array([178, 179, 181, 180, 174, 179, 179, 175, 178, 177, 176, 178, 178,\n       178, 178, 179, 178, 180, 182, 179, 179, 181, 182, 177, 179, 178,\n       179, 178, 177, 178, 179, 179, 179, 179, 181, 185, 185, 182, 180,\n       180, 180, 183, 185, 178, 178, 178, 177, 179, 182, 182, 182, 179,\n       180, 181, 181, 182, 182, 183, 182, 187, 193, 189, 190, 191, 192,\n       193, 193, 192, 194, 193, 184, 172, 161, 144, 125, 119, 132, 144,\n       144, 143, 141, 136, 138, 141, 143, 145, 145, 148, 153, 154, 155,\n       159, 163, 163, 163, 164, 166, 170, 172, 176, 179, 179, 179, 180,\n       180, 183, 190, 186, 185, 183, 184, 187, 187, 185, 187, 183, 188,\n       188, 190, 186], dtype=uint8), array([5.93755418])], [array([182, 179, 181, 183, 181, 178, 180, 181, 180, 179, 177, 177, 180,\n       182, 180, 181, 181, 182, 183, 178, 179, 179, 181, 179, 178, 182,\n       182, 182, 182, 182, 183, 186, 183, 183, 185, 185, 186, 183, 184,\n       183, 185, 184, 182, 185, 185, 185, 183, 184, 185, 188, 187, 189,\n       186, 184, 185, 186, 191, 186, 188, 187, 187, 191, 191, 192, 190,\n       192, 191, 192, 191, 191, 186, 173, 158, 142, 130, 130, 146, 147,\n       147, 149, 145, 145, 147, 146, 146, 148, 151, 151, 152, 155, 157,\n       159, 161, 165, 166, 167, 171, 171, 174, 177, 178, 180, 183, 185,\n       185, 185, 185, 186, 186, 182, 185, 185, 187, 186, 186, 187, 186,\n       189, 187, 193], dtype=uint8), array([5.5774322])], [array([193, 192, 192, 189, 191, 193, 191, 191, 189, 189, 191, 191, 188,\n       190, 189, 190, 189, 190, 191, 192, 193, 192, 187, 193, 192, 191,\n       192, 195, 195, 193, 193, 194, 196, 195, 194, 193, 193, 193, 195,\n       192, 194, 193, 189, 191, 190, 190, 189, 189, 189, 191, 188, 187,\n       184, 182, 183, 184, 181, 181, 180, 176, 176, 174, 170, 168, 166,\n       160, 143, 131, 128, 131, 147, 163, 171, 172, 174, 171, 177, 179,\n       180, 181, 182, 182, 182, 185, 188, 190, 186, 187, 187, 188, 187,\n       188, 190, 188, 189, 194, 193, 191, 191, 192, 191, 190, 189, 188,\n       188, 187, 188, 190, 189, 185, 186, 187, 188, 188, 190, 190, 187,\n       192, 192, 187], dtype=uint8), array([4.19787153])], [array([189, 185, 185, 186, 188, 189, 188, 193, 193, 194, 193, 189, 192,\n       191, 192, 194, 193, 192, 191, 192, 194, 191, 191, 191, 193, 193,\n       192, 195, 194, 194, 193, 190, 192, 193, 190, 191, 193, 192, 192,\n       192, 193, 193, 193, 196, 192, 191, 193, 194, 190, 192, 192, 189,\n       188, 186, 186, 186, 185, 185, 186, 188, 186, 188, 188, 185, 186,\n       182, 180, 177, 172, 161, 147, 131, 132, 141, 152, 157, 162, 169,\n       175, 174, 175, 178, 181, 180, 179, 182, 182, 188, 188, 187, 185,\n       188, 194, 193, 193, 197, 195, 194, 197, 196, 197, 196, 193, 197,\n       195, 196, 196, 195, 192, 193, 194, 196, 194, 194, 193, 196, 195,\n       191, 193, 190], dtype=uint8), array([3.7441611])], [array([174, 173, 172, 172, 173, 175, 174, 173, 171, 174, 176, 177, 178,\n       176, 178, 179, 173, 173, 166, 162, 164, 164, 162, 168, 168, 169,\n       171, 169, 171, 174, 174, 177, 177, 175, 175, 174, 176, 176, 176,\n       177, 177, 175, 174, 174, 176, 176, 175, 176, 176, 177, 177, 176,\n       178, 174, 179, 179, 178, 177, 181, 184, 178, 180, 182, 180, 184,\n       184, 186, 184, 184, 182, 176, 165, 147, 130, 119, 131, 145, 148,\n       147, 147, 147, 145, 145, 147, 149, 152, 151, 152, 156, 158, 159,\n       162, 164, 166, 169, 169, 172, 171, 175, 175, 172, 178, 178, 178,\n       181, 178, 180, 178, 177, 175, 177, 178, 177, 177, 177, 175, 176,\n       177, 177, 176], dtype=uint8), array([5.20109506])], [array([166, 163, 163, 164, 164, 163, 162, 161, 163, 162, 163, 168, 169,\n       167, 166, 166, 168, 169, 169, 169, 166, 168, 171, 171, 171, 169,\n       170, 170, 171, 170, 168, 171, 170, 175, 172, 170, 171, 171, 167,\n       169, 168, 167, 172, 171, 169, 167, 168, 171, 171, 169, 170, 171,\n       172, 172, 171, 166, 165, 165, 167, 172, 172, 175, 177, 180, 182,\n       183, 183, 183, 183, 184, 182, 176, 163, 146, 129, 118, 127, 139,\n       144, 143, 142, 138, 137, 137, 138, 140, 140, 140, 141, 143, 147,\n       148, 151, 153, 154, 157, 157, 159, 160, 161, 162, 160, 162, 161,\n       161, 164, 160, 165, 162, 162, 162, 163, 162, 161, 160, 162, 161,\n       159, 157, 158], dtype=uint8), array([4.87914297])], [array([198, 201, 198, 199, 202, 202, 203, 205, 206, 206, 202, 205, 205,\n       203, 205, 204, 202, 199, 200, 203, 202, 204, 205, 205, 204, 204,\n       204, 204, 203, 205, 206, 205, 205, 200, 201, 201, 201, 203, 204,\n       202, 203, 204, 200, 201, 200, 203, 207, 203, 203, 205, 205, 201,\n       200, 202, 204, 203, 202, 201, 205, 206, 203, 203, 204, 204, 201,\n       204, 203, 203, 202, 200, 201, 205, 203, 202, 202, 203, 204, 205,\n       204, 203, 205, 204, 201, 202, 205, 207, 207, 204, 207, 205, 201,\n       200, 205, 202, 203, 204, 205, 202, 203, 205, 204, 202, 202, 203,\n       203, 203, 203, 202, 205, 200, 202, 204, 203, 204, 202, 202, 203,\n       205, 205, 204], dtype=uint8), array([0.])], [array([190, 192, 188, 187, 191, 190, 185, 187, 185, 184, 189, 187, 187,\n       184, 182, 186, 185, 185, 189, 189, 187, 186, 185, 186, 184, 188,\n       189, 190, 186, 187, 189, 189, 189, 190, 191, 192, 189, 191, 193,\n       191, 192, 191, 190, 190, 190, 192, 192, 194, 192, 192, 193, 191,\n       192, 193, 194, 194, 195, 194, 196, 194, 197, 196, 196, 196, 193,\n       193, 189, 175, 160, 157, 165, 168, 154, 136, 128, 131, 132, 132,\n       127, 122, 121, 122, 125, 129, 132, 134, 133, 133, 135, 137, 140,\n       145, 145, 152, 153, 155, 156, 159, 163, 165, 166, 167, 170, 174,\n       177, 177, 178, 182, 184, 183, 184, 186, 187, 189, 189, 192, 192,\n       193, 193, 194], dtype=uint8), array([8.52101685])], [array([184, 186, 186, 185, 187, 185, 186, 185, 185, 187, 191, 186, 187,\n       188, 188, 186, 186, 189, 188, 187, 189, 188, 187, 191, 187, 188,\n       188, 188, 188, 188, 187, 189, 190, 189, 189, 187, 186, 191, 190,\n       190, 189, 189, 192, 189, 191, 192, 194, 192, 192, 192, 192, 191,\n       193, 196, 194, 195, 194, 199, 198, 196, 197, 199, 199, 197, 195,\n       189, 176, 158, 150, 155, 160, 148, 129, 121, 122, 120, 119, 120,\n       120, 120, 123, 124, 124, 123, 126, 126, 129, 134, 137, 137, 141,\n       144, 148, 151, 153, 154, 156, 158, 162, 165, 164, 169, 172, 172,\n       175, 177, 180, 183, 184, 185, 186, 184, 188, 190, 191, 192, 192,\n       188, 191, 191], dtype=uint8), array([8.73503977])], [array([155, 154, 154, 153, 154, 146, 142, 141, 148, 153, 161, 171, 178,\n       180, 185, 185, 189, 188, 190, 187, 187, 188, 186, 187, 188, 185,\n       183, 184, 185, 186, 188, 187, 187, 186, 187, 188, 186, 185, 185,\n       187, 184, 184, 185, 186, 186, 186, 183, 183, 180, 183, 180, 177,\n       176, 178, 177, 176, 173, 171, 171, 173, 171, 168, 168, 168, 167,\n       165, 165, 164, 164, 162, 157, 150, 144, 142, 143, 152, 162, 165,\n       166, 168, 170, 169, 173, 173, 177, 172, 176, 177, 176, 175, 178,\n       181, 178, 178, 180, 182, 181, 183, 186, 182, 181, 179, 182, 184,\n       185, 181, 180, 182, 183, 183, 183, 183, 182, 182, 182, 182, 183,\n       182, 183, 180], dtype=uint8), array([4.59109883])], [array([189, 189, 188, 187, 187, 186, 187, 189, 188, 187, 185, 185, 189,\n       190, 191, 191, 191, 188, 186, 186, 188, 189, 187, 187, 187, 186,\n       187, 185, 184, 183, 186, 184, 182, 183, 182, 183, 179, 178, 181,\n       177, 177, 174, 171, 169, 168, 168, 165, 165, 164, 161, 158, 158,\n       155, 156, 156, 161, 158, 158, 157, 158, 154, 141, 129, 135, 152,\n       163, 174, 183, 188, 188, 190, 189, 189, 187, 187, 190, 188, 185,\n       187, 186, 189, 186, 184, 183, 183, 183, 182, 182, 180, 183, 184,\n       183, 181, 181, 182, 180, 180, 181, 181, 178, 177, 177, 177, 176,\n       176, 174, 177, 175, 175, 173, 172, 173, 171, 174, 173, 171, 169,\n       171, 171, 169], dtype=uint8), array([4.34090199])], [array([184, 185, 186, 180, 184, 182, 183, 185, 183, 184, 184, 183, 183,\n       183, 181, 180, 180, 181, 183, 184, 185, 185, 184, 184, 184, 187,\n       186, 185, 180, 181, 181, 180, 180, 177, 178, 177, 175, 175, 174,\n       175, 176, 173, 171, 169, 166, 166, 164, 160, 163, 165, 162, 161,\n       161, 161, 162, 161, 162, 162, 162, 162, 158, 151, 145, 150, 160,\n       175, 181, 184, 184, 184, 184, 181, 180, 178, 177, 178, 176, 175,\n       175, 173, 175, 174, 171, 173, 176, 175, 175, 176, 180, 178, 177,\n       179, 178, 175, 176, 178, 179, 177, 178, 175, 176, 177, 179, 179,\n       179, 180, 180, 181, 181, 183, 180, 181, 179, 178, 174, 174, 173,\n       173, 175, 175], dtype=uint8), array([4.35067225])], [array([181, 185, 184, 186, 187, 186, 186, 188, 187, 185, 188, 184, 186,\n       188, 184, 184, 182, 186, 186, 185, 186, 186, 186, 183, 183, 183,\n       180, 181, 188, 183, 180, 181, 180, 178, 178, 176, 173, 169, 167,\n       165, 163, 163, 163, 160, 160, 158, 160, 156, 156, 157, 156, 157,\n       159, 158, 157, 158, 157, 156, 152, 141, 137, 146, 163, 171, 180,\n       186, 186, 187, 186, 183, 182, 182, 177, 177, 177, 171, 172, 170,\n       168, 168, 165, 164, 167, 166, 165, 165, 164, 163, 161, 160, 162,\n       153, 143, 148, 162, 171, 178, 180, 180, 180, 181, 177, 172, 169,\n       169, 172, 173, 174, 177, 178, 174, 174, 174, 173, 171, 169, 169,\n       171, 171, 169], dtype=uint8), array([4.18356936])], [array([172, 172, 173, 171, 173, 172, 172, 167, 168, 169, 168, 171, 170,\n       170, 170, 170, 170, 171, 169, 168, 170, 173, 172, 171, 171, 170,\n       170, 172, 169, 169, 169, 170, 170, 168, 168, 168, 170, 170, 172,\n       170, 168, 169, 165, 170, 168, 167, 171, 171, 169, 171, 168, 169,\n       169, 169, 169, 170, 173, 171, 171, 171, 171, 171, 171, 172, 166,\n       171, 170, 170, 170, 170, 167, 160, 149, 142, 141, 141, 145, 153,\n       156, 154, 156, 150, 146, 149, 144, 145, 147, 144, 144, 146, 147,\n       151, 153, 152, 156, 157, 158, 160, 161, 161, 160, 163, 165, 166,\n       169, 171, 169, 170, 169, 171, 172, 171, 171, 172, 169, 168, 172,\n       171, 173, 173], dtype=uint8), array([5.923182])], [array([176, 175, 173, 171, 172, 174, 173, 177, 173, 177, 174, 175, 172,\n       172, 173, 174, 173, 168, 167, 162, 154, 156, 155, 156, 157, 163,\n       163, 168, 172, 170, 167, 160, 155, 143, 140, 143, 154, 163, 165,\n       167, 170, 170, 171, 173, 175, 173, 175, 176, 179, 180, 180, 177,\n       173, 173, 174, 177, 182, 186, 185, 191, 192, 192, 193, 189, 185,\n       175, 162, 163, 170, 156, 135, 117, 110, 104, 102, 102, 105, 108,\n       110, 110, 114, 114, 115, 117, 120, 123, 123, 125, 127, 129, 135,\n       136, 138, 138, 144, 149, 152, 153, 155, 158, 160, 162, 166, 163,\n       166, 169, 169, 170, 172, 174, 177, 176, 178, 178, 175, 177, 178,\n       180, 181, 183], dtype=uint8), array([8.89809448])], [array([170, 172, 170, 170, 171, 172, 171, 170, 168, 165, 166, 166, 170,\n       171, 173, 173, 170, 175, 174, 171, 173, 170, 174, 173, 176, 172,\n       172, 172, 171, 174, 175, 176, 174, 172, 171, 172, 174, 171, 173,\n       176, 173, 175, 172, 172, 171, 170, 169, 172, 174, 173, 171, 172,\n       169, 170, 170, 167, 165, 167, 168, 166, 163, 164, 166, 163, 161,\n       161, 161, 158, 155, 154, 150, 137, 121, 119, 125, 119, 117, 132,\n       147, 153, 152, 153, 158, 159, 160, 161, 161, 163, 165, 168, 171,\n       170, 168, 171, 172, 174, 171, 172, 175, 175, 175, 174, 175, 173,\n       174, 171, 169, 161, 157, 154, 150, 153, 154, 160, 162, 166, 172,\n       176, 174, 176], dtype=uint8), array([4.7800506])], [array([173, 174, 174, 172, 174, 174, 174, 173, 173, 173, 173, 174, 178,\n       175, 176, 175, 174, 172, 173, 174, 174, 174, 173, 172, 174, 172,\n       172, 174, 172, 171, 172, 173, 176, 175, 172, 172, 174, 172, 171,\n       173, 169, 170, 171, 171, 166, 163, 167, 165, 164, 162, 160, 160,\n       159, 157, 156, 155, 151, 149, 151, 150, 151, 149, 147, 147, 146,\n       147, 150, 148, 147, 143, 136, 120, 121, 128, 126, 136, 147, 158,\n       157, 159, 159, 163, 166, 161, 160, 159, 164, 168, 167, 166, 166,\n       167, 167, 165, 166, 168, 169, 170, 166, 166, 169, 168, 169, 172,\n       168, 167, 166, 169, 172, 173, 174, 172, 173, 170, 171, 172, 169,\n       171, 170, 170], dtype=uint8), array([5.29939395])], [array([173, 174, 171, 170, 173, 173, 174, 172, 172, 170, 174, 172, 173,\n       175, 173, 170, 172, 169, 171, 174, 175, 170, 173, 170, 170, 171,\n       168, 175, 169, 171, 171, 172, 167, 170, 174, 169, 172, 168, 169,\n       171, 167, 171, 171, 167, 168, 170, 168, 171, 167, 163, 164, 166,\n       166, 165, 164, 159, 162, 162, 165, 161, 159, 158, 160, 162, 159,\n       156, 160, 157, 153, 157, 151, 133, 128, 126, 124, 126, 140, 150,\n       151, 152, 154, 153, 155, 153, 157, 158, 158, 161, 157, 160, 158,\n       161, 166, 167, 165, 168, 164, 167, 167, 166, 167, 166, 168, 165,\n       166, 166, 167, 167, 171, 167, 172, 165, 169, 168, 169, 169, 169,\n       166, 169, 169], dtype=uint8), array([5.08347615])], [array([216, 216, 214, 213, 213, 214, 211, 214, 213, 214, 213, 213, 212,\n       210, 211, 212, 209, 210, 209, 211, 212, 211, 211, 211, 213, 212,\n       213, 213, 213, 219, 213, 210, 213, 213, 214, 211, 211, 213, 211,\n       212, 211, 210, 206, 203, 204, 204, 200, 198, 195, 188, 159, 129,\n       135, 158, 158, 126, 104, 117, 140, 143, 146, 148, 153, 157, 162,\n       164, 171, 176, 178, 182, 187, 188, 190, 191, 192, 195, 198, 202,\n       203, 206, 207, 208, 206, 205, 205, 207, 204, 208, 207, 211, 209,\n       210, 212, 212, 210, 211, 215, 212, 215, 214, 215, 213, 213, 214,\n       212, 213, 215, 214, 215, 211, 211, 214, 213, 212, 216, 217, 213,\n       215, 214, 211], dtype=uint8), array([8.36581426])], [array([208, 207, 211, 211, 211, 209, 210, 209, 206, 206, 206, 203, 202,\n       203, 203, 200, 197, 198, 192, 192, 192, 189, 178, 168, 168, 176,\n       176, 188, 198, 202, 204, 205, 206, 201, 201, 203, 203, 203, 204,\n       201, 203, 204, 202, 201, 199, 199, 197, 195, 192, 189, 185, 180,\n       179, 171, 166, 166, 161, 158, 152, 153, 158, 162, 160, 154, 136,\n       109, 113, 131, 139, 133, 131, 150, 176, 191, 197, 196, 200, 202,\n       203, 204, 205, 207, 207, 209, 206, 206, 210, 209, 208, 211, 209,\n       210, 211, 208, 211, 211, 212, 213, 214, 215, 210, 207, 209, 213,\n       213, 210, 213, 215, 212, 214, 214, 213, 214, 213, 211, 211, 212,\n       212, 211, 208], dtype=uint8), array([8.89809448])], [array([210, 209, 213, 213, 212, 211, 212, 213, 213, 210, 209, 211, 212,\n       210, 207, 206, 204, 205, 206, 207, 208, 212, 209, 211, 211, 213,\n       211, 207, 213, 207, 209, 211, 209, 209, 209, 213, 207, 208, 209,\n       210, 213, 212, 210, 207, 209, 212, 209, 209, 212, 213, 211, 209,\n       210, 212, 212, 213, 213, 211, 211, 210, 210, 211, 208, 209, 207,\n       209, 208, 205, 203, 195, 177, 159, 160, 154, 150, 173, 181, 184,\n       189, 193, 194, 197, 201, 205, 201, 201, 205, 210, 205, 209, 209,\n       209, 206, 210, 212, 206, 209, 211, 212, 210, 210, 210, 211, 210,\n       209, 210, 208, 209, 211, 211, 211, 210, 210, 208, 207, 209, 212,\n       207, 209, 209], dtype=uint8), array([4.7800506])], [array([208, 214, 211, 210, 212, 213, 210, 211, 210, 209, 211, 212, 214,\n       214, 212, 213, 212, 212, 212, 212, 210, 210, 211, 212, 208, 210,\n       210, 208, 212, 211, 210, 210, 211, 212, 212, 211, 211, 210, 209,\n       212, 212, 210, 210, 208, 211, 214, 213, 210, 213, 211, 211, 211,\n       216, 214, 214, 213, 215, 213, 214, 212, 214, 213, 211, 209, 209,\n       208, 204, 201, 189, 166, 146, 150, 140, 133, 158, 182, 187, 193,\n       192, 194, 197, 201, 199, 198, 201, 203, 204, 205, 208, 208, 207,\n       207, 208, 207, 207, 209, 205, 193, 180, 175, 175, 188, 203, 206,\n       210, 209, 214, 210, 212, 208, 210, 209, 209, 209, 211, 211, 211,\n       212, 215, 213], dtype=uint8), array([5.29939395])], [array([201, 202, 203, 203, 206, 205, 203, 204, 204, 206, 204, 203, 205,\n       208, 207, 208, 209, 207, 208, 207, 206, 208, 207, 205, 206, 207,\n       207, 208, 209, 206, 206, 207, 207, 209, 209, 209, 207, 209, 210,\n       210, 209, 209, 209, 207, 206, 204, 211, 211, 211, 210, 210, 209,\n       209, 208, 210, 208, 206, 208, 208, 208, 208, 212, 211, 209, 207,\n       205, 205, 207, 200, 198, 191, 171, 159, 154, 148, 166, 186, 191,\n       187, 200, 199, 201, 206, 208, 208, 207, 209, 208, 212, 210, 210,\n       213, 209, 211, 210, 212, 210, 211, 211, 213, 210, 208, 213, 212,\n       210, 213, 214, 214, 214, 213, 210, 213, 209, 211, 210, 212, 212,\n       210, 212, 216], dtype=uint8), array([5.08347615])], [array([208, 208, 208, 206, 204, 206, 206, 206, 207, 208, 205, 207, 209,\n       210, 212, 208, 210, 206, 205, 204, 208, 209, 207, 208, 206, 209,\n       210, 206, 212, 208, 207, 208, 204, 208, 210, 211, 210, 210, 210,\n       209, 209, 210, 211, 207, 208, 207, 211, 213, 208, 207, 208, 209,\n       210, 210, 210, 210, 209, 205, 210, 210, 206, 206, 207, 208, 206,\n       207, 204, 202, 199, 193, 177, 160, 156, 161, 166, 179, 185, 189,\n       192, 192, 196, 194, 199, 200, 203, 205, 206, 206, 206, 209, 210,\n       208, 207, 209, 209, 209, 211, 211, 211, 211, 209, 211, 212, 211,\n       210, 211, 209, 209, 209, 210, 209, 208, 211, 210, 208, 208, 208,\n       209, 209, 210], dtype=uint8), array([5.923182])], [array([204, 202, 202, 201, 196, 189, 185, 181, 176, 171, 168, 171, 180,\n       179, 177, 179, 179, 179, 180, 179, 180, 181, 183, 186, 185, 184,\n       188, 190, 192, 194, 191, 193, 196, 196, 197, 199, 201, 202, 200,\n       201, 205, 202, 204, 203, 203, 206, 207, 206, 207, 209, 207, 208,\n       207, 211, 209, 210, 209, 212, 210, 210, 211, 210, 209, 207, 209,\n       211, 209, 205, 199, 184, 172, 162, 154, 160, 175, 179, 178, 178,\n       181, 182, 185, 185, 184, 190, 192, 193, 196, 198, 203, 203, 203,\n       204, 202, 202, 207, 207, 206, 206, 209, 209, 210, 207, 208, 210,\n       210, 209, 212, 212, 210, 211, 210, 209, 210, 210, 208, 206, 209,\n       208, 210, 207], dtype=uint8), array([4.59109883])], [array([202, 203, 203, 201, 203, 200, 204, 204, 209, 203, 206, 206, 208,\n       207, 205, 205, 207, 207, 206, 206, 207, 207, 205, 207, 208, 203,\n       206, 208, 206, 208, 207, 208, 205, 206, 205, 203, 205, 205, 205,\n       202, 204, 204, 203, 206, 206, 207, 205, 207, 210, 207, 207, 208,\n       207, 206, 206, 206, 204, 204, 202, 201, 196, 190, 179, 169, 169,\n       173, 183, 179, 176, 177, 178, 179, 180, 182, 182, 184, 186, 189,\n       189, 194, 190, 194, 195, 198, 196, 196, 197, 200, 202, 200, 203,\n       203, 202, 204, 203, 206, 206, 208, 208, 208, 208, 209, 208, 208,\n       207, 208, 208, 208, 206, 205, 209, 209, 207, 208, 208, 206, 205,\n       202, 206, 207], dtype=uint8), array([4.34090199])], [array([207, 208, 207, 205, 202, 205, 205, 205, 206, 207, 207, 204, 205,\n       204, 204, 205, 207, 209, 207, 206, 204, 204, 203, 204, 204, 205,\n       202, 203, 204, 202, 205, 203, 202, 204, 202, 200, 200, 199, 195,\n       192, 192, 193, 192, 187, 184, 182, 169, 149, 138, 145, 151, 138,\n       114, 105, 118, 135, 140, 136, 135, 139, 143, 144, 147, 149, 152,\n       157, 162, 163, 168, 171, 173, 179, 182, 182, 189, 190, 193, 195,\n       193, 195, 196, 198, 201, 204, 205, 202, 202, 206, 206, 206, 207,\n       205, 204, 208, 207, 206, 205, 207, 205, 205, 206, 206, 205, 203,\n       202, 204, 204, 204, 204, 203, 199, 200, 200, 201, 201, 204, 203,\n       203, 199, 202], dtype=uint8), array([8.52101685])], [array([204, 206, 206, 206, 205, 209, 201, 206, 203, 206, 207, 209, 208,\n       207, 205, 207, 205, 207, 206, 208, 205, 206, 208, 206, 204, 205,\n       207, 208, 208, 207, 206, 208, 207, 207, 206, 207, 207, 204, 205,\n       203, 199, 199, 198, 198, 196, 193, 190, 183, 164, 145, 140, 156,\n       167, 140, 113, 112, 130, 140, 139, 139, 138, 135, 140, 145, 146,\n       149, 153, 158, 158, 162, 166, 171, 172, 174, 180, 181, 185, 188,\n       185, 190, 193, 195, 197, 201, 197, 203, 201, 200, 203, 206, 204,\n       205, 202, 205, 204, 205, 205, 205, 206, 207, 207, 208, 208, 203,\n       203, 205, 206, 205, 201, 206, 204, 206, 205, 205, 206, 209, 207,\n       207, 207, 205], dtype=uint8), array([8.73503977])], [array([203, 201, 205, 205, 208, 203, 203, 205, 206, 205, 203, 206, 207,\n       205, 207, 207, 206, 205, 204, 205, 207, 206, 208, 207, 207, 205,\n       202, 204, 205, 205, 202, 204, 203, 207, 207, 203, 203, 207, 204,\n       205, 207, 208, 205, 206, 209, 206, 208, 208, 207, 209, 208, 207,\n       207, 204, 203, 199, 195, 186, 177, 166, 159, 156, 161, 171, 170,\n       170, 172, 170, 171, 172, 176, 177, 179, 184, 188, 191, 190, 192,\n       193, 194, 199, 202, 203, 204, 204, 205, 209, 205, 204, 209, 208,\n       206, 209, 207, 209, 208, 203, 197, 190, 178, 171, 169, 173, 176,\n       177, 178, 179, 180, 182, 182, 183, 185, 186, 189, 196, 198, 199,\n       198, 198, 200], dtype=uint8), array([4.18356936])], [array([206, 203, 201, 203, 205, 204, 205, 208, 207, 206, 203, 207, 206,\n       207, 205, 204, 204, 206, 206, 207, 206, 205, 206, 209, 206, 207,\n       207, 206, 208, 204, 207, 206, 206, 204, 204, 204, 204, 204, 203,\n       204, 204, 206, 205, 204, 204, 202, 204, 204, 206, 206, 204, 207,\n       208, 209, 206, 208, 209, 207, 209, 202, 198, 194, 184, 172, 166,\n       169, 175, 176, 172, 175, 175, 176, 176, 179, 182, 182, 181, 182,\n       192, 192, 194, 195, 196, 198, 197, 198, 202, 203, 204, 204, 206,\n       206, 206, 207, 208, 207, 206, 205, 207, 206, 206, 205, 204, 205,\n       210, 206, 210, 210, 208, 205, 205, 202, 200, 201, 195, 196, 197,\n       194, 196, 199], dtype=uint8), array([4.35067225])], [array([186, 182, 184, 182, 183, 185, 185, 184, 184, 186, 188, 189, 187,\n       186, 187, 184, 183, 183, 183, 187, 184, 184, 188, 188, 185, 185,\n       185, 185, 186, 186, 187, 189, 187, 187, 189, 187, 190, 185, 187,\n       185, 185, 188, 186, 186, 185, 185, 185, 185, 187, 186, 186, 185,\n       186, 187, 188, 189, 190, 191, 187, 189, 188, 186, 186, 186, 183,\n       183, 185, 184, 183, 182, 182, 186, 185, 184, 184, 179, 182, 182,\n       180, 181, 183, 182, 184, 185, 184, 184, 183, 183, 184, 182, 182,\n       183, 180, 183, 181, 181, 180, 180, 176, 181, 180, 182, 181, 179,\n       180, 182, 182, 180, 180, 182, 184, 181, 180, 180, 178, 177, 181,\n       180, 181, 180], dtype=uint8), array([0.])], [array([195, 196, 198, 198, 196, 196, 195, 194, 195, 196, 194, 194, 193,\n       193, 195, 194, 195, 194, 192, 193, 195, 193, 195, 197, 196, 197,\n       195, 194, 193, 195, 196, 195, 193, 193, 196, 193, 197, 195, 197,\n       196, 196, 195, 195, 193, 192, 194, 193, 193, 194, 194, 194, 193,\n       194, 196, 191, 189, 194, 195, 197, 196, 196, 197, 195, 198, 196,\n       194, 199, 200, 196, 197, 197, 197, 194, 191, 177, 158, 151, 142,\n       131, 133, 153, 161, 162, 164, 163, 162, 163, 163, 161, 162, 167,\n       167, 166, 170, 179, 177, 176, 177, 182, 183, 186, 188, 187, 187,\n       190, 191, 189, 185, 185, 189, 190, 194, 197, 195, 196, 195, 196,\n       196, 196, 197], dtype=uint8), array([4.75818342])], [array([198, 199, 196, 193, 195, 195, 194, 194, 195, 196, 195, 197, 198,\n       194, 193, 196, 196, 197, 198, 200, 195, 194, 196, 193, 193, 193,\n       194, 191, 190, 190, 192, 187, 186, 186, 184, 184, 180, 177, 177,\n       175, 171, 172, 172, 171, 171, 169, 170, 167, 167, 169, 169, 171,\n       173, 174, 173, 171, 168, 164, 162, 166, 173, 184, 192, 198, 196,\n       197, 195, 198, 195, 197, 194, 195, 198, 191, 199, 199, 196, 196,\n       195, 196, 194, 194, 197, 198, 197, 196, 195, 197, 195, 194, 192,\n       192, 195, 193, 191, 191, 190, 189, 185, 186, 187, 186, 188, 189,\n       190, 191, 190, 189, 189, 190, 193, 192, 191, 191, 191, 191, 193,\n       194, 197, 196], dtype=uint8), array([3.84824603])], [array([193, 193, 194, 193, 193, 193, 195, 192, 196, 190, 189, 191, 191,\n       191, 190, 190, 191, 191, 185, 189, 192, 192, 193, 193, 190, 189,\n       188, 189, 190, 189, 188, 191, 189, 188, 191, 191, 187, 190, 189,\n       187, 183, 185, 185, 186, 185, 181, 178, 178, 181, 178, 178, 175,\n       177, 174, 171, 171, 170, 164, 163, 164, 162, 161, 160, 162, 160,\n       158, 158, 159, 158, 146, 134, 130, 135, 143, 156, 164, 174, 180,\n       183, 183, 186, 187, 188, 189, 189, 189, 188, 188, 188, 187, 188,\n       189, 188, 187, 185, 185, 184, 183, 179, 177, 172, 168, 161, 158,\n       154, 148, 147, 154, 162, 169, 176, 180, 184, 184, 185, 186, 188,\n       189, 188, 187], dtype=uint8), array([5.52762087])], [array([192, 194, 194, 193, 194, 193, 193, 190, 194, 195, 194, 194, 194,\n       192, 193, 192, 193, 190, 189, 191, 194, 189, 190, 191, 187, 186,\n       186, 185, 185, 183, 180, 180, 178, 174, 173, 171, 169, 168, 165,\n       165, 162, 155, 154, 156, 154, 153, 151, 150, 151, 155, 157, 157,\n       156, 157, 155, 149, 143, 141, 146, 157, 168, 179, 187, 192, 196,\n       197, 196, 195, 193, 193, 194, 193, 192, 193, 192, 194, 193, 189,\n       188, 191, 191, 191, 189, 190, 190, 189, 190, 188, 187, 187, 190,\n       189, 188, 188, 188, 188, 187, 190, 184, 182, 183, 185, 190, 188,\n       184, 185, 189, 185, 188, 185, 186, 184, 186, 183, 180, 181, 179,\n       180, 180, 178], dtype=uint8), array([5.24173503])], [array([187, 185, 186, 187, 186, 184, 186, 189, 186, 186, 187, 185, 185,\n       183, 184, 183, 184, 182, 183, 181, 178, 181, 180, 176, 178, 174,\n       177, 175, 174, 170, 166, 165, 161, 159, 160, 158, 158, 158, 157,\n       159, 158, 155, 153, 154, 154, 159, 160, 160, 164, 164, 164, 165,\n       161, 154, 147, 145, 152, 164, 178, 184, 190, 187, 187, 186, 186,\n       183, 185, 179, 181, 183, 184, 181, 181, 182, 180, 180, 183, 181,\n       183, 182, 180, 179, 179, 180, 179, 179, 182, 180, 178, 180, 179,\n       178, 178, 178, 177, 181, 181, 179, 178, 177, 178, 177, 177, 177,\n       179, 180, 181, 180, 179, 179, 179, 179, 180, 182, 183, 180, 178,\n       180, 180, 179], dtype=uint8), array([3.48806279])], [array([181, 182, 183, 182, 182, 184, 181, 182, 182, 185, 180, 182, 181,\n       180, 182, 179, 180, 181, 181, 180, 182, 182, 179, 178, 177, 179,\n       180, 180, 179, 179, 178, 177, 180, 178, 180, 179, 181, 181, 181,\n       179, 179, 178, 179, 178, 177, 179, 179, 180, 179, 180, 179, 177,\n       178, 178, 177, 176, 177, 176, 174, 174, 176, 176, 176, 172, 173,\n       171, 173, 171, 170, 169, 169, 168, 170, 170, 169, 164, 155, 144,\n       137, 131, 124, 134, 150, 156, 155, 154, 157, 155, 156, 155, 156,\n       157, 157, 159, 159, 157, 159, 157, 157, 156, 155, 159, 158, 156,\n       156, 155, 156, 155, 155, 154, 153, 152, 155, 151, 155, 153, 153,\n       152, 149, 137], dtype=uint8), array([4.68352392])], [array([181, 183, 180, 179, 180, 181, 180, 179, 178, 178, 181, 181, 181,\n       182, 180, 180, 181, 177, 175, 176, 175, 177, 177, 176, 175, 173,\n       174, 170, 170, 170, 171, 170, 168, 165, 166, 164, 161, 164, 160,\n       157, 155, 147, 135, 131, 132, 132, 139, 152, 158, 159, 159, 159,\n       160, 161, 162, 163, 162, 164, 162, 162, 162, 163, 162, 164, 165,\n       162, 164, 163, 163, 162, 165, 160, 153, 143, 135, 134, 138, 146,\n       160, 167, 171, 172, 172, 172, 175, 177, 178, 179, 179, 177, 181,\n       179, 179, 180, 181, 176, 179, 179, 178, 178, 179, 179, 179, 178,\n       177, 178, 180, 179, 180, 186, 178, 179, 180, 177, 179, 181, 180,\n       178, 179, 180], dtype=uint8), array([4.45399496])], [array([198, 197, 196, 197, 198, 198, 198, 196, 198, 197, 197, 197, 198,\n       195, 197, 194, 197, 197, 199, 199, 197, 200, 195, 196, 193, 196,\n       197, 196, 200, 198, 196, 195, 196, 196, 196, 198, 199, 196, 194,\n       196, 198, 197, 194, 193, 196, 196, 194, 195, 195, 193, 193, 195,\n       195, 193, 193, 193, 191, 194, 194, 197, 195, 192, 192, 190, 196,\n       193, 194, 195, 195, 193, 193, 193, 193, 195, 195, 194, 194, 193,\n       194, 195, 195, 196, 196, 194, 195, 197, 198, 194, 193, 194, 192,\n       190, 192, 196, 195, 193, 194, 190, 192, 194, 193, 193, 196, 192,\n       192, 193, 193, 196, 194, 195, 192, 196, 194, 192, 190, 191, 186,\n       192, 192, 191], dtype=uint8), array([0.])], [array([209, 211, 211, 209, 211, 212, 211, 211, 213, 209, 216, 211, 207,\n       211, 210, 212, 210, 210, 210, 209, 212, 215, 211, 210, 208, 210,\n       210, 211, 213, 212, 211, 212, 210, 212, 210, 209, 210, 206, 204,\n       208, 208, 210, 212, 214, 212, 211, 211, 208, 207, 208, 211, 207,\n       205, 205, 201, 202, 203, 203, 199, 196, 194, 195, 192, 189, 183,\n       171, 147, 133, 129, 129, 121, 111, 112, 126, 140, 148, 152, 153,\n       157, 160, 166, 170, 174, 179, 180, 186, 190, 193, 194, 198, 197,\n       199, 199, 204, 207, 207, 207, 209, 210, 210, 210, 208, 211, 212,\n       210, 211, 209, 210, 209, 208, 211, 208, 209, 208, 206, 208, 210,\n       210, 210, 210], dtype=uint8), array([8.71474618])], [array([212, 215, 213, 210, 210, 211, 212, 212, 212, 213, 215, 212, 213,\n       213, 212, 209, 208, 213, 212, 212, 209, 212, 212, 212, 209, 212,\n       213, 212, 210, 212, 213, 213, 209, 210, 212, 211, 205, 207, 207,\n       208, 210, 206, 209, 207, 206, 208, 208, 208, 207, 210, 208, 207,\n       209, 207, 206, 205, 204, 203, 198, 201, 198, 196, 188, 190, 186,\n       179, 173, 156, 128, 102,  95, 105, 120, 126, 124, 125, 138, 153,\n       165, 170, 174, 173, 176, 182, 185, 187, 188, 192, 193, 193, 195,\n       200, 201, 201, 203, 204, 205, 210, 208, 208, 205, 206, 208, 212,\n       209, 209, 211, 211, 211, 210, 215, 211, 211, 211, 210, 212, 210,\n       210, 209, 210], dtype=uint8), array([9.02551505])], [array([169, 169, 172, 177, 179, 178, 181, 181, 180, 183, 184, 186, 187,\n       189, 192, 190, 193, 193, 194, 193, 191, 196, 195, 199, 201, 201,\n       201, 203, 204, 204, 198, 201, 205, 204, 204, 204, 204, 204, 203,\n       204, 202, 202, 203, 199, 195, 183, 160, 143, 142, 144, 125, 114,\n       125, 137, 142, 146, 148, 152, 157, 162, 169, 172, 176, 179, 181,\n       183, 189, 194, 196, 194, 196, 202, 202, 202, 205, 207, 207, 205,\n       202, 206, 209, 209, 206, 206, 208, 212, 212, 210, 210, 211, 209,\n       208, 208, 213, 212, 209, 208, 208, 208, 207, 210, 210, 211, 205,\n       204, 210, 209, 209, 212, 210, 209, 208, 208, 207, 209, 210, 210,\n       211, 210, 214], dtype=uint8), array([7.32964192])], [array([211, 211, 211, 213, 214, 212, 214, 215, 216, 214, 209, 210, 215,\n       213, 215, 213, 213, 213, 215, 214, 213, 213, 212, 213, 213, 213,\n       213, 209, 209, 213, 209, 212, 211, 210, 210, 209, 206, 202, 200,\n       201, 197, 198, 208, 206, 206, 209, 212, 209, 211, 213, 211, 208,\n       210, 212, 211, 202, 204, 203, 202, 202, 202, 199, 193, 183, 172,\n       159, 152, 155, 163, 171, 174, 172, 175, 178, 185, 191, 199, 202,\n       203, 202, 205, 210, 205, 211, 213, 210, 211, 212, 211, 210, 212,\n       212, 210, 212, 213, 211, 210, 211, 214, 212, 210, 211, 212, 213,\n       213, 215, 216, 215, 215, 214, 215, 214, 213, 213, 215, 213, 210,\n       209, 212, 210], dtype=uint8), array([4.88385177])], [array([212, 208, 210, 208, 208, 206, 205, 207, 208, 211, 210, 210, 207,\n       207, 207, 208, 208, 210, 209, 210, 208, 207, 207, 208, 210, 208,\n       208, 208, 206, 211, 213, 208, 207, 206, 207, 205, 207, 204, 203,\n       198, 195, 196, 195, 199, 202, 204, 205, 206, 204, 202, 201, 200,\n       200, 197, 191, 185, 185, 185, 185, 185, 186, 186, 183, 178, 174,\n       168, 169, 170, 173, 160, 130, 111, 120, 133, 132, 135, 164, 184,\n       193, 196, 198, 198, 199, 200, 202, 202, 204, 207, 205, 207, 208,\n       207, 209, 210, 209, 208, 210, 212, 209, 207, 207, 209, 211, 208,\n       213, 212, 211, 211, 215, 213, 211, 212, 211, 210, 213, 212, 212,\n       209, 209, 211], dtype=uint8), array([6.54541434])], [array([202, 202, 202, 201, 199, 197, 196, 197, 194, 191, 195, 196, 191,\n       188, 185, 185, 181, 177, 172, 159, 151, 151, 153, 160, 170, 182,\n       185, 189, 190, 191, 188, 183, 177, 164, 151, 149, 152, 157, 158,\n       155, 150, 146, 146, 155, 169, 179, 187, 195, 199, 202, 201, 203,\n       205, 207, 208, 206, 202, 203, 203, 203, 199, 199, 197, 195, 195,\n       195, 194, 191, 186, 177, 154, 127, 119, 129, 128, 127, 141, 171,\n       186, 192, 195, 196, 200, 203, 202, 202, 204, 207, 207, 209, 207,\n       210, 208, 210, 210, 211, 213, 211, 212, 211, 213, 214, 214, 214,\n       212, 212, 213, 213, 211, 213, 211, 215, 212, 213, 209, 209, 207,\n       206, 209, 210], dtype=uint8), array([7.03218657])], [array([201, 197, 200, 202, 194, 195, 190, 182, 174, 164, 137, 125, 127,\n       139, 141, 137, 137, 150, 165, 176, 186, 188, 190, 193, 192, 196,\n       198, 199, 200, 201, 202, 204, 204, 204, 206, 206, 206, 205, 211,\n       207, 208, 207, 208, 207, 211, 209, 209, 205, 205, 206, 201, 203,\n       202, 200, 200, 197, 196, 193, 189, 183, 178, 176, 173, 168, 168,\n       166, 166, 167, 155, 130, 115, 125, 138, 126, 131, 158, 183, 191,\n       193, 198, 198, 201, 203, 204, 206, 207, 212, 209, 209, 211, 209,\n       211, 212, 210, 209, 211, 214, 211, 214, 214, 210, 212, 213, 213,\n       213, 215, 213, 214, 211, 213, 213, 212, 209, 211, 208, 213, 210,\n       209, 211, 210], dtype=uint8), array([6.38074043])], [array([199, 199, 197, 203, 200, 199, 197, 198, 201, 201, 200, 201, 203,\n       202, 202, 204, 206, 205, 203, 205, 206, 207, 202, 205, 209, 206,\n       204, 208, 207, 205, 206, 203, 204, 204, 208, 204, 204, 207, 208,\n       209, 207, 208, 206, 206, 206, 205, 206, 206, 208, 206, 204, 203,\n       206, 205, 203, 201, 200, 199, 200, 200, 201, 200, 196, 188, 189,\n       189, 192, 196, 200, 202, 198, 197, 200, 193, 188, 174, 155, 147,\n       148, 151, 159, 171, 188, 198, 206, 201, 212, 207, 207, 208, 209,\n       209, 210, 210, 210, 211, 209, 207, 209, 208, 211, 212, 210, 211,\n       209, 206, 211, 211, 210, 210, 210, 208, 209, 209, 210, 211, 210,\n       209, 208, 211], dtype=uint8), array([5.54238319])], [array([210, 209, 211, 213, 214, 213, 210, 213, 213, 212, 213, 213, 215,\n       217, 213, 210, 208, 209, 210, 211, 211, 214, 215, 214, 210, 212,\n       211, 211, 211, 207, 209, 205, 204, 207, 205, 210, 207, 205, 201,\n       203, 200, 197, 191, 191, 190, 188, 188, 187, 187, 187, 184, 179,\n       183, 190, 196, 200, 199, 198, 200, 202, 204, 203, 204, 206, 202,\n       202, 202, 199, 197, 197, 197, 194, 191, 188, 183, 179, 177, 171,\n       168, 166, 168, 177, 191, 198, 204, 207, 206, 208, 206, 208, 209,\n       210, 209, 209, 207, 207, 207, 205, 201, 203, 201, 198, 203, 203,\n       202, 197, 199, 201, 202, 207, 208, 206, 206, 210, 209, 209, 212,\n       211, 210, 212], dtype=uint8), array([4.58639866])], [array([215, 218, 216, 215, 218, 217, 213, 213, 216, 215, 216, 218, 215,\n       215, 215, 214, 215, 215, 214, 214, 214, 215, 215, 214, 214, 213,\n       211, 211, 212, 211, 212, 213, 212, 214, 213, 211, 218, 217, 216,\n       213, 213, 214, 213, 211, 212, 211, 209, 206, 206, 208, 205, 197,\n       187, 173, 163, 150, 135, 138, 161, 172, 173, 173, 170, 174, 176,\n       179, 182, 186, 190, 196, 197, 201, 206, 206, 207, 209, 211, 211,\n       212, 214, 213, 214, 214, 216, 217, 215, 212, 215, 213, 212, 217,\n       216, 219, 216, 218, 217, 215, 215, 218, 216, 213, 215, 215, 213,\n       213, 216, 216, 215, 216, 213, 213, 213, 215, 217, 215, 214, 212,\n       214, 214, 216], dtype=uint8), array([5.4984222])], [array([200, 198, 197, 199, 201, 195, 194, 191, 186, 173, 162, 148, 143,\n       136, 131, 124, 129, 130, 134, 140, 149, 154, 155, 156, 160, 165,\n       170, 171, 179, 186, 190, 191, 192, 195, 192, 193, 195, 197, 197,\n       202, 199, 199, 196, 196, 202, 200, 201, 202, 203, 203, 203, 204,\n       205, 205, 203, 203, 200, 201, 204, 202, 200, 199, 201, 200, 199,\n       193, 183, 165, 144, 138, 141, 136, 126, 116, 116, 127, 137, 143,\n       147, 152, 154, 160, 162, 166, 171, 177, 181, 183, 187, 192, 193,\n       196, 200, 200, 203, 205, 204, 204, 206, 205, 206, 207, 209, 210,\n       207, 209, 209, 212, 209, 210, 213, 211, 211, 213, 215, 212, 214,\n       210, 210, 213], dtype=uint8), array([8.81468908])], [array([210, 209, 210, 211, 212, 212, 212, 212, 212, 211, 210, 213, 214,\n       210, 210, 209, 210, 210, 211, 211, 213, 212, 210, 208, 210, 210,\n       211, 211, 210, 209, 212, 212, 212, 213, 211, 210, 208, 212, 210,\n       208, 210, 213, 215, 215, 210, 208, 211, 210, 211, 210, 209, 210,\n       206, 208, 210, 208, 209, 207, 205, 207, 207, 205, 203, 204, 204,\n       204, 202, 203, 202, 202, 197, 199, 196, 193, 190, 187, 178, 149,\n       122, 109, 108, 121, 150, 176, 192, 195, 200, 202, 202, 204, 204,\n       206, 208, 211, 212, 209, 207, 209, 210, 210, 210, 211, 211, 210,\n       213, 214, 209, 210, 218, 209, 210, 212, 212, 213, 213, 209, 210,\n       211, 207, 214], dtype=uint8), array([5.09065576])], [array([184, 185, 184, 184, 185, 184, 182, 185, 187, 186, 185, 186, 187,\n       183, 182, 186, 186, 183, 185, 185, 183, 187, 188, 189, 186, 186,\n       188, 186, 187, 186, 186, 188, 186, 185, 187, 186, 185, 185, 183,\n       182, 185, 185, 186, 185, 185, 186, 190, 187, 186, 185, 186, 187,\n       185, 189, 185, 183, 186, 187, 187, 187, 188, 187, 187, 188, 189,\n       187, 188, 189, 187, 188, 189, 189, 188, 193, 191, 190, 189, 190,\n       191, 188, 192, 189, 190, 190, 192, 192, 191, 190, 191, 191, 189,\n       189, 191, 190, 188, 188, 190, 189, 189, 189, 188, 187, 190, 190,\n       190, 188, 188, 187, 188, 190, 187, 186, 186, 188, 190, 192, 188,\n       186, 187, 188], dtype=uint8), array([0.])], [array([207, 207, 203, 204, 205, 207, 205, 206, 208, 209, 206, 206, 208,\n       205, 207, 206, 207, 207, 206, 205, 206, 208, 207, 208, 206, 205,\n       204, 207, 207, 205, 206, 206, 205, 206, 207, 208, 207, 205, 207,\n       205, 206, 207, 204, 203, 204, 206, 209, 208, 208, 207, 208, 207,\n       209, 205, 205, 206, 206, 206, 207, 204, 205, 201, 202, 194, 181,\n       163, 146, 133, 132, 147, 164, 173, 177, 176, 176, 176, 178, 179,\n       180, 181, 184, 190, 190, 192, 194, 196, 196, 199, 198, 199, 202,\n       202, 202, 204, 205, 203, 204, 209, 206, 205, 207, 207, 208, 207,\n       205, 208, 206, 209, 206, 211, 207, 204, 204, 201, 196, 189, 181,\n       172, 168, 170], dtype=uint8), array([4.42544194])], [array([203, 204, 204, 205, 203, 203, 204, 205, 205, 203, 206, 204, 205,\n       205, 206, 204, 204, 205, 205, 207, 206, 207, 205, 205, 204, 204,\n       207, 207, 209, 208, 207, 207, 206, 207, 209, 208, 209, 207, 206,\n       207, 209, 206, 205, 203, 204, 204, 200, 200, 192, 186, 176, 167,\n       159, 156, 159, 166, 177, 184, 187, 190, 194, 195, 197, 202, 201,\n       200, 201, 201, 203, 204, 202, 199, 192, 182, 171, 155, 146, 145,\n       155, 164, 170, 172, 170, 174, 176, 175, 176, 179, 183, 182, 187,\n       190, 197, 197, 195, 201, 197, 197, 199, 201, 201, 203, 204, 205,\n       204, 207, 206, 207, 208, 207, 207, 206, 204, 205, 205, 205, 208,\n       206, 207, 206], dtype=uint8), array([4.45399496])], [array([175, 177, 178, 184, 187, 186, 186, 188, 187, 190, 188, 185, 189,\n       190, 192, 192, 190, 196, 197, 196, 198, 198, 198, 198, 199, 196,\n       196, 198, 200, 201, 200, 203, 201, 204, 201, 202, 204, 203, 204,\n       203, 203, 206, 203, 205, 205, 205, 208, 207, 206, 204, 206, 207,\n       204, 205, 206, 205, 209, 208, 204, 205, 209, 208, 205, 206, 207,\n       206, 205, 208, 206, 205, 206, 205, 203, 202, 204, 201, 197, 191,\n       178, 159, 143, 134, 139, 153, 166, 173, 177, 181, 182, 184, 185,\n       188, 190, 192, 194, 194, 196, 201, 202, 201, 200, 205, 206, 204,\n       205, 207, 205, 205, 205, 204, 203, 205, 208, 208, 206, 202, 192,\n       177, 162, 149], dtype=uint8), array([4.68352392])], [array([204, 206, 206, 205, 206, 208, 206, 205, 206, 204, 204, 204, 206,\n       205, 205, 207, 206, 207, 205, 206, 202, 203, 202, 204, 204, 205,\n       204, 206, 205, 203, 206, 203, 203, 204, 206, 206, 206, 203, 207,\n       205, 206, 206, 205, 205, 204, 201, 200, 195, 197, 190, 180, 170,\n       159, 161, 167, 175, 182, 185, 189, 191, 189, 186, 186, 188, 188,\n       186, 185, 184, 185, 187, 185, 186, 190, 192, 191, 190, 191, 194,\n       198, 198, 198, 198, 199, 200, 196, 200, 203, 203, 205, 199, 201,\n       203, 201, 205, 206, 207, 204, 206, 206, 204, 205, 206, 206, 205,\n       205, 207, 207, 206, 204, 205, 206, 206, 206, 206, 207, 206, 205,\n       204, 204, 204], dtype=uint8), array([3.48806279])], [array([185, 186, 188, 188, 190, 193, 195, 199, 199, 198, 199, 201, 201,\n       202, 202, 204, 203, 202, 204, 203, 205, 203, 205, 205, 205, 204,\n       204, 207, 206, 205, 205, 206, 205, 206, 205, 202, 207, 206, 205,\n       204, 208, 205, 204, 207, 207, 205, 204, 205, 204, 205, 207, 202,\n       205, 202, 201, 205, 206, 207, 206, 204, 202, 202, 203, 205, 206,\n       204, 203, 206, 205, 207, 205, 205, 205, 197, 189, 177, 163, 148,\n       135, 133, 145, 156, 165, 163, 164, 167, 171, 171, 172, 174, 178,\n       181, 182, 185, 186, 191, 196, 196, 195, 195, 196, 199, 201, 202,\n       205, 206, 201, 205, 201, 205, 208, 207, 205, 204, 206, 203, 205,\n       207, 206, 206], dtype=uint8), array([5.52762087])], [array([205, 203, 202, 203, 205, 203, 202, 202, 205, 206, 203, 200, 203,\n       202, 202, 206, 204, 202, 203, 204, 204, 203, 200, 200, 202, 204,\n       206, 205, 203, 202, 204, 204, 201, 201, 204, 203, 204, 205, 202,\n       198, 194, 189, 188, 189, 193, 199, 202, 201, 201, 203, 203, 200,\n       200, 197, 191, 183, 172, 163, 155, 144, 135, 138, 150, 158, 157,\n       154, 155, 155, 154, 158, 162, 166, 168, 171, 175, 181, 184, 185,\n       185, 188, 191, 193, 195, 197, 197, 200, 202, 201, 199, 199, 201,\n       202, 204, 202, 202, 202, 203, 203, 206, 203, 201, 203, 204, 201,\n       202, 204, 207, 205, 203, 204, 206, 205, 205, 206, 203, 206, 203,\n       207, 206, 204], dtype=uint8), array([5.24173503])], [array([203, 206, 205, 203, 204, 204, 203, 202, 203, 203, 200, 201, 200,\n       200, 201, 202, 201, 203, 203, 198, 201, 205, 205, 203, 201, 199,\n       197, 194, 189, 185, 186, 186, 188, 191, 199, 198, 200, 203, 202,\n       199, 201, 199, 201, 203, 202, 203, 201, 202, 201, 201, 201, 196,\n       199, 198, 200, 198, 197, 193, 193, 191, 190, 188, 184, 181, 181,\n       175, 176, 174, 171, 168, 171, 168, 162, 164, 163, 160, 150, 137,\n       136, 141, 152, 169, 184, 193, 195, 196, 197, 201, 202, 201, 201,\n       202, 202, 202, 203, 203, 201, 199, 199, 200, 205, 202, 201, 202,\n       201, 202, 206, 204, 201, 203, 205, 204, 200, 204, 204, 205, 203,\n       203, 201, 202], dtype=uint8), array([4.75818342])], [array([195, 197, 197, 199, 198, 198, 198, 200, 203, 200, 197, 198, 198,\n       198, 200, 200, 198, 200, 202, 200, 202, 202, 201, 203, 201, 202,\n       203, 203, 201, 201, 198, 197, 201, 202, 198, 198, 198, 201, 201,\n       195, 199, 200, 203, 199, 202, 203, 200, 202, 204, 203, 204, 202,\n       204, 201, 200, 194, 182, 166, 159, 157, 161, 166, 169, 169, 168,\n       167, 165, 164, 166, 170, 172, 174, 177, 181, 183, 184, 187, 191,\n       191, 193, 197, 195, 194, 198, 200, 200, 199, 198, 200, 200, 200,\n       204, 202, 204, 205, 206, 200, 204, 203, 202, 200, 207, 205, 199,\n       202, 202, 201, 201, 202, 202, 200, 191, 190, 190, 189, 186, 186,\n       187, 185, 186], dtype=uint8), array([3.84824603])], [array([196, 198, 196, 194, 195, 192, 194, 194, 196, 194, 193, 194, 191,\n       191, 191, 189, 194, 193, 192, 193, 191, 192, 191, 191, 191, 191,\n       192, 190, 189, 188, 192, 191, 193, 194, 194, 194, 194, 196, 193,\n       195, 193, 196, 195, 196, 197, 197, 197, 198, 196, 196, 195, 198,\n       196, 197, 200, 199, 197, 195, 192, 184, 184, 183, 178, 170, 163,\n       159, 154, 144, 138, 136, 146, 151, 146, 138, 134, 133, 134, 137,\n       141, 143, 146, 149, 152, 154, 158, 162, 164, 169, 170, 172, 173,\n       176, 180, 183, 184, 185, 187, 189, 191, 193, 194, 193, 192, 194,\n       195, 196, 195, 196, 197, 196, 196, 195, 197, 196, 198, 197, 198,\n       199, 200, 201], dtype=uint8), array([6.3266849])], [array([157, 158, 158, 162, 162, 163, 167, 168, 169, 168, 172, 172, 174,\n       175, 176, 176, 178, 178, 180, 180, 182, 183, 183, 184, 186, 189,\n       189, 190, 188, 191, 189, 191, 193, 193, 193, 195, 193, 192, 193,\n       197, 195, 195, 196, 197, 197, 196, 195, 195, 193, 193, 194, 195,\n       194, 192, 196, 194, 191, 189, 186, 177, 163, 155, 152, 161, 166,\n       176, 177, 175, 176, 176, 179, 178, 176, 172, 164, 146, 126, 122,\n       116, 108, 111, 124, 138, 147, 152, 155, 159, 161, 168, 168, 169,\n       171, 177, 179, 181, 183, 186, 188, 188, 189, 192, 192, 193, 194,\n       194, 196, 196, 200, 199, 199, 197, 198, 198, 197, 198, 202, 202,\n       198, 200, 200], dtype=uint8), array([5.48232787])], [array([165, 165, 164, 162, 166, 166, 166, 164, 166, 173, 170, 168, 169,\n       172, 177, 177, 175, 181, 177, 179, 175, 180, 184, 181, 179, 182,\n       184, 188, 181, 184, 187, 186, 184, 191, 186, 188, 185, 189, 188,\n       187, 186, 189, 187, 193, 190, 194, 193, 193, 189, 193, 190, 187,\n       192, 191, 188, 192, 191, 192, 192, 187, 195, 193, 192, 192, 192,\n       190, 194, 194, 194, 197, 197, 195, 197, 200, 199, 194, 184, 174,\n       159, 145, 134, 133, 141, 148, 148, 152, 156, 156, 156, 152, 155,\n       160, 158, 162, 164, 163, 165, 170, 174, 171, 179, 178, 180, 182,\n       184, 188, 192, 190, 191, 186, 188, 192, 193, 192, 195, 191, 197,\n       196, 195, 199], dtype=uint8), array([4.22418291])], [array([207, 208, 206, 210, 209, 209, 210, 209, 206, 204, 206, 205, 208,\n       206, 206, 207, 206, 207, 208, 210, 205, 205, 203, 203, 205, 207,\n       207, 205, 208, 211, 207, 206, 204, 204, 206, 204, 205, 207, 207,\n       207, 208, 208, 208, 207, 206, 206, 205, 210, 206, 204, 210, 209,\n       207, 206, 205, 207, 206, 207, 207, 207, 209, 208, 208, 207, 205,\n       204, 205, 204, 205, 205, 206, 208, 209, 206, 205, 208, 204, 205,\n       207, 209, 210, 206, 206, 205, 206, 206, 209, 209, 208, 208, 207,\n       206, 206, 206, 209, 210, 210, 210, 208, 206, 206, 204, 206, 209,\n       206, 205, 206, 206, 202, 201, 207, 204, 203, 208, 208, 208, 208,\n       208, 207, 205], dtype=uint8), array([0.])], [array([203, 202, 203, 203, 203, 200, 201, 202, 202, 202, 202, 203, 202,\n       203, 202, 202, 205, 203, 202, 204, 203, 203, 203, 202, 203, 205,\n       203, 204, 203, 203, 204, 202, 202, 204, 201, 200, 201, 203, 204,\n       204, 203, 202, 201, 202, 202, 203, 204, 206, 206, 204, 206, 201,\n       206, 208, 206, 202, 205, 209, 202, 207, 203, 204, 204, 202, 199,\n       197, 190, 178, 165, 158, 157, 162, 170, 171, 170, 169, 172, 170,\n       172, 177, 179, 183, 183, 185, 186, 188, 191, 194, 194, 196, 198,\n       197, 199, 201, 200, 203, 201, 198, 203, 202, 204, 203, 201, 205,\n       204, 202, 205, 204, 202, 204, 206, 206, 203, 204, 202, 203, 205,\n       203, 205, 205], dtype=uint8), array([3.71157107])], [array([205, 205, 202, 208, 203, 203, 199, 205, 204, 207, 206, 205, 204,\n       202, 201, 204, 201, 204, 204, 203, 204, 205, 199, 203, 203, 206,\n       205, 205, 205, 202, 200, 201, 202, 205, 204, 201, 200, 201, 199,\n       199, 198, 197, 193, 189, 190, 191, 188, 192, 196, 198, 200, 202,\n       202, 201, 198, 202, 202, 202, 199, 203, 202, 203, 202, 198, 200,\n       201, 200, 198, 195, 192, 193, 188, 186, 176, 161, 148, 138, 134,\n       141, 155, 168, 172, 174, 173, 177, 181, 179, 179, 183, 190, 188,\n       193, 193, 193, 198, 199, 196, 197, 201, 200, 200, 204, 202, 204,\n       206, 203, 203, 202, 202, 198, 200, 203, 205, 205, 204, 204, 203,\n       203, 205, 206], dtype=uint8), array([4.08382213])], [array([204, 208, 205, 205, 205, 209, 205, 203, 204, 205, 202, 204, 206,\n       207, 208, 206, 208, 206, 203, 204, 205, 204, 202, 199, 204, 203,\n       203, 204, 205, 205, 205, 204, 201, 201, 203, 203, 199, 198, 198,\n       198, 196, 192, 191, 191, 187, 176, 163, 151, 142, 154, 172, 185,\n       193, 199, 200, 199, 201, 203, 204, 205, 205, 205, 205, 204, 206,\n       204, 206, 203, 204, 206, 207, 204, 202, 205, 207, 206, 202, 206,\n       206, 204, 205, 207, 208, 202, 208, 211, 207, 208, 210, 208, 207,\n       205, 206, 204, 203, 206, 202, 202, 202, 202, 204, 203, 202, 201,\n       198, 196, 194, 195, 192, 190, 186, 179, 173, 161, 152, 151, 152,\n       155, 162, 168], dtype=uint8), array([3.69767209])], [array([196, 197, 198, 195, 195, 198, 195, 195, 199, 198, 200, 199, 198,\n       201, 203, 200, 200, 200, 200, 193, 188, 178, 171, 165, 165, 171,\n       174, 176, 182, 181, 178, 176, 178, 176, 173, 173, 169, 164, 164,\n       161, 155, 152, 148, 148, 146, 145, 146, 150, 162, 166, 169, 172,\n       177, 181, 180, 180, 180, 180, 181, 183, 185, 185, 191, 186, 186,\n       186, 187, 189, 192, 189, 185, 172, 160, 150, 141, 141, 151, 158,\n       158, 161, 160, 156, 157, 156, 156, 156, 162, 159, 162, 164, 170,\n       175, 174, 174, 176, 177, 184, 183, 185, 187, 189, 189, 191, 190,\n       191, 195, 195, 194, 195, 197, 197, 196, 198, 199, 197, 199, 197,\n       199, 200, 198], dtype=uint8), array([4.18255064])], [array([205, 204, 204, 205, 204, 205, 205, 207, 201, 203, 205, 206, 204,\n       204, 204, 202, 205, 204, 203, 204, 204, 205, 205, 202, 201, 200,\n       201, 202, 201, 201, 203, 201, 201, 202, 203, 202, 200, 199, 199,\n       200, 199, 201, 201, 200, 198, 195, 196, 196, 195, 191, 190, 190,\n       186, 184, 180, 178, 181, 178, 174, 171, 169, 166, 164, 163, 161,\n       159, 161, 159, 158, 143, 122, 116, 128, 138, 130, 123, 132, 157,\n       176, 177, 179, 183, 186, 189, 188, 190, 191, 194, 198, 196, 199,\n       198, 202, 199, 201, 203, 203, 202, 202, 204, 205, 202, 201, 204,\n       202, 200, 203, 202, 203, 203, 201, 200, 201, 203, 200, 201, 202,\n       202, 201, 200], dtype=uint8), array([9.01671984])], [array([163, 166, 171, 170, 172, 175, 176, 175, 175, 175, 176, 175, 174,\n       175, 176, 175, 177, 175, 175, 176, 176, 173, 175, 176, 175, 178,\n       172, 172, 167, 167, 170, 171, 170, 170, 170, 170, 163, 163, 165,\n       170, 168, 165, 162, 159, 156, 146, 140, 142, 147, 154, 161, 164,\n       165, 168, 172, 176, 174, 176, 175, 175, 177, 180, 178, 169, 159,\n       156, 158, 152, 154, 164, 180, 188, 191, 191, 196, 197, 198, 199,\n       198, 198, 198, 197, 198, 200, 199, 197, 201, 200, 200, 197, 197,\n       198, 199, 199, 198, 196, 194, 196, 196, 198, 198, 198, 199, 197,\n       198, 195, 199, 199, 198, 198, 197, 198, 197, 196, 198, 198, 197,\n       194, 197, 196], dtype=uint8), array([6.47364817])], [array([199, 199, 199, 199, 197, 195, 197, 195, 198, 198, 198, 195, 194,\n       198, 197, 197, 196, 199, 198, 194, 197, 199, 196, 197, 195, 197,\n       198, 196, 195, 199, 198, 200, 197, 197, 196, 197, 198, 195, 194,\n       192, 198, 198, 200, 200, 199, 198, 201, 201, 197, 200, 201, 201,\n       199, 200, 202, 199, 200, 199, 201, 201, 200, 199, 200, 198, 200,\n       202, 200, 198, 201, 201, 200, 196, 190, 181, 169, 159, 150, 151,\n       159, 162, 168, 167, 170, 171, 172, 170, 172, 175, 174, 174, 175,\n       176, 178, 179, 180, 184, 187, 187, 189, 188, 189, 191, 191, 193,\n       192, 193, 197, 196, 196, 198, 198, 197, 199, 198, 199, 199, 198,\n       196, 198, 198], dtype=uint8), array([4.51710674])], [array([207, 206, 206, 205, 205, 211, 204, 203, 204, 203, 207, 207, 208,\n       207, 206, 205, 203, 204, 205, 206, 204, 202, 203, 203, 201, 202,\n       204, 206, 206, 204, 207, 205, 201, 202, 209, 208, 207, 206, 205,\n       205, 209, 198, 205, 205, 205, 205, 204, 206, 208, 204, 205, 204,\n       202, 204, 205, 208, 204, 208, 208, 205, 206, 207, 203, 203, 206,\n       207, 207, 204, 204, 207, 207, 205, 205, 204, 201, 199, 191, 184,\n       185, 188, 192, 188, 191, 189, 188, 191, 191, 192, 196, 195, 194,\n       201, 200, 200, 198, 199, 200, 206, 204, 202, 203, 206, 204, 204,\n       202, 202, 204, 203, 204, 203, 202, 206, 206, 206, 206, 202, 203,\n       202, 203, 207], dtype=uint8), array([4.88037655])], [array([208, 208, 208, 208, 207, 209, 207, 209, 204, 206, 207, 206, 205,\n       204, 205, 204, 205, 205, 206, 205, 203, 205, 205, 207, 205, 207,\n       203, 203, 203, 203, 203, 202, 202, 204, 204, 202, 205, 208, 205,\n       204, 204, 204, 205, 202, 203, 206, 204, 203, 203, 202, 205, 201,\n       201, 204, 203, 201, 201, 200, 200, 199, 199, 199, 200, 201, 199,\n       199, 203, 203, 202, 202, 202, 198, 196, 198, 200, 198, 199, 198,\n       200, 201, 201, 199, 199, 200, 200, 202, 202, 200, 195, 192, 195,\n       197, 199, 203, 205, 204, 204, 205, 204, 203, 205, 202, 204, 205,\n       203, 204, 204, 203, 205, 205, 203, 203, 202, 199, 198, 200, 204,\n       206, 202, 203], dtype=uint8), array([4.75318777])], [array([202, 204, 203, 202, 204, 205, 204, 203, 203, 202, 205, 202, 201,\n       200, 202, 201, 199, 202, 198, 199, 197, 196, 195, 192, 189, 188,\n       185, 183, 183, 177, 177, 176, 176, 172, 170, 174, 167, 166, 166,\n       165, 163, 164, 166, 166, 165, 158, 146, 138, 143, 160, 174, 188,\n       195, 196, 196, 197, 200, 202, 201, 200, 201, 201, 205, 202, 205,\n       201, 204, 201, 203, 202, 202, 202, 201, 204, 204, 203, 204, 202,\n       203, 201, 200, 201, 203, 201, 202, 205, 204, 202, 202, 202, 203,\n       203, 201, 200, 203, 201, 202, 203, 204, 201, 198, 201, 202, 204,\n       201, 201, 201, 200, 201, 200, 200, 201, 199, 201, 202, 201, 201,\n       201, 199, 196], dtype=uint8), array([4.67930649])], [array([200, 203, 202, 202, 201, 199, 206, 205, 202, 203, 205, 204, 204,\n       202, 198, 203, 203, 200, 199, 200, 201, 201, 203, 208, 205, 203,\n       204, 201, 200, 198, 199, 200, 200, 199, 199, 197, 198, 196, 192,\n       196, 201, 200, 201, 203, 198, 198, 202, 202, 202, 201, 198, 199,\n       198, 198, 197, 196, 194, 193, 192, 192, 191, 188, 189, 186, 188,\n       185, 187, 176, 167, 162, 168, 176, 178, 181, 183, 183, 183, 184,\n       185, 186, 186, 186, 186, 191, 193, 195, 197, 197, 198, 199, 198,\n       200, 200, 200, 199, 200, 198, 201, 203, 203, 200, 202, 204, 200,\n       201, 203, 202, 204, 201, 200, 203, 202, 201, 202, 207, 205, 201,\n       204, 202, 205], dtype=uint8), array([3.66342182])], [array([179, 178, 183, 183, 181, 181, 182, 178, 178, 179, 180, 181, 180,\n       179, 179, 178, 180, 181, 181, 182, 181, 181, 181, 180, 179, 179,\n       180, 180, 183, 183, 183, 180, 183, 180, 181, 177, 182, 183, 182,\n       184, 181, 178, 182, 180, 178, 178, 180, 177, 181, 182, 180, 180,\n       181, 179, 179, 179, 179, 179, 180, 177, 176, 178, 179, 178, 178,\n       176, 171, 171, 172, 169, 166, 161, 154, 140, 123, 112, 112, 110,\n        94,  82,  86,  92,  93,  93,  96,  99, 107, 108, 110, 113, 115,\n       117, 116, 120, 126, 133, 135, 136, 141, 144, 147, 148, 150, 150,\n       155, 158, 158, 160, 163, 166, 168, 168, 167, 171, 174, 173, 174,\n       174, 176, 177], dtype=uint8), array([11.24816955])], [array([188, 185, 187, 189, 186, 186, 187, 186, 185, 185, 187, 190, 185,\n       185, 185, 181, 180, 180, 180, 179, 176, 174, 174, 175, 171, 169,\n       167, 167, 166, 164, 161, 160, 159, 157, 156, 155, 153, 155, 158,\n       154, 157, 157, 159, 161, 164, 164, 158, 154, 146, 136, 140, 156,\n       170, 179, 188, 189, 191, 194, 189, 189, 190, 190, 189, 186, 189,\n       187, 188, 187, 185, 185, 185, 186, 186, 186, 183, 188, 184, 184,\n       183, 183, 186, 185, 182, 187, 185, 184, 182, 183, 185, 183, 182,\n       181, 181, 183, 181, 181, 182, 182, 185, 185, 185, 185, 184, 181,\n       183, 187, 187, 182, 184, 186, 182, 183, 181, 181, 183, 183, 184,\n       182, 185, 184], dtype=uint8), array([5.29607184])], [array([186, 188, 187, 189, 188, 189, 190, 188, 187, 188, 186, 185, 187,\n       187, 184, 183, 183, 182, 182, 181, 182, 182, 180, 182, 180, 179,\n       175, 176, 175, 172, 168, 169, 167, 164, 163, 159, 157, 155, 152,\n       150, 148, 146, 147, 146, 145, 147, 148, 147, 147, 149, 143, 137,\n       125, 119, 127, 145, 162, 175, 183, 191, 194, 192, 192, 193, 190,\n       190, 190, 191, 192, 190, 190, 186, 186, 189, 187, 186, 186, 188,\n       186, 185, 187, 189, 186, 186, 185, 185, 183, 184, 180, 180, 181,\n       183, 183, 181, 178, 178, 177, 174, 179, 178, 175, 175, 174, 177,\n       175, 175, 175, 175, 177, 178, 179, 184, 184, 182, 183, 183, 185,\n       186, 184, 183], dtype=uint8), array([5.46791157])], [array([187, 187, 188, 187, 184, 184, 184, 185, 187, 189, 187, 187, 188,\n       187, 185, 187, 187, 186, 185, 186, 183, 184, 183, 182, 179, 179,\n       177, 174, 173, 173, 170, 170, 166, 165, 168, 163, 162, 159, 158,\n       157, 156, 153, 152, 149, 147, 147, 146, 147, 147, 148, 151, 152,\n       153, 152, 151, 143, 133, 134, 143, 155, 168, 180, 186, 190, 188,\n       189, 187, 187, 186, 188, 187, 189, 188, 189, 188, 185, 188, 187,\n       187, 187, 186, 186, 187, 185, 186, 189, 189, 187, 188, 189, 189,\n       190, 189, 189, 188, 188, 188, 185, 187, 188, 186, 187, 187, 186,\n       187, 188, 188, 187, 187, 185, 187, 187, 187, 185, 187, 187, 186,\n       186, 185, 178], dtype=uint8), array([5.45620238])], [array([205, 206, 205, 202, 203, 205, 206, 207, 203, 202, 202, 202, 203,\n       201, 199, 201, 203, 204, 203, 202, 201, 202, 204, 206, 205, 205,\n       206, 207, 207, 206, 203, 201, 200, 203, 208, 208, 206, 206, 204,\n       202, 201, 200, 201, 200, 200, 201, 203, 205, 205, 206, 207, 207,\n       203, 205, 205, 202, 205, 206, 204, 203, 205, 206, 207, 207, 205,\n       206, 206, 206, 206, 205, 206, 206, 204, 205, 205, 204, 204, 203,\n       201, 203, 205, 209, 208, 205, 206, 206, 207, 208, 205, 205, 207,\n       206, 206, 207, 205, 203, 203, 203, 202, 203, 205, 206, 206, 205,\n       206, 205, 205, 207, 208, 208, 207, 207, 206, 204, 203, 204, 205,\n       204, 205, 206], dtype=uint8), array([0.])], [array([156, 166, 179, 191, 193, 192, 195, 201, 199, 200, 199, 200, 203,\n       203, 204, 206, 206, 202, 205, 208, 208, 208, 208, 206, 209, 210,\n       208, 208, 208, 208, 211, 210, 210, 208, 208, 207, 208, 212, 211,\n       209, 206, 210, 211, 209, 212, 209, 209, 207, 209, 211, 210, 209,\n       208, 212, 211, 208, 210, 207, 208, 207, 207, 205, 204, 206, 204,\n       206, 200, 201, 202, 200, 192, 175, 149, 121, 113, 115, 120, 115,\n        87,  66,  74,  87,  96, 105, 118, 124, 126, 131, 135, 140, 147,\n       150, 152, 152, 157, 163, 166, 172, 175, 179, 180, 186, 187, 191,\n       193, 196, 196, 200, 199, 200, 203, 204, 205, 205, 206, 205, 207,\n       207, 206, 208], dtype=uint8), array([11.65322989])], [array([208, 207, 207, 209, 207, 205, 210, 207, 205, 210, 207, 209, 208,\n       205, 204, 208, 208, 209, 209, 208, 209, 210, 209, 206, 206, 206,\n       207, 207, 207, 207, 204, 205, 208, 211, 209, 209, 209, 207, 208,\n       209, 204, 205, 207, 205, 206, 208, 208, 205, 207, 210, 211, 211,\n       209, 209, 210, 208, 204, 206, 207, 207, 206, 203, 204, 200, 198,\n       198, 194, 187, 187, 177, 172, 168, 157, 136, 113, 109, 116, 114,\n       106, 103, 104, 114, 127, 137, 142, 146, 150, 154, 159, 163, 167,\n       170, 173, 178, 175, 181, 183, 186, 190, 195, 195, 196, 196, 197,\n       202, 202, 200, 201, 203, 202, 201, 203, 204, 206, 208, 207, 208,\n       205, 205, 206], dtype=uint8), array([11.24816955])], [array([207, 208, 209, 207, 207, 205, 206, 207, 206, 208, 211, 208, 206,\n       208, 209, 210, 211, 211, 209, 208, 208, 208, 206, 207, 208, 208,\n       209, 207, 206, 207, 207, 209, 209, 209, 208, 205, 205, 206, 208,\n       203, 207, 207, 204, 204, 203, 200, 203, 204, 200, 200, 198, 198,\n       197, 194, 192, 189, 189, 189, 185, 177, 167, 151, 139, 140, 146,\n       151, 155, 147, 127, 120, 141, 154, 172, 188, 195, 198, 197, 198,\n       205, 203, 201, 203, 205, 204, 200, 202, 202, 203, 204, 204, 206,\n       208, 203, 203, 207, 206, 205, 206, 205, 205, 205, 207, 206, 207,\n       206, 208, 207, 206, 206, 205, 205, 206, 205, 206, 206, 204, 205,\n       204, 209, 199], dtype=uint8), array([5.29607184])], [array([205, 209, 213, 211, 213, 210, 208, 209, 208, 209, 211, 210, 212,\n       209, 207, 208, 209, 211, 210, 210, 210, 213, 214, 212, 211, 211,\n       211, 210, 213, 212, 212, 211, 212, 213, 214, 212, 211, 209, 212,\n       211, 210, 209, 208, 210, 207, 205, 207, 206, 208, 203, 186, 160,\n       147, 129, 118, 138, 161, 167, 168, 170, 173, 175, 179, 181, 184,\n       188, 192, 194, 195, 198, 202, 206, 205, 206, 206, 209, 210, 209,\n       212, 209, 209, 211, 212, 208, 205, 209, 207, 207, 212, 211, 207,\n       208, 208, 207, 206, 206, 205, 207, 205, 202, 201, 203, 204, 203,\n       204, 204, 205, 206, 206, 208, 210, 209, 208, 209, 210, 209, 212,\n       210, 211, 210], dtype=uint8), array([5.46791157])], [array([210, 208, 207, 206, 207, 208, 208, 209, 208, 206, 206, 208, 207,\n       210, 212, 211, 210, 209, 210, 207, 208, 210, 209, 208, 209, 208,\n       206, 206, 201, 202, 201, 199, 201, 203, 206, 206, 204, 207, 210,\n       211, 210, 210, 217, 210, 206, 208, 207, 207, 207, 206, 205, 204,\n       200, 197, 182, 161, 146, 126, 107, 123, 150, 156, 158, 164, 166,\n       171, 175, 175, 176, 180, 185, 189, 189, 197, 196, 198, 203, 204,\n       206, 206, 203, 208, 208, 207, 208, 204, 207, 209, 206, 208, 209,\n       204, 207, 208, 207, 208, 209, 210, 208, 210, 209, 211, 206, 207,\n       206, 210, 210, 212, 211, 208, 210, 209, 210, 212, 211, 211, 206,\n       207, 206, 210], dtype=uint8), array([5.45620238])], [array([211, 211, 212, 211, 211, 211, 209, 210, 210, 211, 211, 210, 211,\n       212, 214, 210, 209, 212, 211, 212, 211, 208, 208, 210, 213, 215,\n       211, 211, 211, 211, 212, 211, 209, 207, 206, 208, 208, 208, 209,\n       209, 208, 207, 205, 212, 210, 211, 209, 208, 211, 212, 212, 211,\n       209, 208, 211, 212, 208, 206, 206, 209, 209, 206, 210, 212, 211,\n       207, 208, 206, 209, 209, 211, 211, 212, 211, 212, 208, 203, 201,\n       201, 204, 206, 210, 208, 207, 208, 206, 208, 212, 209, 208, 210,\n       210, 211, 209, 206, 211, 213, 209, 208, 211, 212, 212, 211, 210,\n       213, 212, 214, 212, 212, 210, 212, 211, 214, 212, 211, 214, 210,\n       209, 213, 210], dtype=uint8), array([3.54463004])], [array([187, 187, 187, 188, 188, 189, 187, 186, 189, 192, 191, 189, 189,\n       190, 191, 190, 192, 192, 191, 191, 191, 190, 195, 193, 190, 192,\n       190, 191, 188, 190, 194, 194, 194, 193, 193, 190, 193, 192, 192,\n       194, 193, 193, 192, 193, 193, 190, 190, 193, 193, 194, 192, 191,\n       188, 187, 186, 185, 185, 183, 182, 178, 175, 175, 172, 168, 166,\n       163, 161, 156, 153, 152, 149, 149, 144, 146, 143, 143, 135, 119,\n       108, 120, 146, 167, 187, 193, 194, 199, 197, 197, 197, 196, 192,\n       188, 190, 191, 192, 187, 187, 189, 190, 188, 186, 186, 188, 187,\n       183, 185, 185, 184, 185, 184, 183, 180, 181, 181, 179, 181, 182,\n       179, 176, 174], dtype=uint8), array([4.51179147])], [array([204, 203, 199, 204, 204, 203, 203, 205, 207, 203, 205, 207, 205,\n       204, 204, 206, 206, 205, 203, 203, 204, 206, 202, 201, 205, 204,\n       204, 203, 203, 203, 198, 198, 196, 198, 197, 195, 194, 192, 192,\n       192, 191, 191, 190, 190, 188, 189, 188, 187, 182, 185, 182, 182,\n       180, 180, 178, 177, 178, 177, 174, 168, 164, 157, 150, 146, 160,\n       171, 189, 200, 202, 205, 205, 203, 205, 205, 202, 199, 195, 196,\n       196, 197, 197, 199, 198, 194, 196, 195, 193, 194, 194, 194, 193,\n       192, 193, 193, 192, 192, 192, 188, 188, 190, 191, 189, 189, 190,\n       190, 188, 186, 189, 192, 192, 189, 191, 191, 193, 191, 192, 191,\n       192, 193, 191], dtype=uint8), array([4.37560143])], [array([206, 205, 207, 205, 201, 201, 200, 199, 199, 201, 197, 196, 196,\n       196, 195, 196, 194, 195, 194, 196, 199, 198, 198, 198, 200, 200,\n       198, 196, 198, 200, 198, 196, 195, 196, 195, 196, 195, 196, 197,\n       194, 194, 195, 192, 193, 198, 193, 194, 193, 194, 192, 192, 191,\n       191, 192, 191, 188, 186, 185, 184, 178, 181, 178, 178, 175, 172,\n       169, 167, 166, 163, 159, 153, 157, 157, 162, 162, 159, 148, 125,\n       116, 129, 150, 168, 187, 195, 196, 198, 196, 192, 195, 197, 198,\n       197, 193, 189, 190, 189, 187, 187, 186, 185, 186, 183, 186, 183,\n       183, 186, 184, 183, 184, 184, 183, 185, 186, 186, 184, 187, 186,\n       184, 188, 187], dtype=uint8), array([3.95002995])], [array([189, 191, 195, 193, 193, 189, 191, 190, 190, 189, 189, 190, 190,\n       192, 189, 187, 193, 191, 187, 185, 188, 188, 189, 188, 190, 188,\n       192, 188, 191, 193, 190, 189, 190, 187, 189, 191, 188, 188, 191,\n       189, 188, 187, 186, 186, 188, 185, 187, 186, 187, 186, 188, 187,\n       187, 188, 187, 187, 184, 181, 176, 177, 175, 171, 170, 166, 163,\n       165, 163, 161, 162, 160, 158, 158, 153, 151, 147, 136, 128, 138,\n       159, 180, 184, 190, 196, 195, 192, 193, 192, 189, 189, 187, 185,\n       181, 181, 180, 178, 173, 170, 168, 165, 163, 164, 166, 166, 163,\n       166, 174, 178, 178, 179, 181, 180, 180, 177, 176, 175, 174, 177,\n       176, 174, 173], dtype=uint8), array([3.53048839])], [array([166, 164, 167, 166, 165, 162, 161, 160, 160, 160, 157, 157, 154,\n       156, 156, 155, 153, 154, 154, 154, 149, 150, 151, 150, 150, 149,\n       147, 146, 147, 148, 147, 148, 145, 144, 145, 147, 150, 156, 159,\n       163, 166, 166, 167, 165, 163, 159, 157, 159, 159, 161, 163, 165,\n       164, 167, 168, 170, 172, 169, 170, 167, 163, 156, 149, 146, 150,\n       166, 181, 191, 195, 194, 193, 194, 194, 192, 193, 194, 194, 195,\n       195, 193, 192, 193, 190, 190, 189, 188, 189, 190, 189, 190, 193,\n       193, 191, 190, 191, 189, 184, 186, 184, 185, 186, 186, 187, 190,\n       192, 191, 190, 188, 183, 185, 181, 176, 170, 161, 155, 161, 169,\n       178, 185, 184], dtype=uint8), array([3.67640104])], [array([184, 185, 187, 186, 183, 184, 186, 183, 183, 185, 183, 183, 183,\n       182, 185, 184, 184, 185, 184, 181, 183, 182, 183, 185, 185, 185,\n       185, 186, 185, 184, 186, 182, 181, 179, 180, 180, 177, 178, 177,\n       175, 175, 175, 171, 164, 164, 161, 161, 156, 150, 149, 145, 139,\n       137, 134, 132, 130, 128, 125, 119, 115, 110, 106, 100,  97,  92,\n        88,  84,  83,  83,  89,  91,  95, 106, 119, 136, 161, 182, 197,\n       204, 204, 206, 208, 205, 204, 203, 204, 202, 200, 199, 196, 195,\n       196, 195, 192, 191, 188, 187, 189, 186, 182, 180, 180, 180, 178,\n       177, 180, 178, 181, 177, 174, 174, 177, 174, 175, 176, 173, 175,\n       179, 177, 176], dtype=uint8), array([8.97995119])], [array([190, 192, 189, 189, 191, 190, 189, 188, 187, 186, 185, 186, 183,\n       183, 183, 187, 184, 182, 185, 186, 184, 182, 183, 183, 184, 181,\n       182, 181, 180, 178, 178, 177, 177, 177, 180, 179, 175, 181, 179,\n       178, 177, 177, 178, 176, 176, 170, 165, 156, 144, 126, 114, 112,\n       119, 134, 148, 155, 158, 156, 159, 161, 164, 167, 168, 167, 169,\n       172, 172, 175, 174, 176, 182, 176, 177, 178, 181, 180, 182, 183,\n       179, 180, 182, 181, 181, 180, 182, 180, 181, 181, 180, 184, 180,\n       179, 181, 180, 179, 179, 182, 182, 180, 181, 182, 182, 181, 178,\n       183, 180, 177, 183, 182, 180, 178, 177, 179, 179, 180, 180, 180,\n       181, 181, 183], dtype=uint8), array([5.35827466])], [array([183, 183, 186, 185, 184, 184, 188, 187, 190, 191, 194, 192, 191,\n       193, 191, 190, 195, 194, 195, 194, 194, 194, 192, 194, 194, 196,\n       195, 194, 191, 194, 196, 195, 195, 195, 192, 189, 184, 181, 183,\n       184, 186, 186, 187, 190, 191, 191, 189, 190, 192, 194, 197, 197,\n       197, 196, 197, 198, 197, 195, 193, 190, 192, 194, 190, 190, 182,\n       183, 183, 177, 174, 160, 144, 133, 135, 137, 132, 121, 115, 117,\n       118, 120, 123, 124, 129, 130, 134, 135, 136, 138, 139, 141, 142,\n       144, 145, 146, 148, 148, 147, 150, 151, 151, 155, 154, 154, 154,\n       154, 154, 154, 157, 157, 158, 155, 156, 157, 156, 158, 159, 158,\n       158, 157, 159], dtype=uint8), array([8.97995119])], [array([153, 152, 155, 156, 158, 158, 160, 159, 163, 164, 163, 162, 164,\n       168, 164, 168, 164, 162, 164, 165, 163, 162, 164, 164, 164, 163,\n       162, 162, 163, 158, 158, 160, 158, 157, 156, 154, 153, 155, 156,\n       155, 153, 151, 153, 153, 153, 158, 149, 130, 121, 129, 142, 154,\n       168, 183, 192, 193, 193, 199, 195, 196, 196, 197, 197, 193, 193,\n       193, 192, 191, 191, 191, 190, 192, 194, 193, 193, 190, 194, 194,\n       194, 193, 194, 194, 193, 190, 188, 191, 187, 186, 190, 191, 192,\n       190, 190, 190, 191, 192, 194, 194, 192, 192, 192, 195, 193, 191,\n       192, 189, 188, 189, 188, 187, 189, 188, 187, 181, 168, 154, 150,\n       158, 170, 181], dtype=uint8), array([5.35827466])], [array([193, 197, 199, 199, 198, 198, 198, 198, 197, 197, 198, 196, 197,\n       198, 200, 197, 197, 197, 197, 200, 199, 195, 197, 197, 195, 194,\n       197, 194, 194, 196, 196, 196, 197, 197, 198, 196, 196, 196, 196,\n       196, 191, 194, 194, 193, 191, 194, 193, 191, 189, 190, 189, 191,\n       192, 196, 194, 192, 186, 189, 188, 187, 187, 192, 189, 189, 188,\n       184, 187, 188, 187, 185, 188, 186, 183, 183, 174, 160, 150, 138,\n       138, 147, 159, 162, 164, 162, 161, 158, 155, 157, 158, 158, 159,\n       157, 155, 155, 156, 156, 155, 155, 156, 154, 154, 154, 156, 155,\n       153, 152, 154, 152, 155, 154, 152, 152, 153, 151, 154, 153, 154,\n       155, 154, 152], dtype=uint8), array([3.76287851])], [array([200, 200, 203, 199, 201, 201, 200, 200, 201, 204, 198, 199, 201,\n       200, 201, 202, 200, 199, 201, 203, 201, 200, 202, 203, 202, 201,\n       198, 195, 192, 191, 194, 193, 195, 195, 193, 192, 192, 191, 190,\n       188, 184, 181, 178, 179, 184, 189, 193, 190, 193, 191, 191, 194,\n       197, 200, 199, 200, 197, 198, 200, 198, 199, 198, 201, 201, 200,\n       202, 203, 206, 204, 202, 202, 202, 199, 198, 190, 188, 187, 188,\n       188, 185, 186, 185, 185, 186, 185, 186, 186, 187, 190, 191, 189,\n       194, 190, 192, 195, 196, 197, 198, 201, 202, 201, 201, 202, 199,\n       200, 202, 203, 200, 200, 200, 198, 202, 203, 203, 202, 201, 202,\n       205, 203, 204], dtype=uint8), array([3.04808728])], [array([198, 199, 198, 200, 203, 205, 205, 202, 198, 200, 202, 204, 201,\n       200, 196, 206, 206, 205, 201, 205, 204, 201, 204, 205, 205, 205,\n       204, 204, 206, 206, 202, 204, 206, 207, 205, 204, 202, 206, 204,\n       202, 205, 204, 204, 204, 204, 207, 206, 205, 206, 206, 205, 204,\n       201, 205, 205, 198, 206, 206, 208, 204, 207, 207, 206, 208, 205,\n       204, 202, 206, 204, 201, 203, 195, 191, 185, 176, 164, 155, 156,\n       161, 168, 174, 176, 178, 177, 179, 175, 177, 177, 180, 182, 181,\n       182, 183, 184, 184, 182, 182, 187, 188, 189, 182, 185, 184, 186,\n       184, 186, 186, 187, 184, 183, 183, 182, 185, 183, 183, 179, 180,\n       180, 176, 177], dtype=uint8), array([3.04562947])], [array([205, 207, 207, 206, 207, 210, 210, 209, 211, 208, 207, 210, 211,\n       207, 206, 207, 203, 205, 204, 205, 206, 208, 207, 208, 207, 207,\n       207, 209, 208, 207, 206, 206, 209, 210, 209, 209, 208, 210, 207,\n       208, 208, 207, 208, 212, 207, 206, 207, 205, 206, 205, 205, 206,\n       206, 203, 207, 209, 208, 206, 206, 206, 204, 205, 206, 203, 202,\n       206, 203, 201, 201, 197, 192, 184, 173, 149, 139, 143, 164, 180,\n       190, 194, 198, 200, 200, 199, 197, 196, 196, 194, 194, 194, 193,\n       192, 191, 190, 186, 188, 188, 186, 186, 186, 185, 183, 183, 185,\n       185, 185, 182, 182, 181, 177, 175, 172, 164, 154, 151, 144, 136,\n       124, 113, 114], dtype=uint8), array([3.06895321])], [array([203, 204, 203, 205, 205, 203, 203, 198, 199, 196, 200, 200, 200,\n       192, 189, 183, 177, 171, 162, 154, 148, 145, 141, 144, 149, 152,\n       150, 148, 149, 153, 161, 168, 172, 176, 180, 181, 186, 188, 188,\n       186, 188, 192, 194, 193, 194, 194, 197, 193, 195, 189, 185, 180,\n       172, 166, 169, 179, 187, 192, 198, 201, 199, 199, 198, 199, 200,\n       201, 198, 197, 199, 200, 201, 204, 202, 203, 201, 202, 206, 203,\n       204, 206, 203, 203, 205, 207, 207, 206, 206, 207, 207, 207, 209,\n       206, 205, 208, 206, 205, 206, 206, 207, 202, 206, 203, 205, 205,\n       204, 202, 200, 201, 199, 198, 198, 196, 193, 194, 193, 190, 186,\n       185, 182, 182], dtype=uint8), array([2.85702873])], [array([182, 182, 183, 184, 185, 185, 182, 182, 182, 183, 184, 185, 184,\n       183, 185, 182, 181, 182, 184, 183, 183, 182, 184, 182, 182, 180,\n       186, 183, 188, 184, 182, 184, 185, 185, 186, 183, 181, 184, 182,\n       183, 184, 183, 187, 184, 185, 184, 184, 185, 184, 182, 181, 181,\n       183, 182, 183, 184, 186, 183, 182, 183, 183, 182, 183, 185, 184,\n       186, 188, 187, 188, 190, 190, 190, 192, 194, 192, 191, 192, 191,\n       190, 185, 169, 153, 145, 141, 146, 153, 155, 156, 157, 155, 154,\n       153, 154, 154, 154, 155, 155, 158, 158, 162, 164, 163, 167, 169,\n       171, 173, 174, 179, 177, 178, 183, 179, 185, 187, 185, 182, 184,\n       184, 182, 187], dtype=uint8), array([4.51179147])], [array([198, 197, 194, 196, 199, 200, 195, 192, 192, 194, 193, 193, 195,\n       192, 188, 186, 181, 182, 184, 184, 179, 178, 178, 173, 171, 168,\n       164, 158, 154, 146, 140, 134, 132, 132, 132, 135, 137, 139, 148,\n       151, 152, 156, 154, 158, 161, 160, 160, 160, 161, 162, 163, 164,\n       166, 168, 170, 166, 165, 163, 160, 147, 132, 127, 127, 128, 139,\n       149, 152, 153, 152, 150, 149, 146, 145, 144, 144, 147, 147, 148,\n       148, 149, 148, 147, 148, 151, 154, 155, 155, 161, 160, 161, 162,\n       165, 166, 164, 162, 165, 171, 171, 172, 172, 173, 173, 173, 175,\n       174, 175, 173, 178, 177, 180, 180, 182, 182, 182, 182, 181, 181,\n       183, 184, 184], dtype=uint8), array([4.37560143])], [array([159, 157, 153, 150, 148, 145, 146, 147, 148, 149, 146, 149, 149,\n       144, 146, 145, 149, 151, 150, 149, 152, 153, 154, 154, 151, 152,\n       154, 154, 155, 157, 158, 159, 160, 159, 160, 161, 163, 163, 164,\n       166, 169, 168, 166, 167, 169, 170, 172, 174, 172, 171, 174, 174,\n       177, 176, 177, 175, 176, 175, 175, 179, 178, 181, 179, 181, 182,\n       183, 185, 185, 185, 189, 190, 187, 188, 192, 193, 192, 192, 190,\n       186, 175, 159, 139, 130, 136, 147, 155, 154, 155, 158, 159, 158,\n       155, 154, 156, 159, 164, 165, 168, 171, 171, 175, 173, 179, 179,\n       180, 183, 185, 189, 189, 190, 189, 190, 188, 191, 192, 190, 191,\n       191, 191, 192], dtype=uint8), array([3.95002995])], [array([175, 177, 177, 178, 180, 184, 184, 184, 184, 186, 188, 189, 190,\n       190, 189, 189, 190, 193, 192, 192, 193, 192, 192, 195, 193, 197,\n       196, 196, 195, 192, 196, 196, 195, 194, 193, 195, 194, 195, 196,\n       198, 197, 195, 196, 196, 198, 196, 194, 196, 198, 196, 194, 196,\n       198, 197, 196, 194, 195, 196, 198, 198, 198, 196, 193, 194, 195,\n       191, 191, 191, 197, 199, 199, 197, 198, 199, 197, 194, 193, 188,\n       180, 168, 163, 167, 173, 178, 177, 176, 176, 176, 173, 172, 174,\n       177, 174, 179, 178, 179, 182, 184, 185, 187, 189, 188, 188, 192,\n       188, 189, 188, 186, 182, 179, 178, 180, 184, 186, 185, 185, 186,\n       186, 183, 180], dtype=uint8), array([3.53048839])], [array([196, 195, 201, 200, 199, 201, 201, 202, 202, 199, 200, 200, 200,\n       201, 200, 204, 203, 197, 202, 201, 198, 195, 194, 194, 197, 197,\n       197, 199, 198, 197, 194, 195, 193, 189, 191, 194, 195, 197, 198,\n       203, 200, 198, 203, 205, 203, 204, 204, 203, 204, 202, 204, 204,\n       206, 204, 200, 201, 197, 199, 195, 191, 186, 179, 171, 160, 152,\n       162, 171, 178, 181, 185, 187, 185, 185, 190, 187, 190, 190, 190,\n       192, 189, 186, 189, 186, 189, 191, 188, 187, 186, 185, 186, 187,\n       188, 189, 188, 185, 177, 172, 173, 177, 180, 185, 186, 188, 188,\n       189, 188, 192, 190, 191, 194, 196, 195, 193, 193, 194, 193, 193,\n       195, 196, 198], dtype=uint8), array([3.67640104])], [array([197, 195, 192, 192, 193, 191, 192, 189, 188, 189, 189, 188, 188,\n       190, 191, 190, 187, 185, 186, 187, 187, 188, 188, 184, 185, 186,\n       185, 185, 188, 188, 184, 186, 185, 186, 186, 185, 184, 183, 182,\n       184, 179, 181, 180, 181, 180, 180, 180, 180, 178, 176, 176, 178,\n       177, 177, 175, 176, 177, 176, 175, 170, 155, 136, 127, 126, 134,\n       149, 162, 165, 169, 173, 173, 173, 176, 179, 180, 179, 181, 182,\n       185, 186, 184, 182, 178, 168, 161, 162, 170, 179, 186, 190, 190,\n       192, 191, 191, 192, 192, 193, 192, 192, 193, 192, 191, 190, 190,\n       194, 192, 194, 194, 196, 196, 194, 194, 195, 196, 199, 195, 195,\n       195, 194, 194], dtype=uint8), array([5.21064103])], [array([196, 195, 196, 197, 197, 197, 197, 197, 199, 202, 199, 198, 200,\n       198, 194, 198, 197, 196, 200, 198, 196, 196, 199, 197, 192, 192,\n       192, 194, 194, 195, 194, 194, 198, 200, 198, 196, 196, 196, 197,\n       195, 193, 195, 195, 195, 192, 192, 189, 186, 184, 180, 165, 142,\n       127, 124, 132, 148, 164, 169, 169, 170, 171, 169, 165, 163, 161,\n       159, 156, 145, 128, 112, 111, 115, 107,  99, 117, 140, 145, 146,\n       151, 159, 163, 164, 171, 167, 170, 167, 166, 163, 165, 171, 176,\n       179, 183, 183, 184, 185, 186, 187, 190, 189, 190, 190, 191, 192,\n       192, 193, 197, 193, 194, 197, 196, 195, 194, 193, 190, 190, 191,\n       190, 189, 194], dtype=uint8), array([7.26221294])], [array([193, 196, 198, 195, 195, 195, 193, 193, 194, 193, 193, 194, 193,\n       196, 198, 199, 196, 196, 198, 197, 196, 198, 201, 195, 195, 195,\n       196, 197, 196, 196, 198, 195, 195, 199, 200, 200, 200, 201, 197,\n       197, 199, 199, 200, 196, 197, 198, 198, 197, 198, 198, 195, 198,\n       197, 200, 199, 200, 198, 200, 200, 205, 205, 206, 204, 209, 208,\n       211, 211, 210, 208, 210, 203, 189, 171, 154, 132, 122, 132, 151,\n       155, 155, 154, 153, 152, 152, 155, 156, 158, 161, 162, 168, 170,\n       171, 174, 178, 180, 183, 187, 187, 189, 191, 194, 195, 196, 198,\n       198, 200, 203, 201, 200, 202, 201, 201, 204, 203, 205, 202, 202,\n       204, 202, 201], dtype=uint8), array([5.93755418])], [array([197, 197, 196, 198, 198, 197, 196, 198, 195, 197, 196, 194, 194,\n       194, 195, 199, 199, 197, 194, 198, 196, 196, 198, 197, 198, 200,\n       202, 198, 200, 199, 199, 200, 202, 202, 200, 201, 204, 201, 200,\n       202, 202, 201, 200, 202, 201, 202, 203, 205, 202, 203, 203, 203,\n       204, 202, 202, 201, 205, 204, 203, 203, 205, 207, 210, 208, 209,\n       211, 211, 214, 211, 212, 206, 195, 182, 168, 147, 135, 155, 162,\n       160, 159, 162, 159, 157, 158, 160, 162, 164, 166, 168, 165, 170,\n       172, 174, 178, 180, 181, 184, 185, 190, 190, 196, 197, 197, 199,\n       201, 200, 201, 201, 201, 208, 205, 204, 206, 203, 205, 204, 202,\n       205, 204, 211], dtype=uint8), array([5.5774322])], [array([210, 210, 213, 210, 211, 212, 209, 207, 208, 208, 211, 208, 210,\n       208, 207, 209, 204, 208, 212, 207, 208, 210, 210, 211, 210, 209,\n       211, 213, 214, 211, 211, 212, 210, 211, 211, 210, 211, 212, 211,\n       209, 212, 213, 208, 210, 210, 206, 207, 204, 204, 206, 204, 204,\n       200, 200, 200, 200, 198, 198, 196, 195, 195, 192, 189, 188, 182,\n       176, 164, 144, 137, 138, 149, 169, 184, 190, 192, 192, 192, 195,\n       197, 199, 201, 201, 200, 203, 204, 205, 205, 206, 202, 203, 204,\n       205, 205, 207, 205, 205, 208, 211, 208, 208, 210, 208, 208, 207,\n       206, 206, 206, 204, 205, 206, 207, 205, 203, 205, 204, 205, 210,\n       209, 209, 206], dtype=uint8), array([4.19787153])], [array([207, 206, 202, 197, 198, 204, 207, 206, 207, 207, 208, 212, 211,\n       208, 213, 210, 210, 210, 210, 210, 211, 209, 212, 211, 209, 210,\n       210, 211, 211, 208, 208, 209, 210, 213, 212, 211, 213, 211, 212,\n       211, 211, 209, 209, 211, 209, 210, 209, 208, 206, 205, 204, 203,\n       202, 203, 205, 203, 204, 201, 201, 203, 204, 206, 206, 207, 203,\n       201, 198, 194, 190, 181, 162, 150, 143, 148, 164, 175, 179, 184,\n       187, 191, 189, 194, 195, 198, 200, 200, 203, 203, 204, 203, 206,\n       211, 211, 212, 210, 213, 212, 212, 213, 212, 212, 213, 214, 212,\n       216, 214, 214, 212, 209, 211, 212, 215, 213, 213, 213, 212, 212,\n       208, 210, 207], dtype=uint8), array([3.7441611])], [array([189, 191, 191, 194, 194, 192, 192, 191, 190, 191, 190, 189, 192,\n       192, 197, 192, 189, 192, 186, 180, 177, 177, 178, 183, 184, 184,\n       184, 185, 188, 192, 193, 191, 190, 191, 192, 192, 192, 192, 191,\n       190, 191, 193, 192, 192, 193, 194, 193, 194, 192, 192, 193, 196,\n       194, 194, 194, 192, 196, 194, 197, 191, 197, 196, 200, 198, 201,\n       202, 202, 204, 201, 199, 195, 183, 167, 146, 128, 133, 152, 162,\n       159, 159, 158, 156, 157, 158, 159, 164, 165, 166, 171, 174, 175,\n       176, 180, 180, 181, 184, 185, 189, 190, 192, 188, 192, 194, 194,\n       196, 195, 194, 192, 194, 193, 195, 194, 194, 196, 195, 195, 196,\n       196, 196, 193], dtype=uint8), array([5.20109506])], [array([181, 179, 178, 177, 177, 178, 179, 180, 180, 179, 180, 181, 183,\n       184, 182, 182, 184, 186, 185, 185, 184, 182, 184, 187, 186, 182,\n       183, 183, 187, 189, 186, 188, 186, 187, 188, 186, 184, 185, 183,\n       186, 183, 185, 185, 182, 185, 184, 186, 185, 185, 185, 184, 184,\n       189, 189, 187, 184, 180, 180, 184, 187, 189, 192, 194, 194, 198,\n       201, 201, 204, 203, 200, 200, 195, 182, 167, 148, 127, 130, 147,\n       156, 154, 153, 150, 149, 149, 150, 152, 154, 153, 156, 157, 162,\n       162, 168, 164, 167, 171, 171, 173, 172, 174, 171, 176, 177, 176,\n       180, 177, 180, 177, 176, 177, 178, 177, 180, 178, 177, 180, 179,\n       173, 172, 174], dtype=uint8), array([4.87914297])], [array([224, 219, 216, 219, 221, 222, 224, 225, 225, 227, 223, 222, 225,\n       223, 221, 221, 222, 223, 222, 220, 220, 221, 226, 223, 223, 222,\n       221, 220, 222, 225, 224, 221, 219, 221, 223, 222, 224, 223, 222,\n       221, 221, 221, 220, 221, 220, 222, 223, 222, 220, 224, 227, 223,\n       220, 218, 219, 222, 223, 223, 220, 221, 221, 220, 221, 219, 220,\n       222, 222, 221, 223, 221, 220, 220, 222, 222, 221, 222, 225, 225,\n       224, 220, 221, 222, 219, 221, 222, 223, 225, 222, 221, 223, 222,\n       222, 224, 222, 222, 221, 221, 221, 220, 220, 222, 222, 227, 222,\n       221, 220, 220, 222, 221, 224, 222, 222, 223, 226, 222, 217, 221,\n       220, 224, 223], dtype=uint8), array([0.])], [array([208, 211, 207, 207, 206, 206, 202, 204, 205, 205, 202, 203, 202,\n       199, 198, 199, 204, 204, 204, 203, 203, 206, 206, 203, 203, 204,\n       204, 212, 203, 206, 205, 207, 206, 208, 209, 208, 205, 208, 208,\n       208, 212, 211, 205, 206, 208, 211, 211, 210, 207, 207, 210, 209,\n       210, 212, 214, 216, 216, 214, 215, 214, 214, 211, 213, 211, 214,\n       209, 198, 177, 160, 162, 172, 166, 148, 137, 138, 144, 143, 140,\n       137, 131, 129, 135, 140, 143, 146, 146, 148, 149, 149, 153, 155,\n       158, 162, 167, 170, 174, 176, 178, 180, 184, 184, 186, 190, 192,\n       194, 194, 199, 202, 204, 203, 203, 207, 210, 208, 207, 209, 211,\n       211, 214, 213], dtype=uint8), array([8.52101685])], [array([202, 204, 202, 200, 206, 205, 204, 203, 201, 202, 204, 205, 207,\n       204, 204, 205, 205, 204, 204, 207, 202, 203, 206, 207, 205, 204,\n       206, 203, 205, 207, 204, 204, 205, 207, 208, 206, 208, 208, 209,\n       207, 205, 206, 208, 208, 209, 209, 209, 209, 214, 210, 209, 207,\n       211, 212, 216, 215, 216, 217, 216, 215, 216, 215, 215, 215, 207,\n       193, 171, 156, 157, 162, 154, 139, 130, 133, 132, 134, 133, 131,\n       131, 132, 134, 136, 136, 138, 138, 140, 144, 149, 152, 153, 158,\n       162, 162, 168, 172, 173, 176, 180, 183, 186, 183, 186, 190, 192,\n       193, 195, 198, 203, 204, 203, 202, 208, 207, 206, 210, 210, 208,\n       209, 211, 213], dtype=uint8), array([8.73503977])], [array([165, 167, 169, 167, 168, 169, 174, 179, 173, 165, 162, 164, 164,\n       167, 178, 187, 195, 201, 204, 203, 205, 207, 206, 206, 205, 204,\n       204, 202, 202, 203, 201, 203, 204, 205, 206, 206, 203, 205, 204,\n       203, 203, 203, 202, 202, 205, 205, 203, 201, 197, 199, 199, 200,\n       196, 197, 193, 193, 190, 190, 190, 192, 191, 187, 187, 186, 186,\n       185, 182, 180, 180, 181, 179, 173, 163, 154, 151, 148, 157, 172,\n       178, 181, 181, 181, 183, 188, 188, 187, 190, 189, 190, 193, 195,\n       198, 196, 194, 196, 198, 197, 200, 197, 198, 199, 199, 201, 203,\n       201, 200, 199, 202, 200, 199, 201, 199, 195, 197, 200, 202, 204,\n       200, 199, 199], dtype=uint8), array([4.59109883])], [array([205, 207, 208, 209, 203, 208, 206, 207, 211, 207, 204, 204, 206,\n       207, 207, 207, 206, 204, 204, 204, 203, 208, 204, 205, 206, 206,\n       205, 204, 208, 201, 203, 203, 201, 201, 202, 198, 201, 197, 196,\n       195, 193, 196, 193, 190, 189, 187, 186, 186, 180, 181, 181, 177,\n       172, 173, 173, 175, 172, 172, 174, 173, 172, 171, 171, 154, 140,\n       146, 164, 180, 191, 201, 207, 205, 205, 204, 204, 205, 205, 203,\n       204, 206, 207, 203, 206, 204, 203, 203, 201, 202, 199, 202, 202,\n       200, 201, 198, 198, 198, 198, 201, 200, 197, 198, 197, 197, 196,\n       193, 195, 190, 194, 193, 191, 192, 190, 189, 190, 190, 188, 189,\n       186, 185, 187], dtype=uint8), array([4.34090199])], [array([202, 202, 201, 201, 202, 201, 202, 204, 201, 201, 200, 201, 200,\n       199, 200, 202, 202, 201, 201, 199, 200, 203, 202, 201, 201, 203,\n       201, 201, 200, 197, 199, 199, 199, 198, 198, 197, 194, 194, 193,\n       192, 193, 190, 192, 192, 188, 185, 185, 183, 180, 181, 179, 176,\n       175, 178, 174, 177, 174, 176, 177, 177, 175, 178, 175, 165, 155,\n       160, 176, 190, 195, 199, 202, 201, 200, 199, 197, 195, 191, 194,\n       194, 190, 190, 193, 194, 191, 191, 190, 189, 190, 190, 187, 192,\n       193, 192, 193, 193, 195, 192, 193, 194, 194, 193, 190, 193, 196,\n       197, 197, 198, 196, 194, 200, 198, 201, 199, 200, 197, 195, 195,\n       191, 192, 192], dtype=uint8), array([4.35067225])], [array([171, 183, 195, 200, 202, 203, 205, 205, 204, 200, 206, 205, 204,\n       203, 201, 204, 203, 201, 202, 202, 201, 199, 199, 202, 203, 201,\n       202, 201, 199, 203, 202, 201, 200, 198, 196, 194, 193, 191, 188,\n       185, 182, 182, 180, 175, 178, 178, 177, 175, 175, 173, 171, 172,\n       170, 169, 170, 172, 172, 174, 174, 173, 169, 151, 149, 159, 174,\n       188, 198, 205, 204, 201, 201, 200, 197, 197, 197, 196, 191, 193,\n       189, 186, 186, 184, 183, 181, 180, 180, 179, 179, 178, 179, 178,\n       179, 172, 165, 160, 162, 172, 186, 195, 199, 197, 197, 197, 196,\n       188, 184, 181, 184, 189, 191, 191, 190, 189, 190, 190, 190, 190,\n       189, 187, 187], dtype=uint8), array([4.18356936])], [array([190, 188, 189, 186, 185, 187, 184, 186, 185, 185, 185, 188, 187,\n       187, 187, 187, 187, 186, 184, 185, 185, 186, 188, 188, 185, 183,\n       184, 188, 188, 185, 184, 187, 187, 186, 187, 187, 185, 188, 190,\n       187, 186, 185, 188, 185, 187, 188, 185, 188, 187, 189, 186, 186,\n       186, 187, 187, 187, 187, 187, 187, 190, 187, 186, 188, 186, 186,\n       186, 187, 184, 187, 184, 184, 180, 169, 159, 154, 154, 152, 156,\n       167, 168, 171, 169, 166, 166, 161, 162, 159, 159, 160, 162, 165,\n       167, 167, 169, 173, 175, 174, 175, 177, 176, 178, 180, 183, 179,\n       184, 185, 186, 183, 187, 185, 186, 187, 186, 186, 186, 186, 187,\n       188, 188, 188], dtype=uint8), array([5.923182])], [array([193, 192, 188, 189, 190, 190, 190, 190, 193, 191, 190, 191, 188,\n       191, 191, 189, 190, 188, 189, 186, 184, 184, 183, 186, 186, 185,\n       186, 188, 191, 188, 179, 168, 157, 145, 145, 157, 170, 181, 182,\n       184, 188, 186, 189, 190, 194, 193, 195, 195, 197, 199, 196, 194,\n       195, 200, 202, 201, 203, 206, 207, 210, 211, 210, 206, 195, 179,\n       167, 167, 159, 140, 122, 114, 112, 107, 105, 107, 112, 114, 117,\n       117, 118, 120, 123, 126, 128, 132, 136, 137, 140, 141, 144, 147,\n       153, 156, 161, 164, 166, 168, 174, 176, 176, 178, 178, 184, 184,\n       185, 187, 188, 189, 188, 189, 194, 191, 196, 195, 194, 194, 196,\n       196, 197, 198], dtype=uint8), array([8.89809448])], [array([186, 187, 187, 186, 188, 185, 187, 183, 182, 184, 181, 180, 180,\n       184, 186, 184, 186, 187, 189, 188, 186, 186, 189, 193, 188, 188,\n       191, 191, 189, 192, 190, 190, 193, 192, 190, 190, 189, 189, 191,\n       190, 189, 186, 186, 187, 187, 188, 187, 189, 189, 188, 185, 184,\n       182, 186, 185, 183, 182, 182, 181, 180, 177, 177, 181, 181, 181,\n       179, 177, 176, 176, 174, 170, 164, 151, 135, 129, 128, 126, 134,\n       152, 166, 171, 169, 171, 174, 173, 173, 176, 177, 179, 180, 182,\n       182, 184, 185, 185, 186, 187, 187, 189, 188, 190, 190, 190, 190,\n       190, 190, 189, 187, 182, 185, 179, 177, 177, 180, 182, 181, 185,\n       187, 190, 192], dtype=uint8), array([4.7800506])], [array([189, 190, 191, 190, 188, 192, 188, 191, 187, 190, 191, 189, 188,\n       189, 192, 191, 192, 188, 187, 188, 188, 190, 191, 193, 190, 189,\n       192, 189, 188, 191, 191, 191, 190, 186, 184, 190, 192, 185, 191,\n       189, 189, 184, 188, 189, 187, 183, 187, 186, 183, 179, 178, 177,\n       179, 175, 173, 173, 171, 169, 169, 167, 166, 166, 166, 163, 160,\n       160, 160, 158, 162, 162, 163, 156, 142, 137, 144, 140, 141, 156,\n       166, 171, 173, 175, 176, 176, 175, 174, 175, 177, 180, 182, 182,\n       183, 183, 182, 182, 182, 184, 188, 185, 180, 185, 184, 186, 188,\n       188, 186, 181, 184, 187, 187, 187, 188, 190, 188, 187, 189, 187,\n       188, 190, 189], dtype=uint8), array([5.29939395])], [array([190, 190, 191, 187, 192, 188, 189, 187, 186, 185, 188, 184, 190,\n       192, 190, 186, 187, 187, 189, 184, 185, 188, 190, 188, 186, 187,\n       182, 187, 185, 187, 184, 186, 183, 188, 187, 186, 188, 185, 188,\n       183, 184, 183, 184, 188, 184, 186, 183, 184, 187, 182, 183, 181,\n       186, 185, 180, 178, 179, 178, 177, 180, 176, 181, 180, 179, 177,\n       177, 176, 174, 174, 170, 172, 169, 161, 150, 148, 143, 146, 153,\n       167, 163, 167, 166, 169, 169, 167, 169, 173, 175, 175, 173, 178,\n       176, 179, 181, 179, 179, 184, 180, 185, 182, 186, 184, 187, 179,\n       183, 186, 187, 184, 187, 187, 190, 184, 188, 183, 187, 187, 187,\n       187, 187, 184], dtype=uint8), array([5.08347615])], [array([237, 232, 230, 234, 234, 233, 232, 232, 232, 235, 229, 236, 230,\n       230, 230, 228, 226, 226, 225, 229, 226, 231, 230, 228, 229, 231,\n       231, 232, 232, 235, 230, 234, 233, 232, 230, 229, 232, 234, 232,\n       232, 228, 230, 229, 226, 223, 222, 220, 217, 217, 210, 205, 175,\n       145, 150, 176, 178, 145, 116, 126, 145, 158, 160, 165, 169, 174,\n       179, 182, 185, 190, 196, 199, 203, 207, 210, 213, 214, 219, 215,\n       221, 226, 225, 226, 227, 226, 224, 229, 229, 230, 231, 230, 230,\n       230, 232, 234, 229, 229, 232, 231, 232, 235, 234, 232, 231, 233,\n       230, 231, 234, 232, 231, 233, 234, 232, 231, 233, 236, 236, 231,\n       231, 232, 232], dtype=uint8), array([8.36581426])], [array([228, 231, 233, 232, 229, 228, 228, 228, 223, 225, 223, 222, 220,\n       222, 223, 219, 218, 214, 211, 209, 208, 205, 199, 184, 179, 182,\n       190, 203, 214, 221, 224, 224, 227, 226, 223, 227, 224, 221, 224,\n       222, 223, 223, 222, 223, 219, 219, 209, 208, 204, 199, 197, 194,\n       189, 182, 180, 173, 169, 166, 170, 179, 183, 180, 164, 138, 115,\n       134, 164, 169, 154, 152, 171, 198, 208, 215, 218, 221, 220, 221,\n       223, 224, 223, 227, 232, 230, 227, 226, 227, 228, 229, 229, 230,\n       229, 231, 229, 226, 228, 232, 233, 235, 234, 228, 229, 229, 230,\n       232, 229, 231, 233, 232, 230, 232, 235, 229, 232, 232, 231, 231,\n       233, 231, 231], dtype=uint8), array([8.89809448])], [array([232, 232, 230, 229, 231, 232, 233, 235, 232, 230, 230, 230, 230,\n       229, 227, 230, 226, 226, 227, 226, 229, 232, 229, 228, 230, 230,\n       229, 226, 232, 230, 229, 231, 229, 231, 227, 231, 231, 229, 230,\n       227, 227, 229, 228, 224, 225, 228, 229, 227, 226, 230, 231, 228,\n       229, 233, 232, 230, 231, 231, 231, 231, 230, 231, 232, 230, 228,\n       229, 229, 227, 226, 221, 216, 202, 177, 166, 164, 154, 173, 196,\n       201, 204, 212, 211, 217, 218, 222, 223, 223, 223, 221, 224, 226,\n       230, 227, 228, 229, 224, 228, 230, 230, 228, 226, 225, 230, 230,\n       230, 231, 230, 231, 229, 230, 230, 229, 228, 228, 226, 226, 226,\n       224, 228, 228], dtype=uint8), array([4.7800506])], [array([228, 230, 230, 230, 230, 230, 233, 232, 232, 232, 232, 232, 232,\n       229, 230, 231, 230, 230, 230, 230, 230, 232, 233, 231, 229, 233,\n       229, 229, 232, 229, 233, 233, 231, 232, 233, 230, 231, 233, 231,\n       229, 229, 229, 230, 228, 230, 232, 231, 232, 230, 227, 232, 232,\n       233, 229, 231, 232, 233, 232, 231, 228, 230, 232, 233, 228, 225,\n       227, 226, 225, 224, 217, 193, 173, 170, 167, 147, 168, 197, 203,\n       202, 213, 213, 214, 218, 216, 217, 221, 222, 223, 225, 227, 227,\n       229, 231, 228, 227, 228, 233, 225, 226, 222, 217, 218, 223, 228,\n       227, 229, 226, 228, 230, 231, 233, 231, 231, 231, 229, 230, 231,\n       231, 232, 232], dtype=uint8), array([5.29939395])], [array([217, 217, 217, 219, 222, 222, 222, 223, 221, 221, 221, 221, 222,\n       222, 223, 225, 224, 222, 222, 222, 221, 223, 224, 224, 223, 223,\n       221, 221, 223, 223, 223, 223, 223, 226, 227, 226, 224, 225, 229,\n       227, 226, 227, 228, 225, 226, 225, 227, 227, 230, 230, 226, 228,\n       230, 228, 226, 226, 229, 228, 227, 225, 230, 228, 225, 226, 227,\n       223, 221, 225, 221, 221, 216, 203, 174, 161, 160, 155, 179, 203,\n       205, 214, 217, 216, 218, 224, 224, 226, 226, 229, 225, 229, 229,\n       231, 226, 231, 229, 232, 234, 234, 232, 233, 230, 227, 230, 229,\n       231, 231, 232, 234, 235, 233, 230, 233, 234, 230, 229, 229, 229,\n       232, 231, 232], dtype=uint8), array([5.08347615])], [array([226, 225, 224, 225, 223, 223, 223, 226, 230, 227, 224, 227, 226,\n       227, 224, 226, 228, 227, 227, 227, 228, 229, 228, 226, 229, 230,\n       230, 229, 231, 227, 231, 227, 225, 229, 230, 229, 228, 226, 228,\n       230, 233, 230, 229, 230, 231, 229, 228, 228, 228, 225, 224, 226,\n       227, 227, 228, 230, 228, 229, 226, 226, 223, 224, 229, 227, 224,\n       223, 220, 220, 217, 212, 201, 182, 169, 170, 170, 183, 199, 203,\n       207, 211, 212, 216, 216, 218, 219, 222, 223, 223, 226, 223, 225,\n       229, 228, 227, 228, 233, 233, 230, 228, 230, 230, 231, 233, 232,\n       233, 230, 228, 227, 229, 230, 224, 228, 229, 228, 226, 226, 226,\n       228, 231, 231], dtype=uint8), array([5.923182])], [array([225, 225, 225, 228, 226, 221, 219, 215, 211, 207, 190, 177, 180,\n       183, 191, 195, 193, 192, 193, 194, 196, 199, 200, 199, 201, 198,\n       202, 205, 203, 204, 206, 209, 212, 212, 213, 216, 219, 216, 217,\n       223, 221, 222, 218, 220, 223, 224, 224, 227, 227, 225, 226, 226,\n       227, 229, 229, 229, 227, 227, 227, 228, 228, 229, 230, 227, 228,\n       228, 227, 228, 230, 224, 213, 198, 186, 175, 170, 179, 191, 195,\n       193, 195, 198, 200, 197, 203, 205, 207, 213, 213, 217, 218, 221,\n       224, 225, 222, 222, 228, 226, 224, 225, 225, 227, 225, 227, 232,\n       230, 228, 231, 232, 228, 228, 230, 228, 225, 226, 229, 227, 228,\n       226, 227, 227], dtype=uint8), array([4.59109883])], [array([220, 220, 219, 220, 223, 222, 221, 219, 225, 224, 222, 226, 227,\n       223, 226, 226, 225, 226, 225, 227, 226, 225, 221, 226, 227, 223,\n       224, 227, 228, 228, 226, 226, 224, 223, 225, 223, 222, 225, 227,\n       223, 223, 224, 223, 223, 223, 225, 223, 225, 224, 225, 226, 229,\n       229, 226, 224, 222, 225, 227, 227, 226, 220, 221, 213, 203, 195,\n       186, 185, 190, 195, 195, 195, 195, 195, 197, 200, 200, 200, 203,\n       204, 206, 208, 211, 212, 215, 218, 218, 216, 215, 214, 218, 218,\n       221, 222, 223, 221, 224, 225, 226, 224, 225, 226, 225, 226, 228,\n       226, 226, 226, 225, 226, 227, 228, 227, 226, 230, 227, 224, 228,\n       223, 226, 229], dtype=uint8), array([4.34090199])], [array([225, 225, 225, 224, 223, 227, 225, 223, 225, 225, 221, 221, 225,\n       226, 224, 224, 224, 226, 224, 227, 226, 223, 221, 221, 221, 220,\n       222, 222, 222, 219, 223, 222, 220, 223, 218, 216, 218, 218, 217,\n       214, 211, 207, 206, 206, 204, 202, 196, 180, 162, 156, 162, 160,\n       136, 113, 119, 136, 146, 149, 148, 150, 150, 153, 160, 164, 165,\n       171, 175, 178, 181, 183, 185, 193, 198, 203, 202, 205, 207, 211,\n       215, 215, 214, 218, 221, 222, 224, 222, 219, 225, 228, 226, 224,\n       223, 224, 228, 227, 220, 221, 225, 228, 225, 224, 224, 226, 224,\n       222, 221, 219, 221, 221, 219, 224, 221, 217, 218, 221, 223, 220,\n       223, 222, 224], dtype=uint8), array([8.52101685])], [array([221, 221, 222, 224, 224, 224, 224, 225, 224, 226, 226, 225, 230,\n       225, 227, 222, 222, 224, 226, 224, 225, 227, 226, 226, 226, 226,\n       226, 230, 224, 224, 226, 226, 225, 226, 229, 227, 225, 223, 223,\n       220, 219, 217, 212, 212, 212, 211, 208, 206, 199, 176, 152, 152,\n       169, 175, 152, 127, 128, 145, 157, 156, 151, 151, 152, 157, 159,\n       161, 165, 169, 170, 178, 180, 184, 186, 191, 191, 191, 198, 200,\n       202, 207, 211, 212, 214, 215, 217, 218, 218, 220, 221, 222, 222,\n       224, 224, 221, 225, 223, 223, 227, 225, 223, 225, 226, 224, 222,\n       221, 225, 225, 226, 225, 226, 226, 225, 224, 227, 226, 229, 221,\n       223, 225, 224], dtype=uint8), array([8.73503977])], [array([225, 223, 224, 224, 222, 223, 223, 225, 227, 223, 223, 225, 222,\n       226, 227, 225, 224, 224, 224, 222, 225, 225, 225, 226, 226, 224,\n       224, 223, 223, 224, 223, 225, 224, 224, 226, 221, 223, 225, 226,\n       224, 226, 224, 225, 224, 225, 225, 224, 226, 226, 226, 227, 226,\n       224, 223, 223, 220, 218, 218, 215, 202, 188, 183, 176, 165, 177,\n       189, 187, 188, 188, 185, 189, 192, 192, 194, 197, 199, 203, 206,\n       209, 212, 213, 216, 217, 219, 219, 224, 232, 223, 225, 226, 224,\n       225, 222, 229, 223, 225, 224, 224, 225, 217, 206, 196, 187, 185,\n       190, 194, 194, 196, 196, 196, 200, 201, 201, 203, 209, 210, 214,\n       216, 217, 213], dtype=uint8), array([4.18356936])], [array([228, 223, 221, 223, 223, 224, 225, 224, 225, 224, 223, 221, 228,\n       224, 224, 224, 226, 225, 224, 223, 228, 229, 227, 227, 222, 219,\n       224, 223, 228, 225, 229, 226, 224, 222, 225, 226, 224, 225, 224,\n       224, 223, 224, 224, 227, 227, 224, 226, 226, 226, 223, 227, 226,\n       225, 224, 226, 227, 225, 226, 225, 227, 228, 226, 218, 210, 198,\n       187, 183, 183, 190, 195, 193, 192, 190, 193, 192, 194, 196, 201,\n       202, 204, 208, 210, 211, 212, 215, 216, 216, 220, 222, 222, 223,\n       225, 224, 224, 225, 228, 227, 227, 226, 228, 227, 227, 224, 226,\n       229, 227, 230, 228, 229, 227, 224, 222, 223, 221, 220, 219, 214,\n       213, 216, 217], dtype=uint8), array([4.35067225])], [array([200, 203, 201, 200, 198, 200, 200, 200, 203, 205, 203, 203, 205,\n       206, 206, 205, 203, 198, 200, 200, 200, 204, 205, 203, 204, 205,\n       204, 201, 202, 203, 205, 208, 206, 204, 208, 203, 203, 206, 206,\n       200, 198, 203, 206, 202, 200, 202, 204, 204, 203, 201, 201, 204,\n       204, 207, 208, 205, 205, 204, 205, 208, 206, 203, 203, 202, 200,\n       203, 205, 204, 202, 201, 202, 199, 199, 200, 201, 197, 199, 198,\n       198, 198, 200, 199, 203, 202, 200, 200, 201, 202, 202, 200, 198,\n       198, 198, 199, 200, 201, 200, 199, 191, 195, 199, 199, 195, 197,\n       198, 198, 196, 196, 198, 201, 201, 197, 199, 199, 197, 196, 195,\n       197, 196, 201], dtype=uint8), array([0.])], [array([213, 214, 218, 214, 213, 214, 216, 214, 211, 211, 210, 208, 214,\n       214, 210, 212, 212, 214, 213, 216, 215, 212, 211, 217, 212, 211,\n       211, 214, 213, 215, 216, 214, 216, 213, 215, 213, 215, 211, 212,\n       213, 212, 208, 212, 210, 210, 211, 212, 213, 213, 211, 208, 213,\n       212, 211, 211, 208, 213, 213, 214, 213, 217, 214, 214, 217, 218,\n       218, 218, 220, 215, 212, 208, 199, 185, 167, 157, 146, 146, 158,\n       173, 177, 180, 179, 179, 177, 178, 180, 179, 178, 180, 183, 186,\n       188, 191, 194, 197, 195, 199, 200, 202, 204, 205, 205, 207, 205,\n       205, 202, 204, 206, 208, 215, 215, 214, 213, 213, 214, 216, 216,\n       216, 214, 214], dtype=uint8), array([4.75818342])], [array([216, 218, 214, 213, 215, 214, 213, 215, 216, 212, 212, 214, 213,\n       211, 213, 212, 213, 213, 214, 216, 212, 211, 216, 214, 214, 208,\n       213, 207, 209, 209, 209, 205, 207, 203, 202, 198, 197, 201, 197,\n       195, 191, 189, 190, 190, 189, 188, 188, 186, 187, 188, 188, 185,\n       184, 184, 188, 191, 189, 185, 178, 173, 172, 180, 192, 200, 207,\n       215, 214, 218, 211, 211, 213, 211, 215, 215, 213, 214, 212, 216,\n       214, 212, 209, 211, 214, 214, 215, 215, 214, 215, 212, 211, 214,\n       213, 213, 212, 210, 209, 209, 208, 205, 205, 207, 203, 205, 205,\n       204, 209, 206, 206, 209, 206, 207, 209, 212, 210, 211, 214, 210,\n       213, 212, 213], dtype=uint8), array([3.84824603])], [array([213, 214, 211, 212, 214, 215, 211, 208, 212, 212, 212, 210, 210,\n       209, 210, 212, 209, 209, 205, 208, 208, 210, 208, 210, 210, 210,\n       209, 209, 208, 203, 209, 209, 206, 204, 203, 209, 205, 203, 202,\n       204, 206, 206, 203, 201, 200, 195, 197, 197, 197, 197, 194, 192,\n       186, 189, 187, 185, 186, 186, 180, 177, 177, 176, 173, 175, 175,\n       173, 174, 174, 171, 162, 151, 147, 151, 157, 169, 180, 189, 197,\n       201, 205, 203, 205, 203, 203, 204, 207, 209, 204, 202, 204, 205,\n       201, 203, 200, 200, 201, 199, 199, 196, 194, 191, 187, 183, 181,\n       181, 182, 182, 188, 191, 196, 198, 201, 202, 202, 202, 203, 205,\n       206, 207, 205], dtype=uint8), array([5.52762087])], [array([211, 212, 211, 210, 210, 210, 212, 212, 212, 212, 212, 212, 213,\n       210, 211, 211, 211, 209, 208, 210, 211, 210, 207, 208, 208, 208,\n       210, 203, 202, 201, 201, 200, 197, 195, 194, 192, 189, 191, 182,\n       182, 180, 179, 176, 182, 172, 169, 170, 167, 164, 166, 166, 167,\n       170, 171, 172, 174, 172, 167, 157, 149, 158, 171, 181, 190, 200,\n       209, 211, 210, 212, 213, 215, 212, 210, 209, 209, 211, 210, 207,\n       208, 209, 213, 213, 209, 209, 207, 210, 208, 204, 206, 206, 204,\n       205, 206, 204, 206, 206, 206, 207, 202, 205, 206, 204, 206, 205,\n       204, 205, 204, 203, 203, 204, 203, 199, 200, 201, 200, 198, 197,\n       198, 198, 195], dtype=uint8), array([5.24173503])], [array([200, 201, 203, 204, 205, 204, 203, 203, 205, 203, 206, 204, 202,\n       201, 201, 199, 198, 199, 199, 197, 199, 199, 196, 193, 193, 192,\n       195, 194, 192, 187, 189, 186, 184, 187, 181, 176, 173, 174, 175,\n       172, 171, 171, 170, 166, 166, 169, 170, 173, 177, 176, 181, 178,\n       182, 179, 175, 175, 170, 165, 165, 175, 192, 200, 203, 205, 204,\n       204, 204, 200, 199, 200, 200, 196, 196, 196, 199, 197, 198, 198,\n       197, 198, 195, 198, 198, 195, 197, 198, 197, 197, 195, 195, 197,\n       195, 195, 196, 193, 195, 196, 195, 195, 194, 196, 194, 194, 193,\n       196, 195, 197, 197, 196, 196, 197, 196, 197, 197, 197, 196, 196,\n       196, 196, 196], dtype=uint8), array([3.48806279])], [array([196, 199, 200, 198, 199, 199, 197, 199, 202, 199, 198, 199, 196,\n       195, 199, 197, 196, 195, 196, 197, 198, 194, 195, 194, 193, 195,\n       198, 198, 198, 199, 194, 194, 196, 197, 199, 199, 197, 196, 198,\n       194, 195, 195, 197, 195, 198, 197, 196, 193, 194, 196, 197, 195,\n       195, 197, 192, 193, 192, 192, 191, 190, 189, 190, 190, 187, 187,\n       187, 188, 187, 190, 187, 187, 186, 186, 177, 166, 154, 144, 140,\n       140, 150, 161, 169, 171, 172, 172, 170, 172, 171, 169, 166, 169,\n       171, 173, 172, 171, 172, 172, 173, 171, 173, 169, 171, 170, 171,\n       172, 170, 168, 169, 169, 170, 167, 169, 165, 167, 167, 164, 166,\n       161, 154, 144], dtype=uint8), array([4.68352392])], [array([197, 195, 198, 196, 197, 199, 197, 196, 194, 197, 200, 198, 196,\n       198, 196, 198, 195, 193, 195, 195, 193, 192, 189, 189, 188, 188,\n       188, 187, 187, 187, 187, 186, 185, 184, 182, 181, 182, 180, 176,\n       169, 157, 149, 143, 142, 147, 154, 164, 173, 176, 175, 174, 175,\n       177, 177, 174, 177, 176, 173, 178, 175, 173, 176, 178, 176, 178,\n       180, 177, 178, 179, 179, 176, 171, 160, 148, 143, 142, 152, 164,\n       176, 186, 189, 188, 192, 193, 192, 192, 194, 196, 197, 197, 198,\n       197, 197, 198, 192, 196, 195, 195, 193, 193, 196, 194, 195, 197,\n       195, 194, 191, 194, 194, 197, 192, 195, 195, 197, 197, 196, 199,\n       200, 193, 193], dtype=uint8), array([4.45399496])], [array([215, 213, 212, 213, 214, 216, 215, 214, 214, 215, 212, 216, 214,\n       217, 219, 215, 213, 212, 214, 217, 219, 216, 217, 216, 212, 215,\n       210, 213, 214, 213, 212, 213, 213, 214, 213, 214, 213, 215, 214,\n       210, 213, 215, 212, 211, 215, 216, 213, 213, 213, 215, 214, 214,\n       215, 210, 210, 211, 212, 210, 211, 212, 214, 214, 212, 211, 213,\n       214, 210, 214, 213, 212, 214, 216, 214, 211, 209, 211, 212, 208,\n       211, 213, 213, 215, 215, 214, 211, 212, 212, 208, 209, 212, 213,\n       213, 211, 212, 212, 211, 215, 214, 211, 212, 213, 212, 211, 209,\n       212, 211, 209, 210, 211, 211, 211, 211, 210, 211, 211, 212, 209,\n       208, 208, 210], dtype=uint8), array([0.])], [array([228, 230, 233, 233, 227, 231, 228, 228, 231, 230, 230, 229, 228,\n       227, 225, 230, 231, 229, 230, 230, 231, 236, 232, 233, 231, 232,\n       229, 228, 228, 232, 231, 230, 231, 230, 229, 228, 227, 229, 228,\n       229, 226, 228, 231, 230, 227, 227, 226, 225, 226, 225, 224, 225,\n       223, 221, 224, 218, 220, 218, 215, 212, 215, 210, 208, 205, 203,\n       187, 167, 151, 145, 141, 132, 125, 124, 140, 154, 167, 172, 175,\n       177, 179, 184, 187, 194, 191, 197, 202, 206, 211, 216, 216, 219,\n       220, 222, 224, 224, 225, 226, 228, 229, 228, 228, 226, 230, 229,\n       229, 230, 224, 228, 229, 230, 233, 230, 230, 229, 228, 228, 229,\n       229, 229, 230], dtype=uint8), array([8.71474618])], [array([232, 232, 230, 229, 231, 229, 227, 230, 232, 229, 229, 230, 231,\n       233, 230, 229, 227, 229, 232, 232, 229, 233, 231, 227, 228, 228,\n       227, 231, 232, 231, 232, 234, 231, 231, 233, 228, 227, 229, 226,\n       226, 226, 224, 227, 227, 227, 232, 229, 227, 230, 227, 226, 226,\n       227, 228, 226, 224, 221, 220, 218, 218, 215, 213, 208, 206, 202,\n       192, 180, 154, 127, 111, 114, 129, 141, 145, 147, 158, 172, 180,\n       186, 187, 192, 191, 194, 197, 200, 205, 209, 209, 214, 212, 215,\n       218, 219, 221, 222, 225, 225, 223, 226, 229, 229, 229, 230, 228,\n       230, 231, 232, 230, 230, 230, 230, 231, 231, 232, 228, 232, 230,\n       230, 230, 230], dtype=uint8), array([9.02551505])], [array([187, 188, 191, 191, 192, 195, 197, 200, 202, 204, 204, 204, 201,\n       205, 209, 208, 208, 211, 214, 212, 210, 215, 218, 218, 216, 220,\n       224, 223, 226, 220, 222, 223, 222, 223, 225, 225, 224, 225, 222,\n       225, 222, 223, 224, 223, 219, 217, 216, 210, 197, 169, 141, 137,\n       137, 128, 125, 136, 152, 156, 157, 163, 168, 173, 177, 185, 190,\n       193, 197, 201, 204, 207, 212, 215, 214, 216, 221, 223, 224, 228,\n       222, 226, 224, 228, 229, 226, 226, 226, 227, 228, 227, 229, 231,\n       228, 225, 230, 230, 230, 230, 226, 230, 230, 231, 229, 225, 228,\n       227, 228, 230, 229, 228, 227, 229, 229, 228, 230, 229, 227, 228,\n       231, 232, 230], dtype=uint8), array([7.32964192])], [array([234, 231, 229, 234, 231, 229, 233, 233, 231, 230, 230, 229, 233,\n       233, 234, 232, 233, 235, 235, 236, 234, 233, 234, 234, 234, 237,\n       231, 232, 236, 231, 233, 232, 233, 231, 229, 232, 231, 226, 225,\n       226, 222, 227, 229, 229, 224, 229, 231, 232, 232, 232, 230, 225,\n       229, 231, 226, 225, 226, 225, 223, 219, 220, 220, 215, 203, 189,\n       175, 164, 165, 170, 177, 188, 194, 199, 204, 205, 211, 215, 216,\n       219, 222, 226, 227, 225, 230, 230, 229, 230, 230, 228, 231, 232,\n       230, 230, 231, 234, 232, 229, 230, 229, 233, 231, 230, 233, 234,\n       232, 233, 235, 232, 232, 231, 233, 235, 231, 234, 233, 231, 229,\n       232, 235, 234], dtype=uint8), array([4.88385177])], [array([228, 229, 227, 227, 226, 226, 226, 225, 229, 230, 229, 233, 229,\n       228, 227, 225, 227, 229, 225, 229, 230, 226, 230, 227, 229, 225,\n       227, 226, 228, 229, 226, 226, 224, 222, 220, 214, 213, 210, 212,\n       210, 214, 218, 219, 225, 223, 223, 222, 219, 218, 220, 213, 212,\n       210, 207, 200, 200, 197, 198, 197, 196, 197, 197, 190, 187, 191,\n       188, 172, 145, 127, 136, 152, 151, 152, 171, 195, 209, 217, 216,\n       216, 220, 221, 222, 221, 226, 223, 224, 224, 226, 227, 230, 228,\n       228, 228, 227, 227, 234, 229, 230, 231, 228, 229, 230, 228, 227,\n       231, 232, 228, 230, 231, 232, 232, 231, 233, 232, 233, 229, 231,\n       231, 230, 231], dtype=uint8), array([6.54541434])], [array([215, 213, 214, 212, 214, 211, 209, 211, 211, 210, 210, 205, 206,\n       201, 197, 193, 184, 169, 159, 155, 163, 175, 183, 193, 201, 201,\n       200, 198, 188, 172, 159, 159, 166, 171, 183, 190, 196, 193, 196,\n       196, 199, 209, 213, 216, 220, 220, 220, 220, 222, 223, 224, 224,\n       224, 224, 224, 224, 220, 219, 217, 213, 212, 212, 209, 208, 205,\n       203, 194, 173, 144, 136, 139, 140, 140, 157, 181, 202, 212, 217,\n       214, 219, 219, 220, 223, 226, 225, 223, 226, 229, 227, 227, 229,\n       230, 231, 231, 232, 229, 233, 231, 234, 230, 231, 232, 231, 234,\n       228, 230, 232, 233, 232, 237, 229, 230, 228, 228, 226, 227, 231,\n       230, 232, 232], dtype=uint8), array([7.03218657])], [array([210, 207, 205, 203, 198, 195, 188, 175, 163, 161, 161, 158, 153,\n       153, 159, 169, 182, 188, 199, 205, 207, 209, 208, 217, 216, 216,\n       215, 217, 218, 221, 220, 223, 226, 225, 226, 226, 227, 227, 231,\n       231, 230, 228, 226, 228, 225, 225, 224, 223, 223, 223, 219, 215,\n       215, 210, 209, 206, 200, 194, 192, 188, 184, 182, 181, 182, 181,\n       168, 147, 138, 145, 157, 158, 156, 172, 194, 206, 211, 215, 216,\n       216, 221, 223, 224, 228, 225, 225, 227, 227, 228, 231, 231, 232,\n       235, 232, 232, 230, 233, 230, 230, 234, 232, 232, 234, 231, 232,\n       233, 235, 236, 231, 227, 231, 232, 232, 233, 232, 229, 234, 232,\n       230, 228, 230], dtype=uint8), array([6.38074043])], [array([218, 220, 220, 223, 222, 222, 222, 220, 224, 226, 225, 224, 226,\n       227, 226, 225, 222, 229, 225, 227, 226, 226, 227, 226, 228, 227,\n       225, 223, 221, 218, 221, 221, 221, 225, 227, 230, 228, 230, 230,\n       230, 229, 228, 224, 225, 224, 225, 227, 225, 227, 222, 221, 225,\n       227, 222, 222, 218, 218, 218, 218, 218, 217, 216, 216, 216, 220,\n       218, 215, 213, 215, 212, 209, 206, 200, 184, 164, 157, 161, 166,\n       176, 192, 208, 217, 219, 222, 223, 229, 230, 228, 224, 229, 229,\n       227, 228, 229, 227, 226, 230, 233, 230, 230, 231, 231, 234, 233,\n       231, 229, 232, 233, 233, 233, 231, 230, 232, 234, 233, 233, 233,\n       233, 232, 231], dtype=uint8), array([5.54238319])], [array([233, 230, 232, 233, 233, 233, 234, 233, 232, 231, 231, 231, 232,\n       233, 227, 228, 228, 229, 230, 229, 229, 231, 233, 231, 229, 229,\n       227, 226, 224, 225, 222, 224, 227, 223, 225, 223, 215, 217, 212,\n       210, 209, 207, 206, 202, 198, 199, 208, 209, 211, 214, 215, 218,\n       219, 223, 223, 228, 227, 224, 226, 225, 222, 220, 222, 223, 222,\n       219, 218, 216, 212, 208, 210, 209, 202, 198, 195, 187, 179, 178,\n       183, 195, 209, 220, 225, 224, 225, 227, 227, 228, 227, 228, 230,\n       227, 226, 228, 228, 227, 229, 226, 221, 221, 220, 217, 219, 221,\n       218, 217, 218, 217, 217, 219, 219, 226, 225, 230, 227, 231, 232,\n       231, 229, 227], dtype=uint8), array([4.58639866])], [array([234, 236, 234, 236, 232, 234, 235, 233, 234, 230, 234, 235, 238,\n       240, 238, 235, 235, 236, 233, 231, 231, 230, 230, 230, 230, 230,\n       230, 231, 233, 234, 233, 233, 231, 235, 232, 232, 233, 233, 235,\n       228, 233, 232, 234, 233, 231, 232, 230, 229, 227, 228, 227, 223,\n       223, 218, 206, 193, 183, 164, 150, 151, 166, 179, 187, 190, 191,\n       191, 194, 194, 198, 204, 209, 212, 217, 217, 219, 224, 229, 228,\n       229, 233, 233, 234, 238, 237, 234, 235, 238, 235, 235, 236, 230,\n       235, 238, 237, 238, 238, 235, 238, 238, 239, 234, 233, 232, 235,\n       237, 235, 235, 235, 236, 235, 233, 234, 235, 233, 232, 234, 230,\n       235, 234, 234], dtype=uint8), array([5.4984222])], [array([207, 206, 201, 195, 185, 175, 164, 160, 157, 159, 156, 164, 168,\n       169, 173, 179, 191, 198, 207, 212, 212, 213, 217, 218, 221, 219,\n       221, 222, 221, 225, 224, 224, 222, 224, 222, 223, 226, 226, 223,\n       228, 226, 228, 223, 223, 227, 225, 224, 227, 226, 222, 224, 225,\n       224, 223, 224, 223, 223, 221, 224, 222, 222, 222, 222, 218, 213,\n       206, 191, 176, 150, 145, 140, 135, 128, 130, 142, 152, 160, 166,\n       167, 167, 175, 180, 183, 189, 191, 195, 201, 204, 205, 210, 212,\n       214, 219, 222, 222, 225, 227, 231, 228, 227, 229, 231, 231, 227,\n       228, 227, 227, 231, 228, 230, 231, 232, 232, 234, 231, 231, 231,\n       228, 232, 232], dtype=uint8), array([8.81468908])], [array([233, 230, 229, 230, 230, 231, 230, 232, 233, 231, 230, 230, 231,\n       230, 229, 230, 229, 229, 229, 228, 233, 234, 229, 227, 231, 233,\n       233, 232, 230, 231, 232, 231, 230, 232, 233, 231, 230, 230, 229,\n       227, 231, 232, 236, 234, 227, 228, 231, 231, 231, 228, 225, 229,\n       228, 227, 226, 225, 226, 225, 226, 224, 223, 226, 224, 223, 219,\n       219, 218, 217, 214, 213, 209, 210, 205, 194, 171, 137, 126, 126,\n       136, 160, 187, 204, 209, 215, 219, 224, 223, 223, 224, 225, 223,\n       231, 229, 229, 229, 227, 227, 230, 231, 232, 232, 232, 230, 228,\n       236, 228, 228, 230, 234, 234, 230, 231, 230, 230, 231, 229, 227,\n       228, 230, 231], dtype=uint8), array([5.09065576])], [array([202, 201, 204, 203, 203, 202, 200, 203, 203, 202, 201, 203, 204,\n       203, 202, 199, 200, 201, 202, 202, 201, 203, 204, 204, 202, 203,\n       204, 203, 205, 205, 204, 205, 200, 204, 203, 205, 205, 204, 204,\n       204, 205, 204, 203, 205, 202, 203, 205, 205, 207, 204, 204, 206,\n       203, 203, 205, 204, 202, 205, 208, 206, 202, 205, 204, 204, 207,\n       207, 208, 205, 206, 206, 211, 209, 208, 209, 210, 207, 206, 205,\n       206, 208, 210, 208, 209, 208, 208, 209, 209, 207, 206, 203, 205,\n       203, 203, 205, 204, 203, 209, 207, 208, 209, 209, 205, 205, 206,\n       207, 206, 205, 203, 205, 208, 209, 205, 206, 205, 206, 206, 208,\n       207, 209, 211], dtype=uint8), array([0.])], [array([228, 226, 223, 224, 226, 224, 226, 224, 221, 225, 225, 225, 226,\n       227, 223, 225, 231, 226, 223, 220, 224, 225, 226, 226, 225, 224,\n       227, 224, 225, 225, 227, 227, 226, 226, 226, 225, 224, 227, 224,\n       224, 225, 222, 225, 223, 223, 223, 226, 228, 228, 229, 228, 228,\n       227, 226, 224, 224, 224, 226, 226, 225, 221, 221, 220, 209, 194,\n       174, 158, 147, 141, 151, 167, 179, 185, 185, 188, 191, 192, 196,\n       197, 197, 200, 207, 213, 214, 216, 214, 217, 217, 219, 222, 221,\n       221, 222, 222, 228, 225, 225, 226, 226, 222, 225, 225, 227, 226,\n       223, 225, 224, 225, 223, 223, 222, 220, 220, 219, 217, 215, 208,\n       199, 194, 187], dtype=uint8), array([4.42544194])], [array([220, 221, 221, 221, 224, 224, 226, 225, 223, 223, 225, 225, 223,\n       225, 225, 227, 225, 225, 226, 227, 226, 224, 225, 224, 227, 228,\n       226, 224, 226, 224, 223, 225, 225, 228, 229, 229, 229, 228, 227,\n       227, 229, 224, 226, 224, 223, 219, 210, 198, 188, 181, 178, 176,\n       176, 185, 195, 198, 203, 206, 211, 215, 216, 217, 221, 224, 226,\n       225, 224, 221, 221, 224, 220, 213, 202, 184, 169, 158, 159, 171,\n       183, 188, 189, 188, 191, 192, 195, 197, 196, 199, 205, 204, 209,\n       210, 216, 214, 214, 217, 215, 219, 220, 224, 220, 222, 222, 222,\n       224, 224, 221, 225, 228, 228, 228, 225, 225, 226, 224, 224, 225,\n       227, 225, 224], dtype=uint8), array([4.45399496])], [array([189, 195, 201, 205, 201, 204, 203, 203, 204, 206, 207, 207, 206,\n       208, 211, 208, 209, 210, 212, 214, 215, 216, 219, 215, 215, 217,\n       218, 220, 221, 217, 220, 223, 220, 219, 217, 220, 223, 220, 220,\n       223, 223, 225, 222, 225, 225, 223, 222, 223, 226, 227, 224, 224,\n       224, 227, 226, 224, 226, 226, 224, 225, 228, 228, 224, 222, 225,\n       223, 224, 226, 226, 226, 224, 224, 223, 221, 219, 211, 193, 172,\n       157, 144, 150, 170, 184, 189, 191, 194, 196, 199, 202, 206, 208,\n       209, 211, 213, 215, 215, 216, 218, 219, 222, 223, 224, 223, 223,\n       226, 227, 226, 225, 226, 226, 226, 228, 228, 225, 220, 209, 193,\n       179, 163, 148], dtype=uint8), array([4.68352392])], [array([224, 226, 225, 224, 224, 225, 224, 222, 224, 223, 222, 225, 224,\n       223, 224, 225, 225, 223, 226, 224, 222, 220, 221, 221, 226, 224,\n       224, 221, 225, 223, 223, 222, 220, 217, 219, 221, 225, 223, 225,\n       225, 228, 228, 227, 225, 225, 223, 223, 222, 219, 218, 217, 212,\n       201, 190, 178, 171, 174, 185, 195, 202, 203, 203, 207, 206, 203,\n       204, 204, 203, 204, 202, 206, 210, 211, 213, 211, 209, 211, 211,\n       212, 217, 219, 222, 219, 222, 218, 221, 219, 218, 219, 222, 224,\n       222, 222, 220, 219, 225, 228, 227, 225, 224, 225, 225, 225, 225,\n       225, 224, 226, 226, 224, 223, 225, 225, 225, 226, 226, 225, 224,\n       223, 227, 227], dtype=uint8), array([3.48806279])], [array([206, 207, 207, 210, 211, 213, 218, 218, 217, 219, 220, 220, 223,\n       220, 220, 220, 222, 224, 223, 220, 224, 226, 224, 223, 225, 224,\n       222, 222, 221, 226, 224, 225, 225, 225, 223, 224, 227, 226, 225,\n       224, 226, 226, 224, 224, 223, 224, 222, 221, 224, 223, 224, 224,\n       225, 225, 225, 224, 224, 225, 227, 224, 225, 225, 224, 225, 224,\n       223, 223, 230, 226, 227, 224, 222, 216, 200, 177, 163, 154, 142,\n       142, 163, 178, 180, 181, 180, 180, 183, 186, 190, 192, 196, 201,\n       204, 208, 208, 211, 210, 212, 211, 213, 215, 217, 221, 223, 225,\n       226, 225, 223, 225, 225, 227, 224, 225, 224, 222, 227, 225, 227,\n       227, 226, 225], dtype=uint8), array([5.52762087])], [array([222, 222, 222, 223, 223, 223, 225, 224, 223, 222, 221, 222, 221,\n       222, 225, 225, 223, 221, 222, 223, 222, 222, 222, 223, 226, 226,\n       224, 224, 223, 223, 224, 225, 223, 221, 223, 221, 220, 223, 223,\n       220, 216, 205, 189, 179, 181, 189, 203, 213, 217, 219, 222, 223,\n       222, 221, 219, 211, 199, 182, 170, 163, 153, 146, 151, 162, 168,\n       168, 168, 168, 168, 169, 172, 175, 179, 184, 190, 195, 198, 199,\n       201, 203, 206, 208, 211, 210, 213, 216, 216, 218, 218, 219, 220,\n       220, 220, 218, 219, 223, 220, 219, 220, 222, 222, 222, 222, 220,\n       223, 224, 222, 223, 224, 227, 225, 223, 223, 225, 221, 226, 225,\n       223, 223, 224], dtype=uint8), array([5.24173503])], [array([223, 225, 223, 221, 220, 222, 223, 224, 220, 222, 222, 223, 223,\n       220, 219, 219, 221, 223, 221, 220, 217, 225, 225, 220, 216, 208,\n       204, 199, 199, 201, 208, 212, 215, 219, 222, 220, 221, 221, 220,\n       218, 220, 218, 220, 221, 221, 222, 223, 218, 218, 218, 219, 215,\n       216, 214, 214, 213, 214, 211, 208, 206, 204, 196, 196, 197, 191,\n       188, 186, 186, 185, 182, 184, 179, 177, 168, 154, 149, 157, 160,\n       174, 192, 204, 212, 215, 220, 223, 220, 219, 220, 219, 220, 222,\n       220, 218, 218, 219, 217, 218, 221, 219, 218, 220, 215, 222, 224,\n       221, 221, 221, 221, 222, 224, 226, 223, 222, 227, 222, 223, 221,\n       222, 225, 218], dtype=uint8), array([4.75818342])], [array([215, 214, 216, 219, 219, 219, 218, 217, 218, 216, 216, 218, 217,\n       217, 220, 220, 216, 214, 216, 218, 218, 217, 218, 217, 221, 221,\n       222, 221, 219, 221, 217, 217, 218, 224, 216, 216, 217, 216, 222,\n       217, 219, 217, 220, 220, 219, 222, 221, 220, 223, 223, 220, 223,\n       223, 223, 220, 219, 215, 204, 189, 176, 170, 172, 178, 184, 186,\n       185, 183, 183, 184, 183, 183, 183, 186, 192, 194, 197, 202, 206,\n       209, 211, 212, 210, 211, 214, 217, 219, 220, 216, 217, 220, 222,\n       221, 220, 224, 219, 221, 223, 222, 224, 222, 219, 225, 221, 224,\n       221, 220, 220, 220, 219, 221, 224, 221, 214, 214, 212, 210, 207,\n       205, 206, 207], dtype=uint8), array([3.84824603])], [array([215, 213, 212, 211, 213, 215, 213, 215, 215, 213, 212, 214, 212,\n       209, 207, 204, 210, 209, 212, 211, 209, 212, 207, 209, 212, 212,\n       210, 211, 211, 212, 211, 211, 211, 211, 213, 213, 212, 213, 210,\n       213, 213, 212, 215, 212, 215, 217, 216, 215, 215, 217, 215, 215,\n       215, 218, 219, 219, 218, 216, 216, 215, 212, 207, 204, 193, 183,\n       177, 169, 159, 149, 144, 150, 157, 157, 152, 150, 149, 150, 149,\n       151, 153, 160, 161, 164, 167, 171, 175, 177, 182, 184, 188, 191,\n       191, 196, 203, 203, 205, 207, 210, 211, 209, 213, 214, 213, 214,\n       215, 214, 216, 216, 215, 215, 216, 217, 216, 220, 216, 218, 218,\n       220, 218, 220], dtype=uint8), array([6.3266849])], [array([172, 176, 180, 183, 183, 183, 189, 189, 190, 190, 192, 194, 192,\n       192, 194, 196, 197, 199, 197, 199, 202, 206, 206, 207, 207, 208,\n       210, 212, 212, 213, 213, 212, 213, 211, 209, 208, 212, 212, 214,\n       216, 215, 216, 215, 214, 214, 215, 215, 213, 216, 216, 218, 214,\n       212, 208, 209, 204, 198, 189, 173, 171, 172, 180, 190, 195, 195,\n       195, 194, 191, 191, 187, 190, 189, 173, 153, 138, 132, 125, 119,\n       129, 146, 159, 166, 169, 171, 175, 177, 181, 185, 189, 191, 191,\n       195, 199, 202, 204, 206, 206, 209, 209, 207, 210, 212, 214, 214,\n       214, 216, 218, 215, 218, 218, 217, 224, 218, 220, 219, 216, 217,\n       217, 220, 215], dtype=uint8), array([5.48232787])], [array([174, 177, 174, 178, 179, 183, 181, 182, 183, 186, 184, 186, 186,\n       187, 188, 192, 190, 196, 193, 197, 191, 196, 201, 197, 200, 199,\n       203, 203, 199, 201, 206, 203, 203, 208, 203, 204, 200, 199, 199,\n       207, 207, 203, 211, 210, 208, 211, 204, 207, 208, 209, 208, 209,\n       213, 208, 212, 208, 213, 209, 211, 207, 210, 209, 211, 210, 210,\n       214, 212, 212, 214, 212, 220, 220, 215, 218, 210, 201, 184, 163,\n       151, 147, 159, 168, 172, 170, 173, 169, 167, 169, 168, 170, 176,\n       177, 178, 179, 179, 188, 187, 188, 195, 191, 197, 197, 201, 203,\n       205, 207, 207, 205, 212, 210, 211, 211, 214, 215, 214, 211, 213,\n       213, 216, 218], dtype=uint8), array([4.22418291])], [array([224, 227, 224, 224, 226, 226, 227, 228, 227, 226, 222, 226, 227,\n       230, 227, 226, 226, 225, 222, 224, 224, 222, 226, 223, 221, 225,\n       227, 225, 225, 225, 223, 227, 226, 227, 225, 222, 223, 226, 224,\n       226, 227, 224, 228, 228, 227, 227, 226, 228, 228, 224, 226, 223,\n       225, 226, 224, 227, 225, 225, 227, 228, 227, 228, 227, 226, 226,\n       223, 225, 225, 225, 228, 228, 227, 227, 226, 224, 226, 221, 223,\n       225, 228, 226, 224, 225, 228, 227, 225, 227, 228, 227, 226, 229,\n       227, 226, 226, 233, 228, 228, 228, 227, 227, 228, 226, 225, 228,\n       226, 225, 227, 225, 222, 222, 227, 226, 226, 228, 227, 224, 225,\n       227, 229, 226], dtype=uint8), array([0.])], [array([221, 223, 223, 222, 222, 221, 221, 221, 222, 223, 222, 224, 222,\n       222, 220, 220, 224, 218, 221, 222, 219, 218, 220, 218, 221, 222,\n       219, 220, 225, 225, 221, 220, 223, 220, 221, 220, 224, 224, 223,\n       222, 221, 223, 223, 219, 219, 221, 224, 224, 224, 223, 224, 221,\n       223, 221, 224, 225, 225, 224, 222, 227, 225, 225, 223, 222, 222,\n       218, 212, 197, 184, 172, 170, 177, 181, 187, 187, 184, 186, 187,\n       189, 191, 194, 197, 198, 202, 207, 207, 209, 210, 212, 214, 213,\n       219, 215, 217, 222, 222, 218, 219, 220, 222, 222, 219, 222, 225,\n       225, 222, 223, 223, 223, 226, 225, 224, 222, 222, 225, 223, 226,\n       223, 224, 225], dtype=uint8), array([3.71157107])], [array([223, 223, 222, 225, 224, 222, 220, 221, 221, 219, 222, 224, 222,\n       224, 220, 222, 224, 223, 220, 222, 221, 222, 221, 221, 222, 222,\n       225, 223, 223, 221, 220, 221, 224, 222, 221, 224, 216, 217, 218,\n       216, 210, 212, 206, 210, 210, 210, 211, 212, 217, 220, 219, 218,\n       220, 220, 215, 220, 221, 223, 221, 220, 222, 224, 217, 217, 215,\n       212, 213, 212, 211, 207, 201, 189, 171, 154, 151, 149, 156, 173,\n       183, 188, 189, 192, 194, 193, 198, 200, 201, 205, 208, 210, 213,\n       217, 217, 217, 220, 220, 220, 218, 222, 221, 220, 222, 223, 224,\n       225, 222, 221, 220, 224, 223, 224, 225, 221, 221, 224, 226, 220,\n       220, 220, 223], dtype=uint8), array([4.08382213])], [array([226, 224, 226, 225, 221, 224, 224, 223, 221, 222, 222, 225, 226,\n       224, 224, 225, 223, 223, 225, 224, 224, 222, 222, 221, 222, 223,\n       224, 224, 225, 222, 220, 219, 219, 222, 224, 225, 219, 222, 219,\n       220, 219, 216, 216, 211, 208, 204, 203, 195, 175, 162, 154, 162,\n       181, 202, 213, 215, 217, 220, 222, 225, 223, 222, 224, 227, 227,\n       228, 224, 222, 224, 224, 224, 223, 223, 221, 222, 223, 221, 223,\n       227, 225, 227, 228, 227, 225, 225, 226, 226, 226, 226, 228, 227,\n       225, 224, 224, 227, 224, 225, 222, 223, 222, 222, 223, 223, 224,\n       220, 217, 221, 220, 217, 214, 210, 210, 207, 203, 193, 185, 175,\n       170, 171, 173], dtype=uint8), array([3.69767209])], [array([217, 216, 214, 217, 214, 215, 217, 218, 215, 217, 216, 217, 220,\n       217, 222, 218, 218, 220, 218, 211, 200, 190, 182, 175, 177, 182,\n       185, 185, 182, 180, 173, 168, 164, 162, 160, 158, 158, 155, 154,\n       154, 154, 155, 161, 169, 172, 176, 185, 190, 186, 191, 191, 190,\n       193, 194, 192, 192, 198, 201, 197, 202, 204, 203, 206, 209, 211,\n       211, 209, 209, 208, 204, 196, 180, 165, 155, 154, 162, 175, 172,\n       174, 175, 173, 173, 170, 170, 174, 174, 181, 179, 183, 183, 186,\n       188, 192, 194, 195, 196, 202, 203, 205, 206, 207, 206, 211, 211,\n       212, 212, 215, 212, 215, 217, 215, 217, 215, 217, 217, 219, 217,\n       214, 218, 221], dtype=uint8), array([4.18255064])], [array([221, 220, 222, 225, 222, 222, 223, 224, 223, 223, 228, 225, 222,\n       220, 223, 224, 223, 222, 221, 223, 225, 223, 221, 221, 221, 221,\n       221, 222, 218, 221, 217, 222, 221, 222, 220, 221, 220, 221, 219,\n       219, 218, 221, 218, 212, 214, 216, 214, 213, 211, 208, 206, 204,\n       203, 201, 196, 196, 193, 189, 187, 181, 182, 181, 179, 174, 176,\n       177, 180, 180, 162, 137, 142, 163, 172, 156, 141, 156, 184, 196,\n       197, 199, 200, 208, 207, 208, 210, 211, 213, 215, 215, 220, 219,\n       217, 222, 218, 219, 225, 222, 223, 224, 221, 221, 221, 222, 222,\n       221, 216, 222, 221, 221, 221, 220, 222, 222, 219, 218, 218, 218,\n       220, 223, 223], dtype=uint8), array([9.01671984])], [array([192, 193, 191, 191, 193, 192, 195, 193, 194, 193, 195, 195, 194,\n       194, 192, 191, 193, 191, 190, 192, 192, 190, 191, 190, 192, 188,\n       186, 187, 185, 187, 188, 185, 183, 186, 188, 185, 181, 185, 186,\n       187, 185, 187, 185, 185, 180, 178, 164, 153, 145, 146, 147, 151,\n       156, 162, 168, 167, 171, 175, 176, 175, 177, 177, 171, 160, 154,\n       159, 161, 154, 168, 186, 200, 210, 211, 211, 214, 216, 217, 218,\n       217, 218, 215, 215, 217, 217, 220, 218, 217, 222, 219, 214, 214,\n       214, 216, 217, 215, 214, 214, 217, 213, 213, 216, 215, 215, 216,\n       215, 216, 216, 214, 216, 216, 215, 216, 217, 216, 214, 214, 215,\n       215, 215, 214], dtype=uint8), array([6.47364817])], [array([217, 216, 215, 216, 215, 214, 214, 213, 216, 216, 215, 213, 214,\n       219, 216, 218, 214, 216, 217, 215, 214, 215, 214, 219, 215, 213,\n       215, 215, 215, 214, 214, 218, 217, 218, 213, 212, 213, 212, 217,\n       216, 216, 215, 216, 216, 216, 217, 216, 218, 215, 216, 218, 217,\n       218, 214, 219, 217, 220, 220, 220, 219, 217, 220, 221, 221, 218,\n       219, 220, 221, 218, 215, 209, 193, 176, 169, 157, 167, 181, 184,\n       184, 183, 185, 185, 185, 189, 189, 188, 189, 193, 193, 196, 196,\n       198, 200, 199, 200, 207, 203, 208, 208, 209, 210, 213, 214, 214,\n       216, 218, 216, 215, 213, 214, 215, 213, 217, 218, 215, 217, 217,\n       216, 216, 219], dtype=uint8), array([4.51710674])], [array([228, 223, 226, 230, 223, 223, 227, 224, 228, 225, 227, 226, 226,\n       224, 222, 222, 223, 225, 224, 222, 222, 222, 220, 222, 221, 221,\n       223, 224, 223, 223, 222, 222, 224, 224, 230, 224, 223, 223, 223,\n       224, 228, 225, 225, 223, 224, 222, 226, 227, 224, 224, 225, 224,\n       223, 224, 225, 225, 224, 226, 227, 226, 227, 226, 224, 223, 226,\n       226, 225, 226, 227, 227, 224, 222, 220, 211, 202, 193, 192, 202,\n       204, 205, 206, 207, 209, 210, 212, 215, 217, 217, 216, 218, 218,\n       221, 222, 221, 218, 223, 219, 221, 224, 223, 223, 225, 223, 224,\n       224, 225, 225, 225, 224, 225, 225, 221, 222, 224, 224, 224, 222,\n       223, 223, 224], dtype=uint8), array([4.88037655])], [array([228, 229, 225, 224, 227, 224, 225, 226, 224, 225, 224, 223, 225,\n       225, 225, 223, 224, 224, 225, 225, 223, 225, 224, 222, 224, 223,\n       223, 220, 222, 225, 223, 221, 222, 224, 223, 224, 226, 226, 224,\n       224, 226, 224, 224, 222, 218, 221, 223, 221, 222, 221, 221, 222,\n       221, 221, 219, 221, 222, 221, 218, 217, 217, 211, 214, 214, 213,\n       215, 216, 215, 214, 217, 219, 220, 222, 221, 217, 216, 213, 213,\n       215, 215, 219, 218, 218, 220, 220, 219, 220, 217, 218, 210, 210,\n       213, 217, 222, 222, 223, 221, 224, 224, 219, 223, 221, 222, 219,\n       217, 218, 221, 223, 225, 222, 222, 224, 226, 223, 221, 220, 221,\n       221, 221, 217], dtype=uint8), array([4.75318777])], [array([221, 220, 221, 219, 221, 222, 221, 225, 223, 223, 224, 224, 223,\n       221, 218, 219, 218, 217, 218, 216, 215, 219, 215, 213, 210, 213,\n       210, 207, 204, 201, 199, 197, 197, 195, 193, 192, 188, 184, 184,\n       182, 182, 179, 179, 178, 182, 182, 181, 176, 159, 146, 150, 169,\n       187, 206, 216, 216, 214, 219, 216, 217, 220, 222, 222, 220, 218,\n       220, 222, 221, 223, 221, 223, 224, 224, 223, 223, 221, 221, 219,\n       218, 222, 219, 217, 223, 222, 221, 219, 223, 221, 219, 219, 222,\n       219, 221, 222, 221, 220, 221, 221, 220, 218, 220, 219, 219, 218,\n       222, 224, 219, 216, 220, 217, 219, 219, 213, 217, 218, 224, 221,\n       219, 219, 219], dtype=uint8), array([4.67930649])], [array([221, 220, 220, 222, 221, 220, 221, 219, 221, 219, 222, 220, 223,\n       223, 219, 221, 223, 224, 219, 221, 223, 219, 224, 222, 219, 221,\n       219, 220, 220, 218, 218, 218, 216, 219, 221, 220, 219, 216, 215,\n       216, 216, 219, 219, 217, 218, 217, 214, 219, 220, 217, 218, 218,\n       216, 215, 213, 214, 211, 211, 207, 209, 208, 207, 206, 206, 202,\n       200, 197, 188, 179, 175, 183, 193, 200, 203, 201, 201, 203, 206,\n       206, 209, 208, 208, 210, 212, 213, 215, 217, 214, 216, 219, 218,\n       219, 221, 219, 220, 220, 217, 219, 220, 222, 222, 221, 223, 219,\n       221, 225, 224, 223, 220, 220, 222, 223, 222, 221, 221, 221, 220,\n       222, 220, 223], dtype=uint8), array([3.66342182])], [array([197, 195, 200, 199, 196, 196, 198, 198, 199, 198, 198, 197, 198,\n       199, 199, 198, 198, 194, 194, 197, 198, 197, 196, 198, 200, 198,\n       198, 195, 195, 199, 198, 196, 198, 197, 196, 194, 195, 195, 198,\n       199, 195, 198, 197, 197, 199, 196, 197, 196, 197, 197, 197, 201,\n       199, 194, 196, 195, 196, 194, 194, 195, 194, 194, 193, 191, 191,\n       189, 187, 183, 182, 178, 169, 150, 131, 128, 135, 127, 103,  87,\n        93, 105, 102, 102, 107, 112, 118, 121, 123, 125, 126, 130, 137,\n       139, 143, 148, 150, 151, 154, 158, 159, 162, 164, 166, 169, 171,\n       174, 176, 179, 181, 183, 185, 183, 187, 188, 191, 194, 194, 194,\n       195, 197, 196], dtype=uint8), array([11.24816955])], [array([201, 204, 206, 205, 206, 204, 200, 202, 204, 205, 207, 202, 205,\n       203, 206, 202, 200, 201, 201, 200, 194, 195, 195, 191, 190, 191,\n       188, 183, 185, 184, 182, 178, 178, 176, 174, 171, 171, 170, 167,\n       166, 167, 169, 170, 171, 173, 178, 177, 177, 178, 174, 157, 146,\n       151, 171, 188, 195, 202, 207, 206, 206, 207, 209, 207, 208, 206,\n       206, 206, 209, 209, 206, 206, 206, 203, 204, 203, 206, 205, 204,\n       198, 199, 200, 200, 203, 202, 202, 204, 200, 202, 202, 200, 204,\n       201, 198, 200, 201, 200, 201, 201, 201, 202, 202, 202, 200, 201,\n       201, 201, 203, 201, 199, 201, 204, 203, 200, 198, 200, 201, 201,\n       200, 203, 201], dtype=uint8), array([5.29607184])], [array([205, 203, 207, 206, 206, 205, 205, 202, 202, 205, 205, 206, 205,\n       205, 204, 204, 203, 204, 206, 202, 201, 200, 200, 203, 198, 197,\n       196, 194, 195, 194, 188, 187, 186, 184, 180, 179, 176, 174, 172,\n       170, 166, 162, 163, 161, 157, 157, 158, 161, 157, 158, 162, 160,\n       155, 140, 126, 132, 148, 169, 190, 202, 209, 206, 206, 210, 209,\n       208, 208, 209, 209, 208, 206, 205, 205, 208, 208, 208, 204, 205,\n       203, 204, 201, 202, 202, 205, 204, 204, 201, 201, 201, 201, 201,\n       201, 200, 199, 198, 197, 195, 190, 196, 196, 196, 197, 196, 195,\n       196, 197, 194, 193, 192, 194, 196, 199, 197, 199, 201, 203, 202,\n       200, 201, 200], dtype=uint8), array([5.46791157])], [array([206, 206, 203, 202, 206, 206, 202, 204, 200, 205, 203, 203, 204,\n       205, 203, 205, 203, 206, 200, 202, 202, 200, 201, 197, 195, 197,\n       195, 196, 194, 192, 189, 190, 186, 185, 186, 183, 180, 179, 177,\n       176, 173, 169, 169, 168, 167, 163, 161, 161, 159, 157, 162, 164,\n       165, 169, 166, 166, 157, 144, 140, 157, 175, 188, 197, 204, 206,\n       210, 210, 209, 210, 212, 209, 208, 206, 206, 205, 205, 207, 207,\n       209, 205, 204, 204, 204, 205, 205, 203, 203, 201, 205, 205, 205,\n       202, 204, 206, 206, 205, 205, 207, 202, 206, 204, 207, 205, 207,\n       208, 206, 204, 205, 201, 203, 205, 205, 205, 205, 203, 205, 203,\n       203, 204, 203], dtype=uint8), array([5.45620238])], [array([223, 224, 225, 224, 224, 224, 223, 220, 221, 224, 222, 221, 224,\n       221, 220, 223, 223, 224, 222, 222, 224, 223, 223, 224, 225, 225,\n       223, 226, 225, 222, 223, 219, 218, 222, 224, 225, 226, 224, 222,\n       221, 221, 221, 221, 220, 222, 223, 224, 224, 222, 223, 226, 226,\n       226, 225, 224, 225, 223, 225, 225, 224, 227, 226, 224, 225, 225,\n       223, 223, 226, 226, 225, 227, 225, 222, 220, 216, 215, 217, 218,\n       219, 222, 224, 223, 225, 224, 225, 227, 228, 225, 224, 227, 226,\n       223, 224, 227, 226, 225, 225, 221, 221, 225, 227, 226, 224, 225,\n       226, 226, 224, 224, 225, 223, 222, 222, 222, 226, 227, 225, 225,\n       224, 224, 225], dtype=uint8), array([0.])], [array([205, 207, 215, 215, 216, 222, 222, 222, 220, 218, 223, 223, 223,\n       223, 226, 226, 227, 225, 226, 225, 227, 225, 226, 226, 225, 227,\n       228, 226, 228, 226, 229, 226, 230, 227, 228, 227, 232, 231, 229,\n       226, 232, 230, 231, 224, 230, 233, 229, 231, 229, 229, 228, 228,\n       227, 227, 227, 226, 229, 229, 227, 226, 225, 227, 222, 223, 221,\n       220, 219, 216, 212, 197, 165, 135, 119, 123, 126, 108,  87,  84,\n        91, 104, 107, 115, 125, 132, 136, 142, 149, 153, 160, 165, 165,\n       169, 175, 178, 185, 187, 192, 195, 196, 199, 206, 210, 212, 213,\n       215, 217, 217, 219, 221, 222, 221, 223, 222, 226, 226, 226, 226,\n       225, 222, 225], dtype=uint8), array([11.65322989])], [array([229, 225, 226, 224, 223, 226, 232, 230, 229, 228, 229, 227, 228,\n       226, 225, 228, 226, 225, 225, 225, 226, 227, 227, 223, 224, 227,\n       226, 227, 230, 229, 227, 225, 226, 227, 229, 233, 231, 227, 229,\n       225, 223, 223, 227, 222, 223, 224, 225, 227, 228, 230, 229, 227,\n       225, 224, 225, 224, 223, 225, 223, 221, 222, 218, 218, 213, 211,\n       205, 198, 192, 190, 184, 170, 144, 127, 129, 127, 122, 110, 100,\n       106, 119, 136, 150, 156, 158, 164, 169, 175, 179, 180, 185, 188,\n       193, 197, 201, 202, 200, 207, 208, 213, 214, 215, 216, 218, 223,\n       222, 223, 224, 221, 226, 225, 224, 223, 226, 226, 228, 230, 228,\n       225, 223, 225], dtype=uint8), array([11.24816955])], [array([226, 227, 226, 225, 224, 226, 226, 228, 226, 227, 230, 230, 228,\n       230, 231, 228, 229, 227, 226, 225, 226, 226, 225, 226, 228, 228,\n       230, 228, 229, 229, 225, 227, 226, 225, 227, 227, 225, 226, 229,\n       224, 227, 225, 224, 222, 222, 221, 220, 224, 220, 218, 217, 215,\n       211, 209, 210, 207, 203, 197, 184, 172, 164, 155, 147, 149, 150,\n       141, 134, 139, 152, 165, 186, 203, 211, 216, 218, 221, 219, 219,\n       217, 221, 223, 225, 223, 221, 223, 224, 224, 222, 225, 222, 222,\n       221, 223, 225, 225, 228, 224, 224, 225, 223, 222, 223, 229, 227,\n       224, 225, 226, 225, 225, 226, 220, 224, 224, 228, 225, 223, 223,\n       225, 225, 221], dtype=uint8), array([5.29607184])], [array([229, 231, 233, 230, 232, 231, 229, 230, 231, 227, 228, 228, 228,\n       230, 229, 229, 228, 230, 231, 229, 230, 232, 229, 228, 229, 230,\n       230, 229, 228, 227, 231, 230, 230, 233, 231, 228, 231, 230, 233,\n       228, 225, 229, 225, 228, 228, 231, 225, 225, 226, 224, 222, 212,\n       201, 183, 163, 149, 144, 156, 172, 181, 187, 190, 193, 193, 196,\n       201, 205, 211, 210, 211, 215, 216, 220, 222, 225, 227, 231, 229,\n       229, 225, 226, 227, 228, 228, 226, 228, 226, 228, 233, 232, 227,\n       231, 228, 227, 225, 226, 229, 227, 225, 226, 225, 225, 226, 226,\n       225, 222, 219, 222, 224, 224, 226, 228, 228, 226, 231, 230, 231,\n       230, 231, 230], dtype=uint8), array([5.46791157])], [array([228, 225, 225, 227, 227, 224, 223, 226, 229, 227, 228, 229, 229,\n       227, 228, 227, 228, 227, 228, 229, 227, 227, 226, 227, 228, 228,\n       229, 226, 224, 226, 224, 224, 225, 225, 224, 222, 224, 226, 225,\n       226, 230, 230, 234, 228, 227, 229, 229, 229, 225, 226, 224, 226,\n       226, 223, 213, 200, 181, 157, 140, 127, 132, 148, 167, 173, 177,\n       182, 182, 180, 187, 192, 198, 201, 205, 207, 210, 216, 218, 223,\n       223, 222, 221, 227, 227, 226, 225, 227, 225, 226, 227, 228, 223,\n       222, 228, 227, 227, 230, 232, 230, 225, 224, 228, 230, 226, 226,\n       224, 227, 226, 230, 229, 231, 228, 228, 230, 230, 231, 230, 229,\n       232, 230, 230], dtype=uint8), array([5.45620238])], [array([230, 229, 230, 230, 231, 230, 229, 230, 230, 233, 231, 230, 229,\n       230, 233, 232, 231, 230, 229, 228, 228, 230, 232, 232, 232, 233,\n       232, 232, 230, 232, 231, 230, 231, 230, 226, 229, 232, 230, 231,\n       233, 229, 229, 227, 231, 231, 230, 229, 230, 231, 231, 232, 231,\n       235, 230, 234, 230, 228, 229, 226, 229, 228, 229, 232, 232, 229,\n       227, 232, 234, 236, 233, 233, 231, 230, 225, 220, 219, 221, 222,\n       225, 225, 228, 229, 226, 224, 224, 227, 230, 231, 228, 229, 232,\n       231, 232, 231, 230, 234, 232, 229, 228, 230, 231, 232, 235, 231,\n       232, 233, 232, 230, 235, 234, 237, 232, 233, 231, 230, 231, 232,\n       232, 225, 217], dtype=uint8), array([3.54463004])], [array([208, 209, 206, 201, 204, 207, 205, 206, 206, 209, 208, 206, 208,\n       209, 212, 214, 213, 212, 210, 210, 211, 210, 211, 210, 210, 209,\n       208, 215, 211, 204, 211, 212, 210, 210, 210, 210, 211, 208, 210,\n       211, 211, 211, 211, 212, 210, 208, 213, 213, 210, 209, 210, 208,\n       206, 205, 204, 201, 201, 200, 199, 196, 194, 190, 185, 184, 181,\n       179, 178, 173, 169, 166, 163, 159, 160, 161, 160, 159, 149, 129,\n       124, 151, 172, 193, 208, 212, 215, 215, 217, 217, 212, 214, 211,\n       209, 209, 209, 209, 208, 207, 205, 204, 204, 206, 207, 206, 203,\n       201, 201, 202, 203, 204, 203, 203, 200, 199, 199, 200, 200, 197,\n       198, 197, 195], dtype=uint8), array([4.51179147])], [array([222, 221, 221, 224, 226, 220, 227, 226, 229, 225, 223, 225, 224,\n       221, 221, 224, 224, 223, 221, 219, 220, 220, 221, 217, 222, 222,\n       220, 220, 222, 223, 221, 221, 219, 218, 219, 214, 215, 211, 213,\n       209, 209, 209, 207, 208, 205, 206, 204, 204, 198, 201, 199, 197,\n       199, 198, 197, 197, 195, 195, 193, 189, 189, 182, 172, 166, 167,\n       177, 193, 207, 216, 223, 223, 223, 224, 222, 222, 224, 221, 216,\n       218, 213, 213, 212, 211, 214, 215, 210, 210, 213, 213, 212, 212,\n       210, 208, 208, 209, 211, 208, 210, 204, 206, 207, 208, 208, 207,\n       209, 208, 204, 204, 206, 210, 209, 210, 210, 207, 210, 209, 211,\n       211, 209, 208], dtype=uint8), array([4.37560143])], [array([223, 224, 223, 222, 221, 223, 220, 220, 219, 218, 218, 215, 212,\n       213, 215, 215, 220, 217, 217, 218, 221, 218, 219, 218, 218, 220,\n       220, 219, 219, 222, 216, 214, 218, 217, 216, 217, 214, 214, 213,\n       212, 212, 212, 211, 212, 217, 212, 214, 215, 213, 212, 211, 209,\n       209, 209, 206, 203, 205, 205, 200, 198, 197, 194, 194, 193, 191,\n       187, 183, 180, 178, 174, 171, 174, 177, 182, 175, 172, 152, 129,\n       132, 152, 175, 196, 213, 218, 215, 217, 215, 214, 212, 214, 211,\n       211, 211, 207, 208, 208, 207, 204, 203, 202, 206, 200, 204, 201,\n       204, 204, 202, 201, 201, 204, 204, 205, 205, 202, 199, 204, 202,\n       201, 201, 201], dtype=uint8), array([3.95002995])], [array([210, 211, 210, 208, 209, 207, 209, 210, 210, 209, 209, 211, 209,\n       210, 204, 206, 207, 205, 206, 207, 207, 207, 207, 206, 207, 204,\n       208, 207, 208, 208, 207, 206, 208, 206, 204, 209, 206, 203, 205,\n       206, 208, 205, 203, 203, 206, 205, 203, 204, 205, 205, 207, 205,\n       205, 202, 203, 201, 200, 198, 194, 192, 192, 188, 185, 182, 180,\n       182, 181, 177, 173, 173, 169, 167, 167, 162, 153, 149, 158, 179,\n       196, 208, 212, 211, 214, 212, 207, 210, 212, 205, 204, 203, 198,\n       196, 195, 190, 192, 190, 187, 184, 181, 182, 180, 182, 186, 187,\n       190, 193, 197, 197, 197, 197, 195, 198, 193, 193, 196, 193, 194,\n       190, 190, 192], dtype=uint8), array([3.53048839])], [array([181, 182, 181, 179, 179, 179, 175, 175, 174, 175, 174, 172, 171,\n       168, 166, 169, 168, 169, 168, 170, 163, 161, 160, 155, 151, 151,\n       153, 153, 152, 152, 154, 159, 157, 158, 155, 153, 154, 157, 166,\n       174, 177, 179, 181, 184, 183, 177, 173, 174, 173, 175, 179, 176,\n       180, 181, 183, 186, 187, 187, 183, 184, 181, 175, 168, 157, 147,\n       151, 169, 193, 204, 209, 211, 214, 213, 212, 214, 215, 214, 212,\n       215, 213, 211, 212, 212, 210, 208, 208, 207, 207, 205, 208, 208,\n       212, 213, 209, 209, 206, 204, 203, 202, 202, 204, 205, 203, 206,\n       205, 206, 208, 207, 204, 206, 200, 199, 192, 180, 165, 160, 166,\n       178, 188, 195], dtype=uint8), array([3.67640104])], [array([202, 204, 203, 202, 202, 201, 198, 202, 200, 200, 202, 198, 200,\n       198, 202, 198, 198, 203, 201, 200, 205, 199, 198, 201, 201, 202,\n       201, 199, 201, 202, 199, 201, 199, 196, 196, 199, 198, 197, 195,\n       194, 194, 193, 187, 184, 184, 176, 177, 172, 168, 166, 162, 158,\n       155, 152, 148, 145, 142, 139, 134, 132, 127, 121, 114, 109, 107,\n       105, 100,  95,  93, 105, 121, 137, 152, 166, 170, 177, 193, 211,\n       224, 224, 227, 226, 226, 225, 224, 222, 223, 221, 215, 216, 219,\n       216, 214, 214, 212, 207, 205, 208, 204, 201, 199, 198, 198, 197,\n       194, 197, 193, 195, 195, 193, 191, 189, 190, 192, 193, 194, 194,\n       198, 193, 191], dtype=uint8), array([8.97995119])], [array([210, 211, 210, 208, 207, 208, 210, 207, 205, 206, 205, 205, 205,\n       200, 203, 205, 202, 201, 202, 203, 200, 200, 198, 201, 202, 202,\n       199, 197, 198, 197, 193, 194, 198, 195, 199, 194, 195, 196, 194,\n       196, 196, 196, 196, 195, 194, 193, 188, 183, 177, 163, 144, 130,\n       126, 128, 144, 162, 169, 172, 173, 176, 179, 179, 177, 179, 183,\n       186, 187, 191, 190, 191, 197, 194, 193, 197, 196, 197, 196, 195,\n       197, 199, 200, 200, 198, 196, 197, 196, 198, 197, 200, 198, 200,\n       199, 198, 198, 198, 198, 199, 199, 201, 201, 199, 199, 196, 194,\n       198, 194, 198, 198, 199, 197, 201, 199, 197, 196, 198, 197, 194,\n       197, 198, 196], dtype=uint8), array([5.35827466])], [array([203, 203, 206, 202, 206, 207, 206, 207, 209, 209, 209, 210, 211,\n       211, 209, 209, 212, 212, 215, 214, 213, 213, 214, 210, 213, 214,\n       212, 210, 214, 214, 212, 211, 213, 214, 211, 209, 206, 207, 205,\n       205, 207, 204, 205, 209, 210, 209, 209, 210, 210, 209, 215, 214,\n       213, 215, 215, 214, 214, 214, 213, 215, 210, 208, 208, 209, 203,\n       202, 200, 197, 191, 178, 164, 160, 165, 169, 162, 142, 131, 125,\n       124, 128, 133, 139, 140, 143, 146, 146, 149, 151, 155, 154, 156,\n       156, 158, 160, 163, 164, 163, 166, 165, 165, 166, 169, 169, 172,\n       172, 171, 170, 175, 173, 171, 173, 170, 169, 167, 168, 170, 173,\n       174, 177, 176], dtype=uint8), array([8.97995119])], [array([168, 170, 171, 170, 170, 177, 176, 175, 179, 178, 178, 179, 179,\n       180, 182, 181, 177, 181, 182, 181, 182, 183, 182, 182, 182, 181,\n       180, 176, 177, 180, 179, 174, 171, 175, 175, 173, 172, 169, 167,\n       168, 168, 169, 170, 166, 169, 171, 169, 165, 155, 138, 134, 147,\n       160, 175, 193, 207, 214, 214, 217, 215, 216, 216, 214, 213, 213,\n       210, 211, 212, 213, 210, 209, 210, 212, 209, 212, 208, 210, 212,\n       212, 211, 211, 211, 208, 207, 209, 206, 207, 206, 208, 207, 211,\n       210, 208, 206, 208, 209, 208, 209, 210, 212, 211, 208, 208, 209,\n       210, 207, 207, 208, 208, 207, 207, 205, 203, 206, 200, 190, 177,\n       167, 170, 179], dtype=uint8), array([5.35827466])], [array([213, 214, 215, 215, 216, 211, 215, 215, 213, 216, 218, 217, 217,\n       219, 217, 217, 217, 219, 216, 217, 217, 214, 217, 215, 213, 215,\n       217, 213, 212, 214, 213, 214, 215, 215, 214, 215, 216, 215, 216,\n       214, 209, 214, 218, 215, 214, 213, 214, 217, 209, 210, 210, 211,\n       213, 215, 211, 211, 209, 209, 210, 207, 208, 206, 206, 207, 208,\n       205, 207, 207, 208, 208, 206, 203, 200, 195, 185, 174, 165, 158,\n       165, 173, 179, 178, 177, 175, 175, 176, 173, 173, 176, 175, 173,\n       173, 173, 175, 174, 173, 171, 174, 174, 174, 172, 173, 172, 173,\n       171, 170, 168, 171, 172, 168, 169, 166, 166, 166, 166, 168, 167,\n       166, 167, 169], dtype=uint8), array([3.76287851])], [array([217, 219, 219, 220, 222, 221, 217, 218, 221, 219, 219, 216, 219,\n       218, 220, 220, 219, 219, 219, 222, 220, 222, 223, 219, 219, 216,\n       211, 212, 211, 216, 215, 212, 213, 212, 209, 210, 208, 206, 199,\n       197, 194, 196, 201, 205, 208, 206, 212, 211, 213, 213, 214, 211,\n       211, 217, 219, 220, 220, 218, 217, 220, 220, 218, 220, 222, 224,\n       223, 224, 223, 222, 222, 221, 219, 211, 206, 203, 206, 204, 204,\n       207, 204, 202, 202, 202, 201, 203, 203, 205, 207, 207, 210, 214,\n       210, 210, 214, 216, 217, 217, 216, 217, 220, 220, 221, 219, 218,\n       220, 219, 221, 219, 222, 219, 220, 220, 223, 223, 221, 220, 220,\n       220, 220, 220], dtype=uint8), array([3.04808728])], [array([216, 216, 220, 218, 219, 219, 220, 222, 220, 223, 220, 222, 221,\n       221, 220, 225, 222, 219, 225, 226, 225, 222, 222, 223, 226, 221,\n       223, 223, 225, 226, 223, 221, 224, 229, 223, 222, 223, 219, 221,\n       222, 221, 223, 225, 222, 224, 224, 223, 225, 227, 223, 224, 227,\n       225, 223, 223, 220, 223, 223, 225, 220, 224, 224, 217, 224, 223,\n       224, 225, 225, 222, 219, 215, 211, 202, 191, 178, 171, 168, 175,\n       186, 191, 191, 194, 195, 196, 198, 197, 198, 200, 203, 201, 202,\n       201, 200, 201, 204, 203, 200, 207, 208, 208, 206, 208, 206, 207,\n       206, 207, 206, 208, 204, 206, 205, 202, 202, 202, 202, 203, 199,\n       197, 196, 196], dtype=uint8), array([3.04562947])], [array([226, 225, 226, 229, 229, 229, 230, 229, 227, 226, 226, 226, 228,\n       230, 231, 229, 225, 227, 229, 227, 227, 230, 231, 229, 226, 226,\n       225, 224, 229, 225, 227, 227, 229, 228, 228, 228, 230, 227, 226,\n       227, 227, 225, 226, 226, 227, 228, 226, 224, 226, 227, 228, 223,\n       226, 223, 226, 226, 226, 225, 225, 228, 226, 224, 224, 226, 227,\n       224, 223, 223, 220, 215, 209, 202, 193, 176, 172, 174, 189, 201,\n       209, 212, 214, 218, 217, 217, 216, 218, 217, 214, 216, 215, 213,\n       215, 212, 210, 208, 207, 210, 209, 206, 206, 206, 209, 205, 206,\n       206, 205, 206, 206, 203, 200, 195, 194, 189, 185, 182, 174, 161,\n       153, 139, 131], dtype=uint8), array([3.06895321])], [array([224, 224, 224, 221, 221, 219, 218, 224, 218, 216, 217, 216, 213,\n       210, 209, 207, 203, 193, 181, 169, 157, 145, 137, 140, 145, 151,\n       158, 160, 154, 156, 162, 172, 185, 189, 195, 203, 207, 207, 211,\n       213, 211, 212, 212, 214, 216, 215, 213, 215, 213, 210, 206, 204,\n       199, 189, 183, 186, 194, 204, 213, 219, 217, 220, 218, 216, 218,\n       219, 219, 219, 220, 223, 218, 219, 220, 221, 221, 221, 223, 223,\n       223, 226, 226, 222, 221, 221, 223, 223, 224, 225, 226, 226, 226,\n       227, 223, 225, 226, 229, 228, 229, 227, 228, 223, 224, 225, 223,\n       223, 220, 220, 220, 219, 219, 219, 216, 216, 213, 213, 210, 209,\n       206, 203, 200], dtype=uint8), array([2.85702873])], [array([200, 200, 201, 200, 199, 202, 202, 198, 200, 200, 201, 200, 201,\n       201, 201, 200, 201, 201, 199, 201, 200, 201, 201, 196, 198, 204,\n       203, 202, 203, 199, 200, 201, 198, 200, 198, 200, 196, 197, 198,\n       203, 202, 199, 203, 201, 200, 202, 199, 204, 201, 196, 199, 199,\n       199, 198, 199, 201, 201, 200, 199, 201, 202, 199, 201, 204, 202,\n       203, 206, 206, 207, 209, 209, 208, 211, 213, 212, 211, 210, 205,\n       195, 182, 164, 153, 156, 164, 169, 171, 173, 174, 169, 168, 168,\n       166, 167, 166, 168, 168, 171, 175, 177, 178, 181, 182, 187, 186,\n       189, 191, 192, 197, 194, 196, 197, 200, 200, 199, 198, 195, 194,\n       200, 200, 200], dtype=uint8), array([4.51179147])], [array([216, 218, 216, 217, 219, 219, 215, 210, 210, 209, 207, 203, 202,\n       196, 195, 193, 186, 182, 183, 182, 180, 177, 175, 175, 172, 168,\n       162, 156, 149, 144, 142, 140, 144, 150, 154, 160, 163, 164, 168,\n       170, 169, 169, 169, 171, 172, 172, 177, 173, 176, 173, 174, 174,\n       175, 177, 179, 176, 176, 177, 173, 169, 156, 142, 134, 134, 133,\n       142, 153, 161, 164, 163, 162, 161, 163, 161, 156, 159, 159, 163,\n       163, 163, 165, 167, 169, 167, 169, 173, 175, 176, 179, 181, 181,\n       182, 184, 185, 184, 181, 187, 187, 189, 192, 192, 190, 191, 194,\n       194, 194, 196, 195, 197, 200, 200, 199, 201, 201, 200, 199, 198,\n       200, 203, 203], dtype=uint8), array([4.37560143])], [array([173, 170, 166, 164, 161, 160, 162, 162, 158, 160, 158, 158, 158,\n       163, 162, 162, 164, 165, 167, 164, 165, 164, 164, 166, 167, 169,\n       170, 172, 172, 172, 173, 173, 175, 177, 173, 175, 179, 180, 180,\n       181, 183, 183, 185, 183, 185, 188, 189, 190, 191, 191, 192, 190,\n       190, 190, 192, 189, 193, 192, 195, 194, 196, 193, 194, 199, 200,\n       203, 206, 205, 204, 205, 206, 207, 210, 212, 211, 211, 205, 195,\n       184, 168, 149, 147, 158, 166, 166, 171, 170, 171, 173, 170, 170,\n       173, 176, 178, 179, 181, 184, 187, 191, 190, 194, 194, 199, 200,\n       198, 203, 205, 210, 207, 209, 208, 209, 209, 209, 208, 208, 208,\n       207, 210, 212], dtype=uint8), array([3.95002995])], [array([194, 196, 198, 199, 201, 202, 203, 202, 203, 203, 203, 206, 204,\n       205, 208, 209, 210, 211, 209, 211, 211, 212, 213, 213, 211, 212,\n       213, 213, 213, 213, 217, 215, 208, 213, 211, 215, 213, 212, 216,\n       214, 213, 216, 214, 216, 219, 216, 214, 215, 215, 213, 211, 211,\n       212, 214, 215, 212, 217, 213, 217, 217, 218, 215, 211, 208, 209,\n       211, 212, 215, 218, 221, 220, 216, 215, 220, 218, 206, 195, 185,\n       178, 180, 193, 192, 194, 195, 195, 193, 190, 189, 190, 191, 191,\n       194, 195, 194, 196, 199, 206, 207, 207, 208, 211, 212, 209, 208,\n       203, 203, 202, 203, 202, 202, 202, 203, 206, 202, 206, 205, 205,\n       203, 204, 202], dtype=uint8), array([3.53048839])], [array([216, 214, 218, 218, 217, 220, 222, 220, 223, 219, 222, 222, 223,\n       223, 220, 220, 218, 215, 218, 215, 212, 208, 205, 207, 203, 203,\n       204, 203, 202, 201, 201, 202, 208, 207, 207, 208, 210, 209, 208,\n       210, 214, 216, 216, 220, 220, 222, 223, 220, 221, 220, 223, 221,\n       220, 221, 221, 219, 217, 218, 217, 212, 209, 205, 197, 187, 178,\n       172, 178, 187, 197, 202, 201, 200, 202, 203, 203, 206, 208, 207,\n       209, 209, 207, 207, 206, 205, 207, 206, 206, 205, 204, 202, 205,\n       204, 200, 201, 203, 199, 194, 192, 190, 192, 193, 194, 193, 197,\n       201, 202, 206, 206, 207, 208, 211, 209, 210, 211, 209, 210, 213,\n       213, 213, 214], dtype=uint8), array([3.67640104])], [array([211, 211, 209, 209, 210, 210, 210, 208, 209, 207, 209, 208, 208,\n       208, 210, 206, 206, 206, 205, 207, 208, 208, 205, 207, 206, 204,\n       205, 205, 206, 203, 205, 204, 203, 202, 203, 204, 202, 202, 201,\n       201, 200, 201, 197, 198, 199, 201, 200, 200, 199, 198, 195, 195,\n       196, 197, 193, 196, 195, 196, 194, 192, 183, 165, 149, 144, 144,\n       151, 165, 178, 182, 187, 191, 189, 193, 195, 194, 196, 199, 200,\n       203, 203, 203, 203, 197, 195, 198, 201, 200, 201, 206, 205, 208,\n       210, 211, 210, 210, 210, 211, 210, 211, 210, 212, 208, 206, 208,\n       211, 213, 212, 212, 213, 213, 213, 212, 214, 212, 211, 214, 214,\n       211, 211, 213], dtype=uint8), array([5.21064103])], [array([241, 243, 244, 241, 244, 245, 239, 238, 234, 235, 236, 241, 235,\n       234, 235, 236, 239, 239, 235, 236, 239, 237, 240, 238, 239, 239,\n       238, 238, 239, 239, 240, 242, 244, 242, 243, 246, 240, 242, 243,\n       245, 247, 245, 244, 244, 242, 245, 246, 245, 242, 244, 247, 242,\n       245, 246, 248, 250, 247, 247, 249, 251, 250, 248, 249, 246, 248,\n       247, 238, 214, 189, 186, 198, 197, 178, 158, 157, 162, 160, 161,\n       159, 157, 152, 156, 160, 165, 167, 174, 173, 172, 173, 180, 186,\n       186, 190, 196, 196, 199, 204, 211, 214, 213, 213, 217, 218, 224,\n       225, 227, 231, 232, 236, 239, 236, 241, 243, 243, 246, 247, 247,\n       244, 249, 248], dtype=uint8), array([8.52101685])], [array([238, 240, 238, 236, 238, 238, 237, 237, 238, 238, 239, 238, 239,\n       241, 238, 237, 240, 240, 236, 237, 241, 240, 242, 242, 242, 240,\n       241, 242, 242, 239, 238, 238, 241, 240, 240, 241, 240, 242, 241,\n       242, 245, 244, 243, 243, 243, 243, 246, 247, 247, 248, 244, 246,\n       249, 249, 249, 247, 253, 254, 251, 251, 252, 252, 250, 252, 249,\n       232, 211, 178, 169, 179, 183, 168, 147, 142, 147, 152, 156, 156,\n       152, 151, 156, 158, 159, 157, 161, 162, 167, 174, 178, 178, 179,\n       186, 191, 195, 202, 202, 209, 211, 212, 213, 215, 215, 218, 225,\n       226, 228, 232, 236, 237, 241, 234, 237, 241, 244, 243, 245, 244,\n       245, 242, 243], dtype=uint8), array([8.73503977])], [array([197, 199, 200, 199, 194, 191, 187, 186, 187, 197, 206, 213, 225,\n       226, 235, 237, 241, 244, 243, 237, 239, 241, 238, 241, 241, 242,\n       240, 238, 237, 238, 238, 237, 238, 239, 238, 242, 239, 237, 236,\n       238, 237, 238, 236, 238, 238, 235, 232, 229, 230, 229, 231, 231,\n       230, 226, 226, 225, 222, 220, 218, 221, 219, 219, 217, 216, 214,\n       215, 213, 210, 212, 207, 196, 185, 180, 179, 183, 197, 207, 211,\n       215, 214, 219, 220, 221, 220, 223, 221, 225, 227, 225, 227, 229,\n       230, 230, 230, 232, 233, 233, 235, 234, 235, 234, 232, 233, 237,\n       234, 234, 234, 234, 232, 230, 230, 232, 231, 233, 236, 233, 234,\n       232, 232, 231], dtype=uint8), array([4.59109883])], [array([242, 243, 243, 239, 239, 236, 241, 242, 243, 243, 237, 239, 241,\n       241, 241, 243, 242, 239, 240, 239, 239, 240, 229, 235, 239, 239,\n       237, 237, 235, 235, 234, 235, 233, 232, 232, 232, 228, 230, 230,\n       226, 224, 225, 224, 219, 220, 216, 214, 210, 208, 208, 206, 204,\n       202, 203, 199, 203, 200, 200, 203, 201, 196, 184, 166, 166, 184,\n       201, 219, 232, 237, 238, 240, 244, 239, 238, 237, 240, 241, 239,\n       240, 240, 244, 238, 237, 235, 234, 232, 230, 234, 237, 236, 235,\n       233, 233, 233, 232, 231, 230, 232, 231, 228, 230, 229, 226, 226,\n       225, 223, 219, 223, 221, 222, 224, 223, 223, 222, 223, 217, 222,\n       220, 217, 217], dtype=uint8), array([4.34090199])], [array([234, 235, 243, 236, 236, 230, 237, 238, 233, 233, 233, 233, 235,\n       234, 235, 233, 231, 235, 236, 233, 234, 233, 235, 234, 235, 236,\n       236, 233, 233, 232, 231, 232, 232, 230, 230, 229, 227, 227, 227,\n       226, 226, 223, 219, 217, 214, 211, 212, 214, 211, 212, 209, 205,\n       209, 206, 208, 206, 208, 209, 209, 208, 204, 194, 185, 190, 205,\n       219, 228, 231, 234, 236, 235, 234, 231, 229, 229, 224, 225, 226,\n       225, 224, 226, 224, 223, 223, 223, 224, 223, 227, 226, 226, 226,\n       229, 225, 224, 224, 226, 226, 225, 228, 230, 228, 232, 230, 231,\n       227, 229, 233, 235, 231, 233, 230, 233, 230, 230, 234, 227, 223,\n       220, 224, 225], dtype=uint8), array([4.35067225])], [array([229, 236, 236, 235, 237, 237, 235, 238, 240, 241, 236, 238, 238,\n       238, 236, 234, 235, 236, 236, 237, 233, 233, 236, 236, 236, 236,\n       231, 236, 234, 236, 232, 231, 230, 228, 229, 225, 222, 221, 217,\n       215, 217, 215, 207, 203, 207, 206, 200, 202, 202, 198, 200, 200,\n       199, 201, 204, 205, 201, 205, 196, 181, 174, 188, 203, 219, 230,\n       236, 238, 239, 236, 233, 231, 232, 230, 229, 230, 225, 222, 219,\n       220, 217, 217, 216, 213, 212, 211, 210, 208, 208, 207, 205, 206,\n       199, 186, 187, 202, 218, 226, 232, 232, 231, 232, 228, 222, 222,\n       219, 220, 222, 226, 230, 223, 226, 224, 222, 221, 221, 220, 217,\n       218, 217, 216], dtype=uint8), array([4.18356936])], [array([221, 220, 221, 219, 220, 215, 219, 215, 221, 219, 216, 215, 217,\n       218, 218, 219, 218, 219, 219, 216, 219, 222, 221, 220, 218, 219,\n       219, 216, 218, 216, 217, 220, 217, 217, 219, 217, 219, 221, 219,\n       218, 218, 216, 214, 216, 219, 214, 216, 220, 217, 223, 217, 217,\n       219, 218, 218, 220, 220, 220, 219, 219, 220, 219, 221, 221, 215,\n       219, 221, 221, 216, 216, 212, 201, 187, 182, 182, 182, 190, 198,\n       198, 198, 196, 195, 192, 190, 187, 184, 184, 185, 187, 191, 191,\n       195, 198, 199, 200, 200, 201, 208, 212, 209, 211, 217, 214, 215,\n       217, 218, 218, 217, 221, 218, 218, 219, 221, 219, 217, 218, 221,\n       221, 223, 221], dtype=uint8), array([5.923182])], [array([223, 229, 224, 224, 227, 224, 223, 223, 222, 221, 223, 221, 221,\n       221, 222, 221, 220, 214, 209, 205, 198, 192, 197, 197, 204, 209,\n       212, 215, 219, 219, 209, 204, 190, 182, 181, 190, 203, 211, 210,\n       212, 218, 215, 218, 223, 224, 224, 224, 225, 229, 230, 228, 224,\n       218, 221, 225, 233, 232, 239, 240, 240, 239, 242, 242, 239, 231,\n       204, 187, 177, 178, 163, 143, 133, 130, 128, 127, 127, 134, 135,\n       140, 140, 143, 144, 148, 149, 152, 156, 159, 160, 163, 167, 173,\n       175, 178, 185, 187, 192, 196, 198, 202, 204, 204, 212, 215, 215,\n       217, 219, 218, 219, 223, 222, 224, 228, 226, 229, 228, 227, 228,\n       229, 230, 228], dtype=uint8), array([8.89809448])], [array([215, 217, 219, 217, 222, 220, 220, 218, 217, 216, 211, 207, 214,\n       220, 222, 222, 218, 219, 222, 222, 219, 220, 223, 219, 222, 221,\n       219, 226, 223, 225, 223, 225, 224, 223, 222, 218, 219, 222, 221,\n       224, 225, 224, 223, 221, 219, 219, 222, 221, 222, 222, 217, 218,\n       217, 219, 216, 214, 213, 215, 214, 212, 211, 208, 209, 209, 209,\n       208, 205, 201, 200, 198, 188, 167, 151, 152, 155, 150, 157, 179,\n       194, 199, 202, 204, 203, 203, 207, 207, 207, 210, 214, 216, 216,\n       214, 219, 220, 219, 221, 223, 224, 220, 224, 223, 221, 224, 221,\n       221, 219, 217, 211, 200, 198, 200, 198, 202, 205, 212, 214, 222,\n       223, 225, 223], dtype=uint8), array([4.7800506])], [array([223, 222, 226, 224, 222, 224, 223, 225, 223, 219, 220, 221, 226,\n       223, 224, 223, 222, 219, 222, 224, 222, 222, 223, 225, 225, 225,\n       221, 219, 220, 221, 221, 221, 223, 220, 221, 220, 222, 217, 221,\n       219, 220, 218, 218, 218, 216, 215, 214, 212, 211, 207, 205, 205,\n       203, 204, 202, 199, 196, 194, 195, 194, 195, 193, 191, 188, 189,\n       191, 187, 190, 192, 189, 175, 160, 162, 169, 166, 179, 191, 199,\n       202, 205, 205, 205, 204, 207, 208, 208, 210, 211, 212, 213, 213,\n       214, 213, 214, 215, 218, 217, 216, 217, 215, 219, 217, 218, 220,\n       215, 216, 213, 220, 218, 221, 223, 217, 223, 221, 221, 224, 218,\n       222, 222, 217], dtype=uint8), array([5.29939395])], [array([222, 221, 221, 223, 224, 216, 220, 215, 222, 222, 226, 220, 222,\n       223, 221, 223, 218, 220, 222, 222, 219, 217, 222, 218, 219, 222,\n       215, 219, 217, 218, 220, 218, 220, 216, 220, 217, 214, 220, 216,\n       220, 215, 211, 215, 215, 214, 213, 212, 217, 212, 212, 211, 215,\n       211, 210, 214, 209, 207, 207, 209, 204, 205, 207, 209, 204, 200,\n       199, 198, 201, 202, 197, 192, 175, 161, 158, 162, 168, 185, 194,\n       195, 195, 199, 194, 199, 198, 201, 200, 200, 203, 204, 199, 207,\n       208, 209, 211, 209, 217, 213, 210, 214, 213, 216, 214, 217, 214,\n       219, 214, 214, 214, 219, 216, 221, 214, 218, 218, 214, 218, 216,\n       213, 216, 217], dtype=uint8), array([5.08347615])], [array([255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 254, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 252, 251, 250, 233, 196, 177,\n       202, 228, 211, 167, 140, 160, 185, 185, 189, 192, 197, 205, 210,\n       214, 220, 225, 227, 231, 237, 239, 243, 248, 252, 253, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255], dtype=uint8), array([8.36581426])], [array([255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 254, 248, 244, 245, 243, 242, 232, 219, 214,\n       218, 227, 237, 248, 253, 255, 255, 255, 255, 255, 255, 254, 255,\n       255, 255, 255, 255, 255, 255, 252, 245, 246, 245, 244, 238, 230,\n       223, 221, 220, 213, 206, 202, 195, 195, 204, 210, 207, 201, 176,\n       142, 135, 165, 186, 177, 167, 186, 223, 244, 254, 251, 252, 254,\n       254, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255], dtype=uint8), array([8.89809448])], [array([255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 254, 248, 229, 208, 206, 199, 193, 214, 237,\n       236, 243, 244, 254, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255], dtype=uint8), array([4.7800506])], [array([255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 245, 213, 191, 194, 185, 169, 203, 234, 235,\n       239, 245, 251, 253, 254, 251, 248, 251, 254, 254, 254, 255, 255,\n       255, 255, 255, 255, 255, 255, 254, 243, 227, 219, 218, 231, 251,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255], dtype=uint8), array([5.29939395])], [array([255, 255, 255, 254, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 254, 253, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 253, 246, 217, 198, 196, 186, 208, 233,\n       241, 244, 249, 255, 255, 254, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255], dtype=uint8), array([5.08347615])], [array([255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 254, 243, 255, 255, 255, 255,\n       255, 255, 255, 253, 249, 244, 226, 202, 199, 206, 214, 230, 242,\n       238, 246, 249, 252, 253, 253, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255], dtype=uint8), array([5.923182])], [array([255, 255, 255, 255, 252, 247, 243, 237, 233, 226, 217, 214, 221,\n       224, 228, 228, 226, 225, 228, 229, 230, 232, 232, 232, 237, 237,\n       235, 237, 244, 243, 244, 247, 249, 249, 253, 254, 254, 253, 251,\n       255, 255, 254, 255, 255, 254, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 253, 236, 220, 206, 196, 199, 215, 227, 228,\n       231, 233, 234, 237, 233, 239, 245, 243, 246, 251, 254, 253, 254,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255], dtype=uint8), array([4.59109883])], [array([255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 254, 252, 251, 238, 229, 222,\n       219, 227, 230, 227, 227, 229, 228, 230, 234, 233, 234, 239, 239,\n       240, 242, 244, 248, 246, 251, 251, 251, 251, 252, 253, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255], dtype=uint8), array([4.34090199])], [array([255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 254, 255, 255, 253, 254, 255, 254, 254, 254, 255, 247,\n       243, 240, 242, 242, 237, 234, 222, 204, 175, 165, 178, 176, 153,\n       126, 140, 162, 172, 171, 172, 177, 178, 182, 185, 189, 197, 202,\n       204, 209, 210, 219, 223, 224, 232, 233, 239, 245, 245, 244, 251,\n       251, 251, 252, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 253, 254, 255, 255, 255, 252, 254, 252, 253, 255, 255,\n       255, 254, 255], dtype=uint8), array([8.52101685])], [array([255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 251, 251, 251, 251, 250, 244, 238, 223, 199, 176, 178, 195,\n       192, 163, 141, 152, 172, 180, 176, 174, 177, 182, 183, 186, 190,\n       196, 199, 202, 205, 211, 215, 221, 222, 225, 230, 233, 236, 240,\n       244, 248, 250, 250, 248, 249, 252, 255, 251, 252, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255], dtype=uint8), array([8.73503977])], [array([255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 254, 254, 247, 232, 218, 213, 203, 203, 213, 219,\n       219, 217, 221, 223, 219, 221, 224, 229, 234, 236, 238, 242, 246,\n       249, 249, 251, 254, 254, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 241, 254, 255, 255, 251, 239, 225, 218, 219, 223,\n       225, 226, 227, 229, 229, 232, 235, 236, 238, 242, 250, 250, 250,\n       253, 253, 255], dtype=uint8), array([4.18356936])], [array([255, 255, 254, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 254, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 253, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 254, 244, 230, 219,\n       214, 219, 225, 226, 224, 223, 226, 227, 229, 229, 229, 234, 235,\n       241, 244, 247, 250, 249, 252, 251, 249, 255, 254, 255, 255, 254,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 253, 249, 252, 252,\n       252, 253, 255], dtype=uint8), array([4.35067225])], [array([236, 232, 233, 233, 232, 237, 238, 237, 238, 239, 241, 242, 239,\n       237, 238, 236, 237, 238, 232, 236, 236, 237, 239, 236, 236, 237,\n       237, 236, 237, 238, 240, 241, 242, 242, 242, 238, 241, 238, 237,\n       236, 236, 238, 243, 240, 238, 237, 239, 238, 237, 238, 239, 239,\n       237, 240, 241, 239, 235, 237, 238, 238, 237, 239, 237, 236, 236,\n       237, 234, 233, 231, 232, 234, 232, 235, 236, 236, 230, 233, 233,\n       236, 232, 231, 234, 236, 235, 233, 233, 232, 231, 235, 237, 231,\n       229, 228, 229, 233, 232, 234, 232, 226, 230, 235, 230, 230, 228,\n       230, 229, 228, 230, 233, 232, 231, 229, 231, 233, 230, 230, 230,\n       236, 232, 234], dtype=uint8), array([0.])], [array([248, 248, 253, 252, 254, 253, 248, 247, 246, 251, 249, 251, 249,\n       250, 248, 248, 249, 248, 247, 250, 250, 249, 249, 248, 247, 248,\n       246, 249, 248, 251, 251, 249, 250, 250, 250, 250, 252, 253, 247,\n       246, 246, 249, 247, 248, 245, 248, 249, 246, 246, 249, 246, 248,\n       247, 246, 248, 250, 247, 249, 250, 249, 249, 250, 248, 252, 250,\n       250, 253, 254, 252, 252, 251, 250, 248, 236, 215, 190, 178, 164,\n       159, 180, 213, 212, 210, 208, 211, 210, 209, 207, 208, 211, 212,\n       216, 221, 223, 223, 224, 227, 229, 232, 237, 239, 238, 238, 243,\n       244, 245, 240, 236, 236, 242, 244, 248, 248, 248, 249, 251, 252,\n       252, 249, 251], dtype=uint8), array([4.75818342])], [array([253, 251, 250, 248, 250, 251, 249, 251, 251, 249, 249, 248, 250,\n       251, 248, 248, 253, 252, 250, 253, 251, 249, 248, 246, 248, 244,\n       245, 246, 244, 245, 244, 239, 240, 238, 237, 230, 227, 229, 226,\n       224, 221, 219, 219, 221, 219, 217, 217, 216, 217, 217, 217, 219,\n       220, 219, 219, 222, 218, 208, 203, 207, 220, 235, 247, 249, 249,\n       251, 251, 252, 250, 249, 252, 250, 248, 249, 252, 248, 245, 249,\n       246, 246, 249, 249, 249, 248, 249, 249, 247, 248, 247, 248, 250,\n       247, 246, 245, 244, 242, 237, 239, 240, 237, 241, 242, 241, 241,\n       241, 242, 243, 239, 244, 243, 245, 248, 245, 245, 245, 246, 242,\n       246, 249, 253], dtype=uint8), array([3.84824603])], [array([250, 249, 248, 245, 246, 249, 247, 246, 249, 248, 248, 245, 243,\n       245, 243, 243, 244, 243, 239, 246, 244, 245, 247, 245, 247, 242,\n       241, 241, 242, 243, 241, 242, 241, 239, 243, 239, 241, 239, 238,\n       240, 239, 239, 236, 237, 238, 232, 230, 228, 229, 226, 224, 223,\n       223, 222, 222, 220, 217, 221, 210, 206, 207, 207, 200, 203, 202,\n       200, 203, 202, 203, 185, 166, 166, 177, 187, 198, 211, 228, 234,\n       234, 236, 240, 240, 240, 239, 238, 243, 241, 241, 243, 241, 242,\n       238, 237, 235, 236, 235, 232, 233, 230, 224, 218, 208, 205, 201,\n       197, 193, 194, 203, 210, 219, 227, 231, 238, 240, 237, 236, 240,\n       243, 239, 239], dtype=uint8), array([5.52762087])], [array([247, 246, 247, 247, 249, 248, 246, 246, 248, 250, 250, 247, 246,\n       244, 247, 244, 245, 244, 246, 246, 247, 242, 242, 240, 242, 235,\n       237, 237, 237, 232, 230, 231, 226, 224, 224, 219, 220, 218, 213,\n       214, 208, 205, 200, 203, 200, 193, 192, 189, 192, 194, 198, 199,\n       201, 203, 201, 197, 178, 165, 175, 193, 210, 223, 236, 248, 249,\n       250, 250, 251, 248, 250, 251, 250, 247, 245, 246, 246, 248, 246,\n       244, 248, 246, 242, 242, 244, 242, 240, 241, 240, 244, 243, 241,\n       243, 242, 241, 241, 240, 238, 243, 246, 236, 239, 240, 242, 237,\n       238, 241, 240, 237, 237, 243, 236, 235, 237, 234, 232, 230, 226,\n       229, 226, 231], dtype=uint8), array([5.24173503])], [array([236, 233, 236, 241, 236, 237, 241, 242, 239, 238, 241, 234, 235,\n       234, 232, 235, 237, 233, 235, 230, 232, 230, 228, 226, 225, 222,\n       226, 226, 221, 220, 220, 213, 207, 206, 205, 204, 204, 202, 201,\n       199, 197, 194, 199, 196, 200, 206, 206, 209, 210, 208, 212, 209,\n       210, 208, 195, 182, 187, 207, 228, 235, 242, 241, 239, 234, 234,\n       232, 234, 231, 231, 230, 233, 233, 234, 232, 227, 232, 233, 227,\n       231, 235, 231, 229, 229, 227, 228, 229, 234, 232, 230, 230, 232,\n       230, 228, 229, 228, 229, 226, 226, 228, 226, 229, 227, 226, 228,\n       231, 229, 230, 229, 230, 231, 231, 229, 229, 230, 231, 229, 229,\n       229, 229, 229], dtype=uint8), array([3.48806279])], [array([232, 230, 234, 232, 233, 235, 234, 230, 235, 236, 231, 232, 233,\n       231, 235, 230, 227, 230, 229, 228, 227, 228, 230, 228, 225, 227,\n       230, 229, 228, 231, 229, 230, 227, 231, 231, 230, 232, 231, 232,\n       230, 230, 229, 228, 229, 230, 227, 230, 232, 229, 229, 231, 229,\n       227, 226, 223, 227, 224, 226, 226, 224, 224, 222, 222, 220, 219,\n       219, 221, 221, 221, 217, 219, 217, 218, 216, 212, 208, 190, 179,\n       172, 163, 167, 185, 197, 197, 200, 198, 198, 201, 199, 196, 202,\n       200, 201, 202, 200, 199, 203, 201, 203, 203, 202, 203, 202, 199,\n       201, 200, 200, 199, 200, 200, 200, 199, 199, 201, 198, 199, 197,\n       196, 188, 171], dtype=uint8), array([4.68352392])], [array([232, 231, 230, 233, 231, 229, 229, 228, 230, 231, 232, 229, 230,\n       229, 230, 230, 230, 226, 226, 226, 228, 226, 223, 223, 220, 223,\n       220, 216, 219, 219, 219, 217, 216, 217, 211, 212, 211, 209, 208,\n       202, 194, 180, 169, 169, 171, 174, 190, 200, 205, 206, 210, 206,\n       205, 209, 210, 208, 210, 207, 207, 210, 208, 209, 208, 207, 206,\n       210, 208, 211, 211, 210, 208, 204, 189, 169, 162, 162, 172, 191,\n       208, 216, 219, 217, 224, 224, 228, 227, 228, 228, 227, 228, 228,\n       228, 228, 227, 231, 228, 228, 227, 225, 227, 230, 229, 226, 228,\n       227, 227, 230, 226, 229, 233, 230, 231, 230, 229, 231, 230, 231,\n       229, 228, 230], dtype=uint8), array([4.45399496])], [array([248, 251, 249, 249, 249, 251, 249, 250, 247, 249, 246, 248, 247,\n       250, 253, 249, 253, 252, 250, 255, 255, 254, 251, 250, 248, 249,\n       251, 248, 248, 248, 250, 251, 252, 250, 248, 249, 249, 251, 249,\n       246, 250, 250, 250, 248, 248, 250, 249, 250, 251, 251, 249, 247,\n       249, 247, 246, 243, 246, 246, 246, 245, 248, 246, 246, 246, 245,\n       242, 252, 250, 248, 243, 248, 250, 246, 246, 249, 245, 245, 245,\n       247, 246, 247, 247, 249, 249, 248, 248, 248, 249, 249, 247, 247,\n       249, 249, 247, 247, 246, 247, 245, 243, 247, 246, 249, 246, 244,\n       247, 247, 247, 246, 244, 250, 249, 250, 243, 248, 244, 246, 244,\n       245, 245, 244], dtype=uint8), array([0.])], [array([255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 254, 252, 249, 248, 248, 247, 242, 237, 219,\n       185, 153, 162, 177, 162, 136, 143, 167, 190, 195, 195, 204, 208,\n       213, 215, 221, 226, 232, 234, 240, 242, 250, 252, 252, 251, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 254, 243, 253, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255], dtype=uint8), array([8.71474618])], [array([255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 254, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 254, 248, 253, 253, 248, 249, 246, 244, 245, 239, 233,\n       225, 192, 147, 115, 122, 150, 169, 164, 157, 171, 196, 213, 215,\n       220, 224, 225, 225, 230, 236, 239, 244, 248, 247, 249, 250, 251,\n       253, 254, 255, 255, 255, 254, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255], dtype=uint8), array([9.02551505])], [array([225, 224, 226, 233, 234, 231, 233, 237, 237, 242, 243, 242, 238,\n       242, 247, 245, 247, 249, 251, 251, 249, 253, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 254,\n       255, 255, 255, 255, 253, 255, 250, 238, 203, 165, 159, 172, 157,\n       143, 155, 172, 182, 187, 189, 195, 201, 205, 212, 219, 226, 227,\n       233, 236, 239, 241, 246, 249, 253, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255], dtype=uint8), array([7.32964192])], [array([255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 254, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 253, 249, 251,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 251, 246, 231, 213, 203,\n       194, 189, 200, 219, 227, 227, 234, 243, 247, 249, 251, 252, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 254, 254, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255], dtype=uint8), array([4.88385177])], [array([255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 254, 255, 255, 255, 255, 255, 255, 254, 254, 252, 250, 248,\n       244, 244, 246, 246, 255, 255, 255, 255, 255, 255, 255, 254, 254,\n       254, 249, 243, 240, 229, 228, 230, 229, 231, 235, 234, 231, 227,\n       223, 224, 219, 199, 157, 142, 169, 190, 182, 182, 213, 236, 245,\n       248, 252, 253, 255, 254, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255], dtype=uint8), array([6.54541434])], [array([254, 254, 253, 253, 250, 251, 250, 249, 249, 249, 247, 244, 245,\n       240, 237, 232, 229, 226, 217, 196, 183, 179, 188, 200, 214, 230,\n       232, 233, 232, 222, 206, 193, 186, 194, 201, 209, 220, 227, 234,\n       237, 238, 247, 249, 252, 254, 254, 254, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 253, 252, 251, 248, 246, 243,\n       243, 238, 239, 223, 196, 166, 168, 187, 177, 166, 193, 222, 242,\n       243, 243, 249, 252, 254, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255], dtype=uint8), array([7.03218657])], [array([242, 241, 239, 242, 239, 236, 232, 223, 220, 217, 205, 196, 187,\n       176, 171, 176, 182, 192, 210, 225, 236, 242, 242, 248, 246, 248,\n       252, 252, 253, 253, 255, 255, 255, 254, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 253, 251, 246, 242, 240, 233, 229, 226, 221, 214, 209, 210,\n       212, 210, 195, 168, 150, 165, 183, 173, 176, 207, 234, 245, 245,\n       249, 255, 253, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255], dtype=uint8), array([6.38074043])], [array([252, 252, 254, 255, 255, 254, 254, 254, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 246, 253, 255, 255, 254, 251, 248, 244, 246, 251,\n       252, 253, 252, 254, 251, 248, 245, 243, 225, 198, 185, 189, 196,\n       204, 219, 243, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255], dtype=uint8), array([5.54238319])], [array([255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 253, 253,\n       250, 247, 245, 240, 237, 240, 238, 240, 239, 235, 232, 231, 237,\n       246, 253, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 254,\n       254, 255, 253, 251, 247, 244, 243, 236, 229, 227, 223, 215, 214,\n       222, 232, 244, 252, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 254, 254, 254, 251, 255, 255,\n       252, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255], dtype=uint8), array([4.58639866])], [array([255, 255, 255, 255, 255, 255, 255, 255, 255, 246, 254, 255, 255,\n       255, 255, 255, 255, 254, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 254,\n       245, 227, 218, 202, 179, 166, 192, 216, 217, 217, 222, 220, 224,\n       226, 231, 232, 236, 246, 252, 254, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255], dtype=uint8), array([5.4984222])], [array([250, 250, 245, 241, 241, 229, 215, 201, 182, 168, 158, 159, 160,\n       161, 170, 181, 203, 214, 225, 234, 238, 238, 245, 245, 246, 246,\n       253, 254, 254, 255, 255, 255, 255, 255, 255, 255, 255, 254, 248,\n       255, 255, 255, 252, 254, 255, 255, 254, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 247,\n       235, 213, 189, 192, 203, 189, 158, 140, 159, 183, 189, 191, 195,\n       197, 203, 206, 213, 217, 224, 230, 237, 236, 241, 244, 249, 252,\n       254, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255], dtype=uint8), array([8.81468908])], [array([255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 254, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 252, 245, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       254, 255, 253, 251, 251, 248, 248, 245, 240, 226, 190, 148, 136,\n       142, 154, 188, 229, 243, 251, 255, 254, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255], dtype=uint8), array([5.09065576])], [array([235, 236, 237, 235, 236, 233, 231, 237, 237, 235, 237, 232, 237,\n       236, 235, 236, 237, 234, 237, 237, 234, 237, 239, 239, 237, 237,\n       239, 237, 241, 242, 242, 241, 236, 237, 237, 238, 241, 239, 240,\n       237, 239, 237, 236, 238, 236, 238, 242, 240, 242, 238, 237, 240,\n       240, 239, 239, 237, 236, 237, 242, 240, 239, 242, 240, 238, 242,\n       242, 244, 242, 240, 243, 245, 247, 246, 245, 240, 244, 243, 241,\n       244, 242, 247, 246, 243, 242, 245, 244, 247, 244, 244, 244, 240,\n       242, 243, 241, 243, 240, 239, 241, 244, 243, 239, 241, 240, 240,\n       244, 239, 239, 237, 239, 240, 246, 243, 243, 241, 242, 245, 245,\n       242, 241, 243], dtype=uint8), array([0.])], [array([255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 254, 255, 255, 255, 255, 255, 255, 255, 248, 231, 203,\n       182, 171, 166, 175, 198, 212, 218, 219, 220, 224, 228, 227, 231,\n       235, 237, 241, 242, 245, 249, 250, 251, 252, 254, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 254, 254, 253, 254, 255, 254, 252, 244, 228,\n       221, 217, 221], dtype=uint8), array([4.42544194])], [array([255, 255, 255, 255, 255, 254, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 254, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 252, 239, 228, 219, 215, 210, 207,\n       212, 225, 234, 234, 241, 242, 247, 253, 255, 254, 254, 255, 255,\n       255, 255, 255, 255, 255, 250, 237, 223, 200, 187, 186, 204, 217,\n       218, 222, 221, 219, 225, 225, 230, 231, 233, 235, 240, 244, 245,\n       246, 252, 255, 253, 253, 252, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255], dtype=uint8), array([4.45399496])], [array([232, 235, 236, 237, 237, 237, 242, 242, 242, 243, 243, 243, 248,\n       249, 245, 247, 249, 252, 252, 251, 251, 254, 255, 250, 252, 251,\n       254, 255, 255, 255, 255, 255, 252, 254, 255, 255, 255, 255, 255,\n       255, 254, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 254, 250, 242, 221, 199,\n       180, 165, 177, 204, 218, 222, 227, 232, 232, 233, 237, 241, 241,\n       245, 249, 249, 251, 253, 254, 255, 255, 255, 254, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 247, 229, 211,\n       194, 177, 166], dtype=uint8), array([4.68352392])], [array([255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 253, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 251, 252, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 254, 254, 254, 248, 249, 242,\n       227, 209, 196, 196, 209, 227, 236, 238, 238, 237, 240, 244, 242,\n       240, 237, 239, 240, 240, 242, 246, 246, 248, 249, 246, 247, 247,\n       255, 254, 254, 255, 253, 255, 252, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255], dtype=uint8), array([3.48806279])], [array([240, 241, 245, 246, 253, 251, 254, 255, 255, 254, 255, 255, 255,\n       255, 254, 254, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 254, 253, 242, 220, 201, 190, 170, 168,\n       186, 203, 210, 211, 215, 210, 217, 218, 223, 227, 228, 231, 237,\n       240, 244, 243, 246, 247, 250, 253, 254, 253, 255, 254, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255], dtype=uint8), array([5.52762087])], [array([255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 254, 255, 255, 255,\n       251, 241, 223, 203, 203, 222, 239, 248, 253, 254, 255, 255, 255,\n       255, 252, 242, 221, 189, 163, 150, 146, 154, 173, 188, 192, 195,\n       196, 196, 198, 199, 202, 205, 210, 215, 220, 226, 232, 233, 234,\n       234, 238, 242, 245, 247, 248, 253, 255, 255, 255, 255, 254, 254,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 254, 253, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255], dtype=uint8), array([5.24173503])], [array([255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 254, 253, 255, 255, 255, 253, 247,\n       243, 233, 228, 237, 245, 249, 253, 254, 255, 254, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 254, 253, 251, 251,\n       249, 252, 253, 251, 249, 245, 245, 243, 240, 235, 232, 232, 225,\n       225, 222, 219, 220, 217, 216, 212, 209, 210, 196, 169, 169, 173,\n       179, 209, 235, 248, 252, 249, 251, 252, 253, 251, 254, 251, 254,\n       254, 255, 255, 253, 255, 255, 255, 255, 255, 254, 251, 254, 255,\n       255, 255, 255, 254, 255, 255, 255, 255, 254, 255, 255, 255, 255,\n       255, 255, 255], dtype=uint8), array([4.75818342])], [array([251, 254, 249, 252, 255, 255, 255, 255, 254, 253, 253, 253, 252,\n       250, 254, 255, 253, 253, 254, 254, 254, 253, 252, 251, 255, 255,\n       255, 254, 253, 254, 250, 251, 255, 255, 252, 253, 252, 251, 254,\n       253, 255, 252, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 243, 223, 203, 195, 201, 211, 212, 213, 216,\n       214, 214, 213, 213, 216, 218, 219, 224, 229, 232, 238, 241, 243,\n       247, 249, 248, 250, 250, 251, 253, 254, 255, 254, 254, 254, 255,\n       255, 255, 254, 255, 255, 252, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 254, 255, 253, 254, 253, 253, 250, 246, 244, 242, 241,\n       240, 238, 241], dtype=uint8), array([3.84824603])], [array([249, 248, 248, 247, 250, 250, 249, 248, 245, 249, 251, 246, 243,\n       241, 241, 243, 245, 247, 248, 247, 244, 246, 246, 245, 246, 247,\n       247, 246, 243, 246, 248, 247, 249, 247, 247, 250, 246, 249, 249,\n       249, 250, 249, 249, 251, 249, 250, 250, 250, 253, 250, 251, 254,\n       249, 252, 255, 253, 254, 254, 251, 245, 243, 239, 229, 218, 213,\n       208, 195, 177, 171, 181, 185, 185, 181, 175, 172, 174, 176, 178,\n       181, 187, 190, 192, 201, 200, 203, 209, 213, 217, 221, 226, 230,\n       229, 233, 236, 235, 240, 243, 245, 246, 249, 249, 249, 249, 252,\n       251, 253, 252, 253, 254, 253, 252, 252, 252, 251, 254, 252, 254,\n       254, 254, 254], dtype=uint8), array([6.3266849])], [array([208, 213, 214, 218, 219, 218, 221, 222, 223, 224, 226, 226, 228,\n       231, 226, 232, 231, 235, 233, 238, 239, 240, 239, 243, 244, 244,\n       246, 247, 248, 252, 249, 252, 253, 248, 245, 244, 248, 247, 250,\n       250, 250, 250, 253, 251, 251, 250, 247, 251, 249, 248, 252, 249,\n       249, 246, 246, 244, 237, 234, 220, 210, 208, 213, 223, 232, 232,\n       231, 232, 228, 226, 226, 227, 226, 216, 193, 170, 155, 147, 136,\n       148, 173, 184, 191, 196, 200, 203, 205, 210, 214, 218, 222, 223,\n       229, 231, 235, 236, 238, 241, 241, 243, 247, 247, 249, 253, 252,\n       254, 254, 253, 252, 253, 252, 253, 255, 252, 254, 250, 249, 254,\n       255, 254, 254], dtype=uint8), array([5.48232787])], [array([211, 206, 211, 213, 214, 215, 217, 217, 219, 221, 220, 220, 224,\n       226, 227, 227, 228, 229, 231, 230, 232, 231, 229, 235, 235, 232,\n       239, 238, 236, 237, 245, 244, 242, 237, 240, 237, 234, 234, 236,\n       246, 244, 244, 244, 246, 241, 246, 243, 246, 245, 246, 245, 244,\n       249, 240, 247, 247, 250, 246, 244, 245, 248, 250, 250, 245, 249,\n       249, 251, 252, 250, 254, 253, 254, 252, 245, 234, 225, 203, 183,\n       172, 177, 187, 192, 196, 196, 196, 197, 199, 202, 201, 204, 206,\n       213, 210, 212, 220, 220, 222, 223, 226, 228, 232, 231, 237, 239,\n       242, 242, 243, 245, 244, 243, 246, 250, 247, 249, 248, 251, 250,\n       248, 250, 251], dtype=uint8), array([4.22418291])], [array([255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 253, 252, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255], dtype=uint8), array([0.])], [array([255, 255, 255, 255, 255, 254, 254, 254, 255, 255, 255, 255, 255,\n       254, 255, 255, 255, 254, 255, 255, 254, 254, 255, 254, 255, 252,\n       255, 255, 255, 255, 255, 255, 255, 251, 253, 254, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 253,\n       243, 232, 211, 199, 198, 208, 218, 218, 218, 218, 220, 219, 222,\n       225, 229, 233, 232, 237, 239, 243, 244, 246, 246, 248, 252, 253,\n       253, 253, 254, 254, 255, 255, 254, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255], dtype=uint8), array([3.71157107])], [array([255, 255, 255, 255, 255, 255, 255, 255, 255, 253, 254, 255, 255,\n       255, 255, 255, 254, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 254, 255,\n       251, 253, 251, 245, 246, 244, 237, 239, 242, 249, 253, 253, 254,\n       252, 254, 255, 255, 254, 253, 255, 255, 255, 255, 254, 254, 253,\n       254, 252, 248, 247, 245, 241, 231, 215, 191, 178, 179, 168, 189,\n       217, 220, 220, 224, 227, 228, 232, 237, 236, 241, 240, 242, 248,\n       248, 251, 254, 255, 254, 254, 252, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       253, 255, 255], dtype=uint8), array([4.08382213])], [array([255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 253, 253, 255, 255, 255, 255, 255,\n       253, 252, 253, 248, 245, 244, 237, 235, 213, 185, 174, 176, 201,\n       231, 248, 251, 252, 253, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 254, 254, 255, 255, 255, 255, 253,\n       253, 251, 255, 253, 255, 251, 249, 246, 240, 236, 223, 213, 207,\n       199, 203, 202], dtype=uint8), array([3.69767209])], [array([253, 253, 254, 255, 252, 251, 251, 250, 253, 252, 254, 253, 255,\n       255, 255, 252, 252, 250, 243, 233, 221, 214, 211, 211, 218, 227,\n       225, 224, 219, 213, 210, 207, 202, 198, 194, 193, 191, 182, 178,\n       174, 170, 176, 184, 193, 200, 209, 216, 221, 222, 224, 224, 226,\n       226, 231, 230, 229, 232, 236, 237, 239, 242, 242, 242, 245, 243,\n       245, 246, 246, 241, 232, 217, 195, 179, 176, 189, 203, 208, 205,\n       207, 203, 202, 198, 202, 200, 204, 209, 211, 215, 217, 221, 223,\n       226, 227, 229, 233, 235, 241, 242, 241, 241, 243, 247, 247, 248,\n       249, 250, 252, 252, 254, 254, 252, 250, 250, 253, 253, 253, 254,\n       252, 253, 253], dtype=uint8), array([4.18255064])], [array([255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 253, 255, 255, 255, 255, 255, 254,\n       253, 253, 250, 255, 255, 255, 255, 255, 254, 255, 255, 255, 255,\n       252, 252, 255, 254, 251, 248, 254, 249, 247, 241, 241, 243, 241,\n       238, 233, 232, 228, 226, 221, 220, 216, 215, 211, 210, 207, 204,\n       205, 203, 195, 179, 137, 122, 135, 144, 140, 147, 178, 212, 223,\n       228, 229, 236, 240, 239, 240, 247, 246, 246, 250, 249, 253, 254,\n       251, 255, 255, 255, 255, 255, 255, 255, 255, 250, 243, 255, 255,\n       255, 255, 255, 255, 255, 254, 255, 255, 255, 255, 255, 252, 254,\n       255, 255, 255], dtype=uint8), array([9.01671984])], [array([224, 223, 222, 223, 223, 223, 227, 229, 226, 226, 226, 226, 227,\n       228, 223, 225, 223, 226, 221, 224, 223, 221, 223, 221, 222, 224,\n       219, 219, 220, 219, 219, 221, 219, 217, 218, 216, 212, 216, 216,\n       214, 216, 214, 213, 210, 196, 185, 170, 169, 171, 182, 188, 195,\n       203, 211, 212, 214, 209, 213, 212, 215, 216, 213, 203, 186, 177,\n       176, 171, 180, 207, 229, 241, 247, 248, 246, 249, 252, 248, 253,\n       253, 254, 252, 253, 254, 253, 254, 253, 255, 252, 252, 252, 251,\n       250, 252, 250, 249, 251, 251, 249, 250, 251, 253, 251, 251, 251,\n       251, 247, 253, 250, 253, 252, 251, 252, 253, 254, 251, 251, 252,\n       254, 252, 249], dtype=uint8), array([6.47364817])], [array([253, 252, 251, 253, 253, 250, 248, 250, 252, 251, 250, 249, 251,\n       254, 249, 255, 250, 250, 250, 251, 251, 250, 249, 251, 250, 250,\n       251, 251, 252, 254, 252, 250, 248, 252, 251, 251, 252, 252, 252,\n       250, 250, 253, 253, 251, 252, 252, 254, 254, 251, 252, 254, 254,\n       249, 249, 255, 253, 255, 254, 255, 254, 255, 255, 254, 252, 253,\n       255, 254, 254, 255, 254, 250, 245, 220, 201, 187, 182, 192, 207,\n       214, 218, 220, 218, 221, 222, 221, 220, 219, 222, 223, 225, 225,\n       228, 229, 231, 232, 237, 237, 239, 241, 242, 243, 244, 248, 247,\n       246, 250, 251, 251, 251, 251, 250, 251, 251, 252, 250, 252, 253,\n       251, 253, 254], dtype=uint8), array([4.51710674])], [array([255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 254, 254, 254, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 254, 251, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 254, 251, 247, 241, 230, 235,\n       241, 238, 242, 238, 245, 245, 245, 249, 246, 248, 250, 253, 254,\n       255, 255, 255, 255, 255, 255, 255, 253, 254, 255, 255, 255, 255,\n       254, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255], dtype=uint8), array([4.88037655])], [array([255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 254, 250, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 254, 253, 254, 253, 254, 251, 254, 255,\n       255, 254, 254, 253, 254, 254, 254, 254, 254, 253, 248, 249, 252,\n       252, 254, 254, 251, 255, 255, 255, 255, 254, 252, 251, 247, 249,\n       252, 253, 255, 255, 255, 255, 254, 255, 255, 255, 253, 255, 254,\n       254, 255, 255, 255, 255, 255, 255, 255, 254, 254, 255, 255, 255,\n       255, 255, 255], dtype=uint8), array([4.75318777])], [array([255, 255, 255, 255, 255, 255, 255, 255, 254, 255, 255, 255, 255,\n       255, 255, 254, 253, 252, 250, 251, 252, 249, 249, 244, 244, 243,\n       244, 241, 236, 236, 232, 228, 230, 226, 223, 225, 217, 214, 215,\n       214, 213, 212, 212, 212, 211, 212, 203, 184, 174, 182, 200, 222,\n       239, 252, 254, 253, 250, 254, 254, 253, 255, 255, 254, 253, 255,\n       255, 255, 255, 254, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 254, 254,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 253, 252, 254, 255,\n       254, 255, 252, 243, 251, 253, 254, 255, 255, 254, 255, 253, 252,\n       255, 255, 255], dtype=uint8), array([4.67930649])], [array([255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 254, 255,\n       255, 252, 255, 255, 255, 251, 253, 255, 255, 255, 255, 255, 255,\n       253, 253, 254, 254, 252, 255, 254, 254, 254, 254, 253, 250, 250,\n       253, 254, 254, 251, 251, 253, 253, 252, 254, 255, 254, 254, 254,\n       253, 250, 250, 247, 248, 246, 243, 243, 242, 244, 240, 238, 237,\n       231, 227, 215, 209, 214, 224, 231, 231, 233, 235, 238, 238, 240,\n       239, 247, 243, 245, 246, 248, 247, 251, 253, 252, 253, 253, 253,\n       255, 253, 252, 254, 254, 253, 254, 255, 255, 254, 254, 255, 255,\n       252, 255, 255, 255, 253, 254, 254, 255, 253, 254, 255, 255, 255,\n       254, 253, 255], dtype=uint8), array([3.66342182])], [array([233, 229, 233, 233, 231, 230, 231, 232, 230, 231, 232, 232, 231,\n       231, 230, 231, 232, 231, 230, 231, 234, 234, 231, 229, 233, 231,\n       231, 235, 231, 231, 235, 232, 230, 232, 232, 231, 232, 230, 231,\n       230, 232, 231, 234, 229, 230, 228, 235, 232, 231, 229, 229, 231,\n       228, 228, 230, 230, 227, 225, 226, 227, 227, 227, 226, 225, 225,\n       222, 221, 219, 216, 213, 206, 189, 164, 144, 146, 154, 142, 114,\n       101, 113, 118, 117, 119, 127, 133, 139, 141, 141, 145, 147, 150,\n       152, 159, 166, 170, 175, 181, 184, 188, 189, 191, 191, 195, 198,\n       204, 206, 207, 210, 214, 216, 215, 219, 220, 222, 223, 222, 224,\n       228, 229, 231], dtype=uint8), array([11.24816955])], [array([242, 240, 240, 243, 243, 243, 236, 235, 235, 236, 238, 239, 239,\n       238, 239, 237, 236, 233, 231, 229, 230, 226, 227, 224, 221, 219,\n       217, 213, 213, 211, 209, 210, 206, 202, 200, 199, 199, 199, 197,\n       195, 198, 198, 199, 202, 205, 209, 209, 205, 198, 178, 161, 163,\n       179, 204, 222, 235, 244, 248, 243, 243, 242, 244, 241, 238, 240,\n       240, 240, 241, 241, 241, 240, 238, 237, 239, 241, 242, 239, 237,\n       236, 237, 237, 234, 238, 237, 237, 235, 234, 235, 236, 236, 233,\n       234, 235, 233, 234, 233, 233, 234, 236, 235, 233, 234, 233, 231,\n       235, 234, 236, 238, 240, 235, 233, 235, 235, 234, 233, 234, 236,\n       232, 234, 237], dtype=uint8), array([5.29607184])], [array([239, 239, 243, 239, 240, 241, 239, 236, 237, 238, 238, 238, 240,\n       239, 237, 236, 236, 233, 235, 231, 236, 235, 234, 234, 230, 231,\n       229, 225, 226, 226, 219, 217, 216, 213, 209, 206, 204, 202, 200,\n       195, 193, 191, 189, 187, 187, 189, 189, 189, 188, 189, 186, 178,\n       164, 155, 165, 183, 203, 221, 239, 243, 247, 243, 244, 246, 242,\n       242, 242, 241, 243, 243, 242, 242, 241, 239, 241, 242, 238, 240,\n       240, 238, 238, 241, 236, 239, 241, 238, 237, 237, 237, 236, 235,\n       235, 234, 235, 233, 230, 230, 229, 232, 230, 229, 227, 228, 229,\n       227, 227, 228, 226, 227, 228, 228, 233, 232, 233, 236, 236, 235,\n       236, 234, 233], dtype=uint8), array([5.46791157])], [array([237, 242, 240, 239, 238, 237, 235, 239, 240, 240, 240, 242, 241,\n       241, 238, 239, 238, 239, 237, 238, 235, 233, 233, 230, 231, 227,\n       225, 226, 222, 222, 220, 218, 216, 215, 213, 210, 209, 206, 204,\n       204, 201, 197, 194, 193, 192, 188, 190, 187, 185, 188, 192, 196,\n       197, 197, 193, 183, 169, 167, 182, 201, 215, 222, 239, 244, 240,\n       241, 240, 242, 243, 245, 242, 243, 241, 240, 239, 239, 241, 240,\n       240, 239, 237, 239, 240, 240, 240, 243, 237, 238, 241, 241, 240,\n       242, 239, 241, 239, 239, 238, 241, 240, 240, 242, 240, 239, 241,\n       238, 240, 238, 239, 241, 243, 238, 241, 239, 239, 237, 240, 240,\n       236, 236, 227], dtype=uint8), array([5.45620238])], [array([255, 255, 254, 255, 255, 255, 255, 248, 249, 255, 255, 255, 255,\n       254, 255, 255, 254, 254, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       254, 254, 254, 253, 254, 254, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 254,\n       254, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255], dtype=uint8), array([0.])], [array([229, 237, 245, 246, 252, 255, 253, 254, 255, 254, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       254, 252, 255, 255, 255, 255, 255, 255, 255, 255, 254, 255, 255,\n       255, 253, 254, 248, 236, 204, 174, 169, 164, 151, 129, 107, 107,\n       123, 127, 126, 135, 148, 159, 163, 167, 172, 178, 189, 194, 199,\n       198, 206, 209, 211, 216, 227, 231, 232, 237, 240, 244, 247, 250,\n       249, 253, 250, 254, 254, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255], dtype=uint8), array([11.65322989])], [array([255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 253, 250,\n       245, 239, 232, 231, 212, 201, 183, 151, 151, 169, 173, 162, 144,\n       135, 143, 158, 174, 185, 187, 191, 197, 200, 206, 212, 217, 222,\n       228, 227, 236, 237, 238, 242, 243, 248, 251, 253, 253, 255, 255,\n       254, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255], dtype=uint8), array([11.24816955])], [array([255, 255, 255, 255, 255, 255, 255, 253, 254, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 254, 254, 254, 254,\n       253, 247, 244, 244, 240, 234, 228, 217, 201, 188, 172, 164, 167,\n       165, 156, 138, 130, 141, 171, 205, 233, 244, 252, 254, 255, 254,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 248, 254, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255], dtype=uint8), array([5.29607184])], [array([255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 254, 249, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 248, 236,\n       218, 200, 184, 170, 183, 205, 215, 217, 221, 224, 225, 229, 234,\n       236, 241, 246, 248, 251, 253, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 254, 254, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255], dtype=uint8), array([5.46791157])], [array([255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 253, 239, 215, 193, 169, 153, 152, 172, 194, 204, 207, 211,\n       212, 212, 218, 225, 233, 238, 238, 243, 251, 249, 254, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255], dtype=uint8), array([5.45620238])], [array([255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 253, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255], dtype=uint8), array([3.54463004])], [array([243, 240, 236, 237, 240, 243, 239, 244, 248, 246, 247, 244, 239,\n       241, 249, 251, 251, 249, 246, 246, 243, 239, 245, 246, 243, 244,\n       242, 241, 242, 242, 247, 245, 246, 250, 245, 246, 247, 246, 243,\n       249, 244, 250, 249, 248, 247, 244, 244, 246, 242, 244, 245, 245,\n       241, 238, 238, 237, 235, 233, 231, 226, 222, 221, 217, 214, 210,\n       205, 203, 199, 195, 191, 189, 186, 186, 188, 186, 178, 157, 138,\n       150, 177, 208, 233, 246, 246, 250, 247, 248, 250, 248, 248, 246,\n       244, 246, 243, 242, 241, 239, 239, 243, 240, 239, 242, 240, 236,\n       236, 238, 237, 236, 235, 234, 235, 233, 232, 229, 230, 233, 230,\n       228, 228, 224], dtype=uint8), array([4.51179147])], [array([253, 254, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 252, 255, 255, 255, 255, 255, 255, 255, 253, 255, 255, 255,\n       255, 255, 253, 253, 254, 254, 252, 253, 250, 251, 248, 247, 248,\n       241, 243, 241, 239, 239, 238, 239, 241, 238, 233, 233, 231, 229,\n       230, 233, 230, 230, 229, 229, 225, 220, 215, 204, 195, 196, 204,\n       224, 247, 254, 255, 255, 255, 255, 255, 255, 255, 254, 251, 251,\n       252, 252, 253, 251, 251, 250, 249, 247, 246, 249, 250, 247, 247,\n       245, 245, 246, 244, 244, 244, 243, 240, 240, 241, 242, 241, 240,\n       241, 239, 238, 240, 244, 245, 243, 244, 248, 246, 246, 244, 242,\n       244, 246, 246], dtype=uint8), array([4.37560143])], [array([254, 255, 255, 249, 254, 255, 255, 253, 254, 254, 252, 250, 251,\n       250, 250, 251, 252, 254, 255, 254, 252, 251, 252, 253, 254, 253,\n       253, 249, 252, 255, 254, 252, 252, 252, 249, 249, 248, 249, 248,\n       248, 248, 248, 250, 247, 246, 246, 245, 251, 247, 244, 244, 243,\n       240, 240, 240, 239, 237, 233, 233, 227, 227, 225, 226, 221, 217,\n       216, 213, 209, 206, 200, 200, 207, 209, 205, 202, 194, 168, 149,\n       163, 190, 215, 231, 244, 253, 253, 248, 250, 248, 247, 247, 249,\n       249, 245, 244, 244, 241, 239, 237, 238, 236, 240, 235, 237, 237,\n       238, 241, 237, 237, 240, 239, 236, 237, 238, 237, 238, 238, 242,\n       237, 238, 240], dtype=uint8), array([3.95002995])], [array([243, 246, 246, 243, 242, 241, 244, 243, 243, 243, 244, 246, 245,\n       242, 243, 241, 241, 239, 240, 239, 241, 237, 241, 240, 240, 241,\n       240, 243, 242, 240, 240, 243, 242, 240, 242, 242, 237, 241, 246,\n       242, 241, 242, 240, 240, 239, 241, 237, 239, 241, 238, 237, 238,\n       237, 235, 236, 235, 234, 229, 225, 224, 220, 216, 214, 215, 212,\n       212, 213, 207, 203, 200, 197, 197, 195, 193, 178, 166, 172, 199,\n       227, 241, 245, 245, 248, 249, 245, 246, 244, 242, 241, 239, 234,\n       231, 227, 226, 224, 217, 214, 213, 210, 210, 210, 211, 212, 217,\n       222, 226, 230, 231, 230, 230, 231, 231, 225, 226, 228, 224, 222,\n       223, 226, 223], dtype=uint8), array([3.53048839])], [array([215, 212, 212, 211, 212, 210, 206, 205, 202, 205, 204, 199, 199,\n       198, 195, 198, 199, 199, 194, 196, 188, 182, 180, 178, 181, 181,\n       179, 177, 179, 182, 184, 185, 186, 182, 178, 175, 185, 197, 207,\n       209, 212, 216, 215, 211, 210, 206, 204, 202, 201, 206, 210, 212,\n       215, 219, 218, 220, 217, 217, 212, 213, 208, 196, 178, 168, 176,\n       202, 229, 245, 250, 252, 249, 251, 249, 248, 248, 247, 247, 246,\n       248, 247, 244, 244, 244, 247, 243, 241, 241, 242, 243, 246, 246,\n       246, 247, 244, 240, 240, 237, 238, 239, 238, 240, 240, 238, 241,\n       242, 246, 245, 236, 232, 232, 232, 228, 210, 195, 183, 197, 213,\n       228, 234, 234], dtype=uint8), array([3.67640104])], [array([237, 238, 236, 240, 235, 236, 233, 232, 233, 236, 238, 233, 235,\n       235, 235, 234, 234, 233, 234, 234, 238, 236, 235, 236, 238, 237,\n       236, 236, 235, 234, 237, 232, 230, 230, 232, 229, 229, 228, 228,\n       225, 224, 219, 216, 211, 210, 207, 208, 202, 194, 191, 184, 181,\n       179, 172, 170, 166, 163, 162, 159, 150, 143, 136, 131, 127, 124,\n       117, 109, 109, 118, 132, 146, 168, 184, 191, 200, 221, 246, 254,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 254, 255, 252, 249,\n       252, 249, 246, 248, 241, 239, 241, 237, 234, 231, 226, 231, 232,\n       228, 230, 229, 227, 225, 224, 226, 228, 226, 227, 224, 225, 224,\n       226, 222, 225], dtype=uint8), array([8.97995119])], [array([243, 243, 246, 242, 242, 239, 241, 238, 236, 240, 241, 238, 234,\n       235, 233, 239, 237, 233, 238, 235, 235, 229, 232, 230, 231, 232,\n       231, 229, 231, 232, 228, 228, 226, 228, 233, 227, 227, 228, 227,\n       227, 231, 232, 227, 227, 226, 224, 219, 214, 200, 180, 162, 148,\n       137, 154, 179, 193, 199, 202, 204, 207, 209, 211, 214, 213, 213,\n       217, 219, 224, 223, 226, 230, 224, 226, 228, 233, 231, 229, 230,\n       229, 229, 231, 233, 230, 229, 231, 231, 232, 234, 229, 232, 233,\n       232, 232, 232, 232, 232, 233, 231, 231, 232, 230, 233, 231, 231,\n       231, 232, 230, 232, 232, 233, 235, 231, 228, 230, 231, 229, 230,\n       232, 231, 228], dtype=uint8), array([5.35827466])], [array([237, 239, 240, 239, 235, 241, 243, 242, 244, 246, 244, 245, 247,\n       247, 245, 246, 246, 247, 248, 248, 246, 248, 250, 247, 248, 249,\n       248, 244, 246, 248, 249, 249, 249, 249, 245, 241, 234, 235, 235,\n       236, 237, 236, 240, 242, 244, 242, 244, 245, 246, 250, 250, 249,\n       251, 249, 249, 249, 249, 250, 248, 249, 251, 245, 244, 241, 237,\n       237, 235, 236, 224, 203, 178, 170, 184, 185, 174, 163, 150, 148,\n       150, 156, 161, 164, 167, 171, 170, 174, 177, 178, 178, 182, 184,\n       186, 188, 189, 192, 190, 191, 195, 194, 195, 199, 198, 199, 199,\n       197, 196, 196, 198, 203, 202, 200, 200, 200, 201, 203, 205, 203,\n       205, 203, 203], dtype=uint8), array([8.97995119])], [array([198, 198, 203, 201, 204, 206, 206, 205, 209, 209, 210, 212, 213,\n       213, 212, 213, 213, 212, 209, 214, 212, 211, 212, 213, 214, 212,\n       209, 207, 207, 209, 207, 201, 203, 204, 201, 198, 196, 197, 197,\n       196, 196, 199, 198, 197, 199, 198, 195, 178, 155, 155, 171, 186,\n       202, 224, 242, 252, 251, 251, 248, 250, 250, 253, 248, 246, 247,\n       247, 248, 247, 246, 243, 243, 246, 246, 244, 245, 246, 245, 245,\n       246, 247, 246, 246, 243, 242, 243, 243, 245, 245, 243, 245, 241,\n       245, 244, 244, 246, 244, 244, 247, 248, 246, 248, 245, 247, 246,\n       244, 244, 242, 242, 244, 243, 238, 238, 239, 236, 221, 203, 194,\n       196, 208, 226], dtype=uint8), array([5.35827466])], [array([247, 252, 253, 255, 255, 251, 252, 253, 251, 249, 251, 252, 251,\n       251, 254, 253, 250, 252, 252, 253, 251, 248, 253, 251, 250, 250,\n       250, 247, 248, 249, 250, 251, 251, 250, 249, 249, 249, 250, 253,\n       249, 245, 247, 248, 249, 248, 245, 246, 246, 247, 244, 246, 245,\n       244, 247, 245, 244, 244, 244, 241, 237, 237, 240, 238, 238, 242,\n       238, 240, 241, 240, 240, 237, 237, 234, 229, 218, 199, 184, 179,\n       183, 202, 207, 206, 208, 206, 203, 201, 202, 201, 203, 202, 202,\n       203, 202, 203, 203, 202, 201, 198, 199, 201, 201, 201, 199, 198,\n       198, 198, 196, 198, 197, 194, 195, 195, 195, 194, 198, 195, 196,\n       198, 195, 194], dtype=uint8), array([3.76287851])], [array([255, 255, 255, 254, 254, 255, 254, 253, 253, 254, 252, 255, 255,\n       255, 255, 255, 255, 254, 253, 254, 255, 255, 255, 255, 255, 254,\n       252, 247, 243, 244, 247, 243, 246, 248, 248, 245, 242, 242, 243,\n       237, 229, 227, 229, 234, 239, 245, 245, 244, 247, 246, 250, 250,\n       251, 254, 253, 253, 255, 255, 254, 254, 253, 254, 254, 255, 255,\n       253, 255, 255, 255, 255, 255, 253, 252, 242, 235, 237, 242, 241,\n       239, 234, 237, 237, 235, 238, 236, 238, 239, 239, 240, 243, 247,\n       248, 246, 249, 251, 250, 252, 248, 246, 255, 255, 255, 255, 253,\n       254, 252, 253, 254, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255], dtype=uint8), array([3.04808728])], [array([251, 251, 254, 254, 255, 255, 255, 254, 253, 255, 255, 255, 254,\n       253, 255, 255, 255, 255, 255, 255, 255, 255, 255, 254, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 254, 248, 251, 246, 235, 212, 201, 195, 195,\n       214, 221, 224, 228, 225, 229, 229, 227, 229, 231, 233, 233, 233,\n       232, 230, 237, 235, 234, 237, 238, 239, 238, 240, 239, 240, 238,\n       241, 241, 240, 242, 241, 242, 238, 236, 237, 233, 231, 234, 232,\n       228, 230, 227], dtype=uint8), array([3.04562947])], [array([255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 254, 255, 254, 252, 247, 238, 220, 190, 178, 192, 218, 237,\n       246, 251, 253, 255, 254, 251, 250, 251, 249, 247, 248, 249, 245,\n       246, 244, 243, 241, 244, 241, 240, 238, 237, 239, 240, 238, 238,\n       238, 239, 236, 232, 232, 229, 224, 224, 210, 204, 198, 186, 171,\n       152, 136, 132], dtype=uint8), array([3.06895321])], [array([255, 255, 255, 255, 254, 251, 255, 255, 254, 253, 255, 253, 252,\n       247, 243, 237, 232, 222, 209, 190, 176, 169, 165, 171, 176, 183,\n       185, 181, 177, 183, 192, 210, 219, 227, 229, 238, 242, 244, 245,\n       246, 245, 246, 249, 250, 250, 252, 251, 250, 249, 240, 239, 233,\n       222, 211, 211, 223, 237, 248, 252, 254, 255, 254, 253, 254, 253,\n       254, 255, 253, 252, 255, 254, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255, 255,\n       254, 255, 255, 255, 255, 255, 254, 250, 247, 246, 242, 246, 242,\n       237, 234, 234], dtype=uint8), array([2.85702873])], [array([233, 234, 235, 233, 233, 235, 234, 234, 236, 236, 236, 233, 236,\n       236, 235, 233, 233, 233, 235, 236, 234, 231, 234, 233, 234, 236,\n       234, 232, 239, 234, 233, 235, 235, 238, 233, 234, 232, 230, 228,\n       234, 235, 232, 237, 235, 234, 236, 237, 240, 242, 235, 233, 233,\n       233, 233, 232, 234, 233, 237, 235, 234, 235, 234, 236, 239, 237,\n       237, 241, 241, 240, 241, 243, 245, 245, 246, 248, 248, 248, 247,\n       239, 226, 204, 182, 176, 188, 196, 200, 201, 204, 201, 199, 198,\n       197, 196, 197, 197, 200, 200, 205, 208, 208, 210, 212, 215, 214,\n       219, 223, 225, 227, 227, 229, 233, 235, 234, 238, 232, 235, 236,\n       237, 236, 238], dtype=uint8), array([4.51179147])], [array([251, 251, 252, 253, 254, 254, 251, 248, 247, 247, 246, 244, 242,\n       239, 236, 233, 228, 226, 227, 225, 223, 224, 221, 219, 213, 207,\n       206, 197, 190, 179, 169, 162, 166, 168, 173, 181, 184, 189, 195,\n       199, 196, 198, 201, 199, 200, 206, 207, 208, 204, 209, 209, 210,\n       211, 211, 209, 210, 211, 207, 204, 189, 166, 155, 155, 159, 170,\n       189, 194, 193, 191, 190, 188, 188, 188, 185, 187, 187, 187, 187,\n       190, 193, 192, 192, 195, 196, 197, 198, 200, 204, 207, 207, 209,\n       214, 217, 215, 216, 216, 216, 218, 220, 224, 225, 223, 223, 225,\n       230, 229, 230, 230, 231, 230, 234, 234, 234, 234, 234, 233, 237,\n       234, 237, 235], dtype=uint8), array([4.37560143])], [array([204, 200, 197, 196, 192, 192, 189, 188, 186, 186, 186, 187, 186,\n       190, 189, 191, 193, 193, 193, 193, 196, 193, 195, 197, 195, 197,\n       201, 201, 204, 206, 206, 205, 207, 207, 205, 205, 210, 210, 211,\n       211, 215, 217, 219, 217, 218, 221, 222, 223, 221, 222, 225, 226,\n       227, 227, 223, 225, 226, 222, 231, 228, 230, 229, 228, 233, 235,\n       237, 237, 237, 239, 240, 242, 243, 246, 246, 247, 248, 245, 242,\n       232, 215, 190, 170, 167, 183, 193, 198, 202, 202, 200, 199, 201,\n       202, 203, 206, 208, 210, 213, 216, 218, 219, 225, 226, 230, 232,\n       232, 237, 237, 239, 243, 242, 243, 244, 243, 244, 245, 245, 244,\n       243, 244, 246], dtype=uint8), array([3.95002995])], [array([228, 227, 227, 228, 232, 235, 236, 237, 238, 238, 241, 241, 240,\n       239, 243, 243, 245, 244, 244, 245, 246, 248, 249, 246, 250, 250,\n       247, 248, 244, 246, 251, 249, 245, 248, 246, 249, 251, 248, 249,\n       250, 251, 248, 247, 252, 253, 251, 247, 250, 249, 247, 246, 248,\n       252, 251, 249, 249, 252, 247, 252, 255, 253, 250, 251, 248, 248,\n       244, 246, 247, 249, 251, 253, 248, 252, 253, 253, 249, 243, 235,\n       222, 212, 212, 222, 226, 229, 226, 228, 225, 223, 225, 224, 221,\n       224, 224, 229, 227, 231, 236, 237, 239, 242, 243, 243, 246, 250,\n       240, 240, 237, 237, 232, 228, 231, 233, 235, 235, 236, 237, 236,\n       238, 235, 235], dtype=uint8), array([3.53048839])], [array([253, 251, 253, 253, 251, 254, 255, 255, 255, 254, 255, 255, 255,\n       255, 255, 255, 253, 254, 252, 251, 249, 245, 246, 249, 247, 247,\n       252, 251, 249, 246, 246, 248, 248, 241, 244, 246, 250, 251, 251,\n       253, 253, 251, 252, 253, 255, 255, 255, 255, 255, 255, 255, 255,\n       255, 255, 255, 254, 254, 253, 250, 247, 240, 233, 221, 211, 198,\n       202, 219, 229, 232, 236, 238, 238, 238, 237, 240, 242, 243, 246,\n       245, 242, 240, 240, 241, 241, 240, 243, 242, 240, 238, 239, 241,\n       242, 239, 239, 235, 227, 224, 223, 228, 232, 233, 231, 234, 239,\n       239, 240, 244, 242, 247, 248, 249, 250, 247, 248, 251, 249, 248,\n       249, 251, 251], dtype=uint8), array([3.67640104])], [array([248, 248, 247, 247, 247, 246, 242, 242, 245, 246, 245, 240, 243,\n       245, 240, 240, 239, 238, 239, 242, 240, 239, 241, 240, 237, 239,\n       240, 236, 239, 239, 238, 235, 236, 236, 238, 239, 237, 238, 235,\n       234, 230, 231, 228, 232, 230, 232, 231, 228, 229, 230, 228, 230,\n       229, 227, 228, 227, 226, 224, 227, 223, 202, 172, 163, 166, 171,\n       192, 214, 219, 219, 222, 220, 222, 221, 226, 230, 234, 233, 233,\n       239, 237, 236, 232, 230, 223, 219, 223, 228, 235, 239, 242, 243,\n       246, 248, 250, 249, 249, 247, 245, 245, 246, 246, 241, 242, 245,\n       248, 245, 248, 249, 249, 251, 251, 248, 250, 249, 247, 249, 250,\n       248, 244, 249], dtype=uint8), array([5.21064103])]] with type list",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [210]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m both_path \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_tensor_slices\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcouple\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcouple\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_feature\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_feature\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_label\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py:793\u001b[0m, in \u001b[0;36mDatasetV2.from_tensor_slices\u001b[0;34m(tensors, name)\u001b[0m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_tensor_slices\u001b[39m(tensors, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    717\u001b[0m   \u001b[38;5;124;03m\"\"\"Creates a `Dataset` whose elements are slices of the given tensors.\u001b[39;00m\n\u001b[1;32m    718\u001b[0m \n\u001b[1;32m    719\u001b[0m \u001b[38;5;124;03m  The given tensors are sliced along their first dimension. This operation\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    791\u001b[0m \u001b[38;5;124;03m    Dataset: A `Dataset`.\u001b[39;00m\n\u001b[1;32m    792\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 793\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mTensorSliceDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py:4477\u001b[0m, in \u001b[0;36mTensorSliceDataset.__init__\u001b[0;34m(self, element, is_files, name)\u001b[0m\n\u001b[1;32m   4475\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, element, is_files\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   4476\u001b[0m   \u001b[38;5;124;03m\"\"\"See `Dataset.from_tensor_slices()` for details.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 4477\u001b[0m   element \u001b[38;5;241m=\u001b[39m \u001b[43mstructure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43melement\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4478\u001b[0m   batched_spec \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mtype_spec_from_value(element)\n\u001b[1;32m   4479\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tensors \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mto_batched_tensor_list(batched_spec, element)\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/data/util/structure.py:107\u001b[0m, in \u001b[0;36mnormalize_element\u001b[0;34m(element, element_signature)\u001b[0m\n\u001b[1;32m    102\u001b[0m     spec \u001b[38;5;241m=\u001b[39m type_spec_from_value(t, use_fallback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    104\u001b[0m   \u001b[38;5;66;03m# TypeError indicates it was not possible to compute a `TypeSpec` for\u001b[39;00m\n\u001b[1;32m    105\u001b[0m   \u001b[38;5;66;03m# the value. As a fallback try converting the value to a tensor.\u001b[39;00m\n\u001b[1;32m    106\u001b[0m   normalized_components\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 107\u001b[0m       \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcomponent_\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    109\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(spec, sparse_tensor\u001b[38;5;241m.\u001b[39mSparseTensorSpec):\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/profiler/trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m Trace(trace_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrace_kwargs):\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1695\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconvert_to_tensor did not convert to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1691\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe preferred dtype: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m vs \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1692\u001b[0m                       (ret\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mbase_dtype, preferred_dtype\u001b[38;5;241m.\u001b[39mbase_dtype))\n\u001b[1;32m   1694\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1695\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mconversion_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1697\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m   1698\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py:343\u001b[0m, in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_tensor_conversion_function\u001b[39m(v, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    341\u001b[0m                                          as_ref\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    342\u001b[0m   _ \u001b[38;5;241m=\u001b[39m as_ref\n\u001b[0;32m--> 343\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py:267\u001b[0m, in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconstant\u001b[39m(value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConst\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    172\u001b[0m   \u001b[38;5;124;03m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \n\u001b[1;32m    174\u001b[0m \u001b[38;5;124;03m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;124;03m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mallow_broadcast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py:279\u001b[0m, in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.constant\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    278\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[0;32m--> 279\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_eager_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    281\u001b[0m g \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mget_default_graph()\n\u001b[1;32m    282\u001b[0m tensor_value \u001b[38;5;241m=\u001b[39m attr_value_pb2\u001b[38;5;241m.\u001b[39mAttrValue()\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py:304\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_eager_impl\u001b[39m(ctx, value, dtype, shape, verify_shape):\n\u001b[1;32m    303\u001b[0m   \u001b[38;5;124;03m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 304\u001b[0m   t \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_eager_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    101\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: Can't convert non-rectangular Python sequence to Tensor."
     ]
    }
   ],
   "source": [
    "both_path = tf.data.Dataset.from_tensor_slices(\n",
    "    [\n",
    "        list(couple)\n",
    "        for couple in zip(\n",
    "            [np.array(train_feature[i, :]) for i in range(len(train_feature))],\n",
    "            train_label,\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "b7a02141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(527, 120)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "75695e35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([527, 80, 1])"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_augmentation(train_feature).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "9e848b4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([527, 80, 1])"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_augmentation(train_feature).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "50a9c35a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "in user code:\n\n    File \"/tmp/ipykernel_21812/3081659417.py\", line 2, in None  *\n        lambda x: np.expand_dims(x, 0)\n    File \"<__array_function__ internals>\", line 180, in expand_dims  **\n        \n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/numpy/lib/shape_base.py\", line 591, in expand_dims\n        a = asanyarray(a)\n\n    NotImplementedError: Cannot convert a symbolic Tensor (args_0:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [230]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m d1 \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mfrom_tensor_slices(train_feature)\n\u001b[0;32m----> 2\u001b[0m d1_ \u001b[38;5;241m=\u001b[39m \u001b[43md1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand_dims\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py:2016\u001b[0m, in \u001b[0;36mDatasetV2.map\u001b[0;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m   2013\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m deterministic \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m DEBUG_MODE:\n\u001b[1;32m   2014\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `deterministic` argument has no effect unless the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2015\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`num_parallel_calls` argument is specified.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2016\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mMapDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreserve_cardinality\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2017\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2018\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m ParallelMapDataset(\n\u001b[1;32m   2019\u001b[0m       \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2020\u001b[0m       map_func,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2023\u001b[0m       preserve_cardinality\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   2024\u001b[0m       name\u001b[38;5;241m=\u001b[39mname)\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py:5191\u001b[0m, in \u001b[0;36mMapDataset.__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[1;32m   5189\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_inter_op_parallelism \u001b[38;5;241m=\u001b[39m use_inter_op_parallelism\n\u001b[1;32m   5190\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preserve_cardinality \u001b[38;5;241m=\u001b[39m preserve_cardinality\n\u001b[0;32m-> 5191\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func \u001b[38;5;241m=\u001b[39m \u001b[43mstructured_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStructuredFunctionWrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5193\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transformation_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5194\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5195\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_legacy_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_legacy_function\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5196\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata \u001b[38;5;241m=\u001b[39m dataset_metadata_pb2\u001b[38;5;241m.\u001b[39mMetadata()\n\u001b[1;32m   5197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name:\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/data/ops/structured_function.py:271\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m    264\u001b[0m       warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    265\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    266\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    267\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    268\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    269\u001b[0m     fn_factory \u001b[38;5;241m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[0;32m--> 271\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function \u001b[38;5;241m=\u001b[39m \u001b[43mfn_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;66;03m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[1;32m    273\u001b[0m add_to_graph \u001b[38;5;241m&\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly()\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3070\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_concrete_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   3062\u001b[0m   \u001b[38;5;124;03m\"\"\"Returns a `ConcreteFunction` specialized to inputs and execution context.\u001b[39;00m\n\u001b[1;32m   3063\u001b[0m \n\u001b[1;32m   3064\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3068\u001b[0m \u001b[38;5;124;03m       or `tf.Tensor` or `tf.TensorSpec`.\u001b[39;00m\n\u001b[1;32m   3069\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3070\u001b[0m   graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3071\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3072\u001b[0m   graph_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   3073\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3036\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3034\u001b[0m   args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3035\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m-> 3036\u001b[0m   graph_function, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3037\u001b[0m   seen_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[1;32m   3038\u001b[0m   captured \u001b[38;5;241m=\u001b[39m object_identity\u001b[38;5;241m.\u001b[39mObjectIdentitySet(\n\u001b[1;32m   3039\u001b[0m       graph_function\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39minternal_captures)\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3292\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3288\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_define_function_with_shape_relaxation(\n\u001b[1;32m   3289\u001b[0m       args, kwargs, flat_args, filtered_flat_args)\n\u001b[1;32m   3291\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39madd_call_context(cache_key\u001b[38;5;241m.\u001b[39mcall_context)\n\u001b[0;32m-> 3292\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_graph_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3293\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39madd(cache_key, cache_key_deletion_observer,\n\u001b[1;32m   3294\u001b[0m                          graph_function)\n\u001b[1;32m   3296\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function, filtered_flat_args\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3130\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3125\u001b[0m missing_arg_names \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   3126\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (arg, i) \u001b[38;5;28;01mfor\u001b[39;00m i, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(missing_arg_names)\n\u001b[1;32m   3127\u001b[0m ]\n\u001b[1;32m   3128\u001b[0m arg_names \u001b[38;5;241m=\u001b[39m base_arg_names \u001b[38;5;241m+\u001b[39m missing_arg_names\n\u001b[1;32m   3129\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m ConcreteFunction(\n\u001b[0;32m-> 3130\u001b[0m     \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3131\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3132\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3133\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3134\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3135\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3136\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3137\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3138\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3139\u001b[0m \u001b[43m        \u001b[49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3140\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_by_value\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   3141\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_attributes,\n\u001b[1;32m   3142\u001b[0m     function_spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_spec,\n\u001b[1;32m   3143\u001b[0m     \u001b[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[1;32m   3144\u001b[0m     \u001b[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[1;32m   3145\u001b[0m     \u001b[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[1;32m   3146\u001b[0m     \u001b[38;5;66;03m# ConcreteFunction.\u001b[39;00m\n\u001b[1;32m   3147\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   3148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:1161\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1158\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1159\u001b[0m   _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1161\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1163\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1165\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mmap_structure(convert, func_outputs,\n\u001b[1;32m   1166\u001b[0m                                   expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/data/ops/structured_function.py:248\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;129m@eager_function\u001b[39m\u001b[38;5;241m.\u001b[39mdefun_with_attributes(\n\u001b[1;32m    243\u001b[0m     input_signature\u001b[38;5;241m=\u001b[39mstructure\u001b[38;5;241m.\u001b[39mget_flat_tensor_specs(\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_structure),\n\u001b[1;32m    245\u001b[0m     autograph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    246\u001b[0m     attributes\u001b[38;5;241m=\u001b[39mdefun_kwargs)\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_fn\u001b[39m(\u001b[38;5;241m*\u001b[39margs):  \u001b[38;5;66;03m# pylint: disable=missing-docstring\u001b[39;00m\n\u001b[0;32m--> 248\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mwrapper_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    249\u001b[0m   ret \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mto_tensor_list(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_structure, ret)\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m [ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m ret]\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/data/ops/structured_function.py:177\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _should_unpack(nested_args):\n\u001b[1;32m    176\u001b[0m   nested_args \u001b[38;5;241m=\u001b[39m (nested_args,)\n\u001b[0;32m--> 177\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mautograph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtf_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag_ctx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnested_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _should_pack(ret):\n\u001b[1;32m    179\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(ret)\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:692\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    691\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 692\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[1;32m    693\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    694\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: in user code:\n\n    File \"/tmp/ipykernel_21812/3081659417.py\", line 2, in None  *\n        lambda x: np.expand_dims(x, 0)\n    File \"<__array_function__ internals>\", line 180, in expand_dims  **\n        \n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/numpy/lib/shape_base.py\", line 591, in expand_dims\n        a = asanyarray(a)\n\n    NotImplementedError: Cannot convert a symbolic Tensor (args_0:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported\n"
     ]
    }
   ],
   "source": [
    "d1 = tf.data.Dataset.from_tensor_slices(train_feature)\n",
    "d1_ = d1.map(lambda x: np.expand_dims(x, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "9d83d58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 = tf.data.Dataset.from_tensor_slices(train_label)\n",
    "d3 = tf.data.Dataset.zip((d1, d2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "910f3881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 120, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 120, 1), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\"), but it was called on an input with incompatible shape (120,).\n",
      "2022-08-16 18:05:48,465-[WARNING]- tensorflow:665 -> Model was constructed with shape (None, 120, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 120, 1), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\"), but it was called on an input with incompatible shape (120,).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/tmp/ipykernel_21812/1607789451.py\", line 2, in None  *\n        lambda x, y: (data_augmentation(x, training=True), y)\n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/felix/Wks/AMFtrack/amftrack/ml/width/data_augmentation.py\", line 80, in <lambda>\n        lambda x: random_crop_slice(x, original_size, input_size, offset),\n\n    ValueError: Exception encountered when calling layer \"random_crop_with_offset_0\" (type Lambda).\n    \n    in user code:\n    \n        File \"/home/felix/Wks/AMFtrack/amftrack/ml/width/data_augmentation.py\", line 74, in random_crop_slice  *\n            return x[..., start_index : start_index + input_size, :]\n    \n        ValueError: Index out of range using input dim 1; input has only 1 dims for '{{node strided_slice}} = StridedSlice[Index=DT_INT64, T=DT_FLOAT, begin_mask=4, ellipsis_mask=1, end_mask=4, new_axis_mask=0, shrink_axis_mask=0](x, strided_slice/stack, strided_slice/stack_1, strided_slice/Cast)' with input shapes: [120], [3], [3], [3] and with computed input tensors: input[3] = <1 1 1>.\n    \n    \n    Call arguments received:\n      â¢ inputs=tf.Tensor(shape=(120,), dtype=float32)\n      â¢ mask=None\n      â¢ training=True\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [225]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m train \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m----> 2\u001b[0m     \u001b[43md3\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_augmentation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;241m.\u001b[39munbatch()\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;241m.\u001b[39mbatch(BATCHSIZE)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;241m.\u001b[39mprefetch(tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mAUTOTUNE)\n\u001b[1;32m      6\u001b[0m )\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py:2016\u001b[0m, in \u001b[0;36mDatasetV2.map\u001b[0;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m   2013\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m deterministic \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m DEBUG_MODE:\n\u001b[1;32m   2014\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `deterministic` argument has no effect unless the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2015\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`num_parallel_calls` argument is specified.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2016\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mMapDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreserve_cardinality\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2017\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2018\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m ParallelMapDataset(\n\u001b[1;32m   2019\u001b[0m       \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2020\u001b[0m       map_func,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2023\u001b[0m       preserve_cardinality\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   2024\u001b[0m       name\u001b[38;5;241m=\u001b[39mname)\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py:5191\u001b[0m, in \u001b[0;36mMapDataset.__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[1;32m   5189\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_inter_op_parallelism \u001b[38;5;241m=\u001b[39m use_inter_op_parallelism\n\u001b[1;32m   5190\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preserve_cardinality \u001b[38;5;241m=\u001b[39m preserve_cardinality\n\u001b[0;32m-> 5191\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func \u001b[38;5;241m=\u001b[39m \u001b[43mstructured_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStructuredFunctionWrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5193\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transformation_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5194\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5195\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_legacy_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_legacy_function\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5196\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata \u001b[38;5;241m=\u001b[39m dataset_metadata_pb2\u001b[38;5;241m.\u001b[39mMetadata()\n\u001b[1;32m   5197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name:\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/data/ops/structured_function.py:271\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m    264\u001b[0m       warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    265\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    266\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    267\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    268\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    269\u001b[0m     fn_factory \u001b[38;5;241m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[0;32m--> 271\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function \u001b[38;5;241m=\u001b[39m \u001b[43mfn_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;66;03m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[1;32m    273\u001b[0m add_to_graph \u001b[38;5;241m&\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly()\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3070\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_concrete_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   3062\u001b[0m   \u001b[38;5;124;03m\"\"\"Returns a `ConcreteFunction` specialized to inputs and execution context.\u001b[39;00m\n\u001b[1;32m   3063\u001b[0m \n\u001b[1;32m   3064\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3068\u001b[0m \u001b[38;5;124;03m       or `tf.Tensor` or `tf.TensorSpec`.\u001b[39;00m\n\u001b[1;32m   3069\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3070\u001b[0m   graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3071\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3072\u001b[0m   graph_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   3073\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3036\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3034\u001b[0m   args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3035\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m-> 3036\u001b[0m   graph_function, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3037\u001b[0m   seen_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[1;32m   3038\u001b[0m   captured \u001b[38;5;241m=\u001b[39m object_identity\u001b[38;5;241m.\u001b[39mObjectIdentitySet(\n\u001b[1;32m   3039\u001b[0m       graph_function\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39minternal_captures)\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3292\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3288\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_define_function_with_shape_relaxation(\n\u001b[1;32m   3289\u001b[0m       args, kwargs, flat_args, filtered_flat_args)\n\u001b[1;32m   3291\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39madd_call_context(cache_key\u001b[38;5;241m.\u001b[39mcall_context)\n\u001b[0;32m-> 3292\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_graph_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3293\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39madd(cache_key, cache_key_deletion_observer,\n\u001b[1;32m   3294\u001b[0m                          graph_function)\n\u001b[1;32m   3296\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function, filtered_flat_args\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3130\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3125\u001b[0m missing_arg_names \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   3126\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (arg, i) \u001b[38;5;28;01mfor\u001b[39;00m i, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(missing_arg_names)\n\u001b[1;32m   3127\u001b[0m ]\n\u001b[1;32m   3128\u001b[0m arg_names \u001b[38;5;241m=\u001b[39m base_arg_names \u001b[38;5;241m+\u001b[39m missing_arg_names\n\u001b[1;32m   3129\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m ConcreteFunction(\n\u001b[0;32m-> 3130\u001b[0m     \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3131\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3132\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3133\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3134\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3135\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3136\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3137\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3138\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3139\u001b[0m \u001b[43m        \u001b[49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3140\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_by_value\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   3141\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_attributes,\n\u001b[1;32m   3142\u001b[0m     function_spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_spec,\n\u001b[1;32m   3143\u001b[0m     \u001b[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[1;32m   3144\u001b[0m     \u001b[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[1;32m   3145\u001b[0m     \u001b[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[1;32m   3146\u001b[0m     \u001b[38;5;66;03m# ConcreteFunction.\u001b[39;00m\n\u001b[1;32m   3147\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   3148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:1161\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1158\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1159\u001b[0m   _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1161\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1163\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1165\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mmap_structure(convert, func_outputs,\n\u001b[1;32m   1166\u001b[0m                                   expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/data/ops/structured_function.py:248\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;129m@eager_function\u001b[39m\u001b[38;5;241m.\u001b[39mdefun_with_attributes(\n\u001b[1;32m    243\u001b[0m     input_signature\u001b[38;5;241m=\u001b[39mstructure\u001b[38;5;241m.\u001b[39mget_flat_tensor_specs(\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_structure),\n\u001b[1;32m    245\u001b[0m     autograph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    246\u001b[0m     attributes\u001b[38;5;241m=\u001b[39mdefun_kwargs)\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_fn\u001b[39m(\u001b[38;5;241m*\u001b[39margs):  \u001b[38;5;66;03m# pylint: disable=missing-docstring\u001b[39;00m\n\u001b[0;32m--> 248\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mwrapper_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    249\u001b[0m   ret \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mto_tensor_list(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_structure, ret)\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m [ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m ret]\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/data/ops/structured_function.py:177\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _should_unpack(nested_args):\n\u001b[1;32m    176\u001b[0m   nested_args \u001b[38;5;241m=\u001b[39m (nested_args,)\n\u001b[0;32m--> 177\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mautograph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtf_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag_ctx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnested_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _should_pack(ret):\n\u001b[1;32m    179\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(ret)\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:692\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    691\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 692\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[1;32m    693\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    694\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/tmp/ipykernel_21812/1607789451.py\", line 2, in None  *\n        lambda x, y: (data_augmentation(x, training=True), y)\n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/felix/Wks/AMFtrack/amftrack/ml/width/data_augmentation.py\", line 80, in <lambda>\n        lambda x: random_crop_slice(x, original_size, input_size, offset),\n\n    ValueError: Exception encountered when calling layer \"random_crop_with_offset_0\" (type Lambda).\n    \n    in user code:\n    \n        File \"/home/felix/Wks/AMFtrack/amftrack/ml/width/data_augmentation.py\", line 74, in random_crop_slice  *\n            return x[..., start_index : start_index + input_size, :]\n    \n        ValueError: Index out of range using input dim 1; input has only 1 dims for '{{node strided_slice}} = StridedSlice[Index=DT_INT64, T=DT_FLOAT, begin_mask=4, ellipsis_mask=1, end_mask=4, new_axis_mask=0, shrink_axis_mask=0](x, strided_slice/stack, strided_slice/stack_1, strided_slice/Cast)' with input shapes: [120], [3], [3], [3] and with computed input tensors: input[3] = <1 1 1>.\n    \n    \n    Call arguments received:\n      â¢ inputs=tf.Tensor(shape=(120,), dtype=float32)\n      â¢ mask=None\n      â¢ training=True\n"
     ]
    }
   ],
   "source": [
    "train = (\n",
    "    d3.map(lambda x, y: (data_augmentation(x, training=True), y))\n",
    "    .unbatch()\n",
    "    .batch(BATCHSIZE)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7892890c",
   "metadata": {},
   "source": [
    "## BROUILLON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "07f31a2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(377, 120)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1c0fbd40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prov = np.expand_dims(train_feature, axis=-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "91b87668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function from_tensor_slices in module tensorflow.python.data.ops.dataset_ops:\n",
      "\n",
      "from_tensor_slices(tensors, name=None)\n",
      "    Creates a `Dataset` whose elements are slices of the given tensors.\n",
      "    \n",
      "    The given tensors are sliced along their first dimension. This operation\n",
      "    preserves the structure of the input tensors, removing the first dimension\n",
      "    of each tensor and using it as the dataset dimension. All input tensors\n",
      "    must have the same size in their first dimensions.\n",
      "    \n",
      "    >>> # Slicing a 1D tensor produces scalar tensor elements.\n",
      "    >>> dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
      "    >>> list(dataset.as_numpy_iterator())\n",
      "    [1, 2, 3]\n",
      "    \n",
      "    >>> # Slicing a 2D tensor produces 1D tensor elements.\n",
      "    >>> dataset = tf.data.Dataset.from_tensor_slices([[1, 2], [3, 4]])\n",
      "    >>> list(dataset.as_numpy_iterator())\n",
      "    [array([1, 2], dtype=int32), array([3, 4], dtype=int32)]\n",
      "    \n",
      "    >>> # Slicing a tuple of 1D tensors produces tuple elements containing\n",
      "    >>> # scalar tensors.\n",
      "    >>> dataset = tf.data.Dataset.from_tensor_slices(([1, 2], [3, 4], [5, 6]))\n",
      "    >>> list(dataset.as_numpy_iterator())\n",
      "    [(1, 3, 5), (2, 4, 6)]\n",
      "    \n",
      "    >>> # Dictionary structure is also preserved.\n",
      "    >>> dataset = tf.data.Dataset.from_tensor_slices({\"a\": [1, 2], \"b\": [3, 4]})\n",
      "    >>> list(dataset.as_numpy_iterator()) == [{'a': 1, 'b': 3},\n",
      "    ...                                       {'a': 2, 'b': 4}]\n",
      "    True\n",
      "    \n",
      "    >>> # Two tensors can be combined into one Dataset object.\n",
      "    >>> features = tf.constant([[1, 3], [2, 1], [3, 3]]) # ==> 3x2 tensor\n",
      "    >>> labels = tf.constant(['A', 'B', 'A']) # ==> 3x1 tensor\n",
      "    >>> dataset = Dataset.from_tensor_slices((features, labels))\n",
      "    >>> # Both the features and the labels tensors can be converted\n",
      "    >>> # to a Dataset object separately and combined after.\n",
      "    >>> features_dataset = Dataset.from_tensor_slices(features)\n",
      "    >>> labels_dataset = Dataset.from_tensor_slices(labels)\n",
      "    >>> dataset = Dataset.zip((features_dataset, labels_dataset))\n",
      "    >>> # A batched feature and label set can be converted to a Dataset\n",
      "    >>> # in similar fashion.\n",
      "    >>> batched_features = tf.constant([[[1, 3], [2, 3]],\n",
      "    ...                                 [[2, 1], [1, 2]],\n",
      "    ...                                 [[3, 3], [3, 2]]], shape=(3, 2, 2))\n",
      "    >>> batched_labels = tf.constant([['A', 'A'],\n",
      "    ...                               ['B', 'B'],\n",
      "    ...                               ['A', 'B']], shape=(3, 2, 1))\n",
      "    >>> dataset = Dataset.from_tensor_slices((batched_features, batched_labels))\n",
      "    >>> for element in dataset.as_numpy_iterator():\n",
      "    ...   print(element)\n",
      "    (array([[1, 3],\n",
      "           [2, 3]], dtype=int32), array([[b'A'],\n",
      "           [b'A']], dtype=object))\n",
      "    (array([[2, 1],\n",
      "           [1, 2]], dtype=int32), array([[b'B'],\n",
      "           [b'B']], dtype=object))\n",
      "    (array([[3, 3],\n",
      "           [3, 2]], dtype=int32), array([[b'A'],\n",
      "           [b'B']], dtype=object))\n",
      "    \n",
      "    Note that if `tensors` contains a NumPy array, and eager execution is not\n",
      "    enabled, the values will be embedded in the graph as one or more\n",
      "    `tf.constant` operations. For large datasets (> 1 GB), this can waste\n",
      "    memory and run into byte limits of graph serialization. If `tensors`\n",
      "    contains one or more large NumPy arrays, consider the alternative described\n",
      "    in [this guide](\n",
      "    https://tensorflow.org/guide/data#consuming_numpy_arrays).\n",
      "    \n",
      "    Args:\n",
      "      tensors: A dataset element, whose components have the same first\n",
      "        dimension. Supported values are documented\n",
      "        [here](https://www.tensorflow.org/guide/data#dataset_structure).\n",
      "      name: (Optional.) A name for the tf.data operation.\n",
      "    \n",
      "    Returns:\n",
      "      Dataset: A `Dataset`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.data.Dataset.from_tensor_slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fa6672f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unbatching a tensor is only supported for rank >= 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [78]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_ds \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_tensor_slices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprov\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py:793\u001b[0m, in \u001b[0;36mDatasetV2.from_tensor_slices\u001b[0;34m(tensors, name)\u001b[0m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_tensor_slices\u001b[39m(tensors, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    717\u001b[0m   \u001b[38;5;124;03m\"\"\"Creates a `Dataset` whose elements are slices of the given tensors.\u001b[39;00m\n\u001b[1;32m    718\u001b[0m \n\u001b[1;32m    719\u001b[0m \u001b[38;5;124;03m  The given tensors are sliced along their first dimension. This operation\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    791\u001b[0m \u001b[38;5;124;03m    Dataset: A `Dataset`.\u001b[39;00m\n\u001b[1;32m    792\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 793\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mTensorSliceDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py:4482\u001b[0m, in \u001b[0;36mTensorSliceDataset.__init__\u001b[0;34m(self, element, is_files, name)\u001b[0m\n\u001b[1;32m   4480\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tensors:\n\u001b[1;32m   4481\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid `element`. `element` should not be empty.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 4482\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_structure \u001b[38;5;241m=\u001b[39m \u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4483\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcomponent_spec\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomponent_spec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_unbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatched_spec\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   4484\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata \u001b[38;5;241m=\u001b[39m dataset_metadata_pb2\u001b[38;5;241m.\u001b[39mMetadata()\n\u001b[1;32m   4485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name:\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/data/util/nest.py:228\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **check_types_dict)\u001b[0m\n\u001b[1;32m    224\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m    225\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 228\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [func(\u001b[38;5;241m*\u001b[39mx) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries])\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/data/util/nest.py:228\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    224\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (flatten(s) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m    225\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 228\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m], [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries])\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py:4483\u001b[0m, in \u001b[0;36mTensorSliceDataset.__init__.<locals>.<lambda>\u001b[0;34m(component_spec)\u001b[0m\n\u001b[1;32m   4480\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tensors:\n\u001b[1;32m   4481\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid `element`. `element` should not be empty.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   4482\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_structure \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mmap_structure(\n\u001b[0;32m-> 4483\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m component_spec: \u001b[43mcomponent_spec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_unbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, batched_spec)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   4484\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata \u001b[38;5;241m=\u001b[39m dataset_metadata_pb2\u001b[38;5;241m.\u001b[39mMetadata()\n\u001b[1;32m   4485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name:\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/framework/tensor_spec.py:216\u001b[0m, in \u001b[0;36mTensorSpec._unbatch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_unbatch\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    215\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shape\u001b[38;5;241m.\u001b[39mndims \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnbatching a tensor is only supported for rank >= 1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m TensorSpec(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shape[\u001b[38;5;241m1\u001b[39m:], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dtype)\n",
      "\u001b[0;31mValueError\u001b[0m: Unbatching a tensor is only supported for rank >= 1"
     ]
    }
   ],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices(prov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "eb1b9690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n",
      "(1, 120)\n"
     ]
    }
   ],
   "source": [
    "for e in train_ds:\n",
    "    print(e.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ba25fc97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([377, 80, 1])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_preparation(train_feature).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "970cf762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset element_spec=TensorSpec(shape=(120,), dtype=tf.uint8, name=None)>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_feature)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9764f210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 120, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 120, 1), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\"), but it was called on an input with incompatible shape (120,).\n",
      "2022-08-16 16:51:06,205-[WARNING]- tensorflow:665 -> Model was constructed with shape (None, 120, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 120, 1), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\"), but it was called on an input with incompatible shape (120,).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/tmp/ipykernel_21812/1439737797.py\", line 2, in None  *\n        lambda x: (data_augmentation(x, training=True))\n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/felix/Wks/AMFtrack/amftrack/ml/width/data_augmentation.py\", line 80, in <lambda>\n        lambda x: random_crop_slice(x, original_size, input_size, offset),\n\n    ValueError: Exception encountered when calling layer \"random_crop_with_offset_0\" (type Lambda).\n    \n    in user code:\n    \n        File \"/home/felix/Wks/AMFtrack/amftrack/ml/width/data_augmentation.py\", line 74, in random_crop_slice  *\n            return x[..., start_index : start_index + input_size, :]\n    \n        ValueError: Index out of range using input dim 1; input has only 1 dims for '{{node strided_slice}} = StridedSlice[Index=DT_INT64, T=DT_FLOAT, begin_mask=4, ellipsis_mask=1, end_mask=4, new_axis_mask=0, shrink_axis_mask=0](x, strided_slice/stack, strided_slice/stack_1, strided_slice/Cast)' with input shapes: [120], [3], [3], [3] and with computed input tensors: input[3] = <1 1 1>.\n    \n    \n    Call arguments received:\n      â¢ inputs=tf.Tensor(shape=(120,), dtype=float32)\n      â¢ mask=None\n      â¢ training=True\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [57]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m train \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_augmentation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;241m.\u001b[39munbatch()\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;241m.\u001b[39mbatch(BATCHSIZE)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;241m.\u001b[39mprefetch(tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mAUTOTUNE)\n\u001b[1;32m      6\u001b[0m )\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py:2016\u001b[0m, in \u001b[0;36mDatasetV2.map\u001b[0;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m   2013\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m deterministic \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m DEBUG_MODE:\n\u001b[1;32m   2014\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `deterministic` argument has no effect unless the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2015\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`num_parallel_calls` argument is specified.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2016\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mMapDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreserve_cardinality\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2017\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2018\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m ParallelMapDataset(\n\u001b[1;32m   2019\u001b[0m       \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2020\u001b[0m       map_func,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2023\u001b[0m       preserve_cardinality\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   2024\u001b[0m       name\u001b[38;5;241m=\u001b[39mname)\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py:5191\u001b[0m, in \u001b[0;36mMapDataset.__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[1;32m   5189\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_inter_op_parallelism \u001b[38;5;241m=\u001b[39m use_inter_op_parallelism\n\u001b[1;32m   5190\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preserve_cardinality \u001b[38;5;241m=\u001b[39m preserve_cardinality\n\u001b[0;32m-> 5191\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func \u001b[38;5;241m=\u001b[39m \u001b[43mstructured_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStructuredFunctionWrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5193\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transformation_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5194\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5195\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_legacy_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_legacy_function\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5196\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata \u001b[38;5;241m=\u001b[39m dataset_metadata_pb2\u001b[38;5;241m.\u001b[39mMetadata()\n\u001b[1;32m   5197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name:\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/data/ops/structured_function.py:271\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m    264\u001b[0m       warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    265\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    266\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    267\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    268\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    269\u001b[0m     fn_factory \u001b[38;5;241m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[0;32m--> 271\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function \u001b[38;5;241m=\u001b[39m \u001b[43mfn_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;66;03m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[1;32m    273\u001b[0m add_to_graph \u001b[38;5;241m&\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly()\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3070\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_concrete_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   3062\u001b[0m   \u001b[38;5;124;03m\"\"\"Returns a `ConcreteFunction` specialized to inputs and execution context.\u001b[39;00m\n\u001b[1;32m   3063\u001b[0m \n\u001b[1;32m   3064\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3068\u001b[0m \u001b[38;5;124;03m       or `tf.Tensor` or `tf.TensorSpec`.\u001b[39;00m\n\u001b[1;32m   3069\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3070\u001b[0m   graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3071\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3072\u001b[0m   graph_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   3073\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3036\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3034\u001b[0m   args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3035\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m-> 3036\u001b[0m   graph_function, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3037\u001b[0m   seen_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[1;32m   3038\u001b[0m   captured \u001b[38;5;241m=\u001b[39m object_identity\u001b[38;5;241m.\u001b[39mObjectIdentitySet(\n\u001b[1;32m   3039\u001b[0m       graph_function\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39minternal_captures)\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3292\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3288\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_define_function_with_shape_relaxation(\n\u001b[1;32m   3289\u001b[0m       args, kwargs, flat_args, filtered_flat_args)\n\u001b[1;32m   3291\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39madd_call_context(cache_key\u001b[38;5;241m.\u001b[39mcall_context)\n\u001b[0;32m-> 3292\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_graph_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3293\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39madd(cache_key, cache_key_deletion_observer,\n\u001b[1;32m   3294\u001b[0m                          graph_function)\n\u001b[1;32m   3296\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function, filtered_flat_args\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3130\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3125\u001b[0m missing_arg_names \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   3126\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (arg, i) \u001b[38;5;28;01mfor\u001b[39;00m i, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(missing_arg_names)\n\u001b[1;32m   3127\u001b[0m ]\n\u001b[1;32m   3128\u001b[0m arg_names \u001b[38;5;241m=\u001b[39m base_arg_names \u001b[38;5;241m+\u001b[39m missing_arg_names\n\u001b[1;32m   3129\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m ConcreteFunction(\n\u001b[0;32m-> 3130\u001b[0m     \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3131\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3132\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3133\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3134\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3135\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3136\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3137\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3138\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3139\u001b[0m \u001b[43m        \u001b[49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3140\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_by_value\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   3141\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_attributes,\n\u001b[1;32m   3142\u001b[0m     function_spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_spec,\n\u001b[1;32m   3143\u001b[0m     \u001b[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[1;32m   3144\u001b[0m     \u001b[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[1;32m   3145\u001b[0m     \u001b[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[1;32m   3146\u001b[0m     \u001b[38;5;66;03m# ConcreteFunction.\u001b[39;00m\n\u001b[1;32m   3147\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   3148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:1161\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1158\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1159\u001b[0m   _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1161\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1163\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1165\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mmap_structure(convert, func_outputs,\n\u001b[1;32m   1166\u001b[0m                                   expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/data/ops/structured_function.py:248\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;129m@eager_function\u001b[39m\u001b[38;5;241m.\u001b[39mdefun_with_attributes(\n\u001b[1;32m    243\u001b[0m     input_signature\u001b[38;5;241m=\u001b[39mstructure\u001b[38;5;241m.\u001b[39mget_flat_tensor_specs(\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_structure),\n\u001b[1;32m    245\u001b[0m     autograph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    246\u001b[0m     attributes\u001b[38;5;241m=\u001b[39mdefun_kwargs)\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_fn\u001b[39m(\u001b[38;5;241m*\u001b[39margs):  \u001b[38;5;66;03m# pylint: disable=missing-docstring\u001b[39;00m\n\u001b[0;32m--> 248\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mwrapper_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    249\u001b[0m   ret \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mto_tensor_list(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_structure, ret)\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m [ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m ret]\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/data/ops/structured_function.py:177\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _should_unpack(nested_args):\n\u001b[1;32m    176\u001b[0m   nested_args \u001b[38;5;241m=\u001b[39m (nested_args,)\n\u001b[0;32m--> 177\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mautograph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtf_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag_ctx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnested_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _should_pack(ret):\n\u001b[1;32m    179\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(ret)\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:692\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    691\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 692\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[1;32m    693\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    694\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/tmp/ipykernel_21812/1439737797.py\", line 2, in None  *\n        lambda x: (data_augmentation(x, training=True))\n    File \"/home/felix/Wks/AMFtrack/venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/felix/Wks/AMFtrack/amftrack/ml/width/data_augmentation.py\", line 80, in <lambda>\n        lambda x: random_crop_slice(x, original_size, input_size, offset),\n\n    ValueError: Exception encountered when calling layer \"random_crop_with_offset_0\" (type Lambda).\n    \n    in user code:\n    \n        File \"/home/felix/Wks/AMFtrack/amftrack/ml/width/data_augmentation.py\", line 74, in random_crop_slice  *\n            return x[..., start_index : start_index + input_size, :]\n    \n        ValueError: Index out of range using input dim 1; input has only 1 dims for '{{node strided_slice}} = StridedSlice[Index=DT_INT64, T=DT_FLOAT, begin_mask=4, ellipsis_mask=1, end_mask=4, new_axis_mask=0, shrink_axis_mask=0](x, strided_slice/stack, strided_slice/stack_1, strided_slice/Cast)' with input shapes: [120], [3], [3], [3] and with computed input tensors: input[3] = <1 1 1>.\n    \n    \n    Call arguments received:\n      â¢ inputs=tf.Tensor(shape=(120,), dtype=float32)\n      â¢ mask=None\n      â¢ training=True\n"
     ]
    }
   ],
   "source": [
    "train = (\n",
    "    train_dataset.map(lambda x: (data_augmentation(x, training=True)))\n",
    "    .unbatch()\n",
    "    .batch(BATCHSIZE)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cef90cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 120, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 120, 1), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\"), but it was called on an input with incompatible shape (120,).\n",
      "2022-08-16 16:49:36,925-[WARNING]- tensorflow:665 -> Model was constructed with shape (None, 120, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 120, 1), dtype=tf.float32, name='input_1'), name='input_1', description=\"created by layer 'input_1'\"), but it was called on an input with incompatible shape (120,).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"random_crop_with_offset_0\" (type Lambda).\n\nin user code:\n\n    File \"/home/felix/Wks/AMFtrack/amftrack/ml/width/data_augmentation.py\", line 74, in random_crop_slice  *\n        return x[..., start_index : start_index + input_size, :]\n\n    ValueError: Index out of range using input dim 1; input has only 1 dims for '{{node strided_slice}} = StridedSlice[Index=DT_INT64, T=DT_FLOAT, begin_mask=4, ellipsis_mask=1, end_mask=4, new_axis_mask=0, shrink_axis_mask=0](x, strided_slice/stack, strided_slice/stack_1, strided_slice/Cast)' with input shapes: [120], [3], [3], [3] and with computed input tensors: input[3] = <1 1 1>.\n\n\nCall arguments received:\n  â¢ inputs=tf.Tensor(shape=(120,), dtype=float32)\n  â¢ mask=None\n  â¢ training=False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [55]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m----> 2\u001b[0m         \u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_augmentation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;241m.\u001b[39munbatch()\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;241m.\u001b[39mbatch(BATCHSIZE)\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;241m.\u001b[39mprefetch(tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mAUTOTUNE)\n\u001b[1;32m      6\u001b[0m     )\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py:2016\u001b[0m, in \u001b[0;36mDatasetV2.map\u001b[0;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m   2013\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m deterministic \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m DEBUG_MODE:\n\u001b[1;32m   2014\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `deterministic` argument has no effect unless the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2015\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`num_parallel_calls` argument is specified.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2016\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mMapDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreserve_cardinality\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2017\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2018\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m ParallelMapDataset(\n\u001b[1;32m   2019\u001b[0m       \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2020\u001b[0m       map_func,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2023\u001b[0m       preserve_cardinality\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   2024\u001b[0m       name\u001b[38;5;241m=\u001b[39mname)\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py:5191\u001b[0m, in \u001b[0;36mMapDataset.__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[1;32m   5189\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_inter_op_parallelism \u001b[38;5;241m=\u001b[39m use_inter_op_parallelism\n\u001b[1;32m   5190\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preserve_cardinality \u001b[38;5;241m=\u001b[39m preserve_cardinality\n\u001b[0;32m-> 5191\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func \u001b[38;5;241m=\u001b[39m \u001b[43mstructured_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStructuredFunctionWrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5193\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transformation_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5194\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5195\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_legacy_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_legacy_function\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5196\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata \u001b[38;5;241m=\u001b[39m dataset_metadata_pb2\u001b[38;5;241m.\u001b[39mMetadata()\n\u001b[1;32m   5197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name:\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/data/ops/structured_function.py:271\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m    264\u001b[0m       warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    265\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    266\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    267\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    268\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    269\u001b[0m     fn_factory \u001b[38;5;241m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[0;32m--> 271\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function \u001b[38;5;241m=\u001b[39m \u001b[43mfn_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;66;03m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[1;32m    273\u001b[0m add_to_graph \u001b[38;5;241m&\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly()\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3070\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_concrete_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   3062\u001b[0m   \u001b[38;5;124;03m\"\"\"Returns a `ConcreteFunction` specialized to inputs and execution context.\u001b[39;00m\n\u001b[1;32m   3063\u001b[0m \n\u001b[1;32m   3064\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3068\u001b[0m \u001b[38;5;124;03m       or `tf.Tensor` or `tf.TensorSpec`.\u001b[39;00m\n\u001b[1;32m   3069\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3070\u001b[0m   graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3071\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3072\u001b[0m   graph_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   3073\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3036\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3034\u001b[0m   args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3035\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m-> 3036\u001b[0m   graph_function, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3037\u001b[0m   seen_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[1;32m   3038\u001b[0m   captured \u001b[38;5;241m=\u001b[39m object_identity\u001b[38;5;241m.\u001b[39mObjectIdentitySet(\n\u001b[1;32m   3039\u001b[0m       graph_function\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39minternal_captures)\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3292\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3288\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_define_function_with_shape_relaxation(\n\u001b[1;32m   3289\u001b[0m       args, kwargs, flat_args, filtered_flat_args)\n\u001b[1;32m   3291\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39madd_call_context(cache_key\u001b[38;5;241m.\u001b[39mcall_context)\n\u001b[0;32m-> 3292\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_graph_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3293\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39madd(cache_key, cache_key_deletion_observer,\n\u001b[1;32m   3294\u001b[0m                          graph_function)\n\u001b[1;32m   3296\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function, filtered_flat_args\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3130\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3125\u001b[0m missing_arg_names \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   3126\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (arg, i) \u001b[38;5;28;01mfor\u001b[39;00m i, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(missing_arg_names)\n\u001b[1;32m   3127\u001b[0m ]\n\u001b[1;32m   3128\u001b[0m arg_names \u001b[38;5;241m=\u001b[39m base_arg_names \u001b[38;5;241m+\u001b[39m missing_arg_names\n\u001b[1;32m   3129\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m ConcreteFunction(\n\u001b[0;32m-> 3130\u001b[0m     \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3131\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3132\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3133\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3134\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3135\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3136\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3137\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3138\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3139\u001b[0m \u001b[43m        \u001b[49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3140\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_by_value\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   3141\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_attributes,\n\u001b[1;32m   3142\u001b[0m     function_spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_spec,\n\u001b[1;32m   3143\u001b[0m     \u001b[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[1;32m   3144\u001b[0m     \u001b[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[1;32m   3145\u001b[0m     \u001b[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[1;32m   3146\u001b[0m     \u001b[38;5;66;03m# ConcreteFunction.\u001b[39;00m\n\u001b[1;32m   3147\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   3148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:1161\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1158\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1159\u001b[0m   _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1161\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1163\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1165\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mmap_structure(convert, func_outputs,\n\u001b[1;32m   1166\u001b[0m                                   expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/data/ops/structured_function.py:248\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;129m@eager_function\u001b[39m\u001b[38;5;241m.\u001b[39mdefun_with_attributes(\n\u001b[1;32m    243\u001b[0m     input_signature\u001b[38;5;241m=\u001b[39mstructure\u001b[38;5;241m.\u001b[39mget_flat_tensor_specs(\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_structure),\n\u001b[1;32m    245\u001b[0m     autograph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    246\u001b[0m     attributes\u001b[38;5;241m=\u001b[39mdefun_kwargs)\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_fn\u001b[39m(\u001b[38;5;241m*\u001b[39margs):  \u001b[38;5;66;03m# pylint: disable=missing-docstring\u001b[39;00m\n\u001b[0;32m--> 248\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mwrapper_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    249\u001b[0m   ret \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mto_tensor_list(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_structure, ret)\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m [ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m ret]\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/data/ops/structured_function.py:177\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _should_unpack(nested_args):\n\u001b[1;32m    176\u001b[0m   nested_args \u001b[38;5;241m=\u001b[39m (nested_args,)\n\u001b[0;32m--> 177\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mautograph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtf_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag_ctx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnested_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _should_pack(ret):\n\u001b[1;32m    179\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(ret)\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:689\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    688\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 689\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    691\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    374\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39muser_requested \u001b[38;5;129;01mand\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_allowlisted(f):\n\u001b[0;32m--> 377\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;66;03m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;66;03m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;66;03m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;66;03m# things like builtins.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:458\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    455\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m\u001b[38;5;241m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 458\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[0;32m~/Wks/AMFtrack/venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Wks/AMFtrack/amftrack/ml/width/data_augmentation.py:80\u001b[0m, in \u001b[0;36mrandom_crop.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrandom_crop\u001b[39m(original_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m120\u001b[39m, input_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m80\u001b[39m, offset\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWrapper function to generate a random croping layer\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mLambda(\n\u001b[0;32m---> 80\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mrandom_crop_slice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moriginal_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     81\u001b[0m         name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrandom_crop_with_offset_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moffset\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     82\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"random_crop_with_offset_0\" (type Lambda).\n\nin user code:\n\n    File \"/home/felix/Wks/AMFtrack/amftrack/ml/width/data_augmentation.py\", line 74, in random_crop_slice  *\n        return x[..., start_index : start_index + input_size, :]\n\n    ValueError: Index out of range using input dim 1; input has only 1 dims for '{{node strided_slice}} = StridedSlice[Index=DT_INT64, T=DT_FLOAT, begin_mask=4, ellipsis_mask=1, end_mask=4, new_axis_mask=0, shrink_axis_mask=0](x, strided_slice/stack, strided_slice/stack_1, strided_slice/Cast)' with input shapes: [120], [3], [3], [3] and with computed input tensors: input[3] = <1 1 1>.\n\n\nCall arguments received:\n  â¢ inputs=tf.Tensor(shape=(120,), dtype=float32)\n  â¢ mask=None\n  â¢ training=False"
     ]
    }
   ],
   "source": [
    "train_dataset = (\n",
    "    train_dataset.map(data_augmentation)\n",
    "    .unbatch()\n",
    "    .batch(BATCHSIZE)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
