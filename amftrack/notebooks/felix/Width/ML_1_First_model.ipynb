{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8383f8b",
   "metadata": {},
   "source": [
    "# First model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56af904c",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0466677",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "722b9204",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-16 13:36:12.007220: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-05-16 13:36:12.007235: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "/home/ipausers/kahane/Wks/AMFtrack/amftrack/util/dbx.py:1: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "from amftrack.util.sys import storage_path\n",
    "from amftrack.util.file import chose_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a0a139",
   "metadata": {},
   "source": [
    "**Notebook logger**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d989fa7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(\"notebook\")\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "10a6a404",
   "metadata": {},
   "source": [
    "logger.debug(\"1\")\n",
    "logger.info(\"2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfe4ab3",
   "metadata": {},
   "source": [
    "**Paths**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1573776c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.functions_run_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "8c66bab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e38c3e2c",
   "metadata": {},
   "source": [
    "test_file = chose_file(section_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2240d0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = os.path.join(storage_path, \"width3\", \"dataset_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7442f7a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/kahane/AMFtopology02/storage/width3/dataset_2'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14178c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "section_path = os.path.join(dataset_path, \"Img\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1b8a1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_data_path = os.path.join(dataset_path, \"Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff937af",
   "metadata": {},
   "source": [
    "#### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d1086cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nodes(ch):\n",
    "    nodes = ch.split(\"-\")\n",
    "    print(nodes)\n",
    "    return nodes[0], nodes[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c549dd",
   "metadata": {},
   "source": [
    "**Variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e3969b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCHSIZE = 32\n",
    "BUFFERSIZE = 12\n",
    "INPUTSIZE = 120\n",
    "SHUFFLE_BUFFER = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7409ca0d",
   "metadata": {},
   "source": [
    "## I/ Data pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd152c6b",
   "metadata": {},
   "source": [
    "Some remarks:\n",
    "\n",
    "- We use different edges for training validation and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "cbfe02e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_path_to_df_path(path: str):\n",
    "    image_name = os.path.basename(str(path))\n",
    "    image_name_without_ext = os.path.splitext(image_name)[0]\n",
    "    df_name = image_name_without_ext + \".csv\"\n",
    "    edge_data_full_path = os.path.join(edge_data_path, df_name)\n",
    "    return edge_data_full_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "25f46786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/kahane/AMFtopology02/storage/width3/dataset_2/Data/1122-1227.csv'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = '/media/kahane/AMFtopology02/storage/width3/dataset_2/Img/1122-1227.png'\n",
    "image_path_to_df_path(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d388d021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO(FK): make tf function\n",
    "\n",
    "#@tf.function\n",
    "def load_image(filename):\n",
    "    \"From one file name (corresponding to an edge). Loads the data associated with this one file/edge.\"\n",
    "    logger.info(f\"Type of file: {type(filename)}\")\n",
    "    logger.info(f\"File name: {filename}\")\n",
    "    print(filename)\n",
    "    # 1/ Slices from the edge\n",
    "    raw = tf.io.read_file(filename) # open the file\n",
    "    image = tf.image.decode_png(raw, channels=1, dtype = tf.uint8)\n",
    "    logger.debug(f\"Initial shape: {image.shape}\")\n",
    "    # image = image.set_shape([None, 120, 1]) \n",
    "    image = tf.squeeze(image) # removing the last axis\n",
    "    # TODO (FK): chose here only part of the array\n",
    "    logger.debug(f\"Final shape: {image.shape}\")\n",
    "    # TODO (FK): why don't I get the shape\n",
    "    slice_dataset = tf.data.Dataset.from_tensor_slices(image)\n",
    "\n",
    "    # 2/ Information on the edge\n",
    "    # TODO (FK): verify order for the edge dataframe\n",
    "    #edge_name = os.path.splitext(os.path.basename(str(filename)))[0] + \".csv\" # PB: not a tensor\n",
    "    #edge_data_full_path = os.path.join(edge_data_path, edge_name)\n",
    "    #edge_data_full_path = image_path_to_df_path(filename)\n",
    "    edge_data_full_path = tf.map_fn(filename, image_path_to_df_path)\n",
    "    logger.debug(edge_data_full_path)\n",
    "    edge_df = pd.read_csv(edge_data_full_path)\n",
    "    logger.debug(edge_df.columns)\n",
    "    feature_dataset = edge_df[['x1_image', 'y2_image']]\n",
    "    \n",
    "    # 3/ Labels\n",
    "    label_dataset = tf.data.Dataset.from_tensor_slices(tf.convert_to_tensor(edge_df[['width']]))\n",
    "\n",
    "    return tf.data.Dataset.zip((slice_dataset, label_dataset))\n",
    "    #return slice_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "24833c75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-16 14:54:43,635-[INFO]- notebook:6 -> Type of file: <class 'str'>\n",
      "2022-05-16 14:54:43,635-[INFO]- notebook:7 -> File name: /media/kahane/AMFtopology02/storage/width3/dataset_2/Img/826-644.png\n",
      "/media/kahane/AMFtopology02/storage/width3/dataset_2/Img/826-644.png\n",
      "2022-05-16 14:54:44,170-[DEBUG]- notebook:12 -> Initial shape: (136, 120, 1)\n",
      "2022-05-16 14:54:44,172-[DEBUG]- notebook:16 -> Final shape: (136, 120)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute '__name__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [119]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m b \u001b[38;5;241m=\u001b[39m \u001b[43mload_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchose_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43msection_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [118]\u001b[0m, in \u001b[0;36mload_image\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     18\u001b[0m slice_dataset \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mfrom_tensor_slices(image)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# 2/ Information on the edge\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# TODO (FK): verify order for the edge dataframe\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m#edge_name = os.path.splitext(os.path.basename(str(filename)))[0] + \".csv\" # PB: not a tensor\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m#edge_data_full_path = os.path.join(edge_data_path, edge_name)\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m#edge_data_full_path = image_path_to_df_path(filename)\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m edge_data_full_path \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_path_to_df_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(edge_data_full_path)\n\u001b[1;32m     27\u001b[0m edge_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(edge_data_full_path)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/deprecation.py:616\u001b[0m, in \u001b[0;36mdeprecated_arg_values.<locals>.deprecated_wrapper.<locals>.new_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    609\u001b[0m           _PRINTED_WARNING[(func, arg_name)] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    610\u001b[0m         logging\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    611\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFrom \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: calling \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m (from \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) with \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is deprecated and \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    612\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwill be removed \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mInstructions for updating:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    613\u001b[0m             _call_location(), decorator_utils\u001b[38;5;241m.\u001b[39mget_qualified_name(func),\n\u001b[1;32m    614\u001b[0m             func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m, arg_name, arg_value, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124min a future version\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    615\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m date \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m date), instructions)\n\u001b[0;32m--> 616\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/deprecation.py:548\u001b[0m, in \u001b[0;36mdeprecated_args.<locals>.deprecated_wrapper.<locals>.new_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    540\u001b[0m         _PRINTED_WARNING[(func, arg_name)] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    541\u001b[0m       logging\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    542\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFrom \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: calling \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m (from \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) with \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is deprecated and will \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    543\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbe removed \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mInstructions for updating:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    546\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124min a future version\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m date \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m date),\n\u001b[1;32m    547\u001b[0m           instructions)\n\u001b[0;32m--> 548\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/ops/map_fn.py:637\u001b[0m, in \u001b[0;36mmap_fn_v2\u001b[0;34m(fn, elems, dtype, parallel_iterations, back_prop, swap_memory, infer_shape, name, fn_output_signature)\u001b[0m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fn_output_signature \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    636\u001b[0m   fn_output_signature \u001b[38;5;241m=\u001b[39m dtype\n\u001b[0;32m--> 637\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmap_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    638\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    639\u001b[0m \u001b[43m    \u001b[49m\u001b[43melems\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43melems\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    640\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfn_output_signature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfn_output_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    641\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparallel_iterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparallel_iterations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    642\u001b[0m \u001b[43m    \u001b[49m\u001b[43mback_prop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mback_prop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    643\u001b[0m \u001b[43m    \u001b[49m\u001b[43mswap_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswap_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    644\u001b[0m \u001b[43m    \u001b[49m\u001b[43minfer_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfer_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    645\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/deprecation.py:548\u001b[0m, in \u001b[0;36mdeprecated_args.<locals>.deprecated_wrapper.<locals>.new_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    540\u001b[0m         _PRINTED_WARNING[(func, arg_name)] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    541\u001b[0m       logging\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    542\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFrom \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: calling \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m (from \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) with \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is deprecated and will \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    543\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbe removed \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mInstructions for updating:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    546\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124min a future version\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m date \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m date),\n\u001b[1;32m    547\u001b[0m           instructions)\n\u001b[0;32m--> 548\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/ops/map_fn.py:356\u001b[0m, in \u001b[0;36mmap_fn\u001b[0;34m(fn, elems, dtype, parallel_iterations, back_prop, swap_memory, infer_shape, name, fn_output_signature)\u001b[0m\n\u001b[1;32m    353\u001b[0m   fn_output_signature \u001b[38;5;241m=\u001b[39m dtype\n\u001b[1;32m    355\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m callable(fn):\n\u001b[0;32m--> 356\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe provided function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not callable.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    357\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfn must be callable.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    359\u001b[0m in_graph_mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly()\n\u001b[1;32m    360\u001b[0m \u001b[38;5;66;03m# Set the default number of parallel_iterations depending on graph/eager mode.\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute '__name__'"
     ]
    }
   ],
   "source": [
    "b = load_image(chose_file(section_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cef30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for elem in b:\n",
    "    print(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2650a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = b.shuffle(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "7799451d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dataset = tf.data.Dataset.list_files(filepaths)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "38cd3097",
   "metadata": {},
   "source": [
    "for e in path_dataset:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1c02e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "5b0e89d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-16 14:54:46,053-[INFO]- notebook:446 -> Type of file: <class 'tensorflow.python.framework.ops.Tensor'>\n",
      "2022-05-16 14:54:46,071-[INFO]- notebook:446 -> File name: Tensor(\"args_0:0\", shape=(), dtype=string)\n",
      "Tensor(\"args_0:0\", shape=(), dtype=string)\n",
      "2022-05-16 14:54:46,090-[DEBUG]- notebook:446 -> Initial shape: (None, None, 1)\n",
      "2022-05-16 14:54:46,105-[DEBUG]- notebook:446 -> Final shape: <unknown>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ipausers/kahane/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/structured_function.py:264: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "in user code:\n\n    File \"/tmp/ipykernel_5119/3011409102.py\", line 25, in load_image  *\n        edge_data_full_path = tf.map_fn(filename, image_path_to_df_path)\n\n    AttributeError: 'Tensor' object has no attribute '__name__'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [121]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m general_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mpath_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterleave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mload_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcycle_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py:2180\u001b[0m, in \u001b[0;36mDatasetV2.interleave\u001b[0;34m(self, map_func, cycle_length, block_length, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m   2177\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m deterministic \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m DEBUG_MODE:\n\u001b[1;32m   2178\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `deterministic` argument has no effect unless the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2179\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`num_parallel_calls` argument is specified.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2180\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mInterleaveDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2181\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcycle_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2182\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2183\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m ParallelInterleaveDataset(\n\u001b[1;32m   2184\u001b[0m       \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2185\u001b[0m       map_func,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2189\u001b[0m       deterministic\u001b[38;5;241m=\u001b[39mdeterministic,\n\u001b[1;32m   2190\u001b[0m       name\u001b[38;5;241m=\u001b[39mname)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py:5319\u001b[0m, in \u001b[0;36mInterleaveDataset.__init__\u001b[0;34m(self, input_dataset, map_func, cycle_length, block_length, name)\u001b[0m\n\u001b[1;32m   5316\u001b[0m \u001b[38;5;124;03m\"\"\"See `Dataset.interleave()` for details.\"\"\"\u001b[39;00m\n\u001b[1;32m   5318\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_dataset \u001b[38;5;241m=\u001b[39m input_dataset\n\u001b[0;32m-> 5319\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func \u001b[38;5;241m=\u001b[39m \u001b[43mstructured_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStructuredFunctionWrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5320\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transformation_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5321\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func\u001b[38;5;241m.\u001b[39moutput_structure, DatasetSpec):\n\u001b[1;32m   5322\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   5323\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `map_func` argument must return a `Dataset` object. Got \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   5324\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_get_type(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func\u001b[38;5;241m.\u001b[39moutput_structure)\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/structured_function.py:271\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m    264\u001b[0m       warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    265\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    266\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    267\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    268\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    269\u001b[0m     fn_factory \u001b[38;5;241m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[0;32m--> 271\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function \u001b[38;5;241m=\u001b[39m \u001b[43mfn_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;66;03m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[1;32m    273\u001b[0m add_to_graph \u001b[38;5;241m&\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3070\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_concrete_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   3062\u001b[0m   \u001b[38;5;124;03m\"\"\"Returns a `ConcreteFunction` specialized to inputs and execution context.\u001b[39;00m\n\u001b[1;32m   3063\u001b[0m \n\u001b[1;32m   3064\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3068\u001b[0m \u001b[38;5;124;03m       or `tf.Tensor` or `tf.TensorSpec`.\u001b[39;00m\n\u001b[1;32m   3069\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3070\u001b[0m   graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3071\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3072\u001b[0m   graph_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   3073\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3036\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3034\u001b[0m   args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3035\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m-> 3036\u001b[0m   graph_function, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3037\u001b[0m   seen_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[1;32m   3038\u001b[0m   captured \u001b[38;5;241m=\u001b[39m object_identity\u001b[38;5;241m.\u001b[39mObjectIdentitySet(\n\u001b[1;32m   3039\u001b[0m       graph_function\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39minternal_captures)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3292\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3288\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_define_function_with_shape_relaxation(\n\u001b[1;32m   3289\u001b[0m       args, kwargs, flat_args, filtered_flat_args)\n\u001b[1;32m   3291\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39madd_call_context(cache_key\u001b[38;5;241m.\u001b[39mcall_context)\n\u001b[0;32m-> 3292\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_graph_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3293\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39madd(cache_key, cache_key_deletion_observer,\n\u001b[1;32m   3294\u001b[0m                          graph_function)\n\u001b[1;32m   3296\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function, filtered_flat_args\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py:3130\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3125\u001b[0m missing_arg_names \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   3126\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (arg, i) \u001b[38;5;28;01mfor\u001b[39;00m i, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(missing_arg_names)\n\u001b[1;32m   3127\u001b[0m ]\n\u001b[1;32m   3128\u001b[0m arg_names \u001b[38;5;241m=\u001b[39m base_arg_names \u001b[38;5;241m+\u001b[39m missing_arg_names\n\u001b[1;32m   3129\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m ConcreteFunction(\n\u001b[0;32m-> 3130\u001b[0m     \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3131\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3132\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3133\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3134\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3135\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3136\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3137\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3138\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3139\u001b[0m \u001b[43m        \u001b[49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3140\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_by_value\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   3141\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_attributes,\n\u001b[1;32m   3142\u001b[0m     function_spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_spec,\n\u001b[1;32m   3143\u001b[0m     \u001b[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[1;32m   3144\u001b[0m     \u001b[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[1;32m   3145\u001b[0m     \u001b[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[1;32m   3146\u001b[0m     \u001b[38;5;66;03m# ConcreteFunction.\u001b[39;00m\n\u001b[1;32m   3147\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   3148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:1161\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1158\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1159\u001b[0m   _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1161\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1163\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1165\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mmap_structure(convert, func_outputs,\n\u001b[1;32m   1166\u001b[0m                                   expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/structured_function.py:248\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;129m@eager_function\u001b[39m\u001b[38;5;241m.\u001b[39mdefun_with_attributes(\n\u001b[1;32m    243\u001b[0m     input_signature\u001b[38;5;241m=\u001b[39mstructure\u001b[38;5;241m.\u001b[39mget_flat_tensor_specs(\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_structure),\n\u001b[1;32m    245\u001b[0m     autograph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    246\u001b[0m     attributes\u001b[38;5;241m=\u001b[39mdefun_kwargs)\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_fn\u001b[39m(\u001b[38;5;241m*\u001b[39margs):  \u001b[38;5;66;03m# pylint: disable=missing-docstring\u001b[39;00m\n\u001b[0;32m--> 248\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mwrapper_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    249\u001b[0m   ret \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mto_tensor_list(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_structure, ret)\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m [ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m ret]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/structured_function.py:177\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _should_unpack(nested_args):\n\u001b[1;32m    176\u001b[0m   nested_args \u001b[38;5;241m=\u001b[39m (nested_args,)\n\u001b[0;32m--> 177\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mautograph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtf_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag_ctx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnested_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _should_pack(ret):\n\u001b[1;32m    179\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(ret)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:692\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    691\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 692\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[1;32m    693\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    694\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: in user code:\n\n    File \"/tmp/ipykernel_5119/3011409102.py\", line 25, in load_image  *\n        edge_data_full_path = tf.map_fn(filename, image_path_to_df_path)\n\n    AttributeError: 'Tensor' object has no attribute '__name__'\n"
     ]
    }
   ],
   "source": [
    "general_dataset = path_dataset.interleave(load_image, cycle_length=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b42399",
   "metadata": {},
   "outputs": [],
   "source": [
    "general_dataset = general_dataset.shuffle(shuffle_buffer_size).repeat(repeat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "64fc4ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reader_dataset(filepaths, repeat=1, n_readers=5, shuffle_buffer_size = 1000, batch_size=32):\n",
    "    \"\"\"\n",
    "    Take as input a list of the paths to the data files.\n",
    "    And return a tf.Dataset object iterating through the batches.\n",
    "    \"\"\"\n",
    "    path_dataset = tf.data.Dataset.list_files(filepaths) # yield file names randomly\n",
    "    # TODO: make buffer size to size of the dataset\n",
    "    # TODO: get a dataset object from one file\n",
    "    general_dataset = path_dataset.interleave(lambda filepath: load_image(filepath), cycle_length=n_readers)\n",
    "    general_dataset = general_dataset.shuffle(shuffle_buffer_size).repeat(repeat)\n",
    "    return general_dataset.batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "87e05cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepaths = [os.path.join(section_path, file) for file in os.listdir(section_path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3132fc8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/media/kahane/AMFtopology02/storage/width3/dataset_2/Img/2413-2729.png',\n",
       " '/media/kahane/AMFtopology02/storage/width3/dataset_2/Img/1122-1227.png',\n",
       " '/media/kahane/AMFtopology02/storage/width3/dataset_2/Img/1211-1227.png',\n",
       " '/media/kahane/AMFtopology02/storage/width3/dataset_2/Img/1227-1298.png',\n",
       " '/media/kahane/AMFtopology02/storage/width3/dataset_2/Img/1255-1458.png',\n",
       " '/media/kahane/AMFtopology02/storage/width3/dataset_2/Img/1458-1316.png',\n",
       " '/media/kahane/AMFtopology02/storage/width3/dataset_2/Img/1458-1686.png',\n",
       " '/media/kahane/AMFtopology02/storage/width3/dataset_2/Img/1538-1502.png',\n",
       " '/media/kahane/AMFtopology02/storage/width3/dataset_2/Img/1686-1723.png',\n",
       " '/media/kahane/AMFtopology02/storage/width3/dataset_2/Img/1723-1787.png',\n",
       " '/media/kahane/AMFtopology02/storage/width3/dataset_2/Img/1787-1889.png',\n",
       " '/media/kahane/AMFtopology02/storage/width3/dataset_2/Img/1841-1391.png',\n",
       " '/media/kahane/AMFtopology02/storage/width3/dataset_2/Img/185-369.png',\n",
       " '/media/kahane/AMFtopology02/storage/width3/dataset_2/Img/1855-1926.png',\n",
       " '/media/kahane/AMFtopology02/storage/width3/dataset_2/Img/1891-1393.png',\n",
       " '/media/kahane/AMFtopology02/storage/width3/dataset_2/Img/1974-2084.png',\n",
       " '/media/kahane/AMFtopology02/storage/width3/dataset_2/Img/1980-1938.png',\n",
       " '/media/kahane/AMFtopology02/storage/width3/dataset_2/Img/2031-1855.png',\n",
       " '/media/kahane/AMFtopology02/storage/width3/dataset_2/Img/2103-1889.png',\n",
       " '/media/kahane/AMFtopology02/storage/width3/dataset_2/Img/2469-2851.png',\n",
       " '/media/kahane/AMFtopology02/storage/width3/dataset_2/Img/2549-2608.png',\n",
       " '/media/kahane/AMFtopology02/storage/width3/dataset_2/Img/2552-2501.png',\n",
       " '/media/kahane/AMFtopology02/storage/width3/dataset_2/Img/2569-2728.png',\n",
       " '/media/kahane/AMFtopology02/storage/width3/dataset_2/Img/2598-2555.png',\n",
       " '/media/kahane/AMFtopology02/storage/width3/dataset_2/Img/2599-2698.png',\n",
       " '/media/kahane/AMFtopology02/storage/width3/dataset_2/Img/2702-2627.png',\n",
       " '/media/kahane/AMFtopology02/storage/width3/dataset_2/Img/2792-2552.png',\n",
       " '/media/kahane/AMFtopology02/storage/width3/dataset_2/Img/2934-2596.png',\n",
       " '/media/kahane/AMFtopology02/storage/width3/dataset_2/Img/369-414.png',\n",
       " '/media/kahane/AMFtopology02/storage/width3/dataset_2/Img/430-559.png',\n",
       " '/media/kahane/AMFtopology02/storage/width3/dataset_2/Img/440-497.png',\n",
       " '/media/kahane/AMFtopology02/storage/width3/dataset_2/Img/455-97.png',\n",
       " '/media/kahane/AMFtopology02/storage/width3/dataset_2/Img/478-575.png',\n",
       " '/media/kahane/AMFtopology02/storage/width3/dataset_2/Img/482-478.png',\n",
       " '/media/kahane/AMFtopology02/storage/width3/dataset_2/Img/566-491.png',\n",
       " '/media/kahane/AMFtopology02/storage/width3/dataset_2/Img/566-544.png',\n",
       " '/media/kahane/AMFtopology02/storage/width3/dataset_2/Img/572-539.png',\n",
       " '/media/kahane/AMFtopology02/storage/width3/dataset_2/Img/620-640.png',\n",
       " '/media/kahane/AMFtopology02/storage/width3/dataset_2/Img/652-608.png',\n",
       " '/media/kahane/AMFtopology02/storage/width3/dataset_2/Img/688-572.png',\n",
       " '/media/kahane/AMFtopology02/storage/width3/dataset_2/Img/826-644.png',\n",
       " '/media/kahane/AMFtopology02/storage/width3/dataset_2/Img/826-966.png',\n",
       " '/media/kahane/AMFtopology02/storage/width3/dataset_2/Img/999-880.png']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "771c853f",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'general_dataset' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [56]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mreader_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepaths\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [54]\u001b[0m, in \u001b[0;36mreader_dataset\u001b[0;34m(filepaths, repeat, n_readers, shuffle_buffer_size, batch_size)\u001b[0m\n\u001b[1;32m      6\u001b[0m path_dataset \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mlist_files(filepaths) \u001b[38;5;66;03m# yield file names randomly\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# TODO: make buffer size to size of the dataset\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# TODO: get a dataset object from one file\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#general_dataset = path_dataset.interleave(lambda filepath: load_image(filepath), cycle_length=n_readers)\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m general_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mgeneral_dataset\u001b[49m\u001b[38;5;241m.\u001b[39mshuffle(shuffle_buffer_size)\u001b[38;5;241m.\u001b[39mrepeat(repeat)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m general_dataset\u001b[38;5;241m.\u001b[39mbatch(batch_size)\u001b[38;5;241m.\u001b[39mprefetch(\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'general_dataset' referenced before assignment"
     ]
    }
   ],
   "source": [
    "reader_dataset(filepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4ee324fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(32, 120)\n",
      "(2, 120)\n"
     ]
    }
   ],
   "source": [
    "a = reader_dataset(filepaths)\n",
    "for e in a:\n",
    "    print(e.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef0a944d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(os.path.join(dataset_path, \"data.csv\")) #.set_index('edge')\n",
    "#del data['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa1983d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>edge</th>\n",
       "      <th>width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0, edge, width]\n",
       "Index: []"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data[\"edge\"] == f\"(Node({482}),Node({478}))\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aff9ae97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 43 entries, 0 to 42\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Unnamed: 0  43 non-null     int64  \n",
      " 1   edge        43 non-null     object \n",
      " 2   width       43 non-null     float64\n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 1.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d953cbe",
   "metadata": {},
   "source": [
    "### 2/ Coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f147cc87",
   "metadata": {},
   "source": [
    "## II/ First model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cbf510",
   "metadata": {},
   "source": [
    "# Brouillon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a45c8a2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pathlib' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m image_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhypothesis/temp\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m image_root \u001b[38;5;241m=\u001b[39m \u001b[43mpathlib\u001b[49m\u001b[38;5;241m.\u001b[39mPath(image_dir)\n\u001b[1;32m      3\u001b[0m list_ds \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mlist_files(\u001b[38;5;28mstr\u001b[39m(image_root\u001b[38;5;241m/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*.png\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m list_ds:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pathlib' is not defined"
     ]
    }
   ],
   "source": [
    "image_dir = 'hypothesis/temp'\n",
    "image_root = pathlib.Path(image_dir)\n",
    "list_ds = tf.data.Dataset.list_files(str(image_root/'*.png'))\n",
    "for f in list_ds:\n",
    "  image = tf.io.read_file(f)\n",
    "  image = tf.io.decode_png(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d6d220",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_path(file_path):\n",
    "  label = tf.strings.split(file_path, os.sep)[-2]\n",
    "  return tf.io.read_file(file_path), label\n",
    "\n",
    "labeled_ds = list_ds.map(process_path)\n",
    "\n",
    "for image_raw, label_text in labeled_ds.take(1):\n",
    "  print(repr(image_raw.numpy()[:100]))\n",
    "  print()\n",
    "  print(label_text.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d679f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def load_image(filename):\n",
    "    raw = tf.io.read_file(filename)\n",
    "    image = tf.image.decode_png(raw, channels=1)\n",
    "    # the `print` executes during tracing.\n",
    "    print(\"Initial shape: \", image.shape)\n",
    "    image.set_shape([28, 28, 3])\n",
    "    print(\"Final shape: \", image.shape)\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1b81c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_path(file_path):\n",
    "    label = tf.strings.split(file_path, os.sep)[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc526482",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dataset(dataframe, shuffle=True, batch_size=32):\n",
    "    labels = dataframe.pop('label')\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "    ds = ds.batch(batch_size)\n",
    "    ds = ds.prefetch(batch_size)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b8adf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "filenames = [\"./img1.jpg\", \"./img2.jpg\"]\n",
    "labels = [\"A\", \"B\"]\n",
    "\n",
    "def load_image(filePath, label):\n",
    "    print('Loading File: {}' + filePath)\n",
    "    raw_bytes = tf.io.read_file(filePath)\n",
    "    image = tf.io.decode_image(raw_bytes, expand_animations = False)\n",
    "    return tf.data.Dataset.from_tensors((image, label))\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
    "dataset = dataset.interleave(lambda x, y: load_image(x, y), cycle_length=4)\n",
    "\n",
    "for i in dataset.as_numpy_iterator():\n",
    "    image = i[0]\n",
    "    label = i[1]\n",
    "    print(image.shape)\n",
    "    print(label.decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8dc10b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf5538a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('coors.csv', mode='r') as infile:\n",
    "    reader = csv.reader(infile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
