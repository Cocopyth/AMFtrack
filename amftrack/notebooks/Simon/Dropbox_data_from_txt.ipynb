{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0af5bf4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/home6/svstaalduine/AMF_project/amftrack/util/dbx.py:3: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gpfs/scratch1/shared/amftrackflow/temp\n"
     ]
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from IPython.display import clear_output\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# sys.path.insert(0, os.getenv('HOME')+'/pycode/MscThesis/')\n",
    "# sys.path.insert(0,r'C:\\Users\\coren\\Documents\\PhD\\Code\\AMFtrack')\n",
    "\n",
    "import pandas as pd\n",
    "from amftrack.util.sys import (\n",
    "    get_dates_datetime,\n",
    "    get_dirname,\n",
    "    temp_path,\n",
    "    get_data_info,\n",
    "    update_plate_info,\n",
    "    get_current_folders,\n",
    "    get_folders_by_plate_id,\n",
    ")\n",
    "\n",
    "\n",
    "import ast\n",
    "from amftrack.plotutil import plot_t_tp1\n",
    "from scipy import sparse\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import scipy.io as sio\n",
    "from pymatreader import read_mat\n",
    "from matplotlib import colors\n",
    "import cv2\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage.filters import frangi\n",
    "from skimage import filters\n",
    "from random import choice\n",
    "import scipy.sparse\n",
    "import os\n",
    "from amftrack.pipeline.functions.image_processing.extract_graph import (\n",
    "    from_sparse_to_graph,\n",
    "    generate_nx_graph,\n",
    "    sparse_to_doc,\n",
    ")\n",
    "from skimage.feature import hessian_matrix_det\n",
    "\n",
    "# from amftrack.pipeline.functions.image_processing.experiment_class_surf import Experiment\n",
    "from amftrack.pipeline.launching.run import (\n",
    "    run_transfer,\n",
    ")\n",
    "from amftrack.pipeline.launching.run_super import run_parallel_transfer\n",
    "\n",
    "import dropbox\n",
    "from amftrack.util.dbx import upload_folders, download, read_saved_dropbox_state, save_dropbox_state, load_dbx, download, get_dropbox_folders, get_dropbox_video_folders\n",
    "from subprocess import call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1151bb4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go\n",
      "2023-06-27 16:51:11,060-[INFO]- dropbox:390 -> Refreshing access token.\n",
      "2023-06-27 16:51:11,238-[INFO]- dropbox:474 -> Request to files/list_folder\n"
     ]
    },
    {
     "ename": "ApiError",
     "evalue": "ApiError('0bd0e0b488fb45378536bf55aae56328', ListFolderError('path', LookupError('not_found', None)))",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mApiError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[0;32m/scratch-local/svstaalduine/ipykernel_2551711/1663026541.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      3\u001B[0m     \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmakedirs\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdirectory_targ\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 5\u001B[0;31m \u001B[0mall_folders_drop\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mexcel_drop\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtxt_drop\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mget_dropbox_video_folders\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"/DATA/TransportROOT/DATA/1_year/\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      6\u001B[0m \u001B[0mclear_output\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mwait\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[0mall_folders_drop\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/gpfs/home6/svstaalduine/AMF_project/amftrack/util/dbx.py\u001B[0m in \u001B[0;36mget_dropbox_video_folders\u001B[0;34m(dir_drop, skip_size)\u001B[0m\n\u001B[1;32m    311\u001B[0m     \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"go\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    312\u001B[0m     \u001B[0mdbx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mload_dbx\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 313\u001B[0;31m     \u001B[0mresponse\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdbx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfiles_list_folder\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdir_drop\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrecursive\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    314\u001B[0m     \u001B[0mfiles_list\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    315\u001B[0m     \u001B[0mexcel_list\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.9/site-packages/dropbox/base.py\u001B[0m in \u001B[0;36mfiles_list_folder\u001B[0;34m(self, path, recursive, include_media_info, include_deleted, include_has_explicit_shared_members, include_mounted_folders, limit, shared_link, include_property_groups, include_non_downloadable_files)\u001B[0m\n\u001B[1;32m   2143\u001B[0m                                   \u001B[0minclude_property_groups\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2144\u001B[0m                                   include_non_downloadable_files)\n\u001B[0;32m-> 2145\u001B[0;31m         r = self.request(\n\u001B[0m\u001B[1;32m   2146\u001B[0m             \u001B[0mfiles\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlist_folder\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2147\u001B[0m             \u001B[0;34m'files'\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.9/site-packages/dropbox/dropbox_client.py\u001B[0m in \u001B[0;36mrequest\u001B[0;34m(self, route, namespace, request_arg, request_binary, timeout)\u001B[0m\n\u001B[1;32m    349\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    350\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mres\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mRouteErrorResult\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 351\u001B[0;31m             raise ApiError(res.request_id,\n\u001B[0m\u001B[1;32m    352\u001B[0m                            \u001B[0mdeserialized_result\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    353\u001B[0m                            \u001B[0muser_message_text\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mApiError\u001B[0m: ApiError('0bd0e0b488fb45378536bf55aae56328', ListFolderError('path', LookupError('not_found', None)))"
     ]
    }
   ],
   "source": [
    "directory_targ = \"/gpfs/scratch1/shared/amftrackflow/Claire_set/\"\n",
    "if not os.path.exists(directory_targ):\n",
    "    os.makedirs(directory_targ)\n",
    "    \n",
    "all_folders_drop, excel_drop, txt_drop = get_dropbox_video_folders(\"/DATA/TransportROOT/DATA/1_year/\", True)\n",
    "clear_output(wait=False)\n",
    "all_folders_drop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d03972",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_drop[0][:-13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2dfbcd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "txt_addresses = []\n",
    "for file in txt_drop:\n",
    "    file_name = f\"{file.split('/')[-3]}{os.sep}{file.split('/')[-2]}{os.sep}{file.split('/')[-1]}\"\n",
    "    if not os.path.exists(directory_targ + file.split('/')[-3] + os.sep+file.split('/')[-2]):\n",
    "        os.makedirs(directory_targ+ file.split('/')[-3] + os.sep+file.split('/')[-2])\n",
    "    download(file, directory_targ+file_name)\n",
    "    txt_addresses.append(directory_targ+file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8e9d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "series_array = []\n",
    "# print(txt_addresses)\n",
    "for address in txt_addresses:\n",
    "#     print(address)\n",
    "    series = pd.read_csv(address, sep=\": \", engine='python').dropna()\n",
    "    series_array.append(series.T)\n",
    "    \n",
    "dataframe = pd.concat(series_array, axis=0, ignore_index=True)\n",
    "dataframe[\"LocalPath\"] = txt_addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878b158e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def month_to_num(x):\n",
    "    months = {\n",
    "        'January': '01',\n",
    "        'February': '02',\n",
    "        'March': '03',\n",
    "        'April': '04',\n",
    "         'May':'05',\n",
    "         'June':'06',\n",
    "         'July':'07',\n",
    "         'August':'08',\n",
    "         'September':'09',\n",
    "         'October':'10',\n",
    "         'November':'11',\n",
    "         'December':'12'\n",
    "        }\n",
    "    a = x.strip()[:3].lower()\n",
    "    try:\n",
    "        ez = months[a]\n",
    "        return ez\n",
    "    except:\n",
    "        raise ValueError('Not a month')\n",
    "\n",
    "def reshape_video_info_df(video_info):\n",
    "    clean_video_info = video_info.copy()\n",
    "    clean_video_info[\"DateTime\"] = [date.split(',')[-2] for date in clean_video_info[\"DateTime\"]]\n",
    "    clean_video_info[\"DateTime\"] = [int(f\"{date.split(' ')[-1]}{month_to_num(date.split(' ')[-2])}{date.split(' ')[-3]}\") for date in clean_video_info[\"DateTime\"]]\n",
    "    clean_video_info[\"Plate\"] = [str(entry) for entry in clean_video_info[\"Plate\"]]\n",
    "    clean_video_info[\"Time\"] = [int(time.split(' ')[-2]) for time in clean_video_info[\"Time\"]]\n",
    "    clean_video_info[\"Magnification\"] = [entry.split(\" \")[-2][:-1] for entry in clean_video_info[\"Operation\"]]\n",
    "    clean_video_info[\"BF_or_F\"] = [[\"F\", \"BF\"][entry.split(\" \")[-1] == 'Brightfield']for entry in clean_video_info[\"Operation\"]]\n",
    "#     for i, entry in enumerate(clean_video_info[\"X\"]):\n",
    "#         print(str(entry.lower()) == \"auto\")\n",
    "#         print(entry.split(\" \"))\n",
    "#         print(float(entry.split(\" \")[14]))\n",
    "#         print(clean_video_info[\"DateTime\"][i])\n",
    "#         print(clean_video_info[\"Run\"][i])\n",
    "    clean_video_info[\"ExposureTime\"] = [entry.split(\" \")[3] for entry in clean_video_info[\"ExposureTime\"]]\n",
    "    clean_video_info[\"FrameRate\"] = [float(entry.split(\" \")[-3]) for entry in clean_video_info[\"FrameRate\"]]\n",
    "    clean_video_info[\"Binning\"] = [int(entry.split(\"x\")[-1]) for entry in clean_video_info[\"Binning\"]]\n",
    "    clean_video_info[\"X\"] = [float(entry.split(\" \")[14]) for entry in clean_video_info[\"X\"]]\n",
    "    clean_video_info[\"Y\"] = [float(entry.split(\" \")[14]) for entry in clean_video_info[\"Y\"]]\n",
    "    clean_video_info[\"Z\"] = [float(entry.split(\" \")[14]) for entry in clean_video_info[\"Z\"]]\n",
    "    return clean_video_info\n",
    "\n",
    "\n",
    "new_dataframe = reshape_video_info_df(dataframe)\n",
    "new_dataframe[\"StoragePath\"] = [address[:-13] + \"Img/\" for address in txt_drop]\n",
    "# new_dataframe.to_csv(f\"{directory_targ}/PlateInfo.csv\")\n",
    "new_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30efab7",
   "metadata": {},
   "source": [
    "## Download section\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9cee6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
