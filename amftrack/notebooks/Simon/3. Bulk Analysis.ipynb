{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8857b9d2",
   "metadata": {},
   "source": [
    "### In MODULE three,\n",
    "This is where all the bulk analysis is going to be. In high_mag_analysis.py, there are a number of classes and functions that will help you with parsing the data into meaningful graphs. This MODULE assumes the existence of the video_info.json files that are generated partly in MODULE 1.\n",
    "\n",
    "### Below code:\n",
    "Are just import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b57a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import re\n",
    "from amftrack.pipeline.development.high_mag_videos.plot_data import (\n",
    "    plot_summary,\n",
    "    save_raw_data,\n",
    ")\n",
    "from amftrack.pipeline.development.high_mag_videos.high_mag_analysis import (\n",
    "    HighmagDataset,\n",
    "    VideoDataset,\n",
    "    EdgeDataset,\n",
    "    index_videos_dropbox_new,\n",
    "    analysis_run,\n",
    ")\n",
    "from amftrack.pipeline.development.high_mag_videos.kymo_class import (\n",
    "    KymoVideoAnalysis,\n",
    "    KymoEdgeAnalysis\n",
    ")\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import imageio.v2 as imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tifffile import imwrite\n",
    "from tqdm import tqdm\n",
    "import scipy\n",
    "import matplotlib as mpl\n",
    "from pathlib import Path\n",
    "from amftrack.pipeline.launching.run import (\n",
    "    run_transfer,\n",
    ")\n",
    "from amftrack.pipeline.launching.run_super import run_parallel_transfer\n",
    "import dropbox\n",
    "from amftrack.util.dbx import upload_folder, download, read_saved_dropbox_state, save_dropbox_state, load_dbx, get_dropbox_folders, get_dropbox_video_folders, download_video_folders_drop, download_analysis_folders_drop\n",
    "from subprocess import call\n",
    "import logging\n",
    "import datetime\n",
    "import glob\n",
    "import json\n",
    "from amftrack.pipeline.launching.run_super import run_parallel_flows\n",
    "\n",
    "%matplotlib widget\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.debug)\n",
    "mpl.rcParams['figure.dpi'] = 200\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f748c8b",
   "metadata": {},
   "source": [
    "## File declaration\n",
    "As this notebook is designed to work with Snellius (now also on a local computer!), two items to separate are the raw video files and the analysis. The raw video files are large, bulky and not so easy to flip through. Ideally, the video files would be downloaded and the analysis would be stored on a separate folder structure entirely. That way, large scale analysis of analysis folders can happen when there are thousands of videos in the dataset, without having to have those raw video folders on hand.\n",
    "\n",
    "Below function will basically make your folders fertile ground to accept all the video info folders and raw video files.\n",
    "\n",
    "### Input:\n",
    "Please give separately the folder where raw video data is stored, and where the analysis will be stored. Also give the dropbox address of the dataset you want to analyze.\n",
    "\n",
    "### Output:\n",
    "The specified dropbox folder will be looked through, and all relevant video information will be downloaded to an analysis folder structure identical to what is present on teh dropbox. The relevant raw video folder structure will also be generated, if specified so. Will also create cache files in the form of .json files such that next time, the scrounging does not have to happen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fcc13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# videos_folder = \"E:\\\\AMOLF_Data\\\\videos\\\\\"\n",
    "# analysis_folder = \"E:\\\\AMOLF_Data\\\\analysis\\\\\"\n",
    "\n",
    "videos_folder = \"/gpfs/scratch1/shared/amftrackflow/videos/\"\n",
    "analysis_folder = \"/gpfs/home6/svstaalduine/Analysis/\"\n",
    "\n",
    "# dropbox_address = \"/DATA/FLUORESCENCE/DATA_NileRed/\"\n",
    "# dropbox_address=  \"/DATA/MYRISTATE/DATA/2_weeks\"\n",
    "# dropbox_address = \"/DATA/TransportROOT/DATA/\"\n",
    "dropbox_address = \"/DATA/CocoTransport/\"\n",
    "# dropbox_address = \"/DATA/TRANSPORT/DATA/20230308_Plate070/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfc9525",
   "metadata": {},
   "source": [
    "# Module 3: Bulk Analysis\n",
    "## First part: Assemble Edge DataFrame\n",
    "\n",
    "\n",
    "In this initial part of the bulk analysis, all of the analysis folders will be looked through to find the edge data we're looking for. Additionally, there is an optional part to download the analysis folder back to the analysis folder we specified right at the top.\n",
    "\n",
    "## Assuming all the analysis folders are already downloaded:\n",
    "You can use below code to read the video_data.json files that are created during indexing of all the videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509d8133",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_filter = dropbox_address[5:]\n",
    "\n",
    "img_infos = glob.glob(f\"{analysis_folder}{folder_filter}/**/video_data.json\", recursive=True)\n",
    "vid_anls_frame = pd.DataFrame()\n",
    "for address in tqdm(img_infos):\n",
    "    add_info = pd.read_json(address, orient='index').T\n",
    "    vid_anls_frame = pd.concat([vid_anls_frame, add_info], ignore_index=True)\n",
    "\n",
    "vid_frame = vid_anls_frame.sort_values('unique_id').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03fe43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################\n",
    "### This is where you can apply the filters. Only those videos will be analyzed. ###\n",
    "####################################################################################\n",
    "analysis_frame=vid_frame.copy()\n",
    "\n",
    "analysis_frame = analysis_frame[analysis_frame['imaging_day'].ge(\"20230804\")].reset_index(drop=True)\n",
    "analysis_frame['plate_int'] = [entry.split('_')[-1] for entry in analysis_frame['plate_id']]\n",
    "analysis_frame['video_int'] = [entry.split('_')[-1] for entry in analysis_frame['unique_id']]\n",
    "analysis_frame = analysis_frame[analysis_frame['xpos'].le(100)].reset_index(drop=True)\n",
    "# analysis_frame = analysis_frame[analysis_frame['plate_int'] == \"Plate440\"].reset_index(drop=True)\n",
    "# analysis_frame = analysis_frame[analysis_frame['mode'] == \"F\"].reset_index(drop=True)\n",
    "\n",
    "####################################################################################\n",
    "### Below code will prepare for those videos to be downloaded to videos_folder.  ###\n",
    "####################################################################################\n",
    "analysis_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680f90d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_obj = HighmagDataset(analysis_frame, analysis_folder, videos_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27085158",
   "metadata": {},
   "source": [
    "### Example code Fourier Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084a9964",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_obj = data_obj.filter_edges(\"video_int\", \"<=\", \"4\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8b4a7d",
   "metadata": {},
   "source": [
    "### Example code for creating different plate maps\n",
    "Below you can see the filtering options for different plates and the plot_plate_locs function that outputs a map with dots or arrows depending on your wishes. Current drawing modes are:\n",
    "- 'scatter' for dots of the videos, separated by magnification\n",
    "- 'speeds_mean' for black arrows denoting the effective mean speed of the flows\n",
    "- 'speeds_both' for blue and orange arrows denoting the effective speed of flows in both directions\n",
    "- 'flux_mean'   for black arrows pointing to the flux direction. Calculated flux is divided by 100\n",
    "- 'vid_labels'  for a list of what videos were taken at each position\n",
    "\n",
    "spd_thresh is a parameter you can set to make speeds below it appear as dots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22b0c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "mpl.rcParams['figure.dpi'] =500\n",
    "print(data_obj.video_frame.columns)\n",
    "\n",
    "for plate_id in tqdm(data_obj.video_frame['plate_id'].unique()):\n",
    "    plate_group = data_obj.filter_edges('coverage_tot', '>=', 0.3)\n",
    "    plate_group = data_obj.filter_edges('plate_id', '==', plate_id)\n",
    "    if len(plate_group.video_frame) <= 1:\n",
    "        continue\n",
    "    else:\n",
    "        plate_group.plot_plate_locs(analysis_folder, spd_thresh=3.4, modes=['speeds_both'])\n",
    "\n",
    "mpl.rcParams['figure.dpi'] = 200\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354e1118",
   "metadata": {},
   "source": [
    "### Example code 50x speed arrows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606be929",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "data_interest = data_obj.filter_edges('video_int', \">=\", \"000\")\n",
    "data_interest = data_obj.filter_edges('video_int', \">=\", \"006\")\n",
    "data_interest = data_interest.filter_edges('video_int', \"<=\", \"032\")\n",
    "data_interest = data_interest.filter_edges('imaging_day', \"==\", \"20230727\")\n",
    "\n",
    "for vid_obj in tqdm(data_interest.video_objs):\n",
    "    vid_obj.plot_speed_arrows(plot_both=True, save_im=True, video_txt_size=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de1fa2b",
   "metadata": {},
   "source": [
    "### Example code plot summaries of videos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f927be67",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_obj_filt = data_obj.filter_edges(\"imaging_day\", \"==\", \"20230806\")\n",
    "data_obj_filt = data_obj_filt.filter_edges(\"video_int\", \">=\", \"009\")\n",
    "data_obj_filt = data_obj_filt.filter_edges(\"video_int\", \"<=\", \"011\")\n",
    "\n",
    "print(len(data_obj_filt.edges_frame))\n",
    "for edge in data_obj_filt.edge_objs:\n",
    "    edge.show_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b64f7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_obj_BF = data_obj.filter_edges(\"mode\", \"==\", \"BF\")\n",
    "data_obj_FL = data_obj.filter_edges(\"mode\", \"==\", \"F\")\n",
    "\n",
    "fig, ax = plt.subplots(1,2)\n",
    "\n",
    "for i, day in enumerate(data_obj_BF.edges_frame['imaging_day'].unique()):\n",
    "    data_BF_filt = data_obj_BF.filter_edges(\"imaging_day\", \"==\", day)\n",
    "    data_FL_filt = data_obj_FL.filter_edges(\"imaging_day\", \"==\", day)\n",
    "\n",
    "    ax[i].set_title(f\"Data for {day}\")\n",
    "    ax[i].scatter(data_BF_filt.edges_frame['video_int'].astype(int), data_BF_filt.edges_frame['speed_left'], alpha=0.7, c='tab:orange', label='BF')\n",
    "    ax[i].scatter(data_BF_filt.edges_frame['video_int'].astype(int), data_BF_filt.edges_frame['speed_right'], alpha=0.7, c='tab:orange')\n",
    "    ax[i].scatter(data_FL_filt.edges_frame['video_int'].astype(int), data_FL_filt.edges_frame['speed_left'], alpha=0.7, c='tab:blue', label='F')\n",
    "    ax[i].scatter(data_FL_filt.edges_frame['video_int'].astype(int), data_FL_filt.edges_frame['speed_right'], alpha=0.7, c='tab:blue')\n",
    "    ax[i].set_xlabel(\"Video nr\")\n",
    "    ax[i].set_ylabel(\"Velocity $(\\mu m/s)$\")\n",
    "    ax[i].axhline(c='black', linestyle='--')\n",
    "    ax[i].grid(True)\n",
    "    ax[i].legend()\n",
    "    ax[i].set_ylim([-7, 7])\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf4db9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_obj.edges_frame.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8d54fb",
   "metadata": {},
   "source": [
    "### Example code binned violin-plot\n",
    "bin-column represents the value to be binned, then multiple violin plots are graphed on the same axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74287f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "cover_filter_data = data_obj.filter_edges('coverage_tot', '>=', 0.5)\n",
    "filter_BF = cover_filter_data.filter_edges('mode', '==', 'BF')\n",
    "# filter_BF = filter_BF.filter_edges('imaging_day', '>=', '20230728')\n",
    "# filter_BF = cover_filter_data\n",
    "print(len(filter_BF.edges_frame))\n",
    "bin_column = 'edge_width'\n",
    "\n",
    "# bins = np.linspace(5, 15, 10)\n",
    "bins = np.linspace(filter_BF.return_edge_frame()[bin_column].min(), filter_BF.return_edge_frame()[bin_column].max(), 10)\n",
    "bin_series = filter_BF.bin_values(bin_column, bins)\n",
    "# print(bin_series)\n",
    "\n",
    "labels = []\n",
    "fig, ax = filter_BF.plot_violins('speed_right', bins, c='tab:orange', labels=labels)\n",
    "fig, ax = filter_BF.plot_violins('speed_left', bins, c='tab:blue', ax=ax, fig=fig, labels=labels)\n",
    "fig, ax = filter_BF.plot_violins('speed_mean', bins, c='tab:red', ax=ax, fig=fig, labels=labels)\n",
    "\n",
    "ax.axhline(c='black', alpha=0.5, linestyle='--')\n",
    "ax.set_ylabel('v $(\\mu m / s)$')\n",
    "ax.set_xlabel('hyphal width $(\\mu m)$')\n",
    "ax.legend(*zip(*labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bbf946",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
