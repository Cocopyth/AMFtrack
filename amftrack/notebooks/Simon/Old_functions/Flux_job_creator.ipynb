{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118935f1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from amftrack.pipeline.development.high_mag_videos.kymo_class import *\n",
    "from amftrack.pipeline.development.high_mag_videos.plot_data import (\n",
    "    read_video_data,\n",
    "    plot_summary\n",
    ")\n",
    "import os\n",
    "import pandas as pd\n",
    "import imageio.v2 as imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "%matplotlib widget\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from amftrack.pipeline.functions.image_processing.extract_graph import (\n",
    "    from_sparse_to_graph,\n",
    "    generate_nx_graph,\n",
    "    clean_degree_4,\n",
    ")\n",
    "import scipy\n",
    "from pathlib import Path\n",
    "from amftrack.pipeline.launching.run_super import run_parallel_flows\n",
    "import re\n",
    "from amftrack.util.dbx import upload_folders, upload, download, read_saved_dropbox_state, save_dropbox_state, load_dbx, get_dropbox_folders, get_dropbox_video_folders\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 300\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e988655",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "directory_targ = \"/gpfs/scratch1/shared/amftrackflow/videos/MYRISTATE/DATA/2_weeks/\"\n",
    "upload_targ = \"/DATA/MYRISTATE/DATA/2_weeks/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836dd4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_name = glob(directory_targ + \"*\")[0]\n",
    "imgs_address = test_name\n",
    "print(test_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1ba1fb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plate_list = glob(directory_targ + \"*_Plate*/*/\")\n",
    "datadict = {\"tot_path_drop\": plate_list}\n",
    "dataframe = pd.DataFrame(data=datadict)\n",
    "\n",
    "# print(dataframe['tot_path_drop'][0])\n",
    "\n",
    "dataframe[\"video\"] = [\n",
    "    address[:-1].split(os.sep)[-1] for address in dataframe[\"tot_path_drop\"]\n",
    "]\n",
    "dataframe[\"Plate number\"] = [\n",
    "    re.split(\"_|/\", address.split(\"_\")[-1])[0][5:]\n",
    "    for address in dataframe[\"tot_path_drop\"]\n",
    "]\n",
    "dataframe[\"video_int\"] = [\n",
    "    int(re.split(\"_|/\", address[:-1])[-1]) for address in dataframe[\"tot_path_drop\"]\n",
    "]\n",
    "dataframe[\"Date Imaged\"] = [\n",
    "    address.split(\"/\")[-3][:8] for address in dataframe[\"tot_path_drop\"]\n",
    "]\n",
    "dataframe[\"folder\"] = [\n",
    "    f\"{row['Date Imaged']}_plate{row['Plate number']}_{row['video']}\"\n",
    "    for index, row in dataframe.iterrows()\n",
    "]\n",
    "\n",
    "print(dataframe[\"tot_path_drop\"][0])\n",
    "dataframe.sort_values(by=\"video\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc275f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_table = []\n",
    "for row in dataframe.iloc:\n",
    "    excel_file = glob(\n",
    "        str(Path(row[\"tot_path_drop\"]).parent)\n",
    "        + f'/*{row[\"Date Imaged\"]}*{row[\"Plate number\"]}.xl*'\n",
    "    )\n",
    "    if len(excel_file) > 0:\n",
    "        data_table.append(excel_file[0])\n",
    "    else:\n",
    "        csv_file = glob(\n",
    "            str(Path(row[\"tot_path_drop\"]).parent)\n",
    "            + f'/{row[\"Date Imaged\"]}*{row[\"Plate number\"]}.csv'\n",
    "        )\n",
    "        if len(csv_file) > 0:\n",
    "            data_table.append(csv_file[0])\n",
    "excel_addresses = pd.Series(data_table).unique()\n",
    "excel_addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96e170b",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_frame = read_video_data(excel_addresses, dataframe)\n",
    "merge_frame.tot_path[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb97087",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_frame = merge_frame.rename(columns={\"tot_path\": \"folder\"})\n",
    "download_frame = download_frame.sort_values(\"unique_id\")\n",
    "download_frame = download_frame.reset_index(drop=True)\n",
    "# dataframe_filtered = dataframe_filtered[dataframe_filtered['date_imaged'] == \"20221026\"]\n",
    "# dataframe_filtered['plate_nr'].unique()\n",
    "dataframe_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c49c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINAL CHECK FOR SOURCE FOLDER AND UPLOAD FOLDER\n",
    "\n",
    "# Please make sure that the upload folder is correct,\n",
    "# as the program WILL overwrite that which is already there.\n",
    "print(directory_targ)\n",
    "print(upload_targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26548a30",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "nr_parallel = np.min([len(dataframe.index), 16])\n",
    "\n",
    "run_parallel_flows(\n",
    "    \"flux_extract.py\",\n",
    "    [directory_targ, 15, 0.95, 0.001, 60, upload_targ],\n",
    "    dataframe_filtered,\n",
    "    nr_parallel,\n",
    "    \"1:00:00\",\n",
    "    \"flux_extract\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acce42c0",
   "metadata": {},
   "source": [
    "Upload the proper excel files to the analysis folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfaeee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_folder = []\n",
    "data_table = []\n",
    "magnification = []\n",
    "fps = []\n",
    "mode = []\n",
    "binning = []\n",
    "\n",
    "\n",
    "for row in dataframe.iloc:\n",
    "    parent_folder.append(str(Path(row[\"tot_path_drop\"]).parent))\n",
    "    excel_file = glob(\n",
    "        str(Path(row[\"tot_path_drop\"]).parent)\n",
    "        + f'/*{row[\"Date Imaged\"]}*{row[\"Plate number\"]}.xl*'\n",
    "    )\n",
    "    if len(excel_file) > 0:\n",
    "        data_table.append(excel_file[0])\n",
    "        excel_table = pd.read_excel(excel_file[0])\n",
    "        magnification.append(\n",
    "            excel_table[\n",
    "                excel_table[\"Unnamed: 0\"].str.contains(\n",
    "                    row[\"video_name\"], case=False, na=False\n",
    "                )\n",
    "            ][\"Magnification\"].iloc[0]\n",
    "        )\n",
    "        fps.append(\n",
    "            excel_table.loc[\n",
    "                excel_table[\"Unnamed: 0\"].str.contains(\n",
    "                    row[\"video_name\"], case=False, na=False\n",
    "                )\n",
    "            ][\"FPS\"].iloc[0]\n",
    "        )\n",
    "        mode.append(\n",
    "            excel_table.loc[\n",
    "                excel_table[\"Unnamed: 0\"].str.contains(\n",
    "                    row[\"video_name\"], case=False, na=False\n",
    "                )\n",
    "            ][\"Bright-field (BF)\\nor\\nFluorescence (F)\"].iloc[0]\n",
    "        )\n",
    "        if \"Binned (Y/N)\" in excel_table:\n",
    "            binning.append(\n",
    "                excel_table.loc[\n",
    "                    excel_table[\"Unnamed: 0\"].str.contains(\n",
    "                        row[\"video_name\"], case=False, na=False\n",
    "                    )\n",
    "                ][\"Binned (Y/N)\"].iloc[0]\n",
    "            )\n",
    "        else:\n",
    "            binning.append(\"N\")\n",
    "    else:\n",
    "        csv_file = glob(\n",
    "            str(Path(row[\"tot_path_drop\"]).parent)\n",
    "            + f'/{row[\"Date Imaged\"]}*{row[\"Plate number\"]}.csv'\n",
    "        )\n",
    "        if len(csv_file) > 0:\n",
    "            data_table.append(csv_file[0])\n",
    "            df_comma = pd.read_csv(csv_file[0], nrows=1, sep=\",\")\n",
    "            df_semi = pd.read_csv(csv_file[0], nrows=1, sep=\";\")\n",
    "            if df_comma.shape[1] > df_semi.shape[1]:\n",
    "                csv_table = pd.read_csv(csv_file[0], sep=\",\")\n",
    "            else:\n",
    "                csv_table = pd.read_csv(csv_file[0], sep=\";\")\n",
    "\n",
    "            magnification.append(\n",
    "                csv_table[csv_table[\"video\"] == int(row[\"video_name\"])][\"Lens\"].iloc[0]\n",
    "            )\n",
    "            fps.append(\n",
    "                csv_table.loc[\n",
    "                    csv_table[\"video\"] == int(row[\"video_name\"].split(\"_\")[-1])\n",
    "                ][\"fps\"].iloc[0]\n",
    "            )\n",
    "            mode.append(\n",
    "                csv_table.loc[\n",
    "                    csv_table[\"video\"] == int(row[\"video_name\"].split(\"_\")[-1])\n",
    "                ][\"Illumination\"].iloc[0]\n",
    "            )\n",
    "            binning.append(\n",
    "                csv_table.loc[\n",
    "                    csv_table[\"video\"] == int(row[\"video_name\"].split(\"_\")[-1])\n",
    "                ][\"Binned\"].iloc[0]\n",
    "            )\n",
    "        else:\n",
    "            print(\"Halp! No datatable found! Pls add the excel file to the folders.\")\n",
    "\n",
    "dataframe[\"fps\"] = fps\n",
    "dataframe[\"magnification\"] = magnification\n",
    "dataframe[\"mode\"] = mode\n",
    "dataframe[\"parent_folder\"] = [\n",
    "    os.path.relpath(address, directory_targ) for address in dataframe[\"tot_path_drop\"]\n",
    "]\n",
    "dataframe[\"data_table\"] = data_table\n",
    "dataframe[\"binned\"] = binning\n",
    "\n",
    "dataframe = dataframe.sort_values(by=\"video_name\", ignore_index=True)\n",
    "# dataframe = dataframe[dataframe['video_nr']== 9]\n",
    "# dataframe = dataframe[dataframe['plate_nr'] == '046']\n",
    "# print(len(dataframe))\n",
    "# print(data_table)\n",
    "\n",
    "\n",
    "if dataframe.isnull().values.any():\n",
    "    print(\"Found NaNs in the excel files! Blame the experimentalists.\")\n",
    "    dataframe = dataframe.interpolate(method=\"pad\", limit_direction=\"forward\")\n",
    "if dataframe.isnull().values.any():\n",
    "    raise (\"This excel sheet is unworkable, please ask the responsible person\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f08d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_series = pd.Series(data_table).unique()\n",
    "excel_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cb59f7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for xl_address in excel_series:\n",
    "    file_name = \"Analysis/\" + os.path.relpath(xl_address, directory_targ)\n",
    "    print(upload_targ + file_name)\n",
    "    upload(xl_adress, upload_targ + file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bba2118",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
