{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from amftrack.pipeline.development.high_mag_videos.kymo_class import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import hsv_to_rgb\n",
    "import sys\n",
    "import imageio.v3 as imageio\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "from scipy.signal import correlate\n",
    "from scipy.signal import convolve2d\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from scipy.ndimage import zoom\n",
    "import os\n",
    "from skimage.filters import frangi\n",
    "from amftrack.pipeline.development.high_mag_videos.kymo_class import *\n",
    "import tifffile\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 300\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def vel_field(curr_frame, next_frame, win_size, segment, corr_thresh):\n",
    "    ys = np.arange(0, curr_frame.shape[0], win_size)\n",
    "    xs = np.arange(0, curr_frame.shape[1], win_size)\n",
    "    dys = np.zeros((len(ys), len(xs)))\n",
    "    dxs = np.zeros((len(ys), len(xs)))\n",
    "    for iy, y in enumerate(ys):\n",
    "        for ix, x in enumerate(xs):\n",
    "            seg_win = segment[y : y + win_size, x : x + win_size]\n",
    "            if np.sum(seg_win) < 5:\n",
    "                continue\n",
    "            int_win = curr_frame[y : y + win_size, x : x + win_size]\n",
    "            search_win = next_frame[y : y + win_size, x : x + win_size]\n",
    "            cross_corr = correlate(\n",
    "                search_win - search_win.mean(), int_win - int_win.mean(), method=\"fft\"\n",
    "            )\n",
    "            corr_check = cross_corr.max() / np.sum(abs(cross_corr))\n",
    "            if corr_check > corr_thresh:\n",
    "                dys[iy, ix], dxs[iy, ix] = (\n",
    "                    np.unravel_index(np.argmax(cross_corr), cross_corr.shape)\n",
    "                    - np.array([win_size, win_size])\n",
    "                    + 1\n",
    "                )\n",
    "    # draw velocity vectors from the center of each window\n",
    "    ys = ys + win_size / 2\n",
    "    xs = xs + win_size / 2\n",
    "    return xs, ys, dxs, dys\n",
    "\n",
    "def get_max_stack(pics, noise_thresh):\n",
    "    frame = imageio.v3.imread(pics[0])\n",
    "    frame_res = frame.shape\n",
    "    frame_max = frame.copy()\n",
    "    \n",
    "    for pic in tqdm(pics):\n",
    "        pic_frame = imageio.v3.imread(pic)\n",
    "        frame_max = np.maximum(frame_max, pic_frame)\n",
    "    if noise_thresh > 0:\n",
    "        frame_max = np.greater(frame_max, noise_thresh)\n",
    "    return frame_max\n",
    "\n",
    "def calc_arclength_arr(coords):\n",
    "    coords = np.array(coords)\n",
    "    u_arr = np.zeros((len(coords)))\n",
    "    coords2 = np.zeros(coords.shape)\n",
    "    coords2[1:] = coords[:-1]\n",
    "    coords2 = coords2.T\n",
    "    coords = coords.T\n",
    "    coords_dx = coords2[0] - coords[0]\n",
    "    coords_dy = coords2[1] - coords[1]\n",
    "    coords_dr = np.sqrt(coords_dx**2 + coords_dy**2)\n",
    "    u_arr[1:] = np.cumsum(coords_dr[1:])\n",
    "    return u_arr\n",
    "\n",
    "def curve_map_iter(image, iterations=3):\n",
    "    kernel_n = np.array([[0.5, 1, 0.5],\n",
    "                         [1, -10, 1],\n",
    "                         [0.5, 1, 0.5]])\n",
    "    for i in range(iterations):\n",
    "        img_neighbors = convolve2d((image > 0)*1, kernel_n, mode='same')\n",
    "        img_neighbors = np.where(img_neighbors > 0, img_neighbors, np.nan)\n",
    "        img_adj_sum = convolve2d(image, kernel_n, mode='same')\n",
    "#         img_adj_sum = np.where(img_adj_sum > 0, img_adj_sum, 0)\n",
    "        image_out = np.where(img_neighbors > 0, img_adj_sum/img_neighbors, 0)\n",
    "        image += image_out\n",
    "    \n",
    "    return np.where(image > 0, image, np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_folder = \"/gpfs/scratch1/shared/amftrackflow/videos/\"\n",
    "analysis_folder = \"/gpfs/home6/svstaalduine/Analysis/\"\n",
    "\n",
    "video_of_interest = \"/TransportROOT/DATA/20230407_Plate777/001/\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(analysis_folder + video_of_interest + 'video_data.json'):\n",
    "    video_info_frame = pd.read_json(analysis_folder + video_of_interest + 'video_data.json', orient='index')[0]\n",
    "#     print(video_info_frame['fps'])\n",
    "    analysis_obj = Kymo_video_analysis(input_frame = video_info_frame)\n",
    "    analysis_obj.plot_extraction_img(target_length=70)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.imshow(analysis_obj.segmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = imageio.imread(analysis_obj.selection_file[0])\n",
    "target_length = 50\n",
    "\n",
    "for edge in tqdm(analysis_obj.edge_objects):\n",
    "    edge_skeleton = analysis_obj.nx_graph_pruned.get_edge_data(edge.edge_name[0], edge.edge_name[1])[\"pixel_list\"]\n",
    "    u_arr = calc_arclength_arr(edge_skeleton) * analysis_obj.space_pixel_size\n",
    "    arc_map = np.zeros(image.shape).astype(float)\n",
    "    dist_array = np.ones(image.shape).astype(np.uint8)\n",
    "    for i, coord in enumerate(edge_skeleton):\n",
    "        arc_map[coord] = u_arr[i]\n",
    "        dist_array[coord] = 0\n",
    "    width_map = cv2.distanceTransform(dist_array, cv2.DIST_L2, 5)\n",
    "    width_map = np.where(width_map < target_length, width_map, np.nan)\n",
    "    curve_map = curve_map_iter(arc_map.copy(), iterations=target_length)\n",
    "    map_intersect = ~np.isnan(width_map) * ~np.isnan(curve_map)\n",
    "    tiff_out = [np.where(map_intersect, width_map, np.nan), np.where(map_intersect, curve_map, np.nan)]\n",
    "    tifffile.imwrite(f\"{analysis_folder + video_of_interest}/edge {edge.edge_name}/PIV_mask.tiff\", tiff_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_address = Path(videos_folder + video_of_interest)\n",
    "analysis_path = Path(analysis_folder + video_of_interest)\n",
    "\n",
    "video_address = input_address.joinpath('Img')\n",
    "\n",
    "pics = [pic for pic in video_address.glob('*.tiff')]\n",
    "\n",
    "piv_masks = np.ones(image.shape)\n",
    "for edge in analysis_obj.edge_objects:\n",
    "    piv_mask = np.isnan(tifffile.imread(f\"{analysis_folder + video_of_interest}/edge {edge.edge_name}/PIV_mask.tiff\")[0])\n",
    "    piv_masks *= piv_mask\n",
    "segment = (piv_masks == 0) * analysis_obj.segmented\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(segment)\n",
    "\n",
    "\n",
    "if not os.path.exists(analysis_path.joinpath(\"PIV/\")):\n",
    "    os.makedirs(analysis_path.joinpath(\"PIV/\"))\n",
    "pivanal_path = analysis_path.joinpath(\"PIV/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "frame_skip = 3\n",
    "pics = [pic for pic in video_address.glob('*.tif')]\n",
    "\n",
    "speed_thresh = 20 * analysis_obj.space_pixel_size\n",
    "frame_range = np.arange(0, len(pics), frame_skip)\n",
    "\n",
    "print(pics)\n",
    "\n",
    "dxss= []\n",
    "dyss= []\n",
    "\n",
    "for i, frame_nr in enumerate(tqdm(frame_range)):\n",
    "    if i == 0:\n",
    "        continue\n",
    "    else:\n",
    "        curr_frame =  cv2.GaussianBlur(imageio.v3.imread(pics[frame_range[i-1]]), (3,3), 0)\n",
    "        next_frame =  cv2.GaussianBlur(imageio.v3.imread(pics[frame_nr]), (3,3), 0)\n",
    "        _, _, dxs, dys = vel_field(curr_frame, next_frame, 6, segment*1, 0.001)\n",
    "\n",
    "        dxss.append(dxs)\n",
    "        dyss.append(dys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dxs = np.array([dxss, dyss])\n",
    "print(dxs.shape)\n",
    "dxs = dxs.transpose(1, 0, 2,3)\n",
    "tifffile.imwrite(pivanal_path.joinpath(\"PIVdxy.tiff\"), dxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dxs = tifffile.imread(pivanal_path.joinpath(\"PIVdxy.tiff\"))\n",
    "dxs_plt = dxs * 255 / dxs.max()\n",
    "fig, ax = plt.subplots(figsize=(7,7))\n",
    "ax.imshow(dxs_plt[2][0].astype(np.uint8))\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arc_bin_nr = 125\n",
    "wid_bin_nr = 15\n",
    "frame_nr = 0\n",
    "\n",
    "kymograph_x = np.empty((len(dxs), arc_bin_nr))\n",
    "kymograph_x[:] = np.nan\n",
    "kymograph_y = np.empty((len(dxs), arc_bin_nr))\n",
    "kymograph_y[:] = np.nan\n",
    "\n",
    "used_dxy = dxs[0]\n",
    "used_dy, used_dx = used_dxy\n",
    "\n",
    "for edge in analysis_obj.edge_objects:\n",
    "    \n",
    "    width_mask, arc_mask = tifffile.imread(f\"{analysis_folder + video_of_interest}/edge {edge.edge_name}/PIV_mask.tiff\")\n",
    "    width_mask = cv2.resize(width_mask, used_dx.T.shape)\n",
    "    arc_mask = cv2.resize(arc_mask, used_dx.T.shape)\n",
    "    arc_bins = np.linspace(0, np.nanmax(arc_mask), arc_bin_nr)\n",
    "    arc_index = np.digitize(arc_mask, arc_bins)\n",
    "    width_bins = np.linspace(0, np.nanmax(width_mask), wid_bin_nr)\n",
    "    width_index = np.digitize(width_mask, width_bins)\n",
    "    \n",
    "    for f in tqdm(range(len(dxs))):\n",
    "        used_dxy = dxs[f]\n",
    "        used_dy, used_dx = used_dxy\n",
    "        \n",
    "        edge_video_dx = np.empty((arc_bin_nr, wid_bin_nr))\n",
    "        edge_video_dy = np.empty((arc_bin_nr, wid_bin_nr))\n",
    "        edge_video_dx[:] = np.nan\n",
    "        edge_video_dy[:] = np.nan\n",
    "\n",
    "        for i, arc in enumerate(arc_bins):\n",
    "            for j, width in enumerate(width_bins):\n",
    "                vals_index = (arc_index == i) * (width_index==j)\n",
    "                vals_dx = np.nanmean(used_dx[vals_index].flatten())\n",
    "                vals_dy = np.nanmean(used_dy[vals_index].flatten())\n",
    "                edge_video_dx[i][j] = vals_dx\n",
    "                edge_video_dy[i][j] = vals_dy\n",
    "        kymograph_x[f] = np.nanmean(edge_video_dx, axis=1)\n",
    "        kymograph_y[f] = np.nanmean(edge_video_dy, axis=1)\n",
    "    \n",
    "    fig, ax = plt.subplots(1,2, figsize=(8, 4))\n",
    "    ax[0].imshow(kymograph_x, cmap='coolwarm')\n",
    "    ax[1].imshow(kymograph_y, cmap='coolwarm')\n",
    "    fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(np.nanmean(kymograph_x, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# space_res = .08625\n",
    "space_res = 2 * 1.725 / 50 * 2\n",
    "fps = 20\n",
    "noise_thresh = 20\n",
    "\n",
    "frame_max = get_max_stack(pics, noise_thresh)\n",
    "frame = imageio.v3.imread(pics[0])\n",
    "vid_dimen = frame.shape\n",
    "frangi_range = range(30, 160, 30)\n",
    "vid_frangi = frangi(frame, frangi_range)\n",
    "vid_frangi = vid_frangi * (255/np.max(vid_frangi))\n",
    "\n",
    "vid_extent = [0, space_res * vid_dimen[1], 0, space_res*vid_dimen[0]]\n",
    "\n",
    "segment = np.greater(vid_frangi, noise_thresh)\n",
    "\n",
    "fag, ax = plt.subplots(figsize=(6,6))\n",
    "ax.imshow(segment, extent=vid_extent, aspect='auto', cmap='gray', vmin=0)\n",
    "ax.set_xlabel('x ($\\mu m$)')\n",
    "ax.set_ylabel('y ($\\mu m$)')\n",
    "ax.set_title('Segmentation')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "norms_adj = np.where(np.array(norms) < 20, norms, 0)\n",
    "hues = (np.array(oris) + np.pi) / (2*np.pi)\n",
    "vals = np.array(norms_adj) / np.max(norms_adj)\n",
    "sats = np.ones(hues.shape)\n",
    "hsvs = np.array([hues, vals, sats])\n",
    "hsvs = np.transpose(hsvs, axes=[1,2,3,0])\n",
    "color_out = np.array(hsv_to_rgb(hsvs) * 256, dtype=np.uint8)\n",
    "\n",
    "hsvs_mean = hsv_to_rgb(np.max(hsvs, axis=0))\n",
    "\n",
    "imageio.mimwrite(analysis_path.joinpath('Analysis'+os.sep+'out.mp4'),\n",
    "                 color_out,\n",
    "                fps=fps,\n",
    "                quality=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_analysis = Kymo_video_analysis(str(input_address), logging=True, vid_type=None,\n",
    "                                 fps=None, binning=None, filter_step=80,\n",
    "                                seg_thresh=13, show_seg=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_list = vid_analysis.edge_objects\n",
    "\n",
    "### The print statement will give you the edge indices such that you can select which edges to analyze.\n",
    "print('\\n To work with individual edges, here is a list of their indices:')\n",
    "for i, edge in enumerate(edge_list):\n",
    "    print('edge {}, {}'.format(i, edge.edge_name))\n",
    "\n",
    "### Target length here determines the *width* of the analysis box.\n",
    "### Too shallow, and you won't capture the entire hypha, too big and the analysis is plagued with background.\n",
    "target_length = int(1.9*vid_analysis.magnification)\n",
    "\n",
    "vid_analysis.plot_extraction_img(target_length=target_length, save_img=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones((3,3), np.uint8)\n",
    "color_size = [np.shape(color_out)[2], np.shape(color_out)[1]]\n",
    "print(np.shape(color_out))\n",
    "print(frame_res[0]//4, frame_res[1]//4)\n",
    "\n",
    "for i, edge in enumerate(edge_list):\n",
    "    edge_mask_start = np.zeros(frame_res)\n",
    "    start_node, end_node = (edge.edge_name[0], edge.edge_name[1])\n",
    "    edge_skel = edge.video_analysis.nx_graph_pruned[start_node][end_node]['pixel_list']\n",
    "    for coord in edge_skel:\n",
    "        edge_mask_start[coord] = 1\n",
    "    edge_mask = cv2.dilate(edge_mask_start, kernel, iterations = target_length//2)\n",
    "    edge_mask = cv2.resize(edge_mask, color_size)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(color_out[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [img_path for img_path in pivanal_path.glob('*.png')]\n",
    "images = sorted(images)\n",
    "# images = [img_adr for img_adr in glob(img_address)]\n",
    "frame = cv2.imread(str(images[0]))\n",
    "height, width, layers = frame.shape\n",
    "video = cv2.VideoWriter(str(analysis_path.joinpath(\"PIV_video.mp4\")),\n",
    "                        cv2.VideoWriter_fourcc(*'MP4V'),\n",
    "                        10,\n",
    "                        (width,height))\n",
    "for image in images:\n",
    "    video.write(cv2.imread(str(image)))\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "norms_adj = np.where(np.array(norms) < 20, norms, 0)\n",
    "hues = (np.array(oris) + np.pi) / (2*np.pi)\n",
    "vals = np.array(norms_adj) / np.max(norms_adj)\n",
    "sats = np.ones(hues.shape)\n",
    "\n",
    "hsvs = np.array([hues, vals, sats])\n",
    "hsvs = np.transpose(hsvs, axes=[1,2,3,0])\n",
    "\n",
    "color_out = np.array(hsv_to_rgb(hsvs) * 256, dtype=np.uint8)\n",
    "# color_out = zoom(color_out, (1.0, 128, 128, 1))\n",
    "\n",
    "\n",
    "print(color_out.shape)\n",
    "# print(np.array(hsv_to_rgb(hsvs) * 256, dtype=np.uint8))\n",
    "\n",
    "hsvs_mean = hsv_to_rgb(np.max(hsvs, axis=0))\n",
    "\n",
    "imageio.mimwrite(video_address.joinpath('out.mp4'), \n",
    "                 color_out,\n",
    "                fps=fps,\n",
    "                quality=4)\n",
    "\n",
    "fig, ax = plt.subplots(2, figsize=(8, 14))\n",
    "# we need these flips on y since quiver uses a bottom-left origin, while our\n",
    "# arrays use a top-right origin\n",
    "ax[1].quiver(\n",
    "    xs,\n",
    "    ys,\n",
    "    np.where(norm_drs < 20, dxs, 0),\n",
    "    np.where(norm_drs < 20, dys, 0),\n",
    "    np.where(norm_drs < 20, norm_drs, 0),\n",
    "    cmap=\"plasma\",\n",
    "    angles=\"xy\",\n",
    "    scale_units=\"xy\",\n",
    "    scale=0.25,\n",
    ")\n",
    "ax[1].imshow(imageio.v3.imread(pics[-1]))\n",
    "ax[0].imshow(hsvs_mean)\n",
    "ax[0].set_aspect(\"equal\")\n",
    "# ax[1].imshow(np.max(oris, axis=0), cmap='coolwarm', vmin= -np.pi, vmax=np.pi)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
