{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c250d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import imageio.v3 as imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import glob\n",
    "import pandas as pd\n",
    "%matplotlib widget\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from amftrack.pipeline.functions.image_processing.extract_graph import (\n",
    "    from_sparse_to_graph,\n",
    "    generate_nx_graph,\n",
    "    clean_degree_4,\n",
    ")\n",
    "import scipy\n",
    "from matplotlib import gridspec\n",
    "from scipy.signal import correlate, correlation_lags\n",
    "from scipy.stats import pearsonr\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from itertools import groupby\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 300\n",
    "params = {\"ytick.color\" : \"w\",\n",
    "          \"xtick.color\" : \"w\",\n",
    "          \"axes.labelcolor\" : \"w\",\n",
    "          \"axes.edgecolor\" : \"w\"}\n",
    "\n",
    "plt.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1f4240",
   "metadata": {},
   "source": [
    "# Mass analysis module!\n",
    "Here all generated csv sheet will be read, and assembled in to two giant pandas dataframes: videos and hyphae.\n",
    "\n",
    "There are two datasheets that will be read:\n",
    "\n",
    "    - Datasheets that pertain to the properties of the videos\n",
    "    - Datasheets that contain the averaged results of the data\n",
    "Ideally, the first datasheet will be generated by thev VideoInfo.txt files that Morrison outputs, but there are still a lot of videos that were made before Morrison was fully operational. Later on, this document will also be able to read the TIFFs of individual hyphae to create more data.\n",
    "\n",
    "The first question to ask: Where is the analysis data stored? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de93e59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_target = \"/gpfs/scratch1/shared/amftrackflow/Rachael_set/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db4d2c9",
   "metadata": {},
   "source": [
    "## Initial reading\n",
    "This is where the video properties will be read from the excel files. It is called an initial reading, as this is just the raw data, which will be processed into a more legible datasheet in the next block. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b02a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_excels = sorted(glob.glob(directory_target + \"**/*.x*\"))\n",
    "ini_read = pd.read_excel(target_excels[0], nrows=0)\n",
    "\n",
    "for file in target_excels:\n",
    "    read = pd.read_excel(file)\n",
    "    ini_read = pd.concat([ini_read, read], ignore_index=True)\n",
    "\n",
    "ini_read = ini_read.drop(ini_read[ini_read['Magnification'].isnull()].index)\n",
    "ini_read"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29eb8673",
   "metadata": {},
   "source": [
    "## Standardization\n",
    "In the initial reading, the data can be from either an excel sheet, or a csv sheet. The next block will be about shaping that data into a more legible form, and doing some calculations where extra information is necessary. Right now, only excel sheets are supported, but csv support should come soon.\n",
    "\n",
    "This is also where a whole bunch of errors can come from if data documentation was not done properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be66a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_excel = True\n",
    "\n",
    "videos_data = ini_read.copy()\n",
    "videos_data[\"Plate_nr\"] = [int(plate.split('_')[-2][5:]) for plate in videos_data[\"Unnamed: 0\"]]\n",
    "videos_data[\"Magnification\"] = [int(mag) for mag in videos_data[\"Magnification\"]]\n",
    "videos_data[[\"FrameRate\", \"FPS\"][is_excel]] = [int(mag) for mag in videos_data[[\"FrameRate\",\"FPS\"][is_excel]]]\n",
    "videos_data[\"Time after crossing\"] = [int(mag.split(' ')[-2]) for mag in videos_data[\"Time after crossing\"]]\n",
    "videos_data[\"Address\"] = [glob.glob(directory_target + '/' + name.split(\"_\")[-3] + '*/' + name.split(\"_\")[-1]) for name in videos_data[\"Unnamed: 0\"]]\n",
    "# print(videos_data[\"Address\"].iloc[0])\n",
    "\n",
    "videos_data = videos_data[videos_data['Address'].map(len) > 0]\n",
    "videos_data[\"Address\"] = [entry[0] for entry in videos_data[\"Address\"]]\n",
    "videos_data = videos_data.rename(columns={\n",
    "    \"Unnamed: 0\" : \"video_title\",\n",
    "    'Time after crossing' : 'days_old',\n",
    "    'Growing temperature' : 'grow_temp',\n",
    "    'Position mm' : 'xpos',\n",
    "    'Unnamed: 6' : 'ypos',\n",
    "    'Bright-field (BF)\\nor\\nFluorescence (F)' : 'mode',\n",
    "    'Magnification' : 'mag',\n",
    "    'FPS' : 'fps',\n",
    "    'Binned (Y/N)' : 'binning',\n",
    "    'Video Length (s)' : 'vid_len'\n",
    "}, errors='Raise')\n",
    "\n",
    "# Below line takes all empty binning values, and assumes no binning took place. \n",
    "# Mostly for the first few days of Rachael's dataset.\n",
    "videos_data['binning'] = [np.where(entry == entry, np.where(entry == 'Y', 2, 1), 1) for entry in videos_data['binning']]\n",
    "videos_data[\"space_res\"] = 2.0 * 1.725 / videos_data['mag'] * videos_data['binning']\n",
    "\n",
    "videos_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272c0902",
   "metadata": {},
   "source": [
    "## Edges datasheet creation\n",
    "Each video has a number of edges, the averaged data of which is stored in the edges_data.csv file. This block of code reads that file, and creates a new row for each edge. These rows are expansions of the rows in the videos_data DataFrame from above. \n",
    "\n",
    "After many rounds of analysis (read: debugging the segmentation algorithm), there will be many more folders with edge data than edges in the video. By reading the edges_data.csv, only the most recently segmented edges are read. There should at some point be a purge of superfluous edge files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9806c1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_data = videos_data.copy()\n",
    "edges_data[\"edge_addr\"] = [glob.glob(entry + '/Analysis/edge *') for entry in edges_data[\"Address\"]]\n",
    "edges_data = edges_data.explode(\"edge_addr\")\n",
    "edges_data = edges_data.drop(edges_data[edges_data['edge_addr'].isnull()].index)\n",
    "edges_data.index = range(len(edges_data))\n",
    "edges_data[\"edge_name\"] = [row.split(os.sep)[-1][5:] for row in edges_data[\"edge_addr\"]]\n",
    "\n",
    "# print(edges_data.iloc[0])\n",
    "# edges_data = edges_data[edges_data[\"days_old\"] == 10]\n",
    "edge_results = pd.DataFrame()\n",
    "\n",
    "for index, row in edges_data.iterrows():\n",
    "    edge_csv_list = row['Address'] + '/Analysis/edges_data.csv'\n",
    "    if os.path.exists(edge_csv_list):\n",
    "        video_edge_data = pd.read_csv(edge_csv_list)\n",
    "        single_edge_data = video_edge_data[video_edge_data['edge_name'] == row['edge_name']]\n",
    "        if len(single_edge_data) > 0:\n",
    "            edge_results = pd.concat([edge_results, single_edge_data.set_index(pd.Index([index]))])\n",
    "        row = pd.concat([row, single_edge_data])\n",
    "    else:\n",
    "        print(edge_csv_list)\n",
    "        continue\n",
    "print(edge_csv_list)\n",
    "\n",
    "print(edges_data[\"Plate_nr\"].unique())\n",
    "edges_data = edges_data.join(edge_results, lsuffix='_l', rsuffix='_r')\n",
    "edges_data = edges_data[~np.isnan(edges_data['edge_xpos_1'])]\n",
    "\n",
    "print(edges_data.columns)\n",
    "\n",
    "edges_counts = edges_data.pivot_table(columns=['video_title'], aggfunc='size')\n",
    "videos_data['nr_of_edges'] = np.nan\n",
    "for index, row in videos_data.iterrows():\n",
    "    if row['video_title'] not in edges_counts.index:\n",
    "        print(f\"Oh no! {row['video_title']}\")\n",
    "        continue\n",
    "    edge_count = edges_counts[row['video_title']]    \n",
    "#     print(edge_count)\n",
    "    videos_data.loc[index, 'nr_of_edges'] = int(edge_count)\n",
    "    videos_data['coords'] = [str(i)+ str(j) for i,j in videos_data[['xpos', 'ypos']].values]\n",
    "\n",
    "edges_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6954245",
   "metadata": {},
   "source": [
    "### Width distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0b2e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(edges_data.columns)\n",
    "\n",
    "edges_filtered = edges_data.copy()\n",
    "edges_filtered = edges_filtered[edges_filtered['mag'].ge(6)]\n",
    "edges_fluo = edges_filtered[edges_filtered['mode'] == \"F\"]\n",
    "edges_bright = edges_filtered[edges_filtered['mode'] == \"BF\"]\n",
    "\n",
    "fig, ax = plt.subplots(facecolor='black')\n",
    "ax.hist(edges_fluo['edge_width'], bins=30, range=(0, 20), label=\"Fluorescence\", alpha=0.5)\n",
    "ax.hist(edges_bright['edge_width'], bins=30, range=(0, 20), label= \"Brightfield\", alpha=0.5)\n",
    "ax.set_title(\"Hypha widths histogram (50x mag)\", c='w')\n",
    "ax.set_xlabel(\"width $(\\mu m)$\", c='w')\n",
    "ax.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d055c2d",
   "metadata": {},
   "source": [
    "### Add number of edges in each video to videos dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a487b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "width_pairs = []\n",
    "\n",
    "videos_singlets = videos_data[videos_data['nr_of_edges'] == 1]\n",
    "for nr in videos_singlets['Plate_nr'].unique():\n",
    "    vid_single_plate = videos_singlets[videos_singlets['Plate_nr'] == nr]\n",
    "    for coord in vid_single_plate['coords'].unique():\n",
    "        single_edge = vid_single_plate[vid_single_plate['coords'] == coord]\n",
    "        if len(single_edge) > 1:\n",
    "            if single_edge['mode'].nunique() == 2:\n",
    "                single_edge_bf = single_edge[single_edge['mode'] == 'BF']\n",
    "                single_edge_fl = single_edge[single_edge['mode'] == 'F']\n",
    "                for title_bf in single_edge_bf['video_title']:\n",
    "                    edge_bf_data = edges_data[edges_data['video_title'] == title_bf]\n",
    "                    edge_bf_width = edge_bf_data['edge_width'].iloc[0]\n",
    "                    for title_f in single_edge_fl['video_title']:\n",
    "                        edge_fl_data = edges_data[edges_data['video_title'] == title_f]\n",
    "                        edge_fl_width = edge_fl_data['edge_width'].iloc[0]\n",
    "                        if edge_fl_data['binning'].iloc[0] == 1:\n",
    "                            edge_fl_width *= 2\n",
    "                        width_pairs.append([edge_bf_width, edge_fl_width])\n",
    "\n",
    "width_pairs = np.array(width_pairs)\n",
    "\n",
    "fig, ax = plt.subplots(facecolor='black')\n",
    "for pair in width_pairs:\n",
    "    ax.scatter(pair[0], pair[1], c='tab:blue')\n",
    "ax.set_ylim([3, 15])\n",
    "ax.set_xlim([5, 15])\n",
    "ax.set_xlabel(\"Bright-field edge width $(\\mu m)$\", c='w')\n",
    "ax.set_ylabel(\"Fluorescence edge width $(\\mu m)$\", c='w')\n",
    "ax.plot(np.arange(0, 20, 1), np.arange(0, 20, 1), c='black', linestyle='--', label='1:1')\n",
    "ax.set_title(\"Comparison of edge widths\", c='w')\n",
    "ax.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708ca051",
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_thresh = 0.3\n",
    "\n",
    "edges_filtered = edges_data[edges_data['coverage_tot'].ge(cov_thresh)]\n",
    "\n",
    "fig, ax = plt.subplots(facecolor='black')\n",
    "edges_fluo = edges_filtered\n",
    "print(edges_filtered[\"Plate_nr\"].unique())\n",
    "plate_nr = 558\n",
    "edges_filtered_nr = edges_fluo\n",
    "print(len(edges_fluo))\n",
    "\n",
    "ax.scatter(edges_filtered_nr['ypos'], edges_filtered_nr['speed_mean'], s=10, alpha=0.1, label='mean')\n",
    "# ax.scatter(edges_filtered_nr['ypos'], edges_filtered_nr['speed_left'], s=10, alpha=0.1, label='to root')\n",
    "ax.axhline(c='black', linestyle='--')\n",
    "\n",
    "# ax.scatter(edges_filtered_nr['edge_width'], edges_filtered_nr['speed_mean'], s=10, alpha=0.2, label='mean')\n",
    "y_series = sorted(edges_filtered_nr['ypos'].unique())\n",
    "y_r_mean = np.array([edges_filtered_nr['speed_mean'][edges_filtered['ypos'] == y].mean() for y in y_series])\n",
    "# y_r_std = np.array([edges_filtered_nr['speed_right'][edges_filtered['ypos'] == y].std() for y in y_series])\n",
    "# y_l_mean = np.array([edges_filtered_nr['speed_left'][edges_filtered['ypos'] == y].mean() for y in y_series])\n",
    "# y_l_std = np.array([edges_filtered_nr['speed_left'][edges_filtered['ypos'] == y].std() for y in y_series])\n",
    "\n",
    "y_r = pd.Series(data=y_r_mean, index = y_series)\n",
    "# y_l = pd.Series(data=y_l_mean, index = y_series)\n",
    "\n",
    "ax.plot(y_r.rolling(20).mean(), c='black', label='Rolling right average')\n",
    "# ax.fill_between(y_series, \n",
    "#                       y_r_mean + y_r_std, \n",
    "#                       y_r_mean - y_r_std, \n",
    "#                       alpha=0.5, facecolor='tab:blue')\n",
    "# ax.plot(y_l.rolling(20).mean(), c='tab:orange', label='Rolling left average')\n",
    "# ax.fill_between(y_series, \n",
    "#                       y_l_mean + y_l_std, \n",
    "#                       y_l_mean - y_l_std, \n",
    "#                       alpha=0.5, facecolor='tab:orange')\n",
    "\n",
    "# ax.set_xlim((0, 20))\n",
    "ax.set_ylabel(\"Speed $(\\mu m /s )$\", c='w')\n",
    "ax.set_xlabel(\"y-position (mm) (tip -> root)\", c='w')\n",
    "ax.set_title(f\"Scatter of y-position and speeds\", c='w')\n",
    "ax.set_xlim((15000, 50000))\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa575e3f",
   "metadata": {},
   "source": [
    "### Positional distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b9e8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for plate_nr in videos_data['Plate_nr'].unique():\n",
    "# plate_nr = 452\n",
    "\n",
    "    videos_filt = videos_data[videos_data['Plate_nr'] == plate_nr]\n",
    "    edges_filt = edges_data[edges_data['Plate_nr'] == plate_nr]\n",
    "    edges_filt = edges_filt[edges_filt['mode'] == \"F\"]\n",
    "#     edges_filt = edges_filt[edges_filt['mag'] == 50]\n",
    "    arr_lengths_r = np.arctan(edges_filt['speed_right'] / 10) * 6.5\n",
    "    arr_lengths_l = np.arctan(edges_filt['speed_left'] / 10) * 6.5\n",
    "\n",
    "    edge_ori_x = edges_filt['edge_xpos_2'] - edges_filt['edge_xpos_1']\n",
    "    edge_ori_y = edges_filt['edge_ypos_2'] - edges_filt['edge_ypos_1']\n",
    "    edge_ori_theta = -np.arctan2(edge_ori_x, edge_ori_y)\n",
    "    # print(np.array(edge_ori_theta))\n",
    "\n",
    "    xpos_4 = videos_filt[\"xpos\"][videos_filt[\"mag\"] == 4]\n",
    "    ypos_4 = -videos_filt[\"ypos\"][videos_filt[\"mag\"] == 4]\n",
    "\n",
    "    xpos_50 = videos_filt[\"xpos\"][videos_filt[\"mag\"] == 50]\n",
    "    ypos_50 = -videos_filt[\"ypos\"][videos_filt[\"mag\"] == 50]\n",
    "\n",
    "    # theta = np.linspace(0, 2*np.pi, 41, endpoint=True)\n",
    "    # radii, bin_edges = np.histogram(np.array(edge_ori_theta), bins=theta)\n",
    "    # width = (2*np.pi) / 41\n",
    "\n",
    "    # fig2 = plt.figure(facecolor='black')\n",
    "    # ax2 = plt.subplot(111, polar=True)\n",
    "    # bars = ax2.bar(theta[:-1], radii, width=width, bottom=50)\n",
    "    # ax2.set_title(\"Orientation histogram\", c='w')\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(16, 9), facecolor='black')\n",
    "    ax.scatter(xpos_50, ypos_50, c='tab:orange', s=2*12, label='50x mag')\n",
    "    ax.scatter(xpos_4, ypos_4, c='tab:green', s=2*12, label='4x mag', alpha=0.5)\n",
    "\n",
    "    ax.quiver(edges_filt['xpos'], -edges_filt['ypos'], \n",
    "              arr_lengths_r*np.cos(edge_ori_theta), \n",
    "              arr_lengths_r*np.sin(edge_ori_theta),\n",
    "              scale=300, width=0.0015, alpha=1.0, color='tab:blue')\n",
    "    ax.quiver(edges_filt['xpos'], -edges_filt['ypos'], \n",
    "              arr_lengths_l*np.cos(edge_ori_theta), \n",
    "              arr_lengths_l*np.sin(edge_ori_theta),\n",
    "              scale=300, width=0.0015, alpha=1.0, color='tab:orange')\n",
    "\n",
    "    ax.legend()\n",
    "    ax.set_title(f\"Fluorescence videos bi-directional velocity of {plate_nr}\")\n",
    "    ax.set_xlim((-5000, 60000))\n",
    "    ax.set_ylim([-50000, -15000])\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_ylabel(\"ypos\", c='w')\n",
    "    ax.set_xlabel(\"xpos\", c='w')\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(f\"/gpfs/home6/svstaalduine/plot_outs/plate_{plate_nr}_vidposs.png\", transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d014f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "\n",
    "forw=True\n",
    "back=True\n",
    "mean=True\n",
    "\n",
    "labels = []\n",
    "def set_axis_style(ax, labels):\n",
    "    ax.set_xticks(np.arange(1, len(labels) + 1), labels=labels)\n",
    "    ax.set_xlim(0.25, len(labels) + 0.75)\n",
    "    ax.set_xlabel('Sample name')\n",
    "    \n",
    "def add_label(violin, label):\n",
    "    color = violin[\"bodies\"][0].get_facecolor().flatten()\n",
    "    labels.append((mpatches.Patch(color=color), label))\n",
    "\n",
    "# [452 462 510 537 530 545 532 527 528 552 558] are the plate numbers\n",
    "plate_interest= None\n",
    "\n",
    "edges_cov = edges_data[edges_data['coverage_tot'].ge(cov_thresh)]\n",
    "edges_cov = edges_cov[edges_cov['mode'] == 'BF']\n",
    "if plate_interest is not None:\n",
    "    edges_cov = edges_cov[edges_cov['Plate_nr'] == plate_interest]\n",
    "\n",
    "# width_bins = [0, 4, 5,6,7,8,9,10, 11, 12, 13]\n",
    "width_bins = np.linspace(15000, 50000, 12)\n",
    "edges_cov['Binned'] = pd.cut(edges_cov['ypos'], width_bins)\n",
    "edges_binned = edges_cov.sort_values(by=['Binned'])\n",
    "plate_ages = edges_binned['Binned'].unique()\n",
    "bin_lens = []\n",
    "print(plate_ages)\n",
    "\n",
    "fig, ax = plt.subplots(facecolor='black', figsize=(10, 6))\n",
    "if forw:\n",
    "    spd_list_forw = []\n",
    "    for age in plate_ages:\n",
    "        edges_filt = edges_cov[edges_cov['Binned'] == age]\n",
    "        edges_filt = edges_filt.fillna(0)\n",
    "        spd_list_forw.append(np.array(edges_filt['flux_max']))\n",
    "    parts = ax.violinplot(spd_list_forw, showmeans=False, showextrema=False)\n",
    "    for pc in parts['bodies']:\n",
    "        pc.set_facecolor('tab:orange')\n",
    "        pc.set_edgecolor('black')\n",
    "        pc.set_alpha(1)\n",
    "    add_label(parts, 'To tip')\n",
    "    \n",
    "if back:\n",
    "    spd_list_back = []\n",
    "    for age in plate_ages:\n",
    "        edges_filt = edges_cov[edges_cov['Binned'] == age]\n",
    "        edges_filt = edges_filt.fillna(0)\n",
    "        spd_list_back.append(np.array(edges_filt['flux_min']))\n",
    "    parts = ax.violinplot(spd_list_back, showmeans=False, showextrema=False)\n",
    "    for pc in parts['bodies']:\n",
    "        pc.set_facecolor('tab:blue')\n",
    "        pc.set_edgecolor('black')\n",
    "        pc.set_alpha(1)\n",
    "    add_label(parts, 'To root')\n",
    "\n",
    "if mean:\n",
    "    spd_list_mean = []\n",
    "    for age in plate_ages:\n",
    "        edges_filt = edges_cov[edges_cov['Binned'] == age]\n",
    "        edges_filt = edges_filt.fillna(0)\n",
    "        spd_list_mean.append(np.array(edges_filt['flux_avg']))\n",
    "        bin_lens.append(len(edges_filt))\n",
    "    print(bin_lens)\n",
    "    parts = ax.violinplot(spd_list_mean, showmeans=False, showextrema=False)\n",
    "    for pc in parts['bodies']:\n",
    "        pc.set_facecolor('tab:red')\n",
    "        pc.set_edgecolor('black')\n",
    "        pc.set_alpha(1)\n",
    "    add_label(parts, 'Mean')\n",
    "\n",
    "ax.axhline(c='black', linestyle='--')\n",
    "    \n",
    "means = np.array([(i, np.mean(spds)) for i, spds in enumerate(spd_list_mean)]).T\n",
    "\n",
    "mean_ax = ax.scatter(means[0]+1, means[1], c='black', s=10, label='mean')\n",
    "ax.legend(*zip(*labels))\n",
    "plate_ages = [f\"{width.right / 1000 : 0.3}\" for width in plate_ages]\n",
    "\n",
    "\n",
    "set_axis_style(ax, plate_ages)\n",
    "ax.set_ylabel(\"Flux $(\\mu m / s)$\", c='w')\n",
    "# ax.set_xlabel(\"width $(\\mu m)$\", c='w')\n",
    "ax.set_xlabel(\"y-position $(mm)$, tip --> root\", c='w')\n",
    "# ax.set_ylim([-35, 35])\n",
    "ax2 = ax.twiny()\n",
    "ax2.set_xlim(ax.get_xlim())\n",
    "ax2.set_xticks(np.arange(len(bin_lens)) + 1)\n",
    "ax2.set_xticklabels(bin_lens)\n",
    "ax2.set_xlabel(\"Number of edges\", c='w')\n",
    "ax.set_title(\"Flow velocities average flux (fluorescence videos only)\", c='w')\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce28d92",
   "metadata": {},
   "source": [
    "## 50x and 4x comparisons\n",
    "\n",
    "First we filter out many edges with no coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92f9ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "videos_filt = videos_data[videos_data['mag'] == 4]\n",
    "videos_filt.index = range(len(videos_filt))\n",
    "# edges_filt = edges_filt[edges_filt['coverage_tot'] > 0.5]\n",
    "# edges_filt = edges_filt[edges_filt['coverage_left'] > 0.7]\n",
    "# edges_filt = edges_filt[edges_filt['speed_right_std'] < 0.5]\n",
    "# edges_filt['speed_range'] = edges_filt['speed_right'] - edges_filt['speed_left']\n",
    "# edges_filt = edges_filt[edges_filt['speed_range'] > 6]\n",
    "\n",
    "print(videos_filt.columns)\n",
    "# print(edges_filt['edge_name_r'])\n",
    "videos_filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086fd0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_4x_index = 43\n",
    "\n",
    "loc_tolerance = 1000\n",
    "for video_4x_index in tqdm(range(103)):\n",
    "    video_data = videos_filt.iloc[video_4x_index]\n",
    "    img_4x = imageio.imread(glob.glob(video_data['Address'] + \"/Img/Ba*.tif*\")[0])\n",
    "\n",
    "    x_adj = 100-750+400+75\n",
    "    y_adj = -500\n",
    "\n",
    "#     print(img_4x.shape)\n",
    "\n",
    "    edges_4x = edges_data[edges_data['Plate_nr'] == video_data['Plate_nr']]\n",
    "    edges_4x = edges_4x[edges_4x['mode'] == 'F']\n",
    "    edges_4x = edges_4x[edges_4x['xpos'].between(video_data['xpos']- loc_tolerance, video_data['xpos']+ loc_tolerance)]\n",
    "    edges_4x = edges_4x[edges_4x['ypos'].between(video_data['ypos']- loc_tolerance, video_data['ypos']+ loc_tolerance)]\n",
    "\n",
    "    fig, ax = plt.subplots( figsize = (16, 9), facecolor='black')\n",
    "    # ax.imshow(img_4x, extent=((video_data['xpos']- img_4x.shape[1]*0.5) + x_adj, (video_data['xpos'] + img_4x.shape[1]*0.5)+x_adj, \n",
    "    #                           (-video_data['ypos']) + y_adj, (-1*(video_data['ypos'] - img_4x.shape[0]))+y_adj))\n",
    "    ax.scatter(edges_4x['xpos'], -edges_4x['ypos'], label='50x video')\n",
    "    ax.scatter(video_data['xpos'], -video_data['ypos'], label='4x video')\n",
    "\n",
    "    for index, row in edges_4x.iterrows():\n",
    "        if row['mag'] == 4:\n",
    "            continue\n",
    "        arrow_start =  np.array([(row['xpos'] + row['space_res'] *row['edge_ypos_2'], \n",
    "                        (row['ypos'] + row['space_res'] *row['edge_xpos_2'])*-1)])[0]\n",
    "        arrow_end =    np.array([(row['xpos'] + row['space_res'] *row['edge_ypos_1'], \n",
    "                        (row['ypos'] + row['space_res'] *row['edge_xpos_1'])*-1)])[0] - arrow_start\n",
    "        ax.quiver(arrow_start[0], arrow_start[1], arrow_end[0], arrow_end[1], angles='xy', color=['tab:green', 'gray'][row['mag'] == 50], scale_units='xy', scale=1)\n",
    "    #     print(arrow_start, arrow_end)\n",
    "    ax.set_xlim((video_data['xpos']- img_4x.shape[1]*0.5) + x_adj, (video_data['xpos'] + img_4x.shape[1]*0.5)+x_adj)\n",
    "    ax.set_ylim((-video_data['ypos']) + y_adj, (-1*(video_data['ypos'] - img_4x.shape[0]))+y_adj)\n",
    "\n",
    "    used_videos = [row.split('_')[-1] for row in edges_4x['video_title'].unique()]\n",
    "#     print(used_videos)\n",
    "    ax.set_title(f\"4x overview of {video_data['video_title']}, \\n with 50x videos {used_videos[1:]}\", c='w')\n",
    "    ax.set_aspect('equal')\n",
    "    ax.legend()\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(f\"/gpfs/home6/svstaalduine/plot_outs/overviews_4x/{video_data['video_title']}_4x_overview.png\", transparent=True)\n",
    "    plt.close('all')\n",
    "# edges_4x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc03f8bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
