{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "118935f1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from amftrack.pipeline.development.high_mag_videos.kymo_class import *\n",
    "import os\n",
    "import pandas as pd\n",
    "import imageio.v2 as imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "%matplotlib widget\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from amftrack.pipeline.functions.image_processing.extract_graph import (\n",
    "    from_sparse_to_graph,\n",
    "    generate_nx_graph,\n",
    "    clean_degree_4,\n",
    ")\n",
    "import scipy\n",
    "from pathlib import Path\n",
    "from amftrack.pipeline.launching.run_super import run_parallel\n",
    "import re\n",
    "from amftrack.util.dbx import upload_folders, upload, download, read_saved_dropbox_state, save_dropbox_state, load_dbx, get_dropbox_folders, get_dropbox_video_folders\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e988655",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "directory_targ = \"/gpfs/scratch1/shared/amftrackflow/Rachael_set/\"\n",
    "upload_targ = \"/DATA/FLUORESCENCE/DATA_NileRed/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "836dd4d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gpfs/scratch1/shared/amftrackflow/Rachael_set/20230123_Plate545\n"
     ]
    }
   ],
   "source": [
    "test_name = glob(directory_targ + '*')[0]\n",
    "imgs_address = test_name\n",
    "print(test_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7e1ba1fb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gpfs/scratch1/shared/amftrackflow/Rachael_set/20230123_Plate545/34/\n",
      "Found NaNs in the excel files! Blame the experimentalists.\n"
     ]
    }
   ],
   "source": [
    "plate_list = glob(directory_targ + \"*_Plate*/*/\")\n",
    "datadict = {'address_total' : plate_list}\n",
    "dataframe = pd.DataFrame(data=datadict)\n",
    "\n",
    "print(dataframe['address_total'][0])\n",
    "\n",
    "dataframe['video_name'] = [address[:-1].split('/')[-1] for address in dataframe['address_total']]\n",
    "dataframe['plate_nr'] = [re.split('_|/', address.split('_')[-1])[0][5:] for address in dataframe['address_total']]\n",
    "dataframe['video_nr'] = [int(re.split('_|/', address[:-1])[-1]) for address in dataframe['address_total']]\n",
    "dataframe['date_imaged'] = [address.split('/')[-3][:8] for address in dataframe['address_total']]\n",
    "\n",
    "# print(dataframe['date_imaged'])\n",
    "\n",
    "parent_folder = []\n",
    "data_table = []\n",
    "magnification = []\n",
    "fps = []\n",
    "mode = []\n",
    "binning = []\n",
    "\n",
    "for row in dataframe.iloc:\n",
    "#     print(row['address_total'])\n",
    "    parent_folder.append(str(Path(row['address_total']).parent))\n",
    "    excel_file = glob(str(Path(row['address_total']).parent) + f'/*{row[\"date_imaged\"]}*{row[\"plate_nr\"]}.xl*')\n",
    "    if len(excel_file) > 0:\n",
    "        data_table.append(excel_file[0])\n",
    "        excel_table = pd.read_excel(excel_file[0])\n",
    "#         print(row['video_name'])\n",
    "#         print(excel_table['Unnamed: 0'][21])\n",
    "#         print(excel_table[excel_table['Unnamed: 0'].str.contains(row['video_name'], case=False, na=False)]['Magnification'])\n",
    "        magnification.append(excel_table[excel_table['Unnamed: 0'].str.contains(row['video_name'], case=False, na=False)]['Magnification'].iloc[0])\n",
    "    \n",
    "#         magnification.append(excel_table[excel_table['Unnamed: 0'].str.split(pat='_')[-1]] == row['video_name']['Magnification'].iloc[0])\n",
    "    \n",
    "        fps.append(excel_table.loc[excel_table['Unnamed: 0'].str.contains(row['video_name'], case=False, na=False)]['FPS'].iloc[0])\n",
    "        mode.append(excel_table.loc[excel_table['Unnamed: 0'].str.contains(row['video_name'], case=False, na=False)]['Bright-field (BF)\\nor\\nFluorescence (F)'].iloc[0])\n",
    "        if 'Binned (Y/N)' in excel_table:\n",
    "            binning.append(excel_table.loc[excel_table['Unnamed: 0'].str.contains(row['video_name'], case=False, na=False)]['Binned (Y/N)'].iloc[0])\n",
    "        else:\n",
    "            binning.append('N')\n",
    "    else:\n",
    "        csv_file = glob(str(Path(row['address_total']).parent) + f'/{row[\"date_imaged\"]}*{row[\"plate_nr\"]}.csv')\n",
    "        if len(csv_file) > 0:\n",
    "            data_table.append(csv_file[0])\n",
    "            df_comma = pd.read_csv(csv_file[0], nrows=1,sep=\",\")\n",
    "            df_semi = pd.read_csv(csv_file[0], nrows=1, sep=\";\")\n",
    "            if df_comma.shape[1]>df_semi.shape[1]:\n",
    "                csv_table = pd.read_csv(csv_file[0], sep=\",\")\n",
    "            else:\n",
    "                csv_table = pd.read_csv(csv_file[0], sep=\";\")\n",
    "                \n",
    "#             print(csv_table['video'])\n",
    "#             print(row['video_name'])\n",
    "            magnification.append(csv_table[csv_table['video']==int(row['video_name'])]['Lens'].iloc[0])\n",
    "            fps.append(csv_table.loc[csv_table['video'] == int(row['video_name'].split(\"_\")[-1])]['fps'].iloc[0])\n",
    "#             print(csv_table.loc[csv_table['video'] == int(row['video_name'].split(\"_\")[-1])]['fps'].iloc[0])\n",
    "            mode.append(csv_table.loc[csv_table['video'] == int(row['video_name'].split(\"_\")[-1])]['Illumination'].iloc[0])\n",
    "        else:\n",
    "            print(\"Halp! No datatable found! Pls add the excel file to the folders.\")\n",
    "\n",
    "dataframe['fps'] = fps\n",
    "dataframe['magnification'] = magnification\n",
    "dataframe['mode'] = mode\n",
    "dataframe['parent_folder'] = [os.path.relpath(address, directory_targ) for address in dataframe['address_total']]\n",
    "dataframe['data_table'] = data_table\n",
    "dataframe['binned'] = binning\n",
    "\n",
    "dataframe = dataframe.sort_values(by='video_name', ignore_index=True)\n",
    "# dataframe = dataframe[dataframe['video_nr']== 9]\n",
    "# dataframe = dataframe[dataframe['plate_nr'] == '046']\n",
    "# print(len(dataframe))\n",
    "# print(data_table)\n",
    "\n",
    "\n",
    "if dataframe.isnull().values.any():\n",
    "    print(\"Found NaNs in the excel files! Blame the experimentalists.\")\n",
    "    dataframe = dataframe.interpolate(method='pad', limit_direction='forward')\n",
    "if dataframe.isnull().values.any():\n",
    "    raise(\"This excel sheet is unworkable, please ask the responsible person\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "9eb97087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address_total</th>\n",
       "      <th>video_name</th>\n",
       "      <th>plate_nr</th>\n",
       "      <th>video_nr</th>\n",
       "      <th>date_imaged</th>\n",
       "      <th>fps</th>\n",
       "      <th>magnification</th>\n",
       "      <th>mode</th>\n",
       "      <th>parent_folder</th>\n",
       "      <th>data_table</th>\n",
       "      <th>binned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>/gpfs/scratch1/shared/amftrackflow/Rachael_set...</td>\n",
       "      <td>66</td>\n",
       "      <td>452</td>\n",
       "      <td>66</td>\n",
       "      <td>20221026</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>F</td>\n",
       "      <td>20221026_Plate452/66</td>\n",
       "      <td>/gpfs/scratch1/shared/amftrackflow/Rachael_set...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         address_total video_name plate_nr  \\\n",
       "782  /gpfs/scratch1/shared/amftrackflow/Rachael_set...         66      452   \n",
       "\n",
       "     video_nr date_imaged   fps  magnification mode         parent_folder  \\\n",
       "782        66    20221026  10.0            4.0    F  20221026_Plate452/66   \n",
       "\n",
       "                                            data_table binned  \n",
       "782  /gpfs/scratch1/shared/amftrackflow/Rachael_set...      N  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    \n",
    "dataframe_filtered = dataframe[dataframe['video_name'] == '66']\n",
    "dataframe_filtered = dataframe_filtered[dataframe_filtered['date_imaged'] == \"20221026\"]\n",
    "dataframe_filtered['plate_nr'].unique()\n",
    "dataframe_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "b0c49c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gpfs/scratch1/shared/amftrackflow/Rachael_set/\n",
      "/DATA/FLUORESCENCE/DATA_NileRed/\n"
     ]
    }
   ],
   "source": [
    "# FINAL CHECK FOR SOURCE FOLDER AND UPLOAD FOLDER\n",
    "\n",
    "# Please make sure that the upload folder is correct, \n",
    "# as the program WILL overwrite that which is already there.\n",
    "print(directory_targ)\n",
    "print(upload_targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "26548a30",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/svstaalduine/bash/job.sh\n",
      "Sending jobs with id 1687269230725776376\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 128 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 4 jobs.\n",
      "sbatch: By default shared jobs get 1792 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.25 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2946081\n"
     ]
    }
   ],
   "source": [
    "nr_parallel = np.min([len(dataframe.index), 16])\n",
    "\n",
    "run_parallel(\n",
    "    \"flux_extract.py\",\n",
    "    [directory_targ, 15, 0.95, 0.001, 60, upload_targ],\n",
    "    dataframe_filtered,\n",
    "    nr_parallel,\n",
    "    \"1:00:00\",\n",
    "    \"flux_extract\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acce42c0",
   "metadata": {},
   "source": [
    "Upload the proper excel files to the analysis folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57f08d04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['/gpfs/scratch1/shared/amftrackflow/Rachael_set/20230123_Plate545/Fluorescence_ex_20230123_Plate545.xlsx',\n",
       "       '/gpfs/scratch1/shared/amftrackflow/Rachael_set/20221108_Plate462/Fluorescence_ex_20221108_plate462.xlsx',\n",
       "       '/gpfs/scratch1/shared/amftrackflow/Rachael_set/20230125_Plate532/Fluorescence_ex_20230125_Plate532.xlsx',\n",
       "       '/gpfs/scratch1/shared/amftrackflow/Rachael_set/20221109_Plate462/Fluorescence_ex_20221109_plate462.xlsx',\n",
       "       '/gpfs/scratch1/shared/amftrackflow/Rachael_set/20230123_Plate530/Fluorescence_ex_20230123_Plate530.xlsx',\n",
       "       '/gpfs/scratch1/shared/amftrackflow/Rachael_set/20230201_Plate552/Fluorescence_ex_20230201_Plate552.xlsx',\n",
       "       '/gpfs/scratch1/shared/amftrackflow/Rachael_set/20221208_Plate510/Fluorescence_ex_20221208_Plate510.xlsx',\n",
       "       '/gpfs/scratch1/shared/amftrackflow/Rachael_set/20221026_Plate452/Fluorescence_ex_20221026_plate452.xlsx',\n",
       "       '/gpfs/scratch1/shared/amftrackflow/Rachael_set/20230201_Plate558/Fluorescence_ex_20230201_Plate558.xlsx',\n",
       "       '/gpfs/scratch1/shared/amftrackflow/Rachael_set/20221027_Plate452/Fluorescence_ex_20221027_plate452.xlsx',\n",
       "       '/gpfs/scratch1/shared/amftrackflow/Rachael_set/20230126_Plate528/Fluorescence_ex_20230126_Plate528.xlsx',\n",
       "       '/gpfs/scratch1/shared/amftrackflow/Rachael_set/20230126_Plate527/Fluorescence_ex_20230126_Plate527.xlsx',\n",
       "       '/gpfs/scratch1/shared/amftrackflow/Rachael_set/20230118_Plate537/Fluorescence_ex_20230118_Plate537.xlsx'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "excel_series = pd.Series(data_table).unique()\n",
    "excel_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51cb59f7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/DATA/FLUORESCENCE/DATA_NileRed/Analysis/20230123_Plate545/Fluorescence_ex_20230123_Plate545.xlsx\n",
      "2023-06-20 11:12:22,949-[INFO]- dropbox:390 -> Refreshing access token.\n",
      "2023-06-20 11:12:23,475-[INFO]- dropbox:474 -> Request to files/upload\n",
      "/DATA/FLUORESCENCE/DATA_NileRed/Analysis/20221108_Plate462/Fluorescence_ex_20221108_plate462.xlsx\n",
      "2023-06-20 11:12:24,281-[INFO]- dropbox:390 -> Refreshing access token.\n",
      "2023-06-20 11:12:24,452-[INFO]- dropbox:474 -> Request to files/upload\n",
      "/DATA/FLUORESCENCE/DATA_NileRed/Analysis/20230125_Plate532/Fluorescence_ex_20230125_Plate532.xlsx\n",
      "2023-06-20 11:12:24,970-[INFO]- dropbox:390 -> Refreshing access token.\n",
      "2023-06-20 11:12:25,158-[INFO]- dropbox:474 -> Request to files/upload\n",
      "/DATA/FLUORESCENCE/DATA_NileRed/Analysis/20221109_Plate462/Fluorescence_ex_20221109_plate462.xlsx\n",
      "2023-06-20 11:12:25,825-[INFO]- dropbox:390 -> Refreshing access token.\n",
      "2023-06-20 11:12:26,029-[INFO]- dropbox:474 -> Request to files/upload\n",
      "/DATA/FLUORESCENCE/DATA_NileRed/Analysis/20230123_Plate530/Fluorescence_ex_20230123_Plate530.xlsx\n",
      "2023-06-20 11:12:26,936-[INFO]- dropbox:390 -> Refreshing access token.\n",
      "2023-06-20 11:12:27,118-[INFO]- dropbox:474 -> Request to files/upload\n",
      "/DATA/FLUORESCENCE/DATA_NileRed/Analysis/20230201_Plate552/Fluorescence_ex_20230201_Plate552.xlsx\n",
      "2023-06-20 11:12:27,802-[INFO]- dropbox:390 -> Refreshing access token.\n",
      "2023-06-20 11:12:27,951-[INFO]- dropbox:474 -> Request to files/upload\n",
      "/DATA/FLUORESCENCE/DATA_NileRed/Analysis/20221208_Plate510/Fluorescence_ex_20221208_Plate510.xlsx\n",
      "2023-06-20 11:12:28,524-[INFO]- dropbox:390 -> Refreshing access token.\n",
      "2023-06-20 11:12:28,674-[INFO]- dropbox:474 -> Request to files/upload\n",
      "/DATA/FLUORESCENCE/DATA_NileRed/Analysis/20221026_Plate452/Fluorescence_ex_20221026_plate452.xlsx\n",
      "2023-06-20 11:12:29,265-[INFO]- dropbox:390 -> Refreshing access token.\n",
      "2023-06-20 11:12:29,418-[INFO]- dropbox:474 -> Request to files/upload\n",
      "/DATA/FLUORESCENCE/DATA_NileRed/Analysis/20230201_Plate558/Fluorescence_ex_20230201_Plate558.xlsx\n",
      "2023-06-20 11:12:30,140-[INFO]- dropbox:390 -> Refreshing access token.\n",
      "2023-06-20 11:12:30,291-[INFO]- dropbox:474 -> Request to files/upload\n",
      "/DATA/FLUORESCENCE/DATA_NileRed/Analysis/20221027_Plate452/Fluorescence_ex_20221027_plate452.xlsx\n",
      "2023-06-20 11:12:31,018-[INFO]- dropbox:390 -> Refreshing access token.\n",
      "2023-06-20 11:12:31,169-[INFO]- dropbox:474 -> Request to files/upload\n",
      "/DATA/FLUORESCENCE/DATA_NileRed/Analysis/20230126_Plate528/Fluorescence_ex_20230126_Plate528.xlsx\n",
      "2023-06-20 11:12:31,820-[INFO]- dropbox:390 -> Refreshing access token.\n",
      "2023-06-20 11:12:31,989-[INFO]- dropbox:474 -> Request to files/upload\n",
      "/DATA/FLUORESCENCE/DATA_NileRed/Analysis/20230126_Plate527/Fluorescence_ex_20230126_Plate527.xlsx\n",
      "2023-06-20 11:12:32,645-[INFO]- dropbox:390 -> Refreshing access token.\n",
      "2023-06-20 11:12:32,794-[INFO]- dropbox:474 -> Request to files/upload\n",
      "/DATA/FLUORESCENCE/DATA_NileRed/Analysis/20230118_Plate537/Fluorescence_ex_20230118_Plate537.xlsx\n",
      "2023-06-20 11:12:33,430-[INFO]- dropbox:390 -> Refreshing access token.\n",
      "2023-06-20 11:12:33,586-[INFO]- dropbox:474 -> Request to files/upload\n"
     ]
    }
   ],
   "source": [
    "for xl_address in excel_series:\n",
    "    file_name = \"Analysis/\" + os.path.relpath(xl_address, directory_targ)\n",
    "    print(upload_targ + file_name)\n",
    "    upload(xl_adress, upload_targ+file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bba2118",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
