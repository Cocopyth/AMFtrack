{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "118935f1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/home6/svstaalduine/AMF_project/amftrack/util/dbx.py:3: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gpfs/scratch1/shared/amftrackflow/temp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 12:18:26.179670: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-16 12:18:26.428661: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /gpfs/home6/svstaalduine/.local/lib/python3.9/site-packages/cv2/../../lib64:/sw/arch/Centos8/EB_production/2021/software/ZeroMQ/4.3.4-GCCcore-10.3.0/lib:/sw/arch/Centos8/EB_production/2021/software/util-linux/2.36-GCCcore-10.3.0/lib:/sw/arch/Centos8/EB_production/2021/software/libsodium/1.0.18-GCCcore-10.3.0/lib:/sw/arch/Centos8/EB_production/2021/software/OpenPGM/5.2.122-GCCcore-10.3.0/lib:/sw/arch/Centos8/EB_production/2021/software/Python/3.9.5-GCCcore-10.3.0/lib:/sw/arch/Centos8/EB_production/2021/software/OpenSSL/1.1/lib:/sw/arch/Centos8/EB_production/2021/software/libffi/3.3-GCCcore-10.3.0/lib64:/sw/arch/Centos8/EB_production/2021/software/GMP/6.2.1-GCCcore-10.3.0/lib:/sw/arch/Centos8/EB_production/2021/software/XZ/5.2.5-GCCcore-10.3.0/lib:/sw/arch/Centos8/EB_production/2021/software/SQLite/3.35.4-GCCcore-10.3.0/lib:/sw/arch/Centos8/EB_production/2021/software/Tcl/8.6.11-GCCcore-10.3.0/lib:/sw/arch/Centos8/EB_production/2021/software/libreadline/8.1-GCCcore-10.3.0/lib:/sw/arch/Centos8/EB_production/2021/software/ncurses/6.2-GCCcore-10.3.0/lib:/sw/arch/Centos8/EB_production/2021/software/bzip2/1.0.8-GCCcore-10.3.0/lib:/sw/arch/Centos8/EB_production/2021/software/binutils/2.36.1-GCCcore-10.3.0/lib:/sw/arch/Centos8/EB_production/2021/software/zlib/1.2.11-GCCcore-10.3.0/lib:/sw/arch/Centos8/EB_production/2021/software/GCCcore/10.3.0/lib64\n",
      "2023-06-16 12:18:26.428718: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-06-16 12:18:29.340915: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /gpfs/home6/svstaalduine/.local/lib/python3.9/site-packages/cv2/../../lib64:/sw/arch/Centos8/EB_production/2021/software/ZeroMQ/4.3.4-GCCcore-10.3.0/lib:/sw/arch/Centos8/EB_production/2021/software/util-linux/2.36-GCCcore-10.3.0/lib:/sw/arch/Centos8/EB_production/2021/software/libsodium/1.0.18-GCCcore-10.3.0/lib:/sw/arch/Centos8/EB_production/2021/software/OpenPGM/5.2.122-GCCcore-10.3.0/lib:/sw/arch/Centos8/EB_production/2021/software/Python/3.9.5-GCCcore-10.3.0/lib:/sw/arch/Centos8/EB_production/2021/software/OpenSSL/1.1/lib:/sw/arch/Centos8/EB_production/2021/software/libffi/3.3-GCCcore-10.3.0/lib64:/sw/arch/Centos8/EB_production/2021/software/GMP/6.2.1-GCCcore-10.3.0/lib:/sw/arch/Centos8/EB_production/2021/software/XZ/5.2.5-GCCcore-10.3.0/lib:/sw/arch/Centos8/EB_production/2021/software/SQLite/3.35.4-GCCcore-10.3.0/lib:/sw/arch/Centos8/EB_production/2021/software/Tcl/8.6.11-GCCcore-10.3.0/lib:/sw/arch/Centos8/EB_production/2021/software/libreadline/8.1-GCCcore-10.3.0/lib:/sw/arch/Centos8/EB_production/2021/software/ncurses/6.2-GCCcore-10.3.0/lib:/sw/arch/Centos8/EB_production/2021/software/bzip2/1.0.8-GCCcore-10.3.0/lib:/sw/arch/Centos8/EB_production/2021/software/binutils/2.36.1-GCCcore-10.3.0/lib:/sw/arch/Centos8/EB_production/2021/software/zlib/1.2.11-GCCcore-10.3.0/lib:/sw/arch/Centos8/EB_production/2021/software/GCCcore/10.3.0/lib64\n",
      "2023-06-16 12:18:29.341478: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /gpfs/home6/svstaalduine/.local/lib/python3.9/site-packages/cv2/../../lib64:/sw/arch/Centos8/EB_production/2021/software/ZeroMQ/4.3.4-GCCcore-10.3.0/lib:/sw/arch/Centos8/EB_production/2021/software/util-linux/2.36-GCCcore-10.3.0/lib:/sw/arch/Centos8/EB_production/2021/software/libsodium/1.0.18-GCCcore-10.3.0/lib:/sw/arch/Centos8/EB_production/2021/software/OpenPGM/5.2.122-GCCcore-10.3.0/lib:/sw/arch/Centos8/EB_production/2021/software/Python/3.9.5-GCCcore-10.3.0/lib:/sw/arch/Centos8/EB_production/2021/software/OpenSSL/1.1/lib:/sw/arch/Centos8/EB_production/2021/software/libffi/3.3-GCCcore-10.3.0/lib64:/sw/arch/Centos8/EB_production/2021/software/GMP/6.2.1-GCCcore-10.3.0/lib:/sw/arch/Centos8/EB_production/2021/software/XZ/5.2.5-GCCcore-10.3.0/lib:/sw/arch/Centos8/EB_production/2021/software/SQLite/3.35.4-GCCcore-10.3.0/lib:/sw/arch/Centos8/EB_production/2021/software/Tcl/8.6.11-GCCcore-10.3.0/lib:/sw/arch/Centos8/EB_production/2021/software/libreadline/8.1-GCCcore-10.3.0/lib:/sw/arch/Centos8/EB_production/2021/software/ncurses/6.2-GCCcore-10.3.0/lib:/sw/arch/Centos8/EB_production/2021/software/bzip2/1.0.8-GCCcore-10.3.0/lib:/sw/arch/Centos8/EB_production/2021/software/binutils/2.36.1-GCCcore-10.3.0/lib:/sw/arch/Centos8/EB_production/2021/software/zlib/1.2.11-GCCcore-10.3.0/lib:/sw/arch/Centos8/EB_production/2021/software/GCCcore/10.3.0/lib64\n",
      "2023-06-16 12:18:29.341495: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-06-16 12:18:33.219390: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /gpfs/home6/svstaalduine/.local/lib/python3.9/site-packages/cv2/../../lib64:/sw/arch/Centos8/EB_production/2021/software/ZeroMQ/4.3.4-GCCcore-10.3.0/lib:/sw/arch/Centos8/EB_production/2021/software/util-linux/2.36-GCCcore-10.3.0/lib:/sw/arch/Centos8/EB_production/2021/software/libsodium/1.0.18-GCCcore-10.3.0/lib:/sw/arch/Centos8/EB_production/2021/software/OpenPGM/5.2.122-GCCcore-10.3.0/lib:/sw/arch/Centos8/EB_production/2021/software/Python/3.9.5-GCCcore-10.3.0/lib:/sw/arch/Centos8/EB_production/2021/software/OpenSSL/1.1/lib:/sw/arch/Centos8/EB_production/2021/software/libffi/3.3-GCCcore-10.3.0/lib64:/sw/arch/Centos8/EB_production/2021/software/GMP/6.2.1-GCCcore-10.3.0/lib:/sw/arch/Centos8/EB_production/2021/software/XZ/5.2.5-GCCcore-10.3.0/lib:/sw/arch/Centos8/EB_production/2021/software/SQLite/3.35.4-GCCcore-10.3.0/lib:/sw/arch/Centos8/EB_production/2021/software/Tcl/8.6.11-GCCcore-10.3.0/lib:/sw/arch/Centos8/EB_production/2021/software/libreadline/8.1-GCCcore-10.3.0/lib:/sw/arch/Centos8/EB_production/2021/software/ncurses/6.2-GCCcore-10.3.0/lib:/sw/arch/Centos8/EB_production/2021/software/bzip2/1.0.8-GCCcore-10.3.0/lib:/sw/arch/Centos8/EB_production/2021/software/binutils/2.36.1-GCCcore-10.3.0/lib:/sw/arch/Centos8/EB_production/2021/software/zlib/1.2.11-GCCcore-10.3.0/lib:/sw/arch/Centos8/EB_production/2021/software/GCCcore/10.3.0/lib64\n",
      "2023-06-16 12:18:33.219475: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-06-16 12:18:33.219511: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (int4): /proc/driver/nvidia/version does not exist\n",
      "2023-06-16 12:18:33.219994: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from amftrack.pipeline.development.high_mag_videos.kymo_class import *\n",
    "import os\n",
    "import pandas as pd\n",
    "import imageio.v2 as imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "%matplotlib widget\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from amftrack.pipeline.functions.image_processing.extract_graph import (\n",
    "    from_sparse_to_graph,\n",
    "    generate_nx_graph,\n",
    "    clean_degree_4,\n",
    ")\n",
    "import scipy\n",
    "from pathlib import Path\n",
    "from amftrack.pipeline.launching.run_super import run_parallel\n",
    "import re\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e988655",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "directory_targ = \"/gpfs/scratch1/shared/amftrackflow/Hannah_set/1_year/\"\n",
    "upload_targ = \"/DATA/MYRISTATE/DATA/1_year/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "836dd4d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gpfs/scratch1/shared/amftrackflow/Hannah_set/1_year/20230512_Plate061\n"
     ]
    }
   ],
   "source": [
    "test_name = glob(directory_targ + '*')[0]\n",
    "imgs_address = test_name\n",
    "print(test_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e1ba1fb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found NaNs in the excel files! Blame the experimentalists.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address_total</th>\n",
       "      <th>video_name</th>\n",
       "      <th>plate_nr</th>\n",
       "      <th>video_nr</th>\n",
       "      <th>date_imaged</th>\n",
       "      <th>fps</th>\n",
       "      <th>magnification</th>\n",
       "      <th>mode</th>\n",
       "      <th>parent_folder</th>\n",
       "      <th>data_table</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>/gpfs/scratch1/shared/amftrackflow/Hannah_set/...</td>\n",
       "      <td>001</td>\n",
       "      <td>047</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>BF</td>\n",
       "      <td>20230512_Plate047/001</td>\n",
       "      <td>/gpfs/scratch1/shared/amftrackflow/Hannah_set/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>/gpfs/scratch1/shared/amftrackflow/Hannah_set/...</td>\n",
       "      <td>001</td>\n",
       "      <td>045</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>BF</td>\n",
       "      <td>20230512_Plate045/001</td>\n",
       "      <td>/gpfs/scratch1/shared/amftrackflow/Hannah_set/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>/gpfs/scratch1/shared/amftrackflow/Hannah_set/...</td>\n",
       "      <td>001</td>\n",
       "      <td>109</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>BF</td>\n",
       "      <td>20230512_Plate109/001</td>\n",
       "      <td>/gpfs/scratch1/shared/amftrackflow/Hannah_set/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>/gpfs/scratch1/shared/amftrackflow/Hannah_set/...</td>\n",
       "      <td>001</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>BF</td>\n",
       "      <td>20230512_Plate100/001</td>\n",
       "      <td>/gpfs/scratch1/shared/amftrackflow/Hannah_set/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>/gpfs/scratch1/shared/amftrackflow/Hannah_set/...</td>\n",
       "      <td>001</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>BF</td>\n",
       "      <td>20230512_Plate115/001</td>\n",
       "      <td>/gpfs/scratch1/shared/amftrackflow/Hannah_set/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>/gpfs/scratch1/shared/amftrackflow/Hannah_set/...</td>\n",
       "      <td>36</td>\n",
       "      <td>116</td>\n",
       "      <td>36</td>\n",
       "      <td></td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>BF</td>\n",
       "      <td>20230321_Plate116/36</td>\n",
       "      <td>/gpfs/scratch1/shared/amftrackflow/Hannah_set/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>/gpfs/scratch1/shared/amftrackflow/Hannah_set/...</td>\n",
       "      <td>37</td>\n",
       "      <td>116</td>\n",
       "      <td>37</td>\n",
       "      <td></td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>BF</td>\n",
       "      <td>20230321_Plate116/37</td>\n",
       "      <td>/gpfs/scratch1/shared/amftrackflow/Hannah_set/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>/gpfs/scratch1/shared/amftrackflow/Hannah_set/...</td>\n",
       "      <td>38</td>\n",
       "      <td>116</td>\n",
       "      <td>38</td>\n",
       "      <td></td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>BF</td>\n",
       "      <td>20230321_Plate116/38</td>\n",
       "      <td>/gpfs/scratch1/shared/amftrackflow/Hannah_set/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>/gpfs/scratch1/shared/amftrackflow/Hannah_set/...</td>\n",
       "      <td>39</td>\n",
       "      <td>116</td>\n",
       "      <td>39</td>\n",
       "      <td></td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>BF</td>\n",
       "      <td>20230321_Plate116/39</td>\n",
       "      <td>/gpfs/scratch1/shared/amftrackflow/Hannah_set/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>/gpfs/scratch1/shared/amftrackflow/Hannah_set/...</td>\n",
       "      <td>40</td>\n",
       "      <td>116</td>\n",
       "      <td>40</td>\n",
       "      <td></td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>BF</td>\n",
       "      <td>20230321_Plate116/40</td>\n",
       "      <td>/gpfs/scratch1/shared/amftrackflow/Hannah_set/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         address_total video_name plate_nr  \\\n",
       "33   /gpfs/scratch1/shared/amftrackflow/Hannah_set/...        001      047   \n",
       "195  /gpfs/scratch1/shared/amftrackflow/Hannah_set/...        001      045   \n",
       "99   /gpfs/scratch1/shared/amftrackflow/Hannah_set/...        001      109   \n",
       "26   /gpfs/scratch1/shared/amftrackflow/Hannah_set/...        001      100   \n",
       "218  /gpfs/scratch1/shared/amftrackflow/Hannah_set/...        001      115   \n",
       "..                                                 ...        ...      ...   \n",
       "257  /gpfs/scratch1/shared/amftrackflow/Hannah_set/...         36      116   \n",
       "245  /gpfs/scratch1/shared/amftrackflow/Hannah_set/...         37      116   \n",
       "273  /gpfs/scratch1/shared/amftrackflow/Hannah_set/...         38      116   \n",
       "260  /gpfs/scratch1/shared/amftrackflow/Hannah_set/...         39      116   \n",
       "267  /gpfs/scratch1/shared/amftrackflow/Hannah_set/...         40      116   \n",
       "\n",
       "     video_nr date_imaged  fps  magnification mode          parent_folder  \\\n",
       "33          1               20             50   BF  20230512_Plate047/001   \n",
       "195         1               20             50   BF  20230512_Plate045/001   \n",
       "99          1               20             50   BF  20230512_Plate109/001   \n",
       "26          1               20             50   BF  20230512_Plate100/001   \n",
       "218         1               20             50   BF  20230512_Plate115/001   \n",
       "..        ...         ...  ...            ...  ...                    ...   \n",
       "257        36               20             50   BF   20230321_Plate116/36   \n",
       "245        37               20             50   BF   20230321_Plate116/37   \n",
       "273        38               20             50   BF   20230321_Plate116/38   \n",
       "260        39               20             50   BF   20230321_Plate116/39   \n",
       "267        40               20             50   BF   20230321_Plate116/40   \n",
       "\n",
       "                                            data_table  \n",
       "33   /gpfs/scratch1/shared/amftrackflow/Hannah_set/...  \n",
       "195  /gpfs/scratch1/shared/amftrackflow/Hannah_set/...  \n",
       "99   /gpfs/scratch1/shared/amftrackflow/Hannah_set/...  \n",
       "26   /gpfs/scratch1/shared/amftrackflow/Hannah_set/...  \n",
       "218  /gpfs/scratch1/shared/amftrackflow/Hannah_set/...  \n",
       "..                                                 ...  \n",
       "257  /gpfs/scratch1/shared/amftrackflow/Hannah_set/...  \n",
       "245  /gpfs/scratch1/shared/amftrackflow/Hannah_set/...  \n",
       "273  /gpfs/scratch1/shared/amftrackflow/Hannah_set/...  \n",
       "260  /gpfs/scratch1/shared/amftrackflow/Hannah_set/...  \n",
       "267  /gpfs/scratch1/shared/amftrackflow/Hannah_set/...  \n",
       "\n",
       "[284 rows x 10 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plate_list = glob(directory_targ + \"*_Plate*/*/\")\n",
    "datadict = {'address_total' : plate_list}\n",
    "dataframe = pd.DataFrame(data=datadict)\n",
    "\n",
    "# print(dataframe['address_total'][0])\n",
    "\n",
    "dataframe['video_name'] = [address[:-1].split('/')[-1] for address in dataframe['address_total']]\n",
    "dataframe['plate_nr'] = [re.split('_|/', address.split('_')[-1])[0][5:] for address in dataframe['address_total']]\n",
    "dataframe['video_nr'] = [int(re.split('_|/', address[:-1])[-1]) for address in dataframe['address_total']]\n",
    "dataframe['date_imaged'] = [address.split('/')[-1][:8] for address in dataframe['address_total']]\n",
    "\n",
    "parent_folder = []\n",
    "data_table = []\n",
    "magnification = []\n",
    "fps = []\n",
    "mode = []\n",
    "\n",
    "for row in dataframe.iloc:\n",
    "#     print(row['address_total'])\n",
    "    parent_folder.append(str(Path(row['address_total']).parent))\n",
    "    excel_file = glob(str(Path(row['address_total']).parent) + f'/*{row[\"date_imaged\"]}*{row[\"plate_nr\"]}.xl*')\n",
    "    if len(excel_file) > 0:\n",
    "        data_table.append(excel_file[0])\n",
    "        excel_table = pd.read_excel(excel_file[0])\n",
    "#         print(row['video_name'])\n",
    "#         print(excel_table['Unnamed: 0'][21])\n",
    "#         print(excel_table[excel_table['Unnamed: 0'].str.contains(row['video_name'], case=False, na=False)]['Magnification'])\n",
    "        magnification.append(excel_table[excel_table['Unnamed: 0'].str.contains(row['video_name'], case=False, na=False)]['Magnification'].iloc[0])\n",
    "        fps.append(excel_table.loc[excel_table['Unnamed: 0'].str.contains(row['video_name'], case=False, na=False)]['FPS'].iloc[0])\n",
    "        mode.append(excel_table.loc[excel_table['Unnamed: 0'].str.contains(row['video_name'], case=False, na=False)]['Bright-field (BF)\\nor\\nFluorescence (F)'].iloc[0])\n",
    "        \n",
    "    else:\n",
    "        csv_file = glob(str(Path(row['address_total']).parent) + f'/{row[\"date_imaged\"]}*{row[\"plate_nr\"]}.csv')\n",
    "        if len(csv_file) > 0:\n",
    "            data_table.append(csv_file[0])\n",
    "            df_comma = pd.read_csv(csv_file[0], nrows=1,sep=\",\")\n",
    "            df_semi = pd.read_csv(csv_file[0], nrows=1, sep=\";\")\n",
    "            if df_comma.shape[1]>df_semi.shape[1]:\n",
    "                csv_table = pd.read_csv(csv_file[0], sep=\",\")\n",
    "            else:\n",
    "                csv_table = pd.read_csv(csv_file[0], sep=\";\")\n",
    "                \n",
    "#             print(csv_table['video'])\n",
    "#             print(row['video_name'])\n",
    "            magnification.append(csv_table[csv_table['video']==int(row['video_name'])]['Lens'].iloc[0])\n",
    "            fps.append(csv_table.loc[csv_table['video'] == int(row['video_name'].split(\"_\")[-1])]['fps'].iloc[0])\n",
    "#             print(csv_table.loc[csv_table['video'] == int(row['video_name'].split(\"_\")[-1])]['fps'].iloc[0])\n",
    "            mode.append(csv_table.loc[csv_table['video'] == int(row['video_name'].split(\"_\")[-1])]['Illumination'].iloc[0])\n",
    "\n",
    "        else:\n",
    "            print(\"Halp! No datatable found! Pls add the excel file to the folders.\")\n",
    "\n",
    "dataframe['fps'] = fps\n",
    "dataframe['magnification'] = magnification\n",
    "dataframe['mode'] = mode\n",
    "dataframe['parent_folder'] = [os.path.relpath(address, directory_targ) for address in dataframe['address_total']]\n",
    "dataframe['data_table'] = data_table\n",
    "\n",
    "dataframe = dataframe.sort_values(by='video_name')\n",
    "# dataframe = dataframe[dataframe['video_nr']== 9]\n",
    "# dataframe = dataframe[dataframe['plate_nr'] == '046']\n",
    "# print(len(dataframe))\n",
    "\n",
    "\n",
    "if dataframe.isnull().values.any():\n",
    "    print(\"Found NaNs in the excel files! Blame the experimentalists.\")\n",
    "    dataframe = dataframe.interpolate(method='pad', limit_direction='forward')\n",
    "if dataframe.isnull().values.any():\n",
    "    raise(\"This excel sheet is unworkable, please ask the responsible person\")\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b0c49c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gpfs/scratch1/shared/amftrackflow/Hannah_set/1_year/\n",
      "/DATA/MYRISTATE/DATA/1_year/\n"
     ]
    }
   ],
   "source": [
    "# FINAL CHECK FOR SOURCE FOLDER AND UPLOAD FOLDER\n",
    "\n",
    "# Please make sure that the upload folder is correct, \n",
    "# as the program WILL overwrite that which is already there.\n",
    "print(directory_targ)\n",
    "print(upload_targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "26548a30",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/svstaalduine/bash/job.sh\n",
      "Sending jobs with id 1686916354457145723\n",
      "284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 128 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 4 jobs.\n",
      "sbatch: By default shared jobs get 1792 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.25 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2927538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 128 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 4 jobs.\n",
      "sbatch: By default shared jobs get 1792 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.25 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2927539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 128 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 4 jobs.\n",
      "sbatch: By default shared jobs get 1792 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.25 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2927540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 128 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 4 jobs.\n",
      "sbatch: By default shared jobs get 1792 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.25 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2927541\n",
      "Submitted batch job 2927542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 128 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 4 jobs.\n",
      "sbatch: By default shared jobs get 1792 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.25 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2927543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 128 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 4 jobs.\n",
      "sbatch: By default shared jobs get 1792 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.25 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n",
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 128 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 4 jobs.\n",
      "sbatch: By default shared jobs get 1792 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.25 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2927544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 128 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 4 jobs.\n",
      "sbatch: By default shared jobs get 1792 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.25 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2927545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 128 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 4 jobs.\n",
      "sbatch: By default shared jobs get 1792 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.25 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2927546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 128 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 4 jobs.\n",
      "sbatch: By default shared jobs get 1792 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.25 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2927547\n",
      "Submitted batch job 2927548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 128 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 4 jobs.\n",
      "sbatch: By default shared jobs get 1792 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.25 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2927549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 128 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 4 jobs.\n",
      "sbatch: By default shared jobs get 1792 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.25 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n",
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 128 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 4 jobs.\n",
      "sbatch: By default shared jobs get 1792 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.25 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2927550\n",
      "Submitted batch job 2927551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 128 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 4 jobs.\n",
      "sbatch: By default shared jobs get 1792 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.25 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n",
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 128 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 4 jobs.\n",
      "sbatch: By default shared jobs get 1792 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.25 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2927552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 128 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 4 jobs.\n",
      "sbatch: By default shared jobs get 1792 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.25 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2927553\n",
      "Submitted batch job 2927554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 128 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 4 jobs.\n",
      "sbatch: By default shared jobs get 1792 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.25 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    }
   ],
   "source": [
    "nr_parallel = np.min([len(dataframe.index), 16])\n",
    "\n",
    "run_parallel(\n",
    "    \"flux_extract.py\",\n",
    "    [directory_targ, 15, 0.95, 0.001, 60, upload_targ],\n",
    "    dataframe,\n",
    "    nr_parallel,\n",
    "    \"1:00:00\",\n",
    "    \"flux_extract\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cb59f7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
