{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95be08ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/home6/svstaalduine/AMF_project/amftrack/util/dbx.py:3: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gpfs/scratch1/shared/amftrackflow/temp\n"
     ]
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from IPython.display import clear_output\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# sys.path.insert(0, os.getenv('HOME')+'/pycode/MscThesis/')\n",
    "# sys.path.insert(0,r'C:\\Users\\coren\\Documents\\PhD\\Code\\AMFtrack')\n",
    "\n",
    "import pandas as pd\n",
    "from amftrack.util.sys import (\n",
    "    get_dates_datetime,\n",
    "    get_dirname,\n",
    "    temp_path,\n",
    "    get_data_info,\n",
    "    update_plate_info,\n",
    "    get_current_folders,\n",
    "    get_folders_by_plate_id,\n",
    ")\n",
    "\n",
    "\n",
    "import ast\n",
    "from amftrack.plotutil import plot_t_tp1\n",
    "from scipy import sparse\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import scipy.io as sio\n",
    "from pymatreader import read_mat\n",
    "from matplotlib import colors\n",
    "import cv2\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from skimage.filters import frangi\n",
    "from skimage import filters\n",
    "from random import choice\n",
    "import scipy.sparse\n",
    "import os\n",
    "from amftrack.pipeline.functions.image_processing.extract_graph import (\n",
    "    from_sparse_to_graph,\n",
    "    generate_nx_graph,\n",
    "    sparse_to_doc,\n",
    ")\n",
    "from skimage.feature import hessian_matrix_det\n",
    "\n",
    "# from amftrack.pipeline.functions.image_processing.experiment_class_surf import Experiment\n",
    "from amftrack.pipeline.launching.run import (\n",
    "    run_transfer,\n",
    ")\n",
    "from amftrack.pipeline.launching.run_super import run_parallel_transfer\n",
    "\n",
    "import dropbox\n",
    "from amftrack.util.dbx import upload_folders, download, read_saved_dropbox_state, save_dropbox_state, load_dbx, download, get_dropbox_folders, get_dropbox_video_folders\n",
    "from subprocess import call\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.debug)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037f25a3",
   "metadata": {},
   "source": [
    "**To transfer data from dropbox to surfsara**\n",
    "- select the folders of interest within the folders of dropbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "741b6a21",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>folder</th>\n",
       "      <th>Plate number</th>\n",
       "      <th>Date Imaged</th>\n",
       "      <th>tot_path_drop</th>\n",
       "      <th>video</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20230123_Plate530_001</td>\n",
       "      <td>530</td>\n",
       "      <td>20230123</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230123_Plate5...</td>\n",
       "      <td>001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20230123_Plate530_002</td>\n",
       "      <td>530</td>\n",
       "      <td>20230123</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230123_Plate5...</td>\n",
       "      <td>002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20230123_Plate530_003</td>\n",
       "      <td>530</td>\n",
       "      <td>20230123</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230123_Plate5...</td>\n",
       "      <td>003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20230123_Plate530_004</td>\n",
       "      <td>530</td>\n",
       "      <td>20230123</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230123_Plate5...</td>\n",
       "      <td>004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20230123_Plate530_005</td>\n",
       "      <td>530</td>\n",
       "      <td>20230123</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230123_Plate5...</td>\n",
       "      <td>005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>20230201_Plate558_37</td>\n",
       "      <td>558</td>\n",
       "      <td>20230201</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230201_Plate5...</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801</th>\n",
       "      <td>20230201_Plate558_38</td>\n",
       "      <td>558</td>\n",
       "      <td>20230201</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230201_Plate5...</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>20230201_Plate558_39</td>\n",
       "      <td>558</td>\n",
       "      <td>20230201</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230201_Plate5...</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>20230201_Plate558_40</td>\n",
       "      <td>558</td>\n",
       "      <td>20230201</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230201_Plate5...</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>20230201_Plate558_41</td>\n",
       "      <td>558</td>\n",
       "      <td>20230201</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230201_Plate5...</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>805 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    folder Plate number Date Imaged  \\\n",
       "0    20230123_Plate530_001          530    20230123   \n",
       "1    20230123_Plate530_002          530    20230123   \n",
       "2    20230123_Plate530_003          530    20230123   \n",
       "3    20230123_Plate530_004          530    20230123   \n",
       "4    20230123_Plate530_005          530    20230123   \n",
       "..                     ...          ...         ...   \n",
       "800   20230201_Plate558_37          558    20230201   \n",
       "801   20230201_Plate558_38          558    20230201   \n",
       "802   20230201_Plate558_39          558    20230201   \n",
       "803   20230201_Plate558_40          558    20230201   \n",
       "804   20230201_Plate558_41          558    20230201   \n",
       "\n",
       "                                         tot_path_drop video  \n",
       "0    DATA/FLUORESCENCE/DATA_NileRed/20230123_Plate5...   001  \n",
       "1    DATA/FLUORESCENCE/DATA_NileRed/20230123_Plate5...   002  \n",
       "2    DATA/FLUORESCENCE/DATA_NileRed/20230123_Plate5...   003  \n",
       "3    DATA/FLUORESCENCE/DATA_NileRed/20230123_Plate5...   004  \n",
       "4    DATA/FLUORESCENCE/DATA_NileRed/20230123_Plate5...   005  \n",
       "..                                                 ...   ...  \n",
       "800  DATA/FLUORESCENCE/DATA_NileRed/20230201_Plate5...    37  \n",
       "801  DATA/FLUORESCENCE/DATA_NileRed/20230201_Plate5...    38  \n",
       "802  DATA/FLUORESCENCE/DATA_NileRed/20230201_Plate5...    39  \n",
       "803  DATA/FLUORESCENCE/DATA_NileRed/20230201_Plate5...    40  \n",
       "804  DATA/FLUORESCENCE/DATA_NileRed/20230201_Plate5...    41  \n",
       "\n",
       "[805 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory_targ = \"/gpfs/scratch1/shared/amftrackflow/Drp_downs/20221026_Plate452/\"\n",
    "\n",
    "if not os.path.exists(directory_targ):\n",
    "    os.makedirs(directory_targ)\n",
    "\n",
    "all_folders_drop, excel_drop = get_dropbox_video_folders(\"/DATA/FLUORESCENCE/DATA_NileRed/\", True)\n",
    "# folders_drop = all_folders_drop.loc[all_folders_drop[\"Plate number\"] == \"452\"]\n",
    "\n",
    "# for xl_adress in excel_drop:\n",
    "#     file_name = xl_adress.split('/')[-1]\n",
    "    \n",
    "#     download(xl_adress, directory_targ+file_name)\n",
    "clear_output(wait=False)\n",
    "\n",
    "all_folders_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ab21ced",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "directory_targ = \"/gpfs/scratch1/shared/amftrackflow/Rachael_dataset/\"\n",
    "folders_drop = all_folders_drop.loc[all_folders_drop[\"Plate number\"] == \"452\"]\n",
    "all_folders_drop.to_json(\"/gpfs/home6/svstaalduine/dropbox_file_structure/data_nile_red.json\")\n",
    "\n",
    "\n",
    "# save_dropbox_state(\"/DATA/FLUORESCENCE/DATA_NileRed/20230201_Plate552/\", is_video=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fac44fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "folders_drop = folders_drop.sort_values(by=['folder'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fd95d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689543\n",
      "Submitted batch job 2689544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n",
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689581\n",
      "Submitted batch job 2689582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n",
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689598\n",
      "Submitted batch job 2689599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n",
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689612\n",
      "Submitted batch job 2689613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n",
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689617\n",
      "Submitted batch job 2689618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n",
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689642\n",
      "Submitted batch job 2689643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n",
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689822\n",
      "Submitted batch job 2689853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n",
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689855\n",
      "Submitted batch job 2689856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n",
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689889\n",
      "Submitted batch job 2689890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n",
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 2689906\n"
     ]
    }
   ],
   "source": [
    "run_parallel_transfer(\n",
    "    \"from_drop.py\",\n",
    "    [directory_targ],\n",
    "    folders_drop,\n",
    "    1,\n",
    "    \"10:00:00\",\n",
    "    \"transfer_test\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a49f377",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "841d0860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>folder</th>\n",
       "      <th>Plate number</th>\n",
       "      <th>Date Imaged</th>\n",
       "      <th>tot_path_drop</th>\n",
       "      <th>video</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20230126_Plate528_01</td>\n",
       "      <td>528</td>\n",
       "      <td>20230126</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20230126_Plate528_02</td>\n",
       "      <td>528</td>\n",
       "      <td>20230126</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...</td>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20230126_Plate528_03</td>\n",
       "      <td>528</td>\n",
       "      <td>20230126</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...</td>\n",
       "      <td>03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20230126_Plate528_04</td>\n",
       "      <td>528</td>\n",
       "      <td>20230126</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...</td>\n",
       "      <td>04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20230126_Plate528_05</td>\n",
       "      <td>528</td>\n",
       "      <td>20230126</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...</td>\n",
       "      <td>05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20230126_Plate528_06</td>\n",
       "      <td>528</td>\n",
       "      <td>20230126</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...</td>\n",
       "      <td>06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20230126_Plate528_07</td>\n",
       "      <td>528</td>\n",
       "      <td>20230126</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...</td>\n",
       "      <td>07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20230126_Plate528_08</td>\n",
       "      <td>528</td>\n",
       "      <td>20230126</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...</td>\n",
       "      <td>08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20230126_Plate528_09</td>\n",
       "      <td>528</td>\n",
       "      <td>20230126</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...</td>\n",
       "      <td>09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20230126_Plate528_10</td>\n",
       "      <td>528</td>\n",
       "      <td>20230126</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20230126_Plate528_11</td>\n",
       "      <td>528</td>\n",
       "      <td>20230126</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20230126_Plate528_12</td>\n",
       "      <td>528</td>\n",
       "      <td>20230126</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20230126_Plate528_13</td>\n",
       "      <td>528</td>\n",
       "      <td>20230126</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20230126_Plate528_14</td>\n",
       "      <td>528</td>\n",
       "      <td>20230126</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20230126_Plate528_15</td>\n",
       "      <td>528</td>\n",
       "      <td>20230126</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>20230126_Plate528_16</td>\n",
       "      <td>528</td>\n",
       "      <td>20230126</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>20230126_Plate528_17</td>\n",
       "      <td>528</td>\n",
       "      <td>20230126</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>20230126_Plate528_18</td>\n",
       "      <td>528</td>\n",
       "      <td>20230126</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20230126_Plate528_19</td>\n",
       "      <td>528</td>\n",
       "      <td>20230126</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20230126_Plate528_20</td>\n",
       "      <td>528</td>\n",
       "      <td>20230126</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20230126_Plate528_21</td>\n",
       "      <td>528</td>\n",
       "      <td>20230126</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>20230126_Plate528_22</td>\n",
       "      <td>528</td>\n",
       "      <td>20230126</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>20230126_Plate528_23</td>\n",
       "      <td>528</td>\n",
       "      <td>20230126</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>20230126_Plate528_24</td>\n",
       "      <td>528</td>\n",
       "      <td>20230126</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>20230126_Plate528_25</td>\n",
       "      <td>528</td>\n",
       "      <td>20230126</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>20230126_Plate528_26</td>\n",
       "      <td>528</td>\n",
       "      <td>20230126</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>20230126_Plate528_27</td>\n",
       "      <td>528</td>\n",
       "      <td>20230126</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>20230126_Plate528_28</td>\n",
       "      <td>528</td>\n",
       "      <td>20230126</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>20230126_Plate528_29</td>\n",
       "      <td>528</td>\n",
       "      <td>20230126</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>20230126_Plate528_30</td>\n",
       "      <td>528</td>\n",
       "      <td>20230126</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>20230126_Plate528_31</td>\n",
       "      <td>528</td>\n",
       "      <td>20230126</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>20230126_Plate528_32</td>\n",
       "      <td>528</td>\n",
       "      <td>20230126</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>20230126_Plate528_33</td>\n",
       "      <td>528</td>\n",
       "      <td>20230126</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>20230126_Plate528_34</td>\n",
       "      <td>528</td>\n",
       "      <td>20230126</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>20230126_Plate528_35</td>\n",
       "      <td>528</td>\n",
       "      <td>20230126</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>20230126_Plate528_36</td>\n",
       "      <td>528</td>\n",
       "      <td>20230126</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>20230126_Plate528_37</td>\n",
       "      <td>528</td>\n",
       "      <td>20230126</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>20230126_Plate528_38</td>\n",
       "      <td>528</td>\n",
       "      <td>20230126</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>20230126_Plate528_39</td>\n",
       "      <td>528</td>\n",
       "      <td>20230126</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  folder Plate number Date Imaged  \\\n",
       "0   20230126_Plate528_01          528    20230126   \n",
       "1   20230126_Plate528_02          528    20230126   \n",
       "2   20230126_Plate528_03          528    20230126   \n",
       "3   20230126_Plate528_04          528    20230126   \n",
       "4   20230126_Plate528_05          528    20230126   \n",
       "5   20230126_Plate528_06          528    20230126   \n",
       "6   20230126_Plate528_07          528    20230126   \n",
       "7   20230126_Plate528_08          528    20230126   \n",
       "8   20230126_Plate528_09          528    20230126   \n",
       "9   20230126_Plate528_10          528    20230126   \n",
       "10  20230126_Plate528_11          528    20230126   \n",
       "11  20230126_Plate528_12          528    20230126   \n",
       "12  20230126_Plate528_13          528    20230126   \n",
       "13  20230126_Plate528_14          528    20230126   \n",
       "14  20230126_Plate528_15          528    20230126   \n",
       "15  20230126_Plate528_16          528    20230126   \n",
       "16  20230126_Plate528_17          528    20230126   \n",
       "17  20230126_Plate528_18          528    20230126   \n",
       "18  20230126_Plate528_19          528    20230126   \n",
       "19  20230126_Plate528_20          528    20230126   \n",
       "20  20230126_Plate528_21          528    20230126   \n",
       "21  20230126_Plate528_22          528    20230126   \n",
       "22  20230126_Plate528_23          528    20230126   \n",
       "23  20230126_Plate528_24          528    20230126   \n",
       "24  20230126_Plate528_25          528    20230126   \n",
       "25  20230126_Plate528_26          528    20230126   \n",
       "26  20230126_Plate528_27          528    20230126   \n",
       "27  20230126_Plate528_28          528    20230126   \n",
       "28  20230126_Plate528_29          528    20230126   \n",
       "29  20230126_Plate528_30          528    20230126   \n",
       "30  20230126_Plate528_31          528    20230126   \n",
       "31  20230126_Plate528_32          528    20230126   \n",
       "32  20230126_Plate528_33          528    20230126   \n",
       "33  20230126_Plate528_34          528    20230126   \n",
       "34  20230126_Plate528_35          528    20230126   \n",
       "35  20230126_Plate528_36          528    20230126   \n",
       "36  20230126_Plate528_37          528    20230126   \n",
       "37  20230126_Plate528_38          528    20230126   \n",
       "38  20230126_Plate528_39          528    20230126   \n",
       "\n",
       "                                        tot_path_drop video  \n",
       "0   DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...    01  \n",
       "1   DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...    02  \n",
       "2   DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...    03  \n",
       "3   DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...    04  \n",
       "4   DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...    05  \n",
       "5   DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...    06  \n",
       "6   DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...    07  \n",
       "7   DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...    08  \n",
       "8   DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...    09  \n",
       "9   DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...    10  \n",
       "10  DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...    11  \n",
       "11  DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...    12  \n",
       "12  DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...    13  \n",
       "13  DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...    14  \n",
       "14  DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...    15  \n",
       "15  DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...    16  \n",
       "16  DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...    17  \n",
       "17  DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...    18  \n",
       "18  DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...    19  \n",
       "19  DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...    20  \n",
       "20  DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...    21  \n",
       "21  DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...    22  \n",
       "22  DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...    23  \n",
       "23  DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...    24  \n",
       "24  DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...    25  \n",
       "25  DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...    26  \n",
       "26  DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...    27  \n",
       "27  DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...    28  \n",
       "28  DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...    29  \n",
       "29  DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...    30  \n",
       "30  DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...    31  \n",
       "31  DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...    32  \n",
       "32  DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...    33  \n",
       "33  DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...    34  \n",
       "34  DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...    35  \n",
       "35  DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...    36  \n",
       "36  DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...    37  \n",
       "37  DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...    38  \n",
       "38  DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...    39  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_folders_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70a8e114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>folder</th>\n",
       "      <th>Plate number</th>\n",
       "      <th>Date Imaged</th>\n",
       "      <th>tot_path_drop</th>\n",
       "      <th>video</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20230126_Plate528_01</td>\n",
       "      <td>528</td>\n",
       "      <td>20230126</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20230126_Plate528_02</td>\n",
       "      <td>528</td>\n",
       "      <td>20230126</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...</td>\n",
       "      <td>02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20230126_Plate528_03</td>\n",
       "      <td>528</td>\n",
       "      <td>20230126</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...</td>\n",
       "      <td>03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20230126_Plate528_04</td>\n",
       "      <td>528</td>\n",
       "      <td>20230126</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...</td>\n",
       "      <td>04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20230126_Plate528_05</td>\n",
       "      <td>528</td>\n",
       "      <td>20230126</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...</td>\n",
       "      <td>05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20230126_Plate528_06</td>\n",
       "      <td>528</td>\n",
       "      <td>20230126</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...</td>\n",
       "      <td>06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20230126_Plate528_07</td>\n",
       "      <td>528</td>\n",
       "      <td>20230126</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...</td>\n",
       "      <td>07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20230126_Plate528_08</td>\n",
       "      <td>528</td>\n",
       "      <td>20230126</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...</td>\n",
       "      <td>08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20230126_Plate528_09</td>\n",
       "      <td>528</td>\n",
       "      <td>20230126</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...</td>\n",
       "      <td>09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20230126_Plate528_10</td>\n",
       "      <td>528</td>\n",
       "      <td>20230126</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20230126_Plate528_11</td>\n",
       "      <td>528</td>\n",
       "      <td>20230126</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20230126_Plate528_12</td>\n",
       "      <td>528</td>\n",
       "      <td>20230126</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20230126_Plate528_13</td>\n",
       "      <td>528</td>\n",
       "      <td>20230126</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20230126_Plate528_14</td>\n",
       "      <td>528</td>\n",
       "      <td>20230126</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20230126_Plate528_15</td>\n",
       "      <td>528</td>\n",
       "      <td>20230126</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>20230126_Plate528_16</td>\n",
       "      <td>528</td>\n",
       "      <td>20230126</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>20230126_Plate528_17</td>\n",
       "      <td>528</td>\n",
       "      <td>20230126</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>20230126_Plate528_18</td>\n",
       "      <td>528</td>\n",
       "      <td>20230126</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20230126_Plate528_19</td>\n",
       "      <td>528</td>\n",
       "      <td>20230126</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20230126_Plate528_20</td>\n",
       "      <td>528</td>\n",
       "      <td>20230126</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20230126_Plate528_21</td>\n",
       "      <td>528</td>\n",
       "      <td>20230126</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>20230126_Plate528_22</td>\n",
       "      <td>528</td>\n",
       "      <td>20230126</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>20230126_Plate528_23</td>\n",
       "      <td>528</td>\n",
       "      <td>20230126</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>20230126_Plate528_24</td>\n",
       "      <td>528</td>\n",
       "      <td>20230126</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>20230126_Plate528_25</td>\n",
       "      <td>528</td>\n",
       "      <td>20230126</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>20230126_Plate528_26</td>\n",
       "      <td>528</td>\n",
       "      <td>20230126</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>20230126_Plate528_27</td>\n",
       "      <td>528</td>\n",
       "      <td>20230126</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>20230126_Plate528_28</td>\n",
       "      <td>528</td>\n",
       "      <td>20230126</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>20230126_Plate528_29</td>\n",
       "      <td>528</td>\n",
       "      <td>20230126</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>20230126_Plate528_30</td>\n",
       "      <td>528</td>\n",
       "      <td>20230126</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>20230126_Plate528_31</td>\n",
       "      <td>528</td>\n",
       "      <td>20230126</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>20230126_Plate528_32</td>\n",
       "      <td>528</td>\n",
       "      <td>20230126</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>20230126_Plate528_33</td>\n",
       "      <td>528</td>\n",
       "      <td>20230126</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>20230126_Plate528_34</td>\n",
       "      <td>528</td>\n",
       "      <td>20230126</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>20230126_Plate528_35</td>\n",
       "      <td>528</td>\n",
       "      <td>20230126</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>20230126_Plate528_36</td>\n",
       "      <td>528</td>\n",
       "      <td>20230126</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>20230126_Plate528_37</td>\n",
       "      <td>528</td>\n",
       "      <td>20230126</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>20230126_Plate528_38</td>\n",
       "      <td>528</td>\n",
       "      <td>20230126</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>20230126_Plate528_39</td>\n",
       "      <td>528</td>\n",
       "      <td>20230126</td>\n",
       "      <td>DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  folder Plate number Date Imaged  \\\n",
       "0   20230126_Plate528_01          528    20230126   \n",
       "1   20230126_Plate528_02          528    20230126   \n",
       "2   20230126_Plate528_03          528    20230126   \n",
       "3   20230126_Plate528_04          528    20230126   \n",
       "4   20230126_Plate528_05          528    20230126   \n",
       "5   20230126_Plate528_06          528    20230126   \n",
       "6   20230126_Plate528_07          528    20230126   \n",
       "7   20230126_Plate528_08          528    20230126   \n",
       "8   20230126_Plate528_09          528    20230126   \n",
       "9   20230126_Plate528_10          528    20230126   \n",
       "10  20230126_Plate528_11          528    20230126   \n",
       "11  20230126_Plate528_12          528    20230126   \n",
       "12  20230126_Plate528_13          528    20230126   \n",
       "13  20230126_Plate528_14          528    20230126   \n",
       "14  20230126_Plate528_15          528    20230126   \n",
       "15  20230126_Plate528_16          528    20230126   \n",
       "16  20230126_Plate528_17          528    20230126   \n",
       "17  20230126_Plate528_18          528    20230126   \n",
       "18  20230126_Plate528_19          528    20230126   \n",
       "19  20230126_Plate528_20          528    20230126   \n",
       "20  20230126_Plate528_21          528    20230126   \n",
       "21  20230126_Plate528_22          528    20230126   \n",
       "22  20230126_Plate528_23          528    20230126   \n",
       "23  20230126_Plate528_24          528    20230126   \n",
       "24  20230126_Plate528_25          528    20230126   \n",
       "25  20230126_Plate528_26          528    20230126   \n",
       "26  20230126_Plate528_27          528    20230126   \n",
       "27  20230126_Plate528_28          528    20230126   \n",
       "28  20230126_Plate528_29          528    20230126   \n",
       "29  20230126_Plate528_30          528    20230126   \n",
       "30  20230126_Plate528_31          528    20230126   \n",
       "31  20230126_Plate528_32          528    20230126   \n",
       "32  20230126_Plate528_33          528    20230126   \n",
       "33  20230126_Plate528_34          528    20230126   \n",
       "34  20230126_Plate528_35          528    20230126   \n",
       "35  20230126_Plate528_36          528    20230126   \n",
       "36  20230126_Plate528_37          528    20230126   \n",
       "37  20230126_Plate528_38          528    20230126   \n",
       "38  20230126_Plate528_39          528    20230126   \n",
       "\n",
       "                                        tot_path_drop video  \n",
       "0   DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...    01  \n",
       "1   DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...    02  \n",
       "2   DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...    03  \n",
       "3   DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...    04  \n",
       "4   DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...    05  \n",
       "5   DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...    06  \n",
       "6   DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...    07  \n",
       "7   DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...    08  \n",
       "8   DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...    09  \n",
       "9   DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...    10  \n",
       "10  DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...    11  \n",
       "11  DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...    12  \n",
       "12  DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...    13  \n",
       "13  DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...    14  \n",
       "14  DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...    15  \n",
       "15  DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...    16  \n",
       "16  DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...    17  \n",
       "17  DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...    18  \n",
       "18  DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...    19  \n",
       "19  DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...    20  \n",
       "20  DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...    21  \n",
       "21  DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...    22  \n",
       "22  DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...    23  \n",
       "23  DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...    24  \n",
       "24  DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...    25  \n",
       "25  DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...    26  \n",
       "26  DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...    27  \n",
       "27  DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...    28  \n",
       "28  DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...    29  \n",
       "29  DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...    30  \n",
       "30  DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...    31  \n",
       "31  DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...    32  \n",
       "32  DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...    33  \n",
       "33  DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...    34  \n",
       "34  DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...    35  \n",
       "35  DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...    36  \n",
       "36  DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...    37  \n",
       "37  DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...    38  \n",
       "38  DATA/FLUORESCENCE/DATA_NileRed/20230126_Plate5...    39  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folders_drop = all_folders_drop.loc[all_folders_drop[\"Plate number\"] == \"528\"]\n",
    "folders_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49166661",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_targ = \"/gpfs/scratch1/shared/amftrackflow/Drp_downs/20230201_Plate528/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65a4cc3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-11 11:22:49,196-[INFO]- dropbox:390 -> Refreshing access token.\n",
      "2023-04-11 11:22:49,395-[INFO]- dropbox:474 -> Request to files/download\n"
     ]
    }
   ],
   "source": [
    "for xl_adress in excel_drop:\n",
    "    file_name = xl_adress.split('/')[-1]\n",
    "    \n",
    "    download(xl_adress, directory_targ+file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4c6a198",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_parallel_transfer(\n",
    "    \"from_drop.py\",\n",
    "    [directory_targ],\n",
    "    folders_drop,\n",
    "    1,\n",
    "    \"10:00:00\",\n",
    "    \"transfer_test\"\n",
    ")\n",
    "clear_output(wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4137b51f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
