{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Master video notebook!\n",
    "This title might be a bit ambitious, but this notebook is supposed to be able to do all of the administration work when it comes to downloading, processing and analysing videos. The most important functions that will be called are stored in other python files, such that this notebook will remain legible. Analysis will be able to be done with a hierarchy structure of dataset, plate, video, hypha.\n",
    "\n",
    "BEWARE:\n",
    "When saving this document through a GitHub commit, make sure to clear all outputs. This document can easily go over the 100 MB size limit of GitHub files. \n",
    "\n",
    "### In MODULE one,\n",
    "the Dropbox is scoured for information about videos. If the videos do not have a VideoInfo.txt, the program will look for a .csv, if there is no .csv, the program will look for a .xlsx file. Once these files have been found, all information will be merged into a pandas dataframe, and saved as a json file for the dataset and for each video. Some datasets contain thousands of videos, so scouring the dropbox for info on all of them is going to be an hours-long affair. Plan your analysis accordingly.\n",
    "\n",
    "After scouring is complete, a final filtering step can be taken, whereupon the whole list of videos can be downloaded. NB: Downloading happens in two ways: videos are downloaded to the specified analysis folder, whereas video parameters and analysis will be downloaded to the specified analysis folder. This separation is done such that videos can be stored on larger storage drives, and analysis folders on faster storage drives.\n",
    "\n",
    "(if Snellius is still used, it is recommended to use your scratch storage to store videos, and your home storage to store analysis. Scratch storage gets wiped every two weeks, but is much larger than home storage. )\n",
    "\n",
    "TODO: Give options to download with SLURM job or manually.\n",
    "\n",
    "### In MODULE two,\n",
    "the downloaded videos with their respective information can be filtered, then analysed with a large SLURM job. In the future there might need to be functionality that allows processing without the use of a SLURM job. If you're reading this in 2024, you better apply for another Snellius grant!\n",
    "\n",
    "### In MODULE three,\n",
    "This is where all the bulk analysis is going to be. In high_mag_analysis.py, there are a number of classes and functions that will help you with parsing the data into meaningful graphs. This MODULE assumes the existence of the video_info.json files that are generated partly in MODULE 1.\n",
    "\n",
    "### Below code:\n",
    "Are just import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "import re\n",
    "import dropbox\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import imageio.v2 as imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import logging\n",
    "import datetime\n",
    "import glob\n",
    "import json\n",
    "import scipy\n",
    "import matplotlib as mpl\n",
    "\n",
    "from subprocess import call\n",
    "from tifffile import imwrite\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from amftrack.util.dbx import (\n",
    "    upload_folder,\n",
    "    download,\n",
    "    read_saved_dropbox_state,\n",
    "    save_dropbox_state,\n",
    "    load_dbx,\n",
    "    get_dropbox_folders_prince,\n",
    "    get_dropbox_video_folders,\n",
    "    download_video_folders_drop,\n",
    "    download_analysis_folders_drop,\n",
    ")\n",
    "from amftrack.pipeline.launching.run import (\n",
    "    run_transfer,\n",
    ")\n",
    "from amftrack.pipeline.launching.run_super import run_parallel_transfer\n",
    "from amftrack.pipeline.launching.run_super import run_parallel_flows\n",
    "from amftrack.pipeline.functions.transport_processing.high_mag_videos.plot_data import (\n",
    "    plot_summary,\n",
    "    save_raw_data,\n",
    ")\n",
    "from amftrack.pipeline.functions.transport_processing.high_mag_videos.high_mag_analysis import (\n",
    "    HighmagDataset,\n",
    "    VideoDataset,\n",
    "    EdgeDataset,\n",
    "    index_videos_dropbox_new,\n",
    "    analysis_run,\n",
    ")\n",
    "from amftrack.pipeline.functions.transport_processing.high_mag_videos.kymo_class import (\n",
    "    KymoVideoAnalysis,\n",
    "    KymoEdgeAnalysis,\n",
    ")\n",
    "from IPython.display import clear_output\n",
    "\n",
    "%matplotlib widget\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.debug)\n",
    "mpl.rcParams[\"figure.dpi\"] = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File declaration\n",
    "As this notebook is designed to work with Snellius (now also on a local computer!), two items to separate are the raw video files and the analysis. The raw video files are large, bulky and not so easy to flip through. Ideally, the video files would be downloaded and the analysis would be stored on a separate folder structure entirely. That way, large scale analysis of analysis folders can happen when there are thousands of videos in the dataset, without having to have those raw video folders on hand.\n",
    "\n",
    "Below function will basically make your folders fertile ground to accept all the video info folders and raw video files.\n",
    "\n",
    "### Input:\n",
    "Please give separately the folder where raw video data is stored, and where the analysis will be stored. Also give the dropbox address of the dataset you want to analyze.\n",
    "\n",
    "### Output:\n",
    "The specified dropbox folder will be looked through, and all relevant video information will be downloaded to an analysis folder structure identical to what is present on teh dropbox. The relevant raw video folder structure will also be generated, if specified so. Will also create cache files in the form of .json files such that next time, the scrounging does not have to happen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# videos_folder = \"F:\\\\AMOLF_Data\\\\videos\\\\\"\n",
    "# analysis_folder = \"F:\\\\AMOLF_Data\\\\analysis\\\\\"\n",
    "\n",
    "# videos_folder = \"/gpfs/scratch1/shared/amftrackflow/videos/\"\n",
    "# analysis_folder = \"/gpfs/home6/svstaalduine/Analysis/\"\n",
    "videos_folder = \"/projects/0/einf914/videos/\"\n",
    "\n",
    "analysis_folder = \"/projects/0/einf914/analysis_videos/\"\n",
    "videos_folder = \"/scratch-shared/amftrack/videos/\"\n",
    "\n",
    "analysis_folder = \"/scratch-shared/amftrack/analysis_videos/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropbox_address = \"/DATA/FLUORESCENCE/DATA_NileRed/\"\n",
    "# dropbox_address=  \"/DATA/MYRISTATE/DATA/2_weeks/\"\n",
    "# dropbox_address = \"/DATA/TransportROOT/DATA/\"\n",
    "# dropbox_address = \"/DATA/MYRISTATE/MorrisonDATA/20230508_Plate067/\"\n",
    "dropbox_address = \"/DATA/TransportROOT/DATA/\"\n",
    "# dropbox_address = \"/DATA/MYRISTATE/MorrisonDATA/\"\n",
    "\n",
    "# dropbox_address = \"/DATA/TRANSPORT/DATA/20230308_Plate070/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbx = load_dbx()\n",
    "\n",
    "response = dbx.files_list_folder(dropbox_address, recursive=False)\n",
    "names = [entry.name for entry in response.entries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "names.index(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"20230522_Plate926\",'20230523_Plate926']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f\"{dropbox_address}{name}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for name in names:\n",
    "    video_param_frame = index_videos_dropbox_new(\n",
    "        analysis_folder,\n",
    "        videos_folder,\n",
    "        f\"{dropbox_address}{name}/\",\n",
    "        REDO_SCROUNGING=True,\n",
    "        # date_start=20230801,\n",
    "        # date_end=20230813,\n",
    "        plate_names=None,\n",
    "    )\n",
    "    download_frame = video_param_frame.copy()\n",
    "    run_parallel_transfer(\n",
    "        \"from_drop_video.py\",\n",
    "        [videos_folder],\n",
    "        download_frame,\n",
    "        20,\n",
    "        \"24:00:00\",\n",
    "        \"transfer_test\",\n",
    "    )\n",
    "    clear_output(wait=False)\n",
    "\n",
    "clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "video_param_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "video_param_frame = index_videos_dropbox_new(\n",
    "    analysis_folder,\n",
    "    videos_folder,\n",
    "    dropbox_address,\n",
    "    REDO_SCROUNGING=True,\n",
    "    # date_start=20230801,\n",
    "    # date_end=20230813,\n",
    "    plate_names=None,\n",
    ")\n",
    "clear_output(wait=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Where to go?\n",
    "If you want to download videos:\n",
    "Use MODULE 1\n",
    "\n",
    "If you want to analyze already downloaded videos:\n",
    "Skip MODULE 1, use MODULE 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODULE 1: Downloading\n",
    "This section, there is one block of code that will ask you one last time whether all of the parameters are correct. The block of code after that will initiate Snellius jobs to download the videos in the DataFrame from the dropbox. Downloading videos is not that costly, but of course we prefer it to be done as efficiently as possible.\n",
    "## I'm not on Snellius! How do i download stuff??\n",
    "Easy. Just skip the second block of code. The one below will just use the dropbox API to properly download all your raw data.\n",
    "WARNING: This process can be quite long if you are queueing up a lot of videos. Do not use that block of code on Snellius, they will get mad at you (and prematurely stop your running program), just use the SLURM job in that case.\n",
    "\n",
    "### Input:\n",
    "Nothing\n",
    "### Output:\n",
    "Print statement with the DataFrame and the folders where everything will be stored.\n",
    "Subsequent block of code will download raw video files to the videos folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#####################################################################################\n",
    "### This is where you can apply the filters. Only those videos will be downloaded ###\n",
    "#####################################################################################\n",
    "\n",
    "download_frame = video_param_frame.copy()\n",
    "# download_frame = download_frame[download_frame['mode'] == \"F\"]\n",
    "# download_frame = download_frame[download_frame['plate_id']==\"20230803_Plate999\"]\n",
    "\n",
    "#####################################################################################\n",
    "### Below code will prepare for those videos to be downloaded into videos_folder  ###\n",
    "#####################################################################################\n",
    "print(f\"Number of videos that will be downloaded: {len(download_frame)}\")\n",
    "download_frame.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run_parallel_transfer(\n",
    "    \"from_drop_video.py\",\n",
    "    [videos_folder],\n",
    "    download_frame,\n",
    "    20,\n",
    "    \"24:00:00\",\n",
    "    \"transfer_test\",\n",
    ")\n",
    "clear_output(wait=False)\n",
    "\n",
    "print(\n",
    "    \"Sent all the jobs! Use the command '$ squeue' in the terminal to see the progress\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download videos from Dropbox (Not a SLURM job)\n",
    "This block of code can be used to download videos individually from dropbox. \n",
    "Be aware:\n",
    "- This is significantly slower than launching a SLURM job\n",
    "- This downloads videos sequentially, not in parallel\n",
    "- If this function is running for too long on Snellius, it might get you booted from the interactive node\n",
    "- Videos are large. Make sure you have the space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "download_video_folders_drop(download_frame, videos_folder)\n",
    "clear_output(wait=False)\n",
    "print(\"All videos downloaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Analysis folders from Dropbox (not a SLURM job)\n",
    "Similar warnings apply as the video download function above. The file sizes for the analysis folders are, however, vastly smaller than video files. This allows for a bit more wiggle room."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_analysis_folders_drop(analysis_folder, dropbox_address)\n",
    "clear_output(wait=False)\n",
    "print(\"All analysis folders downloaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 2: Processing\n",
    "\n",
    "Now that the files have been downloaded, it's time to analyse them. In the below code, you'll be able to either do a complete survey of the analysis folder for as many videos as possible, or use the DataFrame of recently downloaded videos to filter for the videos you want to analyse.\n",
    "\n",
    "Also possible to analyse videos directly in this notebook. Be aware again that this is a sequential, and slower analysis than running a SLURM job. \n",
    "\n",
    "### Input:\n",
    "DataFrame filters of all videos to be analysed\n",
    "### Output:\n",
    "Print statements for all parameters of the analysis session that is about to take place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "folder_filter = dropbox_address[5:]\n",
    "\n",
    "img_infos = glob.glob(\n",
    "    f\"{analysis_folder}{folder_filter}/**/video_data.json\", recursive=True\n",
    ")\n",
    "vid_anls_frame = pd.DataFrame()\n",
    "for address in img_infos:\n",
    "    add_info = pd.read_json(address, orient=\"index\").T\n",
    "    vid_anls_frame = pd.concat([vid_anls_frame, add_info], ignore_index=True)\n",
    "\n",
    "vid_anls_frame = vid_anls_frame.sort_values(\"unique_id\").reset_index(drop=True)\n",
    "# vid_anls_frame.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vid_anls_frame[\"analysis_folder\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "####################################################################################\n",
    "### This is where you can apply the filters. Only those videos will be analyzed. ###\n",
    "####################################################################################\n",
    "\n",
    "# analysis_frame = vid_anls_frame[\n",
    "#     vid_anls_frame[\"imaging_day\"].ge(\"20230814\")\n",
    "# ].reset_index(drop=True)\n",
    "# analysis_frame = vid_anls_frame[vid_anls_frame['xpos'].le(100)].reset_index(drop=True)\n",
    "# analysis_frame = analysis_frame[analysis_frame['mode']==\"F\"]\n",
    "# analysis_frame = vid_anls_frame[vid_anls_frame['plate_id'] != \"20230729_Plate440\"]\n",
    "# analysis_frame = analysis_frame[analysis_frame['video_int'].isin([1])]\n",
    "analysis_frame = vid_anls_frame\n",
    "\n",
    "####################################################################################\n",
    "### Below code will prepare for those videos to be downloaded to videos_folder.  ###\n",
    "####################################################################################\n",
    "\n",
    "print(f\"Number of videos to be analyzed: {len(analysis_frame)}\")\n",
    "# analysis_frame.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_frame = analysis_frame.loc[200:280]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run SLURM Analysis job\n",
    "Two options: For small analysis, use the first block. This will just do the calculations on the machine. For large-scale analysis, use the second block, as it will create a Snellius job.\n",
    "## Input:\n",
    "Snellius job parameters\n",
    "## Output:\n",
    "Analysis folder will be populated with analysis tiffs and csv sheets. At the same time, this analysis folder will also be uploaded to the dropbox."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### LARGE VIDEO ANALYSIS\n",
    "\n",
    "nr_parallel = np.min([len(analysis_frame.index), 8])\n",
    "\n",
    "run_parallel_flows(\n",
    "    \"flux_extract.py\",\n",
    "    [analysis_folder, 9, 0.95, 0.005, 200, dropbox_address],\n",
    "    analysis_frame,\n",
    "    nr_parallel,\n",
    "    \"2:00:00\",\n",
    "    \"flux_extract\",\n",
    "    name_job=\"flux_extract.sh\",\n",
    ")\n",
    "clear_output(wait=False)\n",
    "\n",
    "print(\n",
    "    \"Sent all the jobs! Use the command '$ squeue' in the terminal to see the progress\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### LARGE VIDEO ANALYSIS\n",
    "\n",
    "nr_parallel = np.min([len(analysis_frame.index), 1])\n",
    "\n",
    "run_parallel_flows(\n",
    "    \"flux_upload.py\",\n",
    "    [analysis_folder, 9, 0.95, 0.005, 200, dropbox_address],\n",
    "    analysis_frame,\n",
    "    nr_parallel,\n",
    "    \"2:00:00\",\n",
    "    \"flux_upload\",\n",
    "    node=\"staging\",\n",
    "    cpus=1,\n",
    "    # dependency = \"flux_extract.sh\",\n",
    "    name_job=\"flux_upload.sh\",\n",
    ")\n",
    "clear_output(wait=False)\n",
    "\n",
    "print(\n",
    "    \"Sent all the jobs! Use the command '$ squeue' in the terminal to see the progress\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_video = KymoVideoAnalysis(\n",
    "    input_frame=analysis_frame.iloc[58], logging=True, samepos_frame=pd.DataFrame()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "fig, ax = plt.subplots(figsize=(2, 2))\n",
    "ax.imshow(test_video.segmented)\n",
    "# test_video.segmented.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(2, 2))\n",
    "ax.imshow(segmented, alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_address = Path(analysis_frame.iloc[9][\"videos_folder\"])\n",
    "images_total_path = [str(adr) for adr in imgs_address.glob(\"*_*.ti*\")]\n",
    "images_total_path.sort()\n",
    "[imageio.imread(addresses) for addresses in images_total_path[:30]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from amftrack.pipeline.functions.transport_processing.high_mag_videos.high_mag_videos_fun import *\n",
    "\n",
    "segmented, _, _ = segment_fluo_new(\n",
    "    [imageio.imread(addresses) for addresses in test_video.selection_file[:30]],\n",
    "    threshtype=\"hist_edge\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [imageio.imread(addresses) for addresses in test_video.selection_file[:30]]\n",
    "std_image = np.mean(images, axis=0)\n",
    "smooth_im_blur = cv2.blur(std_image, (20, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(2, 2))\n",
    "ax.hist(smooth_im_blur.flatten(), 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = find_histogram_edge(smooth_im_blur)\n",
    "seg_thresh = 1.10\n",
    "segmented = (smooth_im_blur >= thresh * seg_thresh).astype(np.uint8) * 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "fig, ax = plt.subplots(figsize=(4, 5))\n",
    "ax.imshow(std_image)\n",
    "ax.imshow(segmented, alpha=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run local analysis\n",
    "This is code where you can run a specialized analysis on a limited number of videos. This uses the same analysis frame which you use to filter videos for the SLURM jobs.\n",
    "\n",
    "First the analysis function is defined, which you can change to fit the parameters you want. Then the next block of code will use that function to go through each row in the video analyis dataframe and executes the analysis. NOTE: This is not code to go through the analysis, that is for MODULE 3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_objs = analysis_run(\n",
    "    analysis_frame.iloc[:4],\n",
    "    analysis_folder,\n",
    "    videos_folder,\n",
    "    dropbox_address,\n",
    "    logging=True,  # Print progress to console\n",
    "    kymo_normalize=True,  # Normalize the kymograph for visual representation\n",
    "    kymo_section_width=1.8,  # Width of kymograph lines, adjusted for magnification\n",
    "    thresh_adjust=0,  # Adjustment for thresholding the frangi filter. Will be added to Otsu threshold.\n",
    "    frangi_range=np.arange(10, 120, 20),  # Range of distances in pixels to expect hyp\n",
    "    close_size=200,  # Size of kernel to use in closing operation after thresholding frangi filter\n",
    "    edge_len_min=40,  # Minimum edge length to select for\n",
    "    save_edge_extraction_plot=True,  # Save picture of extracted edges\n",
    "    make_video=False,  # Make mp4 of raw data TIFFs\n",
    "    create_snapshot=True,  # Save image of edge\n",
    "    create_edge_video=False,  # Save video of edge\n",
    "    photobleach_adjust=False,  # Adjust kymograph for photobleaching\n",
    "    speed_ext_window_number=9,  # Size range to investigate speeds\n",
    "    speed_ext_window_start=3,  # Start size of window for GST\n",
    "    speed_ext_c_thresh=0.95,  # Confidence threshold for speed determination\n",
    "    speed_ext_c_falloff=0.005,  # Confidence falloff as window size increases\n",
    "    speed_ext_blur_size=1,  # Kymograph blur Gaussian kernel size\n",
    "    speed_ext_blur=True,  # Whether to preblur at all\n",
    "    speed_ext_max_thresh=80,  # Maximum expected speeds (in um/s)\n",
    "    dropbox_upload=False,  # Whether to upload results to dropbox\n",
    "    fourier_radius=30,  # From what pixel radius to include the fourier spectrum during fourier analysis\n",
    "    fourier_prominence=1,  # Prominence metric for finding peaks in fourier analysis\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for edge_group in edges_objs:\n",
    "#     print(edge_group)\n",
    "# print(np.array(edges_objs).flatten())\n",
    "small_data_obj = HighmagDataset(analysis_frame, analysis_folder, videos_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for edge in small_data_obj.edge_objs:\n",
    "    edge.show_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Width profile Kymograph analysis\n",
    "This is going to be some special code to extract multiple kymographs from the same edge, all next to each other. Requires running the previous code to get the analysis objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([[edge.edge_name for edge in edge_list] for edge_list in edges_objs])\n",
    "edge_interest = edges_objs[0][0]\n",
    "\n",
    "width_len = 4\n",
    "# TODO: Get effective mean speed calculation in here too\n",
    "\n",
    "kymos = edge_interest.extract_multi_kymo(width_len, target_length=70)\n",
    "fourier_kymos = edge_interest.fourier_kymo()\n",
    "speeds, times = edge_interest.extract_speeds(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array(times).shape)\n",
    "speed_max = 20\n",
    "fig, ax = plt.subplots(width_len)\n",
    "for i in range(width_len):\n",
    "    ax[i].plot(times[i], np.nanmean(speeds[i][0], axis=1))\n",
    "    ax[i].plot(times[i], np.nanmean(speeds[i][1], axis=1))\n",
    "    ax[i].fill_between(\n",
    "        times[i],\n",
    "        np.nanmean(speeds[i][0], axis=1) + np.nanstd(speeds[i][0], axis=1),\n",
    "        np.nanmean(speeds[i][0], axis=1) - np.nanstd(speeds[i][0], axis=1),\n",
    "        alpha=0.5,\n",
    "        facecolor=\"tab:blue\",\n",
    "    )\n",
    "    ax[i].fill_between(\n",
    "        times[i],\n",
    "        np.nanmean(speeds[i][1], axis=1) + np.nanstd(speeds[i][1], axis=1),\n",
    "        np.nanmean(speeds[i][1], axis=1) - np.nanstd(speeds[i][1], axis=1),\n",
    "        alpha=0.5,\n",
    "        facecolor=\"tab:orange\",\n",
    "    )\n",
    "    ax[i].set_ylim((-speed_max, speed_max))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for i in range(1, width_len):\n",
    "    ax.set_title(\"Speeds along the width\")\n",
    "    ax.scatter(\n",
    "        i, np.mean(np.nanmean(speeds[i][0], axis=1)), c=\"tab:blue\", label=\"to tip\"\n",
    "    )\n",
    "    ax.errorbar(\n",
    "        i,\n",
    "        np.mean(np.nanmean(speeds[i][0], axis=1)),\n",
    "        np.nanstd(speeds[i][0].flatten()),\n",
    "        capsize=5,\n",
    "        c=\"tab:blue\",\n",
    "    )\n",
    "    ax.scatter(\n",
    "        i, np.mean(np.nanmean(speeds[i][1], axis=1)), c=\"tab:orange\", label=\"to root\"\n",
    "    )\n",
    "    ax.errorbar(\n",
    "        i,\n",
    "        np.mean(np.nanmean(speeds[i][1], axis=1)),\n",
    "        np.nanstd(speeds[i][1].flatten()),\n",
    "        capsize=5,\n",
    "        c=\"tab:orange\",\n",
    "    )\n",
    "    ax.set_ylim([-15, 15])\n",
    "    ax.set_xlabel(\"Width fraction nr\")\n",
    "    ax.set_ylabel(\"Velocity $(\\mu m /s)$\")\n",
    "    ax.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(kymos)):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(kymos[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 3: Bulk Analysis\n",
    "## First part: Assemble Edge DataFrame\n",
    "\n",
    "\n",
    "In this initial part of the bulk analysis, all of the analysis folders will be looked through to find the edge data we're looking for. Additionally, there is an optional part to download the analysis folder back to the analysis folder we specified right at the top."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assuming all the analysis folders are already downloaded:\n",
    "You can use below code to read the video_data.json files that are created during indexing of all the videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_filter = dropbox_address[5:]\n",
    "\n",
    "img_infos = glob.glob(\n",
    "    f\"{analysis_folder}{folder_filter}/**/video_data.json\", recursive=True\n",
    ")\n",
    "vid_anls_frame = pd.DataFrame()\n",
    "for address in tqdm(img_infos):\n",
    "    add_info = pd.read_json(address, orient=\"index\").T\n",
    "    vid_anls_frame = pd.concat([vid_anls_frame, add_info], ignore_index=True)\n",
    "\n",
    "vid_frame = vid_anls_frame.sort_values(\"unique_id\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################\n",
    "### This is where you can apply the filters. Only those videos will be analyzed. ###\n",
    "####################################################################################\n",
    "\n",
    "# analysis_frame = vid_frame[vid_frame['imaging_day'].le(20230725)].reset_index(drop=True)\n",
    "analysis_frame = vid_frame\n",
    "\n",
    "analysis_frame[\"plate_int\"] = [\n",
    "    entry.split(\"_\")[-1] for entry in analysis_frame[\"plate_id\"]\n",
    "]\n",
    "analysis_frame[\"video_int\"] = [\n",
    "    entry.split(\"_\")[-1] for entry in analysis_frame[\"unique_id\"]\n",
    "]\n",
    "\n",
    "# analysis_frame = analysis_frame[analysis_frame['plate_int'] != \"Plate440\"].reset_index(drop=True)\n",
    "analysis_frame = analysis_frame[\n",
    "    analysis_frame[\"imaging_day\"].ge(\"20230810\")\n",
    "].reset_index(drop=True)\n",
    "analysis_frame = analysis_frame[analysis_frame[\"xpos\"].le(100)].reset_index(drop=True)\n",
    "\n",
    "### Run below to update analysis and videos folder entries if you've downloaded the analysis\n",
    "analysis_frame[\"analysis_folder\"] = [\n",
    "    str((Path(analysis_folder) / entry[\"folder\"]).parent)\n",
    "    for index, entry in analysis_frame.iterrows()\n",
    "]\n",
    "analysis_frame[\"videos_folder\"] = [\n",
    "    str(Path(videos_folder) / entry[\"folder\"])\n",
    "    for index, entry in analysis_frame.iterrows()\n",
    "]\n",
    "\n",
    "####################################################################################\n",
    "### Below code will prepare for those videos to be downloaded to videos_folder.  ###\n",
    "####################################################################################\n",
    "analysis_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_obj = HighmagDataset(analysis_frame, analysis_folder, videos_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example code for plotting fraction bar graphs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_ranges = [\n",
    "    edge.time_data[\"speed_weight_mean\"].quantile(0.95)\n",
    "    - edge.time_data[\"speed_weight_mean\"].quantile(0.05)\n",
    "    for edge in data_obj.edge_objs\n",
    "]\n",
    "data_obj.edges_frame[\"speed_range\"] = speed_ranges\n",
    "data_int_obj = data_obj.filter_edges(\"coverage_tot\", \">=\", 0.5)\n",
    "speed_linear_rachael = data_int_obj.filter_edges(\"speed_range\", \"<=\", 2.0)\n",
    "speed_bulk_rachael = data_int_obj.filter_edges(\"speed_range\", \">=\", 2.0)\n",
    "print(len(speed_linear_rachael.edges_frame))\n",
    "print(len(speed_bulk_rachael.edges_frame))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(speed_bulk_rachael.edges_frame[\"unique_id\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 3\n",
    "linear = (676, 899, 3671)\n",
    "bulk = (689, 190, 230)\n",
    "vid_sums = np.add(linear, bulk)\n",
    "linear = np.divide(linear, vid_sums)\n",
    "bulk = bulk / vid_sums\n",
    "linear\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(\n",
    "    np.arange(N), linear, 0.3, label=\"$\\overline{v}_{.95} - \\overline{v}_{.05} < 2.0$\"\n",
    ")\n",
    "ax.bar(\n",
    "    np.arange(N),\n",
    "    bulk,\n",
    "    0.3,\n",
    "    bottom=linear.T,\n",
    "    label=\"$\\overline{v}_{.95} - \\overline{v}_{.05} > 2.0$\",\n",
    ")\n",
    "ax.set_xticks(\n",
    "    np.arange(N),\n",
    "    (\n",
    "        f\"Lid Off 1 (n={vid_sums[0]})\",\n",
    "        f\"Lid Off 2 (n={vid_sums[1]})\",\n",
    "        f\"Lid On (n={vid_sums[2]})\",\n",
    "    ),\n",
    ")\n",
    "ax.set_title(\"Linear / Bulk flow partitions using speed range\")\n",
    "ax.set_ylabel(\"Fraction\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example code for creating different plate maps\n",
    "Below you can see the filtering options for different plates and the plot_plate_locs function that outputs a map with dots or arrows depending on your wishes. Current drawing modes are:\n",
    "- 'scatter' for dots of the videos, separated by magnification\n",
    "- 'speeds_mean' for black arrows denoting the effective mean speed of the flows\n",
    "- 'speeds_both' for blue and orange arrows denoting the effective speed of flows in both directions\n",
    "- 'vid_labels'  for a list of what videos were taken at each position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_ranges = [\n",
    "    edge.time_data[\"speed_weight_mean\"].quantile(0.95)\n",
    "    - edge.time_data[\"speed_weight_mean\"].quantile(0.05)\n",
    "    for edge in data_obj.edge_objs\n",
    "]\n",
    "data_obj.edges_frame[\"speed_ranges\"] = speed_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist(speed_ranges, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "mpl.rcParams[\"figure.dpi\"] = 500\n",
    "print(data_obj.video_frame.columns)\n",
    "\n",
    "for plate_id in tqdm(data_obj.video_frame[\"plate_id\"].unique()):\n",
    "    plate_group = data_obj.filter_edges(\"coverage_tot\", \">=\", 0.3)\n",
    "    plate_group = plate_group.filter_edges(\"plate_id\", \"==\", plate_id)\n",
    "    #     plate_group = plate_group.filter_edges('mode', '==', \"BF\")\n",
    "    plate_group = plate_group.filter_edges(\"speed_ranges\", \">=\", 3.0)\n",
    "    if len(plate_group.video_frame) <= 1:\n",
    "        continue\n",
    "    else:\n",
    "        plate_group.plot_plate_locs(\n",
    "            analysis_folder, spd_thresh=0.5, modes=[\"speeds_both\"]\n",
    "        )\n",
    "\n",
    "mpl.rcParams[\"figure.dpi\"] = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example code 50x speed arrows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "data_interest = data_obj.filter_edges(\"video_int\", \">=\", \"071\")\n",
    "data_interest = data_interest.filter_edges(\"video_int\", \"<=\", \"080\")\n",
    "data_interest = data_interest.filter_edges(\"mode\", \"==\", \"BF\")\n",
    "data_interest = data_interest.filter_edges(\"imaging_day\", \"==\", \"20230810\")\n",
    "\n",
    "for vid_obj in data_interest.video_objs:\n",
    "    vid_obj.plot_speed_arrows(plot_both=True, save_im=True, video_txt_size=30)\n",
    "\n",
    "# for edge in data_interest.edge_objs:\n",
    "#     edge.direction_filter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example code plot summaries of videos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "\n",
    "data_obj_filt = data_obj.filter_edges(\"video_int\", \">=\", \"000\")\n",
    "data_obj_filt = data_obj_filt.filter_edges(\"video_int\", \">=\", \"001\")\n",
    "data_obj_filt = data_obj_filt.filter_edges(\"video_int\", \"<=\", \"003\")\n",
    "data_obj_filt = data_obj_filt.filter_edges(\"coverage_tot\", \">=\", 0.5)\n",
    "data_obj_filt = data_obj_filt.filter_edges(\"speed_range\", \">=\", 1.5)\n",
    "# data_obj_filt = data_obj_filt.filter_edges('coverage_left', '<=', 0.3)\n",
    "# data_obj_filt = data_obj_filt.filter_edges('coverage_right', '<=', 0.3)\n",
    "\n",
    "# print(len(data_oj))\n",
    "for edge in data_obj_filt.edge_objs:\n",
    "    #     video.show_segmentation()\n",
    "    edge.show_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example code binned violin-plot\n",
    "bin-column represents the value to be binned, then multiple violin plots are graphed on the same axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cover_filter_data = data_obj.filter_edges(\"coverage_tot\", \">=\", 0.5)\n",
    "filter_BF = cover_filter_data.filter_edges(\"mode\", \"==\", \"BF\")\n",
    "filter_BF = filter_BF.filter_edges(\"imaging_day\", \">=\", \"20230814\")\n",
    "# filter_BF = cover_filter_data\n",
    "bin_column = \"ypos\"\n",
    "\n",
    "# bins = np.linspace(5, 15, 10)\n",
    "bins = np.linspace(\n",
    "    filter_BF.return_edge_frame()[bin_column].min(),\n",
    "    filter_BF.return_edge_frame()[bin_column].max(),\n",
    "    20,\n",
    ")\n",
    "bin_series = filter_BF.bin_values(bin_column, bins)\n",
    "# print(bin_series)\n",
    "\n",
    "labels = []\n",
    "fig, ax = filter_BF.plot_violins(\"speed_right\", bins, c=\"tab:orange\", labels=labels)\n",
    "fig, ax = filter_BF.plot_violins(\n",
    "    \"speed_left\", bins, c=\"tab:blue\", ax=ax, fig=fig, labels=labels\n",
    ")\n",
    "fig, ax = filter_BF.plot_violins(\n",
    "    \"speed_mean\", bins, c=\"tab:red\", ax=ax, fig=fig, labels=labels\n",
    ")\n",
    "\n",
    "ax.axhline(c=\"black\", alpha=0.5, linestyle=\"--\")\n",
    "ax.set_ylabel(\"v $(\\mu m / s)$\")\n",
    "ax.set_xlabel(\"hyphal width $(\\mu m)$\")\n",
    "ax.legend(*zip(*labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example code for bin-less violin plots\n",
    "This can be for comparing videos, plates, anything with a unique ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cover_filter_data = data_obj.filter_edges(\"coverage_tot\", \">=\", 0.5)\n",
    "cover_filter_data = cover_filter_data.filter_edges(\"plate_int\", \"<=\", \"Plate449\")\n",
    "\n",
    "filter_BF = cover_filter_data\n",
    "\n",
    "labels = []\n",
    "fig, ax = filter_BF.plot_violins(\n",
    "    \"speed_right\", bin_separator=\"plate_id\", c=\"tab:orange\", labels=labels\n",
    ")\n",
    "fig, ax = filter_BF.plot_violins(\n",
    "    \"speed_left\", bin_separator=\"plate_id\", c=\"tab:blue\", ax=ax, fig=fig, labels=labels\n",
    ")\n",
    "fig, ax = filter_BF.plot_violins(\n",
    "    \"speed_mean\", bin_separator=\"plate_id\", c=\"tab:red\", ax=ax, fig=fig, labels=labels\n",
    ")\n",
    "\n",
    "ax.axhline(c=\"black\", alpha=0.5, linestyle=\"--\")\n",
    "ax.set_ylabel(\"v $(\\mu m / s)$\")\n",
    "ax.set_xlabel(\"Plate id's\")\n",
    "ax.legend(*zip(*labels))\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_obj.video_frame[\"video_int\"].to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example code on visualizing 4x/50x comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_4x_filter = data_obj.filter_edges(\"magnification\", \"==\", 4.0)\n",
    "mag_corr_groups = [\n",
    "    data_obj.context_4x(row) for index, row in data_4x_filter.video_frame.iterrows()\n",
    "]\n",
    "for group in tqdm(mag_corr_groups):\n",
    "    group.plot_4x_locs(analysis_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "\n",
    "spd_maxes_BF = []\n",
    "spd_maxes_BF_440 = []\n",
    "spd_maxes_BF_441 = []\n",
    "spd_maxes_BF_449 = []\n",
    "spd_maxes_BF_414 = []\n",
    "flux_avgs_BF = []\n",
    "spd_maxes_FL = []\n",
    "flux_avgs_FL = []\n",
    "\n",
    "print(data_obj.video_frame[\"plate_int\"].unique())\n",
    "\n",
    "# linear_edges = data_obj.filter_edges('plate_int',  '==', 'Plate440')\n",
    "# linear_edges = data_obj.filter_edges('imaging_day',  '>=', '20230728')\n",
    "# linear_edges = linear_edges.filter_edges('imaging_day',  '<=', '20230727')\n",
    "linear_edges = data_obj.filter_edges(\"coverage_left\", \">=\", 0.45)\n",
    "linear_edges = linear_edges.filter_edges(\"coverage_right\", \">=\", 0.45)\n",
    "# linear_edges = linear_edges.filter_edges('mode',  '==', 'BF')\n",
    "# linear_edges_440 = linear_edges.filter_edges('plate_int',  '==', 'Plate440')\n",
    "# linear_edges_441 = linear_edges.filter_edges('plate_int',  '==', 'Plate441')\n",
    "# linear_edges_449 = linear_edges.filter_edges('plate_int',  '==', 'Plate449')\n",
    "# linear_edges_414 = linear_edges.filter_edges('plate_int',  '==', 'Plate414')\n",
    "linear_edges_BF = linear_edges.filter_edges(\"mode\", \"==\", \"BF\")\n",
    "linear_edges_FL = linear_edges.filter_edges(\"mode\", \"==\", \"F\")\n",
    "\n",
    "for edge in tqdm(linear_edges_BF.edge_objs):\n",
    "    spd_maxes_BF.append(\n",
    "        edge.plot_speed_histo(\n",
    "            spd_extent=10,\n",
    "            spd_tiff_lowbound=0.5,\n",
    "            spd_cutoff=0.5,\n",
    "            bin_res=1000,\n",
    "            plot_fig=False,\n",
    "        )\n",
    "    )\n",
    "    flux_avgs_BF.append(edge.time_data[\"flux_mean\"].mean())\n",
    "# for edge in tqdm(linear_edges_440.edge_objs):\n",
    "#     spd_maxes_BF_440.append(edge.plot_speed_histo(spd_extent=10, spd_tiff_lowbound=0.0, spd_cutoff = 0.0, bin_res=1000, plot_fig=False))\n",
    "# for edge in tqdm(linear_edges_441.edge_objs):\n",
    "#     spd_maxes_BF_441.append(edge.plot_speed_histo(spd_extent=10, spd_tiff_lowbound=0.0, spd_cutoff = 0.0, bin_res=1000, plot_fig=False))\n",
    "# for edge in tqdm(linear_edges_449.edge_objs):\n",
    "#     spd_maxes_BF_449.append(edge.plot_speed_histo(spd_extent=10, spd_tiff_lowbound=0.0, spd_cutoff = 0.0, bin_res=1000, plot_fig=False))\n",
    "# for edge in tqdm(linear_edges_414.edge_objs):\n",
    "#     spd_maxes_BF_414.append(edge.plot_speed_histo(spd_extent=10, spd_tiff_lowbound=0.0, spd_cutoff = 0.0, bin_res=1000, plot_fig=False))\n",
    "for edge in tqdm(linear_edges_FL.edge_objs):\n",
    "    spd_maxes_FL.append(\n",
    "        edge.plot_speed_histo(\n",
    "            spd_extent=10,\n",
    "            spd_tiff_lowbound=0.5,\n",
    "            spd_cutoff=0.5,\n",
    "            bin_res=1000,\n",
    "            plot_fig=False,\n",
    "        )\n",
    "    )\n",
    "    flux_avgs_FL.append(edge.time_data[\"flux_mean\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(linear_edges_BF.edges_frame[\"unique_id\"].to_string())\n",
    "print(linear_edges_FL.edges_frame[\"unique_id\"].to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spd_maxes_BF = np.array(spd_maxes_BF)\n",
    "spd_maxes_FL = np.array(spd_maxes_FL)\n",
    "spd_maxes_BF_440 = np.array(spd_maxes_BF_440)\n",
    "spd_maxes_BF_441 = np.array(spd_maxes_BF_441)\n",
    "spd_maxes_BF_449 = np.array(spd_maxes_BF_449)\n",
    "spd_maxes_BF_414 = np.array(spd_maxes_BF_414)\n",
    "\n",
    "colors = [\"tab:orange\", \"tab:blue\", \"tab:green\", \"tab:red\", \"tab:purple\"]\n",
    "\n",
    "video_bins = [[0, 500]]\n",
    "\n",
    "fig, ax = plt.subplots(2, figsize=(10, 10))\n",
    "\n",
    "for i, bins in enumerate(video_bins):\n",
    "    ax[0].scatter(\n",
    "        -linear_edges_BF.edges_frame[\"ypos\"].astype(float),\n",
    "        spd_maxes_BF.T[1],\n",
    "        marker=\"s\",\n",
    "        c=colors[i],\n",
    "        alpha=0.7,\n",
    "        label=f\"to tip, hypha {i+1}\",\n",
    "    )\n",
    "    ax[0].scatter(\n",
    "        -linear_edges_BF.edges_frame[\"ypos\"].astype(float),\n",
    "        spd_maxes_BF.T[0],\n",
    "        marker=\"o\",\n",
    "        c=colors[i],\n",
    "        alpha=0.7,\n",
    "        label=f\"to root, hypha {i+1}\",\n",
    "    )\n",
    "#     ax[0].scatter(-linear_edges_BF.edges_frame['ypos'].astype(float)[bins[0]:bins[1]], np.array(flux_avgs_BF[bins[0]:bins[1]]), marker='P',c=colors[i+1], alpha=0.7, label=f'flux, hypha {i+1}')\n",
    "for i, bins in enumerate(video_bins):\n",
    "    ax[1].scatter(\n",
    "        -linear_edges_FL.edges_frame[\"ypos\"].astype(float),\n",
    "        spd_maxes_FL.T[1],\n",
    "        marker=\"s\",\n",
    "        c=colors[i + 1],\n",
    "        alpha=0.7,\n",
    "        label=f\"to tip, hypha {i+1}\",\n",
    "    )\n",
    "    ax[1].scatter(\n",
    "        -linear_edges_FL.edges_frame[\"ypos\"].astype(float),\n",
    "        spd_maxes_FL.T[0],\n",
    "        marker=\"o\",\n",
    "        c=colors[i + 1],\n",
    "        alpha=0.7,\n",
    "        label=f\"to root, hypha {i+1}\",\n",
    "    )\n",
    "#     ax[1].scatter(-linear_edges_FL.edges_frame['ypos'].astype(float)[bins[0]:bins[1]], np.array(flux_avgs_FL[bins[0]:bins[1]]), marker='P',c=colors[i+2], alpha=0.7, label=f'flux, hypha {i+1}')\n",
    "\n",
    "for j in range(2):\n",
    "    ax[j].grid(True)\n",
    "    ax[j].set_ylabel(\"Measured speed $(\\mu m /s)$\")\n",
    "    ax[j].set_xlabel(\"y-position (root to tip)\")\n",
    "    ax[j].set_title(\"Speeds along a single hypha\")\n",
    "    ax[j].set_ylim([-10, 10])\n",
    "    ax[j].axhline(c=\"black\")\n",
    "    ax[j].legend()\n",
    "    fig.tight_layout()\n",
    "# print(linear_edges.edges_frame['video_int'].to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist(flux_avgs_BF, density=True, alpha=0.6, bins=40, range=[-350, 350], label=\"BF\")\n",
    "ax.hist(flux_avgs_FL, density=True, alpha=0.6, bins=40, range=[-350, 350], label=\"FL\")\n",
    "ax.axvline()\n",
    "ax.legend()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(\n",
    "    spd_maxes_BF.T[0],\n",
    "    alpha=0.6,\n",
    "    density=True,\n",
    "    bins=80,\n",
    "    range=[-5, 5],\n",
    "    color=\"tab:orange\",\n",
    "    label=\"Bright-field, n=674\",\n",
    ")\n",
    "ax.hist(\n",
    "    spd_maxes_BF.T[1],\n",
    "    alpha=0.6,\n",
    "    density=True,\n",
    "    bins=80,\n",
    "    range=[-5, 5],\n",
    "    color=\"tab:orange\",\n",
    ")\n",
    "ax.hist(\n",
    "    spd_maxes_FL.T[0],\n",
    "    alpha=0.6,\n",
    "    density=True,\n",
    "    bins=80,\n",
    "    range=[-5, 5],\n",
    "    color=\"tab:blue\",\n",
    "    label=\"Fluorescence, n=388\",\n",
    ")\n",
    "ax.hist(\n",
    "    spd_maxes_FL.T[1], alpha=0.6, density=True, bins=80, range=[-5, 5], color=\"tab:blue\"\n",
    ")\n",
    "ax.set_xlabel(\"Velocity $(\\mu m / s)$\")\n",
    "ax.set_ylabel(\"Frequency\")\n",
    "ax.set_title(\"Speed profiles lid On\")\n",
    "ax.set_ylabel(\"Frequency\")\n",
    "ax.set_xlabel(\"Flux (to root --> to tip)\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot for a beautiful butterfly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spd_maxes_BF = np.array(spd_maxes_BF)\n",
    "# spd_maxes_FL = np.array(spd_maxes_FL)\n",
    "\n",
    "colors = [\"tab:orange\", \"tab:blue\", \"tab:green\", \"tab:red\", \"tab:purple\"]\n",
    "titles = [\"Plate 440\", \"Plate 441\", \"Plate 449\", \"Plate 414\", \"tab:purple\"]\n",
    "\n",
    "video_bins = [[0, 500]]\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(8, 8))\n",
    "\n",
    "for i, bins in enumerate(video_bins):\n",
    "    ax[0][0].scatter(\n",
    "        -spd_maxes_BF_440.T[0],\n",
    "        spd_maxes_BF_440.T[1],\n",
    "        marker=\"s\",\n",
    "        c=colors[i],\n",
    "        alpha=0.2,\n",
    "        label=f\"Brightfield\",\n",
    "    )\n",
    "    ax[0][1].scatter(\n",
    "        -spd_maxes_BF_441.T[0],\n",
    "        spd_maxes_BF_441.T[1],\n",
    "        marker=\"s\",\n",
    "        c=colors[i],\n",
    "        alpha=0.2,\n",
    "        label=f\"Brightfield\",\n",
    "    )\n",
    "    ax[1][0].scatter(\n",
    "        -spd_maxes_BF_449.T[0],\n",
    "        spd_maxes_BF_449.T[1],\n",
    "        marker=\"s\",\n",
    "        c=colors[i],\n",
    "        alpha=0.2,\n",
    "        label=f\"Brightfield\",\n",
    "    )\n",
    "    ax[1][1].scatter(\n",
    "        -spd_maxes_BF_414.T[0],\n",
    "        spd_maxes_BF_414.T[1],\n",
    "        marker=\"s\",\n",
    "        c=colors[i],\n",
    "        alpha=0.2,\n",
    "        label=f\"Brightfield\",\n",
    "    )\n",
    "#     ax[1].scatter(-spd_maxes_FL.T[0][bins[0]:bins[1]], spd_maxes_FL.T[1][bins[0]:bins[1]], marker='s',c=colors[i+1], alpha=0.2, label=f'Fluorescence')\n",
    "\n",
    "for i, axis in enumerate(ax.flatten()):\n",
    "    axis.grid(True)\n",
    "    axis.set_ylabel(\"Speed $(\\mu m /s)$ towards Tip\")\n",
    "    axis.set_xlabel(\"Speed $(\\mu m /s)$ towards Root\")\n",
    "    axis.set_title(f\"{titles[i]}\")\n",
    "    axis.set_aspect(\"equal\")\n",
    "    axis.set_ylim([0, 10])\n",
    "    axis.set_xlim([0, 10])\n",
    "#     axis.legend()\n",
    "fig.tight_layout()\n",
    "# print(linear_edges.edges_frame['video_int'].to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
