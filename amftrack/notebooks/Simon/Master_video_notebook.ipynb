{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Master video notebook!\n",
    "This title might be a bit ambitious, but this notebook is supposed to be able to do all of the administration work when it comes to analysing videos. Of course, many functions are already inherent to the kymo_class file and the plot_data file. Ultimately, this notebook is about creating a file hierarchy for the analysis files.\n",
    "\n",
    "In step one, the Dropbox is scoured for information about videos. If the videos do not have a VideoInfo.txt, the program will look for a .csv, if there is no .csv, the program will look for a .xlsx file. This is currently in conflict with what is happening in the kymo_class.py file, so that one will have to be amended.\n",
    "\n",
    "### Let's say that there are three ways to initiate a kymograph class:\n",
    "1. No info file is submitted, and the class will look for such a file itself.\n",
    "2. An info file is submitted, and the class will use the data in there.\n",
    "3. A kymograph is submitted, and the class will instantiate with the parameters that are passed with the kymograph.\n",
    "\n",
    "TODO: Make it so in the kymo_class\n",
    "TODO: Streamline the variable storage such that edge properties are stored in the edge_analysis class, and video properties are stored in the video_analysis class.\n",
    "\n",
    "### Below code:\n",
    "Are just import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "import re\n",
    "from amftrack.pipeline.development.high_mag_videos.kymo_class import *\n",
    "from amftrack.pipeline.development.high_mag_videos.plot_data import (\n",
    "    save_raw_data,\n",
    "    plot_summary,\n",
    "    read_video_data\n",
    ")\n",
    "import sys\n",
    "import os\n",
    "import imageio.v2 as imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tifffile import imwrite\n",
    "from tqdm import tqdm\n",
    "%matplotlib widget\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from amftrack.pipeline.functions.image_processing.extract_graph import (\n",
    "    from_sparse_to_graph,\n",
    "    generate_nx_graph,\n",
    "    clean_degree_4,\n",
    ")\n",
    "import scipy\n",
    "import matplotlib as mpl\n",
    "\n",
    "from amftrack.pipeline.launching.run import (\n",
    "    run_transfer,\n",
    ")\n",
    "from amftrack.pipeline.launching.run_super import run_parallel_transfer\n",
    "\n",
    "import dropbox\n",
    "from amftrack.util.dbx import upload_folders, download, read_saved_dropbox_state, save_dropbox_state, load_dbx, download, get_dropbox_folders, get_dropbox_video_folders\n",
    "from subprocess import call\n",
    "import logging\n",
    "import datetime\n",
    "import glob\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.debug)\n",
    "mpl.rcParams['figure.dpi'] = 300\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File declaration\n",
    "As this notebook is designed to work with Snellius, two items to separate are the raw video files and the anaylsis. The raw video files are large, bulky and not so easy to flip through. Ideally, the video files would be downloaded and the analysis would be stored on a separate folder structure entirely. That way, large scale analysis of analysis folders can happen when there are thousands of videos in the dataset, without having to have those raw video folders on hand.\n",
    "\n",
    "### Input and output:\n",
    "Please give separately the folder where raw video data is stored, and where the analysis will be stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_folder = \"/gpfs/scratch1/shared/amftrackflow/videos/\"\n",
    "analysis_folder = \"/gpfs/home6/svstaalduine/Analysis/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 1: Downloading videos from DropBox\n",
    "\n",
    "## Dropbox scrounging\n",
    "The below code is meant to scour the dropbox for information files on the videos. It is also to create a list of the videos within a certain database. The expectation at the very least is that one plate contains many videos, all labeled with a number. The code will take this list, and recreate the hierarchy within the Analysis_Output folder.\n",
    "\n",
    "### Input and output:\n",
    "The input will be the highest folder of the dropbox that needs to be analyzed, in addition to a folder which will store the excel sheets that will be downloaded for the DataFrame. The output will be a DataFrame that can be filtered in the next code block to prepare for downloading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropbox_address = \"/DATA/FLUORESCENCE/DATA_NileRed/20230201_Plate552/\"\n",
    "dropbox_address=  \"/DATA/MYRISTATE/DATA/2_weeks/20230313_Plate031/\"\n",
    "# dropbox_address = \"/DATA/TransportROOT/DATA/20230331_Plate773/\"\n",
    "\n",
    "excel_storage = \"/gpfs/home6/svstaalduine/excel_storage/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA/MYRISTATE/DATA/2_weeks/20230313_Plate031/01/Img\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>folder</th>\n",
       "      <th>Plate number</th>\n",
       "      <th>Date Imaged</th>\n",
       "      <th>tot_path_drop</th>\n",
       "      <th>video</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20230313_Plate031_01/Img/</td>\n",
       "      <td>031</td>\n",
       "      <td>20230313</td>\n",
       "      <td>DATA/MYRISTATE/DATA/2_weeks/20230313_Plate031/...</td>\n",
       "      <td>01/Img/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20230313_Plate031_02/Img/</td>\n",
       "      <td>031</td>\n",
       "      <td>20230313</td>\n",
       "      <td>DATA/MYRISTATE/DATA/2_weeks/20230313_Plate031/...</td>\n",
       "      <td>02/Img/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20230313_Plate031_03/Img/</td>\n",
       "      <td>031</td>\n",
       "      <td>20230313</td>\n",
       "      <td>DATA/MYRISTATE/DATA/2_weeks/20230313_Plate031/...</td>\n",
       "      <td>03/Img/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20230313_Plate031_04/Img/</td>\n",
       "      <td>031</td>\n",
       "      <td>20230313</td>\n",
       "      <td>DATA/MYRISTATE/DATA/2_weeks/20230313_Plate031/...</td>\n",
       "      <td>04/Img/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20230313_Plate031_05/Img/</td>\n",
       "      <td>031</td>\n",
       "      <td>20230313</td>\n",
       "      <td>DATA/MYRISTATE/DATA/2_weeks/20230313_Plate031/...</td>\n",
       "      <td>05/Img/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20230313_Plate031_06/Img/</td>\n",
       "      <td>031</td>\n",
       "      <td>20230313</td>\n",
       "      <td>DATA/MYRISTATE/DATA/2_weeks/20230313_Plate031/...</td>\n",
       "      <td>06/Img/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      folder Plate number Date Imaged  \\\n",
       "0  20230313_Plate031_01/Img/          031    20230313   \n",
       "1  20230313_Plate031_02/Img/          031    20230313   \n",
       "2  20230313_Plate031_03/Img/          031    20230313   \n",
       "3  20230313_Plate031_04/Img/          031    20230313   \n",
       "4  20230313_Plate031_05/Img/          031    20230313   \n",
       "5  20230313_Plate031_06/Img/          031    20230313   \n",
       "\n",
       "                                       tot_path_drop    video  \n",
       "0  DATA/MYRISTATE/DATA/2_weeks/20230313_Plate031/...  01/Img/  \n",
       "1  DATA/MYRISTATE/DATA/2_weeks/20230313_Plate031/...  02/Img/  \n",
       "2  DATA/MYRISTATE/DATA/2_weeks/20230313_Plate031/...  03/Img/  \n",
       "3  DATA/MYRISTATE/DATA/2_weeks/20230313_Plate031/...  04/Img/  \n",
       "4  DATA/MYRISTATE/DATA/2_weeks/20230313_Plate031/...  05/Img/  \n",
       "5  DATA/MYRISTATE/DATA/2_weeks/20230313_Plate031/...  06/Img/  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_folders_drop, excel_drop, txt_drop = get_dropbox_video_folders(dropbox_address, True)\n",
    "\n",
    "clear_output(wait=False)\n",
    "print(all_folders_drop['tot_path_drop'][0])\n",
    "all_folders_drop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files downloaded!\n"
     ]
    }
   ],
   "source": [
    "excel_addresses = np.array([re.search(\"^.*Plate.*\\/.*Plate.*$\", entry, re.IGNORECASE) for entry in excel_drop])\n",
    "excel_addresses = excel_addresses[excel_addresses != None]\n",
    "excel_addresses = [address.group(0) for address in excel_addresses]\n",
    "\n",
    "info_addresses  = []\n",
    "for address in np.concatenate([excel_addresses,txt_drop]):\n",
    "    csv_name_len = len(address.split(os.sep)[-1])\n",
    "    if not os.path.exists(analysis_folder + address[6:-csv_name_len]):\n",
    "        os.makedirs(analysis_folder + address[6:-csv_name_len])\n",
    "    download(address, analysis_folder + address[6:])\n",
    "    info_addresses.append(analysis_folder + address[6:])\n",
    "clear_output(wait=False)\n",
    "print(\"All files downloaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['unique_id', 'video_int', 'treatment', 'strain', 'xpos', 'ypos', 'mode',\n",
      "       'binning', 'magnification', 'fps', 'time', 'file_name', 'index',\n",
      "       'Plate number', 'imaging_day', 'tot_path_drop', 'video_folder',\n",
      "       'plate_id_xl', 'tot_path', 'video_id', 'plate_nr'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>video_int</th>\n",
       "      <th>treatment</th>\n",
       "      <th>strain</th>\n",
       "      <th>xpos</th>\n",
       "      <th>ypos</th>\n",
       "      <th>mode</th>\n",
       "      <th>binning</th>\n",
       "      <th>magnification</th>\n",
       "      <th>fps</th>\n",
       "      <th>...</th>\n",
       "      <th>file_name</th>\n",
       "      <th>index</th>\n",
       "      <th>Plate number</th>\n",
       "      <th>imaging_day</th>\n",
       "      <th>tot_path_drop</th>\n",
       "      <th>video_folder</th>\n",
       "      <th>plate_id_xl</th>\n",
       "      <th>tot_path</th>\n",
       "      <th>video_id</th>\n",
       "      <th>plate_nr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20230313_Plate031_01</td>\n",
       "      <td>1</td>\n",
       "      <td>0Myr</td>\n",
       "      <td>C2</td>\n",
       "      <td>28520</td>\n",
       "      <td>80140</td>\n",
       "      <td>BF</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>20230313_Plate031</td>\n",
       "      <td>0</td>\n",
       "      <td>031</td>\n",
       "      <td>20230313</td>\n",
       "      <td>DATA/MYRISTATE/DATA/2_weeks/20230313_Plate031/...</td>\n",
       "      <td>01/Img/</td>\n",
       "      <td>20230313_Plate031</td>\n",
       "      <td>MYRISTATE/DATA/2_weeks/20230313_Plate031/01/Img/</td>\n",
       "      <td>01</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20230313_Plate031_02</td>\n",
       "      <td>2</td>\n",
       "      <td>0Myr</td>\n",
       "      <td>C2</td>\n",
       "      <td>27140</td>\n",
       "      <td>80180</td>\n",
       "      <td>BF</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>20230313_Plate031</td>\n",
       "      <td>1</td>\n",
       "      <td>031</td>\n",
       "      <td>20230313</td>\n",
       "      <td>DATA/MYRISTATE/DATA/2_weeks/20230313_Plate031/...</td>\n",
       "      <td>02/Img/</td>\n",
       "      <td>20230313_Plate031</td>\n",
       "      <td>MYRISTATE/DATA/2_weeks/20230313_Plate031/02/Img/</td>\n",
       "      <td>02</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20230313_Plate031_03</td>\n",
       "      <td>3</td>\n",
       "      <td>0Myr</td>\n",
       "      <td>C2</td>\n",
       "      <td>32600</td>\n",
       "      <td>86020</td>\n",
       "      <td>BF</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>20230313_Plate031</td>\n",
       "      <td>2</td>\n",
       "      <td>031</td>\n",
       "      <td>20230313</td>\n",
       "      <td>DATA/MYRISTATE/DATA/2_weeks/20230313_Plate031/...</td>\n",
       "      <td>03/Img/</td>\n",
       "      <td>20230313_Plate031</td>\n",
       "      <td>MYRISTATE/DATA/2_weeks/20230313_Plate031/03/Img/</td>\n",
       "      <td>03</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20230313_Plate031_04</td>\n",
       "      <td>4</td>\n",
       "      <td>0Myr</td>\n",
       "      <td>C2</td>\n",
       "      <td>35220</td>\n",
       "      <td>78840</td>\n",
       "      <td>BF</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>20230313_Plate031</td>\n",
       "      <td>3</td>\n",
       "      <td>031</td>\n",
       "      <td>20230313</td>\n",
       "      <td>DATA/MYRISTATE/DATA/2_weeks/20230313_Plate031/...</td>\n",
       "      <td>04/Img/</td>\n",
       "      <td>20230313_Plate031</td>\n",
       "      <td>MYRISTATE/DATA/2_weeks/20230313_Plate031/04/Img/</td>\n",
       "      <td>04</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20230313_Plate031_05</td>\n",
       "      <td>5</td>\n",
       "      <td>0Myr</td>\n",
       "      <td>C2</td>\n",
       "      <td>38860</td>\n",
       "      <td>93780</td>\n",
       "      <td>BF</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>20230313_Plate031</td>\n",
       "      <td>4</td>\n",
       "      <td>031</td>\n",
       "      <td>20230313</td>\n",
       "      <td>DATA/MYRISTATE/DATA/2_weeks/20230313_Plate031/...</td>\n",
       "      <td>05/Img/</td>\n",
       "      <td>20230313_Plate031</td>\n",
       "      <td>MYRISTATE/DATA/2_weeks/20230313_Plate031/05/Img/</td>\n",
       "      <td>05</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20230313_Plate031_06</td>\n",
       "      <td>6</td>\n",
       "      <td>0Myr</td>\n",
       "      <td>C2</td>\n",
       "      <td>39560</td>\n",
       "      <td>93820</td>\n",
       "      <td>BF</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>20230313_Plate031</td>\n",
       "      <td>5</td>\n",
       "      <td>031</td>\n",
       "      <td>20230313</td>\n",
       "      <td>DATA/MYRISTATE/DATA/2_weeks/20230313_Plate031/...</td>\n",
       "      <td>06/Img/</td>\n",
       "      <td>20230313_Plate031</td>\n",
       "      <td>MYRISTATE/DATA/2_weeks/20230313_Plate031/06/Img/</td>\n",
       "      <td>06</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              unique_id  video_int treatment strain   xpos   ypos mode  \\\n",
       "0  20230313_Plate031_01          1      0Myr     C2  28520  80140   BF   \n",
       "1  20230313_Plate031_02          2      0Myr     C2  27140  80180   BF   \n",
       "2  20230313_Plate031_03          3      0Myr     C2  32600  86020   BF   \n",
       "3  20230313_Plate031_04          4      0Myr     C2  35220  78840   BF   \n",
       "4  20230313_Plate031_05          5      0Myr     C2  38860  93780   BF   \n",
       "5  20230313_Plate031_06          6      0Myr     C2  39560  93820   BF   \n",
       "\n",
       "   binning  magnification  fps  ...          file_name index  Plate number  \\\n",
       "0        2             50   20  ...  20230313_Plate031     0           031   \n",
       "1        2             50   20  ...  20230313_Plate031     1           031   \n",
       "2        2             50   20  ...  20230313_Plate031     2           031   \n",
       "3        2             50   20  ...  20230313_Plate031     3           031   \n",
       "4        2             50   20  ...  20230313_Plate031     4           031   \n",
       "5        2             50   20  ...  20230313_Plate031     5           031   \n",
       "\n",
       "  imaging_day                                      tot_path_drop video_folder  \\\n",
       "0    20230313  DATA/MYRISTATE/DATA/2_weeks/20230313_Plate031/...      01/Img/   \n",
       "1    20230313  DATA/MYRISTATE/DATA/2_weeks/20230313_Plate031/...      02/Img/   \n",
       "2    20230313  DATA/MYRISTATE/DATA/2_weeks/20230313_Plate031/...      03/Img/   \n",
       "3    20230313  DATA/MYRISTATE/DATA/2_weeks/20230313_Plate031/...      04/Img/   \n",
       "4    20230313  DATA/MYRISTATE/DATA/2_weeks/20230313_Plate031/...      05/Img/   \n",
       "5    20230313  DATA/MYRISTATE/DATA/2_weeks/20230313_Plate031/...      06/Img/   \n",
       "\n",
       "         plate_id_xl                                          tot_path  \\\n",
       "0  20230313_Plate031  MYRISTATE/DATA/2_weeks/20230313_Plate031/01/Img/   \n",
       "1  20230313_Plate031  MYRISTATE/DATA/2_weeks/20230313_Plate031/02/Img/   \n",
       "2  20230313_Plate031  MYRISTATE/DATA/2_weeks/20230313_Plate031/03/Img/   \n",
       "3  20230313_Plate031  MYRISTATE/DATA/2_weeks/20230313_Plate031/04/Img/   \n",
       "4  20230313_Plate031  MYRISTATE/DATA/2_weeks/20230313_Plate031/05/Img/   \n",
       "5  20230313_Plate031  MYRISTATE/DATA/2_weeks/20230313_Plate031/06/Img/   \n",
       "\n",
       "  video_id plate_nr  \n",
       "0       01       31  \n",
       "1       02       31  \n",
       "2       03       31  \n",
       "3       04       31  \n",
       "4       05       31  \n",
       "5       06       31  \n",
       "\n",
       "[6 rows x 21 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_frame = read_video_data(info_addresses, all_folders_drop)\n",
    "print(merge_frame.columns)\n",
    "merge_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropbox filtering\n",
    "If you want all videos in a plate or dataset, you can run this block and forget about it.\n",
    "Otherwise, this block is where filtering can take place to only download videos with certain properties, like imaging mode. Then a file structure will be created in the videos and analysis folder, and videoInfo.txt folders are created for every video, in the analysis folder. The intent here is to have a uniform Analysis folder structure that works with the Morrison setup.\n",
    "\n",
    "### Input\n",
    "Use the section between commented lines to filter the DataFrame, otherwise leave blank\n",
    "### Output\n",
    "Within the video and analysis folder, a hierarchy will be created to mimic that of the dropbox folder structure, using the filtered DataFrame. Inside the analysis folder hierarchy, the VideoInfo.txt file will be generated. Either from an existing videoInfo.txt, or the excel/csv sheets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>video_int</th>\n",
       "      <th>treatment</th>\n",
       "      <th>strain</th>\n",
       "      <th>xpos</th>\n",
       "      <th>ypos</th>\n",
       "      <th>mode</th>\n",
       "      <th>binning</th>\n",
       "      <th>magnification</th>\n",
       "      <th>fps</th>\n",
       "      <th>...</th>\n",
       "      <th>file_name</th>\n",
       "      <th>index</th>\n",
       "      <th>Plate number</th>\n",
       "      <th>imaging_day</th>\n",
       "      <th>tot_path_drop</th>\n",
       "      <th>video_folder</th>\n",
       "      <th>plate_id_xl</th>\n",
       "      <th>folder</th>\n",
       "      <th>video_id</th>\n",
       "      <th>plate_nr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20230313_Plate031_01</td>\n",
       "      <td>1</td>\n",
       "      <td>0Myr</td>\n",
       "      <td>C2</td>\n",
       "      <td>28520</td>\n",
       "      <td>80140</td>\n",
       "      <td>BF</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>20230313_Plate031</td>\n",
       "      <td>0</td>\n",
       "      <td>031</td>\n",
       "      <td>20230313</td>\n",
       "      <td>DATA/MYRISTATE/DATA/2_weeks/20230313_Plate031/...</td>\n",
       "      <td>01/Img/</td>\n",
       "      <td>20230313_Plate031</td>\n",
       "      <td>MYRISTATE/DATA/2_weeks/20230313_Plate031/01/Img/</td>\n",
       "      <td>01</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20230313_Plate031_02</td>\n",
       "      <td>2</td>\n",
       "      <td>0Myr</td>\n",
       "      <td>C2</td>\n",
       "      <td>27140</td>\n",
       "      <td>80180</td>\n",
       "      <td>BF</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>20230313_Plate031</td>\n",
       "      <td>1</td>\n",
       "      <td>031</td>\n",
       "      <td>20230313</td>\n",
       "      <td>DATA/MYRISTATE/DATA/2_weeks/20230313_Plate031/...</td>\n",
       "      <td>02/Img/</td>\n",
       "      <td>20230313_Plate031</td>\n",
       "      <td>MYRISTATE/DATA/2_weeks/20230313_Plate031/02/Img/</td>\n",
       "      <td>02</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20230313_Plate031_03</td>\n",
       "      <td>3</td>\n",
       "      <td>0Myr</td>\n",
       "      <td>C2</td>\n",
       "      <td>32600</td>\n",
       "      <td>86020</td>\n",
       "      <td>BF</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>20230313_Plate031</td>\n",
       "      <td>2</td>\n",
       "      <td>031</td>\n",
       "      <td>20230313</td>\n",
       "      <td>DATA/MYRISTATE/DATA/2_weeks/20230313_Plate031/...</td>\n",
       "      <td>03/Img/</td>\n",
       "      <td>20230313_Plate031</td>\n",
       "      <td>MYRISTATE/DATA/2_weeks/20230313_Plate031/03/Img/</td>\n",
       "      <td>03</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20230313_Plate031_04</td>\n",
       "      <td>4</td>\n",
       "      <td>0Myr</td>\n",
       "      <td>C2</td>\n",
       "      <td>35220</td>\n",
       "      <td>78840</td>\n",
       "      <td>BF</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>20230313_Plate031</td>\n",
       "      <td>3</td>\n",
       "      <td>031</td>\n",
       "      <td>20230313</td>\n",
       "      <td>DATA/MYRISTATE/DATA/2_weeks/20230313_Plate031/...</td>\n",
       "      <td>04/Img/</td>\n",
       "      <td>20230313_Plate031</td>\n",
       "      <td>MYRISTATE/DATA/2_weeks/20230313_Plate031/04/Img/</td>\n",
       "      <td>04</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20230313_Plate031_05</td>\n",
       "      <td>5</td>\n",
       "      <td>0Myr</td>\n",
       "      <td>C2</td>\n",
       "      <td>38860</td>\n",
       "      <td>93780</td>\n",
       "      <td>BF</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>20230313_Plate031</td>\n",
       "      <td>4</td>\n",
       "      <td>031</td>\n",
       "      <td>20230313</td>\n",
       "      <td>DATA/MYRISTATE/DATA/2_weeks/20230313_Plate031/...</td>\n",
       "      <td>05/Img/</td>\n",
       "      <td>20230313_Plate031</td>\n",
       "      <td>MYRISTATE/DATA/2_weeks/20230313_Plate031/05/Img/</td>\n",
       "      <td>05</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20230313_Plate031_06</td>\n",
       "      <td>6</td>\n",
       "      <td>0Myr</td>\n",
       "      <td>C2</td>\n",
       "      <td>39560</td>\n",
       "      <td>93820</td>\n",
       "      <td>BF</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>20230313_Plate031</td>\n",
       "      <td>5</td>\n",
       "      <td>031</td>\n",
       "      <td>20230313</td>\n",
       "      <td>DATA/MYRISTATE/DATA/2_weeks/20230313_Plate031/...</td>\n",
       "      <td>06/Img/</td>\n",
       "      <td>20230313_Plate031</td>\n",
       "      <td>MYRISTATE/DATA/2_weeks/20230313_Plate031/06/Img/</td>\n",
       "      <td>06</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              unique_id  video_int treatment strain   xpos   ypos mode  \\\n",
       "0  20230313_Plate031_01          1      0Myr     C2  28520  80140   BF   \n",
       "1  20230313_Plate031_02          2      0Myr     C2  27140  80180   BF   \n",
       "2  20230313_Plate031_03          3      0Myr     C2  32600  86020   BF   \n",
       "3  20230313_Plate031_04          4      0Myr     C2  35220  78840   BF   \n",
       "4  20230313_Plate031_05          5      0Myr     C2  38860  93780   BF   \n",
       "5  20230313_Plate031_06          6      0Myr     C2  39560  93820   BF   \n",
       "\n",
       "   binning  magnification  fps  ...          file_name index  Plate number  \\\n",
       "0        2             50   20  ...  20230313_Plate031     0           031   \n",
       "1        2             50   20  ...  20230313_Plate031     1           031   \n",
       "2        2             50   20  ...  20230313_Plate031     2           031   \n",
       "3        2             50   20  ...  20230313_Plate031     3           031   \n",
       "4        2             50   20  ...  20230313_Plate031     4           031   \n",
       "5        2             50   20  ...  20230313_Plate031     5           031   \n",
       "\n",
       "  imaging_day                                      tot_path_drop video_folder  \\\n",
       "0    20230313  DATA/MYRISTATE/DATA/2_weeks/20230313_Plate031/...      01/Img/   \n",
       "1    20230313  DATA/MYRISTATE/DATA/2_weeks/20230313_Plate031/...      02/Img/   \n",
       "2    20230313  DATA/MYRISTATE/DATA/2_weeks/20230313_Plate031/...      03/Img/   \n",
       "3    20230313  DATA/MYRISTATE/DATA/2_weeks/20230313_Plate031/...      04/Img/   \n",
       "4    20230313  DATA/MYRISTATE/DATA/2_weeks/20230313_Plate031/...      05/Img/   \n",
       "5    20230313  DATA/MYRISTATE/DATA/2_weeks/20230313_Plate031/...      06/Img/   \n",
       "\n",
       "         plate_id_xl                                            folder  \\\n",
       "0  20230313_Plate031  MYRISTATE/DATA/2_weeks/20230313_Plate031/01/Img/   \n",
       "1  20230313_Plate031  MYRISTATE/DATA/2_weeks/20230313_Plate031/02/Img/   \n",
       "2  20230313_Plate031  MYRISTATE/DATA/2_weeks/20230313_Plate031/03/Img/   \n",
       "3  20230313_Plate031  MYRISTATE/DATA/2_weeks/20230313_Plate031/04/Img/   \n",
       "4  20230313_Plate031  MYRISTATE/DATA/2_weeks/20230313_Plate031/05/Img/   \n",
       "5  20230313_Plate031  MYRISTATE/DATA/2_weeks/20230313_Plate031/06/Img/   \n",
       "\n",
       "  video_id plate_nr  \n",
       "0       01       31  \n",
       "1       02       31  \n",
       "2       03       31  \n",
       "3       04       31  \n",
       "4       05       31  \n",
       "5       06       31  \n",
       "\n",
       "[6 rows x 21 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#####################################################################################\n",
    "### This is where you can apply the filters. Only those videos will be downloaded ###\n",
    "#####################################################################################\n",
    "\n",
    "download_frame = merge_frame.copy()\n",
    "\n",
    "#####################################################################################\n",
    "### Below code will prepare for those videos to be downloaded into videos_folder  ###\n",
    "#####################################################################################\n",
    "\n",
    "download_frame = download_frame.rename(columns={'tot_path' : 'folder'})\n",
    "download_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in download_frame.iterrows():\n",
    "    target_anals_file = f\"{analysis_folder}{row['folder'][:-4]}\"\n",
    "    target_video_file = f\"{videos_folder}{row['folder']}\"\n",
    "    \n",
    "    if not os.path.exists(target_anals_file):\n",
    "        os.makedirs(target_anals_file)\n",
    "    if not os.path.exists(target_video_file):\n",
    "        os.makedirs(target_video_file)\n",
    "    \n",
    "    row.to_json(f\"{target_anals_file}/video_data.json\", orient=\"index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading\n",
    "This section, there is one block of code that will ask you one last time whether all of the parameters are correct. The block of code after that will initiate Snellius jobs to download the videos in the DataFrame from the dropbox. Downloading videos is not that costly, but of course we prefer it to be done as efficiently as possible.\n",
    "### Input:\n",
    "Nothing\n",
    "### Output:\n",
    "Print statement with the DataFrame and the folders where everything will be stored.\n",
    "Subsequent block of code will download raw video files to the videos folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 3003245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 3003246\n",
      "Submitted batch job 3003247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n",
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 3003248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 3003249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 3003250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 32 CPU cores, 229376 MiB of memory and 0 GPUs and can be shared by up to 32 jobs.\n",
      "sbatch: By default shared jobs get 7168 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 0.03125 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 3003251\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/scratch-local/svstaalduine/ipykernel_3607504/617512689.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m run_parallel_transfer(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;34m\"from_drop.py\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0mvideos_folder\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdownload_frame\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/gpfs/home6/svstaalduine/AMF_project/amftrack/pipeline/launching/run_super.py\u001b[0m in \u001b[0;36mrun_parallel_transfer\u001b[0;34m(code, args, folders, num_parallel, time, name, cpus, node, name_job, dependency)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0mmy_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"wait\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0mmy_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m         \u001b[0mcall_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_job\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdependency\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/gpfs/home6/svstaalduine/AMF_project/amftrack/pipeline/launching/run_super.py\u001b[0m in \u001b[0;36mcall_code\u001b[0;34m(path_job, dependency)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"sbatch --dependency=singleton {path_job}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshell\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run_parallel_transfer(\n",
    "    \"from_drop.py\",\n",
    "    [videos_folder],\n",
    "    download_frame,\n",
    "    1,\n",
    "    \"10:00:00\",\n",
    "    \"transfer_test\"\n",
    ")\n",
    "clear_output(wait=False)\n",
    "\n",
    "print(\"Sent all the jobs! Use the command '$ squeue' in the terminal to see the progress\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 2: Analysis\n",
    "Now that the files have been downloaded, it's time to analyse them. In the below code, you'll be able to either do a complete survey of the analysis folder for as many videos as possible, or use the DataFrame of recently downloaded videos to filter for the videos you want to analyse.\n",
    "\n",
    "### Input:\n",
    "DataFrame filters of all videos to be analysed\n",
    "### Output:\n",
    "Print statements for all parameters of the analysis session that is about to take place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imaging_day</th>\n",
       "      <th>storage_path</th>\n",
       "      <th>plate_id</th>\n",
       "      <th>root</th>\n",
       "      <th>strain</th>\n",
       "      <th>treatment</th>\n",
       "      <th>crossing_day</th>\n",
       "      <th>video_int</th>\n",
       "      <th>time_(s)</th>\n",
       "      <th>mode</th>\n",
       "      <th>...</th>\n",
       "      <th>magnification</th>\n",
       "      <th>time</th>\n",
       "      <th>file_name</th>\n",
       "      <th>index</th>\n",
       "      <th>Plate number</th>\n",
       "      <th>video_folder</th>\n",
       "      <th>plate_id_xl</th>\n",
       "      <th>folder</th>\n",
       "      <th>video_id</th>\n",
       "      <th>plate_nr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20230331</td>\n",
       "      <td>Dropbox\\DATA\\TransportROOT\\DATA</td>\n",
       "      <td>20230331_Plate773</td>\n",
       "      <td>Carrot</td>\n",
       "      <td>C2</td>\n",
       "      <td>001P100N100C</td>\n",
       "      <td>20230327</td>\n",
       "      <td>68</td>\n",
       "      <td>30.0</td>\n",
       "      <td>BF</td>\n",
       "      <td>...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20230331</td>\n",
       "      <td>Dropbox\\DATA\\TransportROOT\\DATA</td>\n",
       "      <td>20230331_Plate773</td>\n",
       "      <td>Carrot</td>\n",
       "      <td>C2</td>\n",
       "      <td>001P100N100C</td>\n",
       "      <td>20230327</td>\n",
       "      <td>18</td>\n",
       "      <td>30.0</td>\n",
       "      <td>BF</td>\n",
       "      <td>...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20230331</td>\n",
       "      <td>Dropbox\\DATA\\TransportROOT\\DATA</td>\n",
       "      <td>20230331_Plate773</td>\n",
       "      <td>Carrot</td>\n",
       "      <td>C2</td>\n",
       "      <td>001P100N100C</td>\n",
       "      <td>20230327</td>\n",
       "      <td>14</td>\n",
       "      <td>30.0</td>\n",
       "      <td>BF</td>\n",
       "      <td>...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20230331</td>\n",
       "      <td>Dropbox\\DATA\\TransportROOT\\DATA</td>\n",
       "      <td>20230331_Plate773</td>\n",
       "      <td>Carrot</td>\n",
       "      <td>C2</td>\n",
       "      <td>001P100N100C</td>\n",
       "      <td>20230327</td>\n",
       "      <td>56</td>\n",
       "      <td>30.0</td>\n",
       "      <td>BF</td>\n",
       "      <td>...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20230331</td>\n",
       "      <td>Dropbox\\DATA\\TransportROOT\\DATA</td>\n",
       "      <td>20230331_Plate773</td>\n",
       "      <td>Carrot</td>\n",
       "      <td>C2</td>\n",
       "      <td>001P100N100C</td>\n",
       "      <td>20230327</td>\n",
       "      <td>6</td>\n",
       "      <td>30.0</td>\n",
       "      <td>BF</td>\n",
       "      <td>...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>20230313</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C2</td>\n",
       "      <td>0Myr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BF</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>30</td>\n",
       "      <td>20230313_Plate031</td>\n",
       "      <td>4</td>\n",
       "      <td>031</td>\n",
       "      <td>05/Img/</td>\n",
       "      <td>20230313_Plate031</td>\n",
       "      <td>MYRISTATE/DATA/2_weeks/20230313_Plate031/05/Img/</td>\n",
       "      <td>05</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>20230313</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C2</td>\n",
       "      <td>0Myr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BF</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>30</td>\n",
       "      <td>20230313_Plate031</td>\n",
       "      <td>0</td>\n",
       "      <td>031</td>\n",
       "      <td>01/Img/</td>\n",
       "      <td>20230313_Plate031</td>\n",
       "      <td>MYRISTATE/DATA/2_weeks/20230313_Plate031/01/Img/</td>\n",
       "      <td>01</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>20230313</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C2</td>\n",
       "      <td>0Myr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BF</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>20230313_Plate031</td>\n",
       "      <td>3</td>\n",
       "      <td>031</td>\n",
       "      <td>04/Img/</td>\n",
       "      <td>20230313_Plate031</td>\n",
       "      <td>MYRISTATE/DATA/2_weeks/20230313_Plate031/04/Img/</td>\n",
       "      <td>04</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>20230313</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C2</td>\n",
       "      <td>0Myr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BF</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>20230313_Plate031</td>\n",
       "      <td>2</td>\n",
       "      <td>031</td>\n",
       "      <td>03/Img/</td>\n",
       "      <td>20230313_Plate031</td>\n",
       "      <td>MYRISTATE/DATA/2_weeks/20230313_Plate031/03/Img/</td>\n",
       "      <td>03</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>20230313</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C2</td>\n",
       "      <td>0Myr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BF</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>20230313_Plate031</td>\n",
       "      <td>5</td>\n",
       "      <td>031</td>\n",
       "      <td>06/Img/</td>\n",
       "      <td>20230313_Plate031</td>\n",
       "      <td>MYRISTATE/DATA/2_weeks/20230313_Plate031/06/Img/</td>\n",
       "      <td>06</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   imaging_day                     storage_path           plate_id    root  \\\n",
       "0     20230331  Dropbox\\DATA\\TransportROOT\\DATA  20230331_Plate773  Carrot   \n",
       "1     20230331  Dropbox\\DATA\\TransportROOT\\DATA  20230331_Plate773  Carrot   \n",
       "2     20230331  Dropbox\\DATA\\TransportROOT\\DATA  20230331_Plate773  Carrot   \n",
       "3     20230331  Dropbox\\DATA\\TransportROOT\\DATA  20230331_Plate773  Carrot   \n",
       "4     20230331  Dropbox\\DATA\\TransportROOT\\DATA  20230331_Plate773  Carrot   \n",
       "..         ...                              ...                ...     ...   \n",
       "69    20230313                              NaN                NaN     NaN   \n",
       "70    20230313                              NaN                NaN     NaN   \n",
       "71    20230313                              NaN                NaN     NaN   \n",
       "72    20230313                              NaN                NaN     NaN   \n",
       "73    20230313                              NaN                NaN     NaN   \n",
       "\n",
       "   strain     treatment crossing_day video_int time_(s) mode  ...  \\\n",
       "0      C2  001P100N100C     20230327        68     30.0   BF  ...   \n",
       "1      C2  001P100N100C     20230327        18     30.0   BF  ...   \n",
       "2      C2  001P100N100C     20230327        14     30.0   BF  ...   \n",
       "3      C2  001P100N100C     20230327        56     30.0   BF  ...   \n",
       "4      C2  001P100N100C     20230327         6     30.0   BF  ...   \n",
       "..    ...           ...          ...       ...      ...  ...  ...   \n",
       "69     C2          0Myr          NaN         5      NaN   BF  ...   \n",
       "70     C2          0Myr          NaN         1      NaN   BF  ...   \n",
       "71     C2          0Myr          NaN         4      NaN   BF  ...   \n",
       "72     C2          0Myr          NaN         3      NaN   BF  ...   \n",
       "73     C2          0Myr          NaN         6      NaN   BF  ...   \n",
       "\n",
       "   magnification time          file_name index Plate number video_folder  \\\n",
       "0           50.0  NaN                NaN   NaN          NaN          NaN   \n",
       "1           50.0  NaN                NaN   NaN          NaN          NaN   \n",
       "2           50.0  NaN                NaN   NaN          NaN          NaN   \n",
       "3           50.0  NaN                NaN   NaN          NaN          NaN   \n",
       "4           50.0  NaN                NaN   NaN          NaN          NaN   \n",
       "..           ...  ...                ...   ...          ...          ...   \n",
       "69            50   30  20230313_Plate031     4          031      05/Img/   \n",
       "70            50   30  20230313_Plate031     0          031      01/Img/   \n",
       "71            50   10  20230313_Plate031     3          031      04/Img/   \n",
       "72            50   10  20230313_Plate031     2          031      03/Img/   \n",
       "73            50   10  20230313_Plate031     5          031      06/Img/   \n",
       "\n",
       "          plate_id_xl                                            folder  \\\n",
       "0                 NaN                                               NaN   \n",
       "1                 NaN                                               NaN   \n",
       "2                 NaN                                               NaN   \n",
       "3                 NaN                                               NaN   \n",
       "4                 NaN                                               NaN   \n",
       "..                ...                                               ...   \n",
       "69  20230313_Plate031  MYRISTATE/DATA/2_weeks/20230313_Plate031/05/Img/   \n",
       "70  20230313_Plate031  MYRISTATE/DATA/2_weeks/20230313_Plate031/01/Img/   \n",
       "71  20230313_Plate031  MYRISTATE/DATA/2_weeks/20230313_Plate031/04/Img/   \n",
       "72  20230313_Plate031  MYRISTATE/DATA/2_weeks/20230313_Plate031/03/Img/   \n",
       "73  20230313_Plate031  MYRISTATE/DATA/2_weeks/20230313_Plate031/06/Img/   \n",
       "\n",
       "   video_id plate_nr  \n",
       "0       NaN      NaN  \n",
       "1       NaN      NaN  \n",
       "2       NaN      NaN  \n",
       "3       NaN      NaN  \n",
       "4       NaN      NaN  \n",
       "..      ...      ...  \n",
       "69       05       31  \n",
       "70       01       31  \n",
       "71       04       31  \n",
       "72       03       31  \n",
       "73       06       31  \n",
       "\n",
       "[74 rows x 34 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_infos = glob.glob(f\"{analysis_folder}/**/video_data.json\", recursive=True)\n",
    "vid_anls_frame = pd.DataFrame()\n",
    "for address in img_infos:\n",
    "    add_info = pd.read_json(address, orient='index').T\n",
    "    vid_anls_frame = pd.concat([vid_anls_frame, add_info], ignore_index=True)\n",
    "\n",
    "vid_anls_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Analysis job\n",
    "Below code will use the aforementioned DataFrame to initiate analysis jobs on Snellius.\n",
    "## Input:\n",
    "Snellius job parameters\n",
    "## Output:\n",
    "Analysis folder will be populated with analysis tiffs and csv sheets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 3: Bulk Analysis\n",
    "## First part: Assemble Edge DataFrame\n",
    "In this initial part of the bulk analysis, all of the analysis folders will be looked through to find the edge data we're looking for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
