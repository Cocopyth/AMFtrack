{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed8b1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from amftrack.pipeline.development.high_mag_videos.kymo_class import *\n",
    "from amftrack.pipeline.development.high_mag_videos.plot_data import (\n",
    "    save_raw_data,\n",
    "    plot_summary,\n",
    ")\n",
    "\n",
    "# from amftrack.pipeline.development.high_mag_videos.high_mag_videos_fun import segment_brightfield\n",
    "import os\n",
    "import imageio.v2 as imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tifffile import imwrite\n",
    "from tifffile import imread\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib widget\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from amftrack.pipeline.functions.image_processing.extract_graph import (\n",
    "    from_sparse_to_graph,\n",
    "    generate_nx_graph,\n",
    "    clean_degree_4,\n",
    ")\n",
    "import scipy\n",
    "from pathlib import Path\n",
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rcParams[\"figure.dpi\"] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86da390e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_brightfield(\n",
    "    image, thresh=0.5e-6, frangi_range=np.arange(70, 170, 30), seg_thresh=11, binning=2\n",
    "):\n",
    "    frangi_range = frangi_range * 2 / binning\n",
    "    smooth_im_blur = cv2.blur(-image, (11, 11))\n",
    "    smooth_im = frangi(-smooth_im_blur, frangi_range)\n",
    "    smooth_im = np.array(smooth_im * (255/np.max(smooth_im)), dtype=np.uint8)\n",
    "    seg_shape = smooth_im.shape\n",
    "\n",
    "#     for i in range(1, 100):\n",
    "#         _, segmented = cv2.threshold(smooth_im, i, 255, cv2.THRESH_BINARY)\n",
    "#         coverage = 100 * np.sum(1 * segmented.flatten()) / (255 * seg_shape[0] * seg_shape[1])\n",
    "#         if coverage < seg_thresh:\n",
    "#             break\n",
    "    return smooth_im\n",
    "\n",
    "def segment_fluo(image, thresh=0.5e-7, seg_thresh=4.5, k_size=40, magnif=50, binning=2, test_plot=False):\n",
    "    k_size = [30, 5][magnif < 50]\n",
    "    kernel = np.ones((k_size, k_size), np.uint8)\n",
    "    kernel_2 = np.ones((10, 10), np.uint8)\n",
    "    smooth_im = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "#     smooth_im = cv2.morphologyEx(smooth_im, cv2.MORPH_TOPHAT, kernel)\n",
    "#     im_canny_smooth = cv2.GaussianBlur(im_canny, (5, 5), 0)\n",
    "    smooth_im_close = cv2.morphologyEx(smooth_im, cv2.MORPH_OPEN, kernel)\n",
    "    std_im = generic_filter(image, np.std, size=60)\n",
    "    if magnif < 30:\n",
    "        im_canny = cv2.Canny(smooth_im, 0, 20)\n",
    "        smooth_im = cv2.morphologyEx(im_canny, cv2.MORPH_DILATE, kernel)\n",
    "\n",
    "\n",
    "\n",
    "#     criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.85)\n",
    "#     retval, labels, centers = cv2.kmeans(k_data, [4, 2][magnif < 30], None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
    "#     centers = np.uint8(centers)\n",
    "#     labels = np.array(labels.T[0])\n",
    "#     centers = [center[0] for center in centers]\n",
    "#     segmented_data = np.array([centers[label] for label in labels])\n",
    "#     segmented_image = segmented_data.reshape((smooth_im.shape))\n",
    "#     segmented_image = np.uint8(segmented_image > np.min(centers))\n",
    "#     segmented = cv2.morphologyEx(segmented_image, cv2.MORPH_CLOSE, kernel_2)\n",
    "\n",
    "#     skeletonized = skeletonize(segmented > thresh)\n",
    "\n",
    "#     if test_plot:\n",
    "#         fig, ax = plt.subplots(7, figsize=(9, 25))\n",
    "#         ax[0].imshow(im_canny)\n",
    "#         ax[0].set_title(\"Smooth\")\n",
    "#         ax[1].imshow(std_im)\n",
    "#         ax[1].set_title(\"open\")\n",
    "#         ax[2].imshow(smooth_im)\n",
    "#         ax[2].set_title(\"smooth_im\")\n",
    "#         ax[3].imshow(segmented)\n",
    "#         ax[3].set_title(\"segmented\")\n",
    "#         ax[4].imshow(skeletonized)\n",
    "#         ax[5].hist(smooth_im_close.flatten(), log=True, bins=50)\n",
    "#         ax[6].plot(smooth_im_close[1000])\n",
    "#         fig.tight_layout()\n",
    "\n",
    "#     skeleton = scipy.sparse.dok_matrix(skeletonized)\n",
    "#     nx_graph, pos = generate_nx_graph(from_sparse_to_graph(skeleton))\n",
    "#     nx_graph_pruned, pos = remove_spurs(nx_graph, pos, threshold=200)\n",
    "    return smooth_im, smooth_im_close, std_im\n",
    "\n",
    "# def segm_std(frames, magnification=50, binning=2):\n",
    "    \n",
    "    \n",
    "\n",
    "vid_folder = Path(\"/gpfs/scratch1/shared/amftrackflow/videos/CocoTransport/\")\n",
    "plate = \"20230906_Plate310\"\n",
    "vid_interest = \"004\"\n",
    "# edge_interest = \"edge (115, 104)\"\n",
    "img_address = vid_folder / plate #/ vid_interest\n",
    "# img_address = vid_folder\n",
    "\n",
    "\n",
    "# print(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4f832f",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = sorted([path for path in img_address.glob(\"*/*.ti*\")])\n",
    "frames = []\n",
    "frame_max = imread(imgs[0])\n",
    "for address in tqdm(imgs):\n",
    "    frame2 = imread(address)\n",
    "    \n",
    "    if (len(frames) < 60):\n",
    "        frames.append(frame2)\n",
    "        \n",
    "    frame_max = np.maximum(frame_max, frame2)\n",
    "img = frame_max\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc78099b",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_matrix = np.stack(frames, axis=0)\n",
    "\n",
    "std_matrix = np.std(video_matrix, axis=0)\n",
    "\n",
    "plt.imshow(std_matrix, cmap='viridis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543472bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Path to the TIFF video\n",
    "video_path = str(img_address)\n",
    "\n",
    "# Open the video file\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Initialize a list to store frames\n",
    "frames = []\n",
    "\n",
    "# Read the first five frames and store them in the frames list\n",
    "frame_count = 0\n",
    "while frame_count < 5:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"empty\")\n",
    "        # If the video has fewer than 5 frames, break out of the loop\n",
    "        break\n",
    "    frames.append(frame)\n",
    "    frame_count += 1\n",
    "\n",
    "print(frame_count)\n",
    "\n",
    "# Convert the list of frames into a numpy array\n",
    "video_matrix = np.stack(frames, axis=0)\n",
    "\n",
    "# video_matrix now contains the first five frames as a 3D numpy array\n",
    "# You can access individual frames using video_matrix[index], where index is 0 to 4.\n",
    "\n",
    "std_matrix = np.std(video_matrix)\n",
    "\n",
    "\n",
    "\n",
    "# Release the video capture object\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b05813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# segmented = segment_brightfield(img, frangi_range = np.arange(5, 40, 3))\n",
    "# segmented = segment_brightfield(img, frangi_range = np.arange(10, 150, 20))\n",
    "segmented, segment_alt, std_im = segment_fluo(img, magnif=50)\n",
    "# _, segment_thresh = cv2.threshold(segment_alt, 0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "\n",
    "# segmented, segment_alt = segment_fluo(img, magnif=50)\n",
    "\n",
    "_, segment_thresh = cv2.threshold(std_im, 0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "segment_thresh = cv2.morphologyEx(segment_thresh, cv2.MORPH_CLOSE, np.ones((9,9)))\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(10, 5))\n",
    "ax[0][0].imshow(img)\n",
    "ax[0][1].imshow(segmented)\n",
    "ax[1][0].imshow(segment_thresh)\n",
    "ax[1][1].imshow(segment_alt)\n",
    "fig.tight_layout()\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.hist(segmented.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d7eb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "ftimage = np.fft.fft2(img)\n",
    "ftimage = np.fft.fftshift(ftimage)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(np.log(abs(ftimage.real)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851c4ff4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
