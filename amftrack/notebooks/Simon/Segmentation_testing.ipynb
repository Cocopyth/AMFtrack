{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed8b1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from amftrack.pipeline.functions.transport_processing.high_mag_videos.kymo_class import *\n",
    "from amftrack.pipeline.functions.transport_processing.high_mag_videos.plot_data import (\n",
    "    save_raw_data,\n",
    "    plot_summary\n",
    ")\n",
    "# from amftrack.pipeline.development.high_mag_videos.high_mag_videos_fun import segment_brightfield\n",
    "import os\n",
    "import imageio.v2 as imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tifffile import imwrite\n",
    "from tifffile import imread\n",
    "from tqdm import tqdm\n",
    "%matplotlib widget\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from amftrack.pipeline.functions.image_processing.extract_graph import (\n",
    "    from_sparse_to_graph,\n",
    "    generate_nx_graph,\n",
    "    clean_degree_4,\n",
    ")\n",
    "import scipy\n",
    "from pathlib import Path\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 300\n",
    "from scipy.optimize import minimize_scalar\n",
    "from skimage.filters import try_all_threshold\n",
    "from skimage.filters import threshold_yen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86da390e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def calculate_renyi_entropy(threshold, pixels):\n",
    "    # Calculate probabilities and entropies\n",
    "    Ps = np.mean(pixels <= threshold)\n",
    "    Hs = -np.sum(pixels[pixels <= threshold] * np.log(pixels[pixels <= threshold] + 1e-10))\n",
    "    Hn = -np.sum(pixels * np.log(pixels + 1e-10))\n",
    "\n",
    "    # Calculate phi(s)\n",
    "    phi_s = np.log(Ps * (1 - Ps)) + Hs / Ps + (Hn - Hs) / (1 - Ps)\n",
    "\n",
    "    return -phi_s\n",
    "\n",
    "def RenyiEntropy_thresholding(image):\n",
    "    # Flatten the image\n",
    "    pixels = image.flatten()\n",
    "#     print(pixels)\n",
    "    # Find the optimal threshold\n",
    "    initial_threshold = np.mean(pixels)\n",
    "    result = minimize_scalar(calculate_renyi_entropy, bounds=(0, 255), args=(pixels,), method='bounded')\n",
    "    \n",
    "    optimal_threshold = result.x\n",
    "#     print(optimal_threshold)\n",
    "#     print(np.max(image))\n",
    "    _, thresholded = cv2.threshold(image/np.max(image)*255, optimal_threshold, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    return thresholded\n",
    "\n",
    "\n",
    "def segment_brightfield(image, thresh=0.5e-6, frangi_range=np.arange(70, 170, 30), seg_thresh = 11, binning=2):\n",
    "    frangi_range = frangi_range * 2 / binning\n",
    "    smooth_im_blur = cv2.blur(-image, (11, 11))\n",
    "    smooth_im = frangi(-smooth_im_blur, frangi_range)\n",
    "    smooth_im = np.array(smooth_im * (255/np.max(smooth_im)), dtype=np.uint8)\n",
    "    seg_shape = smooth_im.shape\n",
    "\n",
    "#     for i in range(1, 100):\n",
    "#         _, segmented = cv2.threshold(smooth_im, i, 255, cv2.THRESH_BINARY)\n",
    "#         coverage = 100 * np.sum(1 * segmented.flatten()) / (255 * seg_shape[0] * seg_shape[1])\n",
    "#         if coverage < seg_thresh:\n",
    "#             break\n",
    "    return smooth_im\n",
    "\n",
    "def segment_fluo(image, thresh=0.5e-7, seg_thresh=4.5, k_size=40, magnif=50, binning=2, test_plot=False):\n",
    "    k_size = [30, 5][magnif < 50]\n",
    "    kernel = np.ones((k_size, k_size), np.uint8)\n",
    "    kernel_2 = np.ones((10, 10), np.uint8)\n",
    "    smooth_im = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "#     smooth_im = cv2.morphologyEx(smooth_im, cv2.MORPH_TOPHAT, kernel)\n",
    "#     im_canny_smooth = cv2.GaussianBlur(im_canny, (5, 5), 0)\n",
    "    smooth_im_close = cv2.morphologyEx(smooth_im, cv2.MORPH_OPEN, kernel)\n",
    "    std_im = generic_filter(image, np.std, size=60)\n",
    "    if magnif < 30:\n",
    "        im_canny = cv2.Canny(smooth_im, 0, 20)\n",
    "        smooth_im = cv2.morphologyEx(im_canny, cv2.MORPH_DILATE, kernel)\n",
    "\n",
    "\n",
    "\n",
    "#     criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.85)\n",
    "#     retval, labels, centers = cv2.kmeans(k_data, [4, 2][magnif < 30], None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
    "#     centers = np.uint8(centers)\n",
    "#     labels = np.array(labels.T[0])\n",
    "#     centers = [center[0] for center in centers]\n",
    "#     segmented_data = np.array([centers[label] for label in labels])\n",
    "#     segmented_image = segmented_data.reshape((smooth_im.shape))\n",
    "#     segmented_image = np.uint8(segmented_image > np.min(centers))\n",
    "#     segmented = cv2.morphologyEx(segmented_image, cv2.MORPH_CLOSE, kernel_2)\n",
    "\n",
    "#     skeletonized = skeletonize(segmented > thresh)\n",
    "\n",
    "#     if test_plot:\n",
    "#         fig, ax = plt.subplots(7, figsize=(9, 25))\n",
    "#         ax[0].imshow(im_canny)\n",
    "#         ax[0].set_title(\"Smooth\")\n",
    "#         ax[1].imshow(std_im)\n",
    "#         ax[1].set_title(\"open\")\n",
    "#         ax[2].imshow(smooth_im)\n",
    "#         ax[2].set_title(\"smooth_im\")\n",
    "#         ax[3].imshow(segmented)\n",
    "#         ax[3].set_title(\"segmented\")\n",
    "#         ax[4].imshow(skeletonized)\n",
    "#         ax[5].hist(smooth_im_close.flatten(), log=True, bins=50)\n",
    "#         ax[6].plot(smooth_im_close[1000])\n",
    "#         fig.tight_layout()\n",
    "\n",
    "#     skeleton = scipy.sparse.dok_matrix(skeletonized)\n",
    "#     nx_graph, pos = generate_nx_graph(from_sparse_to_graph(skeleton))\n",
    "#     nx_graph_pruned, pos = remove_spurs(nx_graph, pos, threshold=200)\n",
    "    return smooth_im, smooth_im_close, std_im\n",
    "\n",
    "# def segm_std(frames, magnification=50, binning=2):\n",
    "    \n",
    "def segment_brightfield_std(\n",
    "    images,\n",
    "    seg_thresh=1.05,\n",
    "):\n",
    "    \"\"\"\n",
    "    Segmentation method for brightfield video, uses vesselness filters to get result.\n",
    "    image:          Input image\n",
    "    thresh:         Value close to zero such that the function will output a boolean array\n",
    "    frangi_range:   Range of values to use a frangi filter with. Frangi filter is very good for brightfield vessel segmentation\n",
    "\n",
    "    \"\"\"\n",
    "    std_image = np.std(images,axis=0)/np.mean(images,axis=0)\n",
    "    smooth_im_blur = cv2.blur(std_image, (101, 101))\n",
    "    print(np.max(std_image))\n",
    "    print(np.max(smooth_im_blur))\n",
    "    \n",
    "    \n",
    "#     plt.figure(2)\n",
    "#     plt.imshow(smooth_im_blur)\n",
    "    \n",
    "#     plt.figure(3)\n",
    "#     plt.imshow(std_image)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "#     fig, ax = try_all_threshold(smooth_im_blur, figsize=(10, 8), verbose=False)\n",
    "#     plt.show()\n",
    "    # this works well, the other yen implementation doesn't work yet. not worth to try myself when this works well already\n",
    "    thresh = threshold_yen(smooth_im_blur)\n",
    "    # the renyi entropy works now aswell.\n",
    "    # It is weird that we calculate with an image [0,1] and rescale to [0,255] for thresholding\n",
    "    segmented = RenyiEntropy_thresholding(smooth_im_blur)\n",
    "    segmented2 = (smooth_im_blur >= thresh * seg_thresh).astype(np.uint8) * 255\n",
    "\n",
    "    skeletonized = skeletonize(segmented > 0)\n",
    "\n",
    "    skeleton = scipy.sparse.dok_matrix(skeletonized)\n",
    "    nx_graph, pos = generate_nx_graph(from_sparse_to_graph(skeleton))\n",
    "    nx_graph_pruned, pos = remove_spurs(nx_graph, pos, threshold=200)\n",
    "\n",
    "    return (segmented, nx_graph_pruned, pos, segmented2)   \n",
    "\n",
    "vid_folder = Path(\"/gpfs/scratch1/shared/amftrackflow/videos/CocoTransport/\")\n",
    "plate = \"20230906_Plate310\"\n",
    "vid_interest = \"003\"\n",
    "# edge_interest = \"edge (115, 104)\"\n",
    "img_address = vid_folder / plate / vid_interest \n",
    "# img_address = vid_folder\n",
    "\n",
    "\n",
    "print(img_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0653ce49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_yen_threshold(pixels):\n",
    "    hist, bins = np.histogram(pixels, bins=256, range=[0,256], density=True)\n",
    "    hist_cumsum = hist.cumsum()\n",
    "\n",
    "    threshold = np.argmax(hist_cumsum * (1 - hist_cumsum))\n",
    "    return threshold\n",
    "\n",
    "def yen_threshold(image):\n",
    "    pixels = image.flatten()\n",
    "#     print(pixels)\n",
    "    optimal_threshold = calculate_yen_threshold(pixels)\n",
    "#     print(optimal_threshold)\n",
    "    _, thresholded = cv2.threshold(image, optimal_threshold, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    return thresholded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab667f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_histogram_edge(image,plot=False):\n",
    "    # Calculate the histogram\n",
    "    hist, bins = np.histogram(image.flatten(), 40)\n",
    "    hist = hist.astype(float) / hist.max()  # Normalize the histogram\n",
    "\n",
    "    # Sobel Kernel\n",
    "    sobel_kernel = np.array([-1, 0, 1])\n",
    "\n",
    "    # Apply Sobel edge detection to the histogram\n",
    "    sobel_hist = convolve(hist, sobel_kernel)\n",
    "\n",
    "    # Find the point with the highest gradient change\n",
    "    threshold = np.argmax(sobel_hist)\n",
    "\n",
    "    # Optional: Plot the results\n",
    "    if plot:\n",
    "        plt.figure(figsize=(10, 5))\n",
    "\n",
    "        # Plot the original histogram\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(hist)\n",
    "        plt.axvline(x=threshold, color='r', linestyle='--')\n",
    "\n",
    "        plt.title(\"Histogram\")\n",
    "\n",
    "        # Plot the Sobel histogram\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(sobel_hist)\n",
    "        plt.title(\"Sobel Histogram\")\n",
    "        plt.axvline(x=threshold, color='r', linestyle='--')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    return bins[threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4f832f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "imgs = sorted([path for path in img_address.glob(\"*/*.ti*\")])\n",
    "print(imgs)\n",
    "frames = []\n",
    "frame_max = imread(imgs[0])\n",
    "for address in tqdm(imgs):\n",
    "    frame2 = imread(address)\n",
    "    \n",
    "    if (len(frames) < 600):\n",
    "        frames.append(frame2)\n",
    "        \n",
    "    frame_max = np.maximum(frame_max, frame2)\n",
    "img = frame_max\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628e5225",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "plt.close('all')\n",
    "segmented_std, nx_graph_pruned, posi, segmented2 = segment_brightfield_std(frames)\n",
    "\n",
    "plt.figure(1)\n",
    "plt.imshow(segmented_std)\n",
    "\n",
    "plt.figure(2)\n",
    "plt.imshow(segmented2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc78099b",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_matrix = np.stack(frames, axis=0)\n",
    "\n",
    "std_matrix = np.std(video_matrix, axis=0)\n",
    "\n",
    "plt.imshow(std_matrix, cmap='viridis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04272022",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.filters import try_all_threshold\n",
    "\n",
    "img = data.page()\n",
    "\n",
    "fig, ax = try_all_threshold(img, figsize=(10, 8), verbose=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543472bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Path to the TIFF video\n",
    "video_path = str(img_address)\n",
    "\n",
    "# Open the video file\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Initialize a list to store frames\n",
    "frames = []\n",
    "\n",
    "# Read the first five frames and store them in the frames list\n",
    "frame_count = 0\n",
    "while frame_count < 5:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"empty\")\n",
    "        # If the video has fewer than 5 frames, break out of the loop\n",
    "        break\n",
    "    frames.append(frame)\n",
    "    frame_count += 1\n",
    "\n",
    "print(frame_count)\n",
    "\n",
    "# Convert the list of frames into a numpy array\n",
    "video_matrix = np.stack(frames, axis=0)\n",
    "\n",
    "# video_matrix now contains the first five frames as a 3D numpy array\n",
    "# You can access individual frames using video_matrix[index], where index is 0 to 4.\n",
    "\n",
    "std_matrix = np.std(video_matrix)\n",
    "\n",
    "\n",
    "\n",
    "# Release the video capture object\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b05813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# segmented = segment_brightfield(img, frangi_range = np.arange(5, 40, 3))\n",
    "# segmented = segment_brightfield(img, frangi_range = np.arange(10, 150, 20))\n",
    "segmented, segment_alt, std_im = segment_fluo(img, magnif=50)\n",
    "# _, segment_thresh = cv2.threshold(segment_alt, 0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "\n",
    "# segmented, segment_alt = segment_fluo(img, magnif=50)\n",
    "\n",
    "_, segment_thresh = cv2.threshold(std_im, 0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "segment_thresh = cv2.morphologyEx(segment_thresh, cv2.MORPH_CLOSE, np.ones((9,9)))\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(10, 5))\n",
    "ax[0][0].imshow(img)\n",
    "ax[0][1].imshow(segmented)\n",
    "ax[1][0].imshow(segment_thresh)\n",
    "ax[1][1].imshow(segment_alt)\n",
    "fig.tight_layout()\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.hist(segmented.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d7eb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "ftimage = np.fft.fft2(img)\n",
    "ftimage = np.fft.fftshift(ftimage)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow(np.log(abs(ftimage.real)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c649138a",
   "metadata": {},
   "source": [
    "some new efforts to give Loreto a mask of the edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c60fdbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_json(\n",
    "    f\"/gpfs/home6/svstaalduine/Analysis/CocoTransport/20230906_Plate310/001/Img/video_data.json\",\n",
    "    orient='index',\n",
    "    typ='series'\n",
    ")\n",
    "# dataframe = dataframe.iloc[1]\n",
    "selection_frame = dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35d8224",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea2ac76",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_video = KymoVideoAnalysis(input_frame = dataframe, samepos_frame = selection_frame, logging=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ce1780",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_length = int(2.4 * test_video.magnification)\n",
    "edge_objs = test_video.edge_objects\n",
    "img_seq = np.arange(len(edge_objs[0].video_analysis.selection_file))\n",
    "bin_nr=1\n",
    "\n",
    "GST_params = [9, 0.95, 0.005, 80]\n",
    "\n",
    "for edge in edge_objs:\n",
    "    edge.view_edge(img_frame=0, save_im=True, target_length=target_length)\n",
    "    edge.view_edge(img_frame=img_seq, save_im=True, quality=6, target_length=target_length)\n",
    "    edge.extract_multi_kymo(bin_nr, target_length=target_length, kymo_adj=False, kymo_normalize=True)\n",
    "    edge.fourier_kymo(return_self=False)\n",
    "    edge.extract_speeds(int(GST_params[0]), w_start=3, C_thresh=float(GST_params[1]), C_thresh_falloff=float(GST_params[2]), blur_size=3, preblur=True, speed_thresh=int(GST_params[3]))\n",
    "    edge.extract_transport()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68951656",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_video.plot_extraction_img(target_length=target_length, save_img=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97028f07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc034a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
