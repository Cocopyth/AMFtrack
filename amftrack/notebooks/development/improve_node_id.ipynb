{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from PIL import Image\n",
    "from scipy import sparse\n",
    "import cv2\n",
    "from pymatreader import read_mat\n",
    "\n",
    "# from extract_graph import dic_to_sparse\n",
    "from util.sys import get_path, get_dates_datetime, get_dirname\n",
    "from plotutil import (\n",
    "    show_im,\n",
    "    overlap,\n",
    "    show_im_rgb,\n",
    "    plot_nodes,\n",
    "    plot_nodes_from_list,\n",
    "    plot_t_tp1,\n",
    ")\n",
    "from extract_graph import (\n",
    "    generate_graph_tab_from_skeleton,\n",
    "    generate_nx_graph_from_skeleton,\n",
    "    generate_skeleton,\n",
    "    clean,\n",
    ")\n",
    "import networkx as nx\n",
    "from node_id import (\n",
    "    second_identification,\n",
    "    whole_movement_identification,\n",
    "    first_identification,\n",
    "    relabel_nodes,\n",
    "    clean_nodes,\n",
    "    orient,\n",
    ")\n",
    "from extract_graph import (\n",
    "    dic_to_sparse,\n",
    "    from_sparse_to_graph,\n",
    "    generate_nx_graph,\n",
    "    prune_graph,\n",
    "    from_nx_to_tab,\n",
    "    from_nx_to_tab_matlab,\n",
    "    sparse_to_doc,\n",
    "    connections_pixel_list_to_tab,\n",
    "    transform_list,\n",
    "    clean_degree_4,\n",
    ")\n",
    "from sparse_util import dilate, zhangSuen\n",
    "from realign import realign, reconnect, realign2\n",
    "from util.sys import get_path\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import ast\n",
    "import os\n",
    "import scipy.sparse\n",
    "import scipy.io as sio\n",
    "import pickle\n",
    "import sys\n",
    "from time import time\n",
    "from node_id import reconnect_degree_2, relabel_nodes_downstream, reduce_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def second_identification(\n",
    "    nx_graph_tm1,\n",
    "    nx_graph_t,\n",
    "    pos_tm1,\n",
    "    pos_t,\n",
    "    length_id=50,\n",
    "    downstream_graphs=[],\n",
    "    downstream_pos=[],\n",
    "    tolerance=50,\n",
    "):\n",
    "    reconnect_degree_2(nx_graph_t, pos_t)\n",
    "    t = time()\n",
    "    corresp, to_remove = first_identification(\n",
    "        nx_graph_tm1, nx_graph_t, pos_tm1, pos_t, tolerance\n",
    "    )\n",
    "    print(\"first_id\", time() - t)\n",
    "    t = time()\n",
    "    #     nx_graph_tm1=clean_nodes(nx_graph_tm1,to_remove,pos_tm1)\n",
    "    #     print(\"clean_node\",time()-t)\n",
    "    #     t=time()\n",
    "    downstream_graphs = [nx_graph_t] + downstream_graphs\n",
    "    downstream_pos = [pos_t] + downstream_pos\n",
    "    new_graphs, new_poss = relabel_nodes_downstream(\n",
    "        corresp, downstream_graphs, downstream_pos\n",
    "    )\n",
    "    print(\"relabel\", time() - t)\n",
    "    t = time()\n",
    "    pos_t = new_poss[0]\n",
    "    nx_graph_t = new_graphs[0]\n",
    "    downstream_pos = new_poss\n",
    "    downstream_graphs = new_graphs\n",
    "    corresp_tips = {node: node for node in corresp.keys()}\n",
    "    tips = [node for node in nx_graph_tm1.nodes if nx_graph_tm1.degree(node) == 1]\n",
    "    ambiguous = set()\n",
    "    Sedge = sparse.csr_matrix((26309, 49814))\n",
    "    for edge in nx_graph_t.edges:\n",
    "        pixel_list = nx_graph_t.get_edge_data(*edge)[\"pixel_list\"]\n",
    "        pixela = pixel_list[0]\n",
    "        pixelb = pixel_list[-1]\n",
    "        Sedge[pixela[0], pixela[1]] = edge[0]\n",
    "        Sedge[pixelb[0], pixelb[1]] = edge[1]\n",
    "    for i, tip in enumerate(tips):\n",
    "        #         print(i/len(tips))\n",
    "        mini1 = np.inf\n",
    "        posanchor = pos_tm1[tip]\n",
    "        window = 1000\n",
    "        potential_surrounding_t = Sedge[\n",
    "            max(0, posanchor[0] - 2 * window) : posanchor[0] + 2 * window,\n",
    "            max(0, posanchor[1] - 2 * window) : posanchor[1] + 2 * window,\n",
    "        ]\n",
    "        #         potential_surrounding_t=Sedge\n",
    "        #         for edge in nx_graph_t.edges:\n",
    "        #             pixel_list=nx_graph_t.get_edge_data(*edge)['pixel_list']\n",
    "        #             if np.linalg.norm(np.array(pixel_list[0])-np.array(pos_tm1[tip]))<=5000:\n",
    "        #                 distance=np.min(np.linalg.norm(np.array(pixel_list)-np.array(pos_tm1[tip]),axis=1))\n",
    "        #                 if distance<mini1:\n",
    "        #                     mini1=distance\n",
    "        #                     right_edge1 = edge\n",
    "        #         print('t1 re',right_edge)\n",
    "        mini = np.inf\n",
    "        for node_root in potential_surrounding_t.data:\n",
    "            for edge in nx_graph_t.edges(int(node_root)):\n",
    "                pixel_list = nx_graph_t.get_edge_data(*edge)[\"pixel_list\"]\n",
    "                if (\n",
    "                    np.linalg.norm(np.array(pixel_list[0]) - np.array(pos_tm1[tip]))\n",
    "                    <= 5000\n",
    "                ):\n",
    "                    distance = np.min(\n",
    "                        np.linalg.norm(\n",
    "                            np.array(pixel_list) - np.array(pos_tm1[tip]), axis=1\n",
    "                        )\n",
    "                    )\n",
    "                    if distance < mini:\n",
    "                        mini = distance\n",
    "                        right_edge = edge\n",
    "        #         print('t2 re',right_edge)\n",
    "        #         if right_edge!=right_edge1:\n",
    "        #             print('alaba',right_edge,right_edge1)\n",
    "        #             print('len(surrounding)',len(potential_surrounding_t.data))\n",
    "        if mini == np.inf:\n",
    "            print(f\"didnt find a tip to match tip in pos {posanchor}\")\n",
    "            continue\n",
    "        origin = np.array(\n",
    "            orient(\n",
    "                nx_graph_tm1.get_edge_data(*list(nx_graph_tm1.edges(tip))[0])[\n",
    "                    \"pixel_list\"\n",
    "                ],\n",
    "                pos_tm1[tip],\n",
    "            )\n",
    "        )\n",
    "        origin_vector = origin[0] - origin[-1]\n",
    "        branch = np.array(\n",
    "            orient(\n",
    "                nx_graph_t.get_edge_data(*right_edge)[\"pixel_list\"],\n",
    "                pos_t[right_edge[0]],\n",
    "            )\n",
    "        )\n",
    "        candidate_vector = branch[-1] - branch[0]\n",
    "        dot_product = np.dot(origin_vector, candidate_vector)\n",
    "        if dot_product >= 0:\n",
    "            root = right_edge[0]\n",
    "            next_node = right_edge[1]\n",
    "        else:\n",
    "            root = right_edge[1]\n",
    "            next_node = right_edge[0]\n",
    "        last_node = root\n",
    "        current_node = next_node\n",
    "        last_branch = np.array(\n",
    "            orient(\n",
    "                nx_graph_t.get_edge_data(root, next_node)[\"pixel_list\"],\n",
    "                pos_t[current_node],\n",
    "            )\n",
    "        )\n",
    "        i = 0\n",
    "        loop = []\n",
    "        while (\n",
    "            nx_graph_t.degree(current_node) != 1\n",
    "            and not current_node in nx_graph_tm1.nodes\n",
    "        ):  # Careful : if there is a cycle with low angle this might loop indefinitely but unprobable\n",
    "            i += 1\n",
    "            if i >= 100:\n",
    "                print(\n",
    "                    \"identified infinite loop\",\n",
    "                    i,\n",
    "                    tip,\n",
    "                    current_node,\n",
    "                    pos_t[current_node],\n",
    "                )\n",
    "                break\n",
    "            mini = np.inf\n",
    "            origin_vector = (\n",
    "                last_branch[0] - last_branch[min(length_id, len(last_branch) - 1)]\n",
    "            )\n",
    "            unit_vector_origin = origin_vector / np.linalg.norm(origin_vector)\n",
    "            candidate_vectors = []\n",
    "            for neighbours_t in nx_graph_t.neighbors(current_node):\n",
    "                if neighbours_t != last_node:\n",
    "                    branch_candidate = np.array(\n",
    "                        orient(\n",
    "                            nx_graph_t.get_edge_data(current_node, neighbours_t)[\n",
    "                                \"pixel_list\"\n",
    "                            ],\n",
    "                            pos_t[current_node],\n",
    "                        )\n",
    "                    )\n",
    "                    candidate_vector = (\n",
    "                        branch_candidate[min(length_id, len(branch_candidate) - 1)]\n",
    "                        - branch_candidate[0]\n",
    "                    )\n",
    "                    unit_vector_candidate = candidate_vector / np.linalg.norm(\n",
    "                        candidate_vector\n",
    "                    )\n",
    "                    candidate_vectors.append((unit_vector_candidate,branch_candidate.shape[0]))\n",
    "                    dot_product = np.dot(unit_vector_origin, unit_vector_candidate)\n",
    "                    angle = np.arccos(dot_product)\n",
    "                    score = angle/min(branch_candidate.shape[0],50)\n",
    "                    if score < mini:\n",
    "                        mini = score\n",
    "                        next_node = neighbours_t\n",
    "            #                     print('angle',dot_product,pos_t[last_node],pos_t[current_node],pos_t[neighbours_t],angle/(2*np.pi)*360)\n",
    "            #!!!bug may happen here if two nodes are direct neighbours : I would nee to check further why it the case, optimal segmentation should avoid this issue.\n",
    "            # This is especially a problem for degree 4 nodes. Maybe fuse nodes that are closer than 3 pixels.\n",
    "            if i >= 100:\n",
    "                print(mini / (2 * np.pi) * 360, pos_t[next_node])\n",
    "                if next_node in loop:\n",
    "                    break\n",
    "                else:\n",
    "                    loop.append(next_node)\n",
    "            if len(candidate_vectors) < 2:\n",
    "                print(\n",
    "                    \"candidate_vectors < 2\",\n",
    "                    nx_graph_t.degree(current_node),\n",
    "                    pos_t[current_node],\n",
    "                    [node for node in nx_graph_t.nodes if nx_graph_t.degree(node) == 2],\n",
    "                )\n",
    "            competitor_angle = np.arccos(np.dot(candidate_vectors[0][0], -candidate_vectors[1][0]))\n",
    "            competitor_score = competitor_angle/min(candidate_vectors[0][1],candidate_vectors[1][1],50)\n",
    "            if mini < competitor_score:\n",
    "                current_node, last_node = next_node, current_node\n",
    "            else:\n",
    "                break\n",
    "        if current_node in nx_graph_tm1.nodes:\n",
    "            if last_node not in nx_graph_tm1.nodes:\n",
    "                if last_node in corresp_tips.values():\n",
    "                    ambiguous.add(tip)\n",
    "                corresp_tips[tip] = last_node\n",
    "        else:\n",
    "            if current_node in corresp_tips.values():\n",
    "                ambiguous.add(tip)\n",
    "            corresp_tips[tip] = current_node\n",
    "    print(\"tip_id\", time() - t)\n",
    "    t = time()\n",
    "    while len(ambiguous) > 0:\n",
    "        node = ambiguous.pop()\n",
    "        identifier = corresp_tips[node]\n",
    "        candidates = [\n",
    "            nod for nod in corresp_tips.keys() if corresp_tips[nod] == identifier\n",
    "        ]\n",
    "        mini = np.inf\n",
    "        for candidate in candidates:\n",
    "            distance = np.linalg.norm(pos_tm1[candidate] - pos_t[identifier])\n",
    "            #             print(identifier,distance)\n",
    "            if distance < mini:\n",
    "                right_candidate = candidate\n",
    "                mini = distance\n",
    "        for candidate in candidates:\n",
    "            if candidate != right_candidate:\n",
    "                corresp_tips.pop(candidate)\n",
    "                ambiguous.discard(candidate)\n",
    "    new_graphs, new_poss = relabel_nodes_downstream(\n",
    "        corresp_tips, downstream_graphs, downstream_pos\n",
    "    )\n",
    "    downstream_pos = new_poss\n",
    "    downstream_graphs = new_graphs\n",
    "    #     print(\"second relabeling\")\n",
    "    #     print(len(nx_graph_tm1.nodes),len(new_graphs[0].nodes))\n",
    "    new_graphs, new_poss = reduce_labels(\n",
    "        [nx_graph_tm1] + downstream_graphs, [pos_tm1] + downstream_pos\n",
    "    )\n",
    "    #     print(\"third relabeling\")\n",
    "    #     print(len(new_graphs[0].nodes),len(new_graphs[1].nodes))\n",
    "    return (new_graphs, new_poss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "plate = 40\n",
    "begin = 0\n",
    "end = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cbisot/anaconda3/envs/test/lib/python3.7/site-packages/scipy/sparse/_index.py:82: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first_id 0.3854639530181885\n",
      "relabel 0.0017657279968261719\n",
      "tip_id 7.162640810012817\n",
      "i= 3\n",
      "first_id 0.27884602546691895\n",
      "relabel 0.003098726272583008\n",
      "tip_id 5.729527473449707\n",
      "i= 2\n",
      "first_id 0.14496469497680664\n",
      "relabel 0.00426030158996582\n",
      "tip_id 4.781526565551758\n",
      "i= 1\n",
      "first_id 0.12015175819396973\n",
      "relabel 0.005464315414428711\n",
      "tip_id 4.430450201034546\n",
      "i= 0\n",
      "first_id 0.11016249656677246\n",
      "relabel 0.006307363510131836\n",
      "tip_id 3.9980249404907227\n"
     ]
    }
   ],
   "source": [
    "from directory import directory\n",
    "\n",
    "\n",
    "dates_datetime = get_dates_datetime(directory,plate)\n",
    "dates_datetime.sort()\n",
    "dates_datetime_chosen = dates_datetime[begin : end + 1]\n",
    "dates = dates_datetime_chosen\n",
    "\n",
    "nx_graph_pos = []\n",
    "for date in dates:\n",
    "    directory_name = get_dirname(date, plate)\n",
    "    path_snap = directory + directory_name\n",
    "    path_save = path_snap + \"/Analysis/nx_graph_pruned.p\"\n",
    "    nx_graph_pos.append(pickle.load(open(path_save, \"rb\")))\n",
    "nx_graph_pruned = [c[0] for c in nx_graph_pos]\n",
    "poss_aligned = [c[1] for c in nx_graph_pos]\n",
    "downstream_graphs = []\n",
    "downstream_pos = []\n",
    "begin = len(dates) - 1\n",
    "downstream_graphs = [nx_graph_pruned[begin]]\n",
    "downstream_poss = [poss_aligned[begin]]\n",
    "for i in range(begin - 1, -1, -1):\n",
    "    print(\"i=\", i)\n",
    "    new_graphs, new_poss = second_identification(\n",
    "        nx_graph_pruned[i],\n",
    "        downstream_graphs[0],\n",
    "        poss_aligned[i],\n",
    "        downstream_poss[0],\n",
    "        50,\n",
    "        downstream_graphs[1:],\n",
    "        downstream_poss[1:],\n",
    "        tolerance=30,\n",
    "    )\n",
    "    downstream_graphs = new_graphs\n",
    "    downstream_poss = new_poss\n",
    "\n",
    "nx_graph_pruned = downstream_graphs\n",
    "poss_aligned = downstream_poss\n",
    "# for i, g in enumerate(nx_graph_pruned):\n",
    "#     directory_name = get_dirname(date, plate)\n",
    "#     path_snap = directory + directory_name\n",
    "#     path_save = path_snap + \"/Analysis/nx_graph_pruned_labeled.p\"\n",
    "#     pos = poss_aligned[i]\n",
    "#     pickle.dump((g, pos), open(path_save, \"wb\"))\n",
    "\n",
    "# for i, date in enumerate(dates):\n",
    "#     tab = from_nx_to_tab(nx_graph_pruned[i], poss_aligned[i])\n",
    "#     directory_name = get_dirname(date, plate)\n",
    "#     path_snap = directory + directory_name\n",
    "#     path_save = path_snap + \"/Analysis/graph_full_labeled.mat\"\n",
    "#     sio.savemat(path_save, {name: col.values for name, col in tab.items()})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
