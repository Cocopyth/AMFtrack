{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Import Lib *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from itertools import combinations\n",
    "import pickle\n",
    "from keras.models import  Model, load_model\n",
    "from keras.layers import Dense, Input\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib widget\n",
    "\n",
    "from amftrack.pipeline.launching.run_super import (\n",
    "    run_launcher,\n",
    "    directory_scratch,\n",
    "    directory_project,\n",
    "    directory_project,\n",
    "    run_parallel_stitch,\n",
    "    run_parallel_transfer,\n",
    ")\n",
    "import os\n",
    "from amftrack.util.sys import (\n",
    "    get_dates_datetime,\n",
    "    get_dirname,\n",
    "    temp_path,\n",
    "    get_data_info,\n",
    "    update_plate_info,\n",
    "    update_analysis_info,\n",
    "    get_analysis_info,\n",
    "    get_current_folders,\n",
    "    get_folders_by_plate_id,\n",
    ")\n",
    "\n",
    "from time import time_ns\n",
    "from datetime import datetime\n",
    "from amftrack.pipeline.launching.run_super import (\n",
    "    run_parallel,\n",
    "    directory_scratch,\n",
    "    directory_project,\n",
    "    run_parallel_stitch,\n",
    ")\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from amftrack.util.sys import get_dirname, temp_path\n",
    "import pandas as pd\n",
    "import ast\n",
    "from scipy import sparse\n",
    "import scipy.io as sio\n",
    "import cv2\n",
    "import imageio.v2 as imageio\n",
    "import numpy as np\n",
    "import scipy.sparse\n",
    "import os\n",
    "from time import time\n",
    "from amftrack.pipeline.functions.image_processing.extract_skel import (\n",
    "    extract_skel_new_prince,\n",
    "    run_back_sub,\n",
    "    bowler_hat,\n",
    ")\n",
    "\n",
    "from amftrack.util.sys import get_dates_datetime, get_dirname\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "from amftrack.pipeline.functions.image_processing.experiment_class_surf import (\n",
    "    Experiment,\n",
    "    save_graphs,\n",
    "    load_graphs,\n",
    "    Edge,\n",
    "    Node,\n",
    ")\n",
    "from amftrack.pipeline.functions.image_processing.experiment_util import (\n",
    "    get_random_edge,\n",
    "    distance_point_edge,\n",
    "    plot_edge,\n",
    "    plot_edge_cropped,\n",
    "    find_nearest_edge,\n",
    "    get_edge_from_node_labels,\n",
    "    plot_full_image_with_features,\n",
    "    get_all_edges,\n",
    "    get_all_nodes,\n",
    "    find_neighboring_edges,\n",
    "    reconstruct_image,\n",
    "    reconstruct_skeletton_from_edges,\n",
    "    reconstruct_skeletton_unicolor,\n",
    "    reconstruct_image_from_general,\n",
    "    plot_full,\n",
    "    plot_edge_color_value,\n",
    ")\n",
    "from matplotlib import cm\n",
    "from matplotlib.patches import Rectangle\n",
    "from IPython.display import clear_output\n",
    "import re\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import imageio.v2 as imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tifffile import imwrite\n",
    "from tqdm import tqdm\n",
    "import scipy\n",
    "import matplotlib as mpl\n",
    "from pathlib import Path\n",
    "from amftrack.pipeline.launching.run import (\n",
    "    run_transfer,\n",
    ")\n",
    "from amftrack.pipeline.launching.run_super import run_parallel_transfer\n",
    "import dropbox\n",
    "from amftrack.util.dbx import (\n",
    "    upload_folder,\n",
    "    download,\n",
    "    read_saved_dropbox_state,\n",
    "    save_dropbox_state,\n",
    "    load_dbx,\n",
    "    get_dropbox_video_folders,\n",
    "    download_video_folders_drop,\n",
    "    download_analysis_folders_drop,\n",
    ")\n",
    "from subprocess import call\n",
    "import logging\n",
    "import datetime\n",
    "import glob\n",
    "import json\n",
    "from amftrack.pipeline.launching.run_super import run_parallel_flows\n",
    "from amftrack.util.dbx import upload\n",
    "# from amftrack.pipeline.functions.image_processing.extract_width_fun import extract_section_profiles_for_edge_exp\n",
    "import networkx as nx\n",
    "import random\n",
    "from scipy.optimize import curve_fit\n",
    "import cv2\n",
    "from amftrack.pipeline.functions.post_processing.util import is_in_ROI_node\n",
    "\n",
    "mpl.rcParams[\"figure.dpi\"] = 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import Graph *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Import Data *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# To Change according to your need\n",
    "directory_targ = '/projects/0/einf914/transport/'\n",
    "plates = [\"441_20230807\"]\n",
    "first_index = 0\n",
    "last_index = 10\n",
    "\n",
    "update_plate_info(directory_targ, local=True, strong_constraint=False)\n",
    "all_folders = get_current_folders(directory_targ, local=True)\n",
    "\n",
    "folders = all_folders.loc[all_folders[\"unique_id\"] == plates[0]]\n",
    "folders = folders.loc[folders[\"/Analysis/nx_graph_pruned_width.p\"] == True]\n",
    "\n",
    "folders = folders.sort_values(by=\"datetime\")\n",
    "\n",
    "exp = Experiment(directory_targ)\n",
    "exp.dimX_dimY = 0, 0\n",
    "\n",
    "try:\n",
    "    exp.load(folders.iloc[first_index:last_index+1].copy(), suffix=\"_width\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "exp.save_location = exp.folders.iloc[0]['total_path']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Plot t=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dpi = 400\n",
    "\n",
    "vmax = 1\n",
    "vmin = 0\n",
    "downsizing = 10\n",
    "plt.close(\"all\")\n",
    "fig, ax = plot_edge_color_value(\n",
    "    exp,\n",
    "    first_index,\n",
    "    lambda edge: 1,\n",
    "    # cmap=mpl.colormaps.get_cmap(\"seismic\"),\n",
    "    v_min=vmin,\n",
    "    v_max=vmax,\n",
    "    show_background=False,\n",
    "    dilation=5,\n",
    "    figsize=(12, 8),\n",
    "    downsizing=downsizing,\n",
    "    region=[[0, 0], [30000, 56000]]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Plot t=last_inde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dpi = 400\n",
    "\n",
    "vmax = 1\n",
    "vmin = 0\n",
    "downsizing = 10\n",
    "plt.close(\"all\")\n",
    "fig, ax = plot_edge_color_value(\n",
    "    exp,\n",
    "    last_index,\n",
    "    lambda edge: 1,\n",
    "    # cmap=mpl.colormaps.get_cmap(\"seismic\"),\n",
    "    v_min=vmin,\n",
    "    v_max=vmax,\n",
    "    show_background=False,\n",
    "    dilation=5,\n",
    "    figsize=(12, 8),\n",
    "    downsizing=downsizing,\n",
    "    region=[[0, 0], [30000, 56000]]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Video of a region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "region = [[24600, 49400], [25000, 49600]]\n",
    "image_folder = \"/Users/amin/Documents/AMOLF/Data/Examples/Weird_time_intersection\"\n",
    "\n",
    "def is_in_region(pos, region):\n",
    "        if region[0][0] < pos[0] and pos[0] < region[1][0] and region[0][1] < pos[1] and pos[1] < region[1][1]:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "for t in range(last_index+1):\n",
    "    plt.close(\"all\")\n",
    "\n",
    "    for edge in get_all_edges(exp, t):\n",
    "        if is_in_region(edge.begin.pos(t), region) or is_in_region(edge.end.pos(t), region):\n",
    "            y, x = zip(*edge.pixel_list(t))\n",
    "            plt.plot(x, y, color=\"b\")\n",
    "\n",
    "    plt.xlim(region[0][1], region[1][1])\n",
    "    plt.ylim(region[1][0], region[0][0])\n",
    "    image_path = os.path.join(image_folder, f'{t:02d}.png')\n",
    "    plt.savefig(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_name = 'test.avi'\n",
    "\n",
    "images = [img for img in os.listdir(image_folder) if img.endswith(\".png\")]\n",
    "images.sort()\n",
    "frame = cv2.imread(os.path.join(image_folder, images[0]))\n",
    "height, width, layers = frame.shape\n",
    "\n",
    "video_path = os.path.join(image_folder, video_name)\n",
    "video = cv2.VideoWriter(video_path, 0, 1, (width,height))\n",
    "\n",
    "for image in images:\n",
    "    video.write(cv2.imread(os.path.join(image_folder, image)))\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "video.release()\n",
    "print('Video_saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Segmented graph with time *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Cut each edge into segments *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Size of the segment in pixels\n",
    "segments_length = 5\n",
    "\n",
    "final_graph = exp.nx_graph[last_index]\n",
    "node_not_in_ROI = []\n",
    "for node in final_graph:\n",
    "    if not is_in_ROI_node(Node(node, exp), last_index):\n",
    "        node_not_in_ROI.append(node)\n",
    "final_graph.remove_nodes_from(node_not_in_ROI)\n",
    "\n",
    "label = max(final_graph.nodes) + 1\n",
    "graph_segemented_final = nx.empty_graph()\n",
    "nodes_pos = {}\n",
    "edges_indexes = {}\n",
    "segments_index = {}\n",
    "segments_center_final = []\n",
    "\n",
    "for edge in final_graph.edges:\n",
    "    e = Edge(Node(edge[0], exp), Node(edge[1], exp), exp)\n",
    "    edges_indexes[f\"{edge[0]},{edge[1]}\"] = []\n",
    "    pixels = e.pixel_list(last_index)\n",
    "    length = len(pixels)\n",
    "    if length < segments_length:\n",
    "        graph_segemented_final.add_edge(edge[0], edge[1])\n",
    "        segments_index[f\"{edge[0]},{edge[1]}\"] = len(segments_center_final)\n",
    "        edges_indexes[f\"{edge[0]},{edge[1]}\"].append(len(segments_center_final))\n",
    "        central_point = np.mean(np.array(pixels), axis=0)\n",
    "        segments_center_final.append(central_point)\n",
    "        nodes_pos[edge[0]] = pixels[0]\n",
    "        nodes_pos[edge[1]] = pixels[-1]\n",
    "        continue\n",
    "\n",
    "    for i in range(0, length, segments_length):\n",
    "        sub_list = pixels[i:i+segments_length]\n",
    "        if i==0:\n",
    "            graph_segemented_final.add_edge(edge[0], label)\n",
    "            segments_index[f\"{edge[0]},{label}\"] = len(segments_center_final)\n",
    "            edges_indexes[f\"{edge[0]},{edge[1]}\"].append(len(segments_center_final))\n",
    "            central_point = np.mean(np.array(sub_list), axis=0)\n",
    "            segments_center_final.append(central_point)\n",
    "            nodes_pos[edge[0]] = sub_list[0]\n",
    "            nodes_pos[label] = sub_list[-1]\n",
    "            label += 1\n",
    "        elif i+segments_length >= length:\n",
    "            graph_segemented_final.add_edge(label-1, edge[1])\n",
    "            segments_index[f\"{label-1},{edge[1]}\"] = len(segments_center_final)\n",
    "            edges_indexes[f\"{edge[0]},{edge[1]}\"].append(len(segments_center_final))\n",
    "            central_point = np.mean(np.array(sub_list), axis=0)\n",
    "            segments_center_final.append(central_point)\n",
    "            nodes_pos[edge[1]] = sub_list[-1]\n",
    "        else:\n",
    "            graph_segemented_final.add_edge(label-1, label)\n",
    "            segments_index[f\"{label-1},{label}\"] = len(segments_center_final)\n",
    "            edges_indexes[f\"{edge[0]},{edge[1]}\"].append(len(segments_center_final))\n",
    "            central_point = np.mean(np.array(sub_list), axis=0)\n",
    "            segments_center_final.append(central_point)\n",
    "            nodes_pos[label] = sub_list[-1]\n",
    "            label += 1\n",
    "\n",
    "print(f\"amount of nodes: {graph_segemented_final.number_of_nodes()}\")\n",
    "print(f\"amount of segments: {graph_segemented_final.number_of_edges()}\")\n",
    "\n",
    "array_segments_center_final = np.array(segments_center_final)\n",
    "shape_segments_center = array_segments_center_final.shape\n",
    "print(f\"Shape array_segments_center_final: {shape_segments_center}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Min distances over time of each segment while shifting them *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def closest_point(point, points):\n",
    "    dist_square = np.sum((points-point)**2, axis=1)\n",
    "    min_index = np.argmin(dist_square)\n",
    "    return points[min_index], dist_square[min_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# When there is a point at a distance of segment under the threshold, the segment is activated (distance in pixel)\n",
    "# A good distance is (2*segments_length)**2\n",
    "# Don't forget to square because closest_point give the distance squared\n",
    "threshold = 10**2\n",
    "\n",
    "segments_centers = []\n",
    "segments_min_distances = []\n",
    "array_segments_center = array_segments_center_final.copy()\n",
    "for time in reversed(range(last_index+1)):\n",
    "    print(f\"Process time {time}\")\n",
    "    rows = []\n",
    "    cols = []\n",
    "    previous_edges = get_all_edges(exp, time)\n",
    "    for edge in previous_edges:\n",
    "        p_list = edge.pixel_list(time)\n",
    "        row, col = zip(*p_list)\n",
    "        rows.extend(row)\n",
    "        cols.extend(col)\n",
    "    \n",
    "    data = np.ones(len(rows))\n",
    "    points_matrix = sparse.csr_matrix((data, (rows, cols)))\n",
    "    \n",
    "    centers_distance = []\n",
    "    new_centers = array_segments_center.copy()\n",
    "    for index, center in enumerate(array_segments_center):\n",
    "        xc, yc = center\n",
    "        xc, yc = int(xc), int(yc)\n",
    "\n",
    "        min_x, max_x = max(0, xc-4*segments_length), xc+4*segments_length\n",
    "        min_y, max_y = max(0, yc-4*segments_length), yc+4*segments_length\n",
    "        coords = points_matrix[min_x:max_x, min_y:max_y].nonzero()\n",
    "        coords = np.column_stack(coords)\n",
    "        if not coords.shape[0]:\n",
    "            centers_distance.append(32*(segments_length**2))\n",
    "            continue\n",
    "\n",
    "        xc -= min_x\n",
    "        yc -= min_y\n",
    "\n",
    "        new_center, min_dist = closest_point([xc, yc], coords)\n",
    "        centers_distance.append(min_dist)\n",
    "        if min_dist < threshold:\n",
    "            new_centers[index] = new_center + np.array([min_x, min_y])\n",
    "    \n",
    "    array_segments_center = new_centers\n",
    "    segments_centers.append(new_centers)\n",
    "    segments_min_distances.append(centers_distance)\n",
    "\n",
    "segments_min_distances.reverse()\n",
    "# Index t are the centers of the segments at time t\n",
    "segments_centers.reverse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Each edge time interval *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Amount of segment to look for at in an edge to get the date at which the edge encounter the node\n",
    "# Depends of how big segments are and what threshold you use\n",
    "amount_of_border_segment = 7\n",
    "\n",
    "segments_min_distances_array = np.array(segments_min_distances)\n",
    "segments_min_distances_array = np.where(segments_min_distances_array<threshold, 1, 0)\n",
    "segments_time = segments_min_distances_array.argmax(axis=0)\n",
    "\n",
    "edges_time_interval = {}\n",
    "\n",
    "for e in final_graph.edges:\n",
    "    edge = Edge(Node(e[0], exp), Node(e[1], exp), exp)\n",
    "    segments_indexes = edges_indexes[f\"{edge.begin.label},{edge.end.label}\"]\n",
    "    segments_times = np.array([segments_time[index] for index in segments_indexes])\n",
    "\n",
    "    begin = np.median(segments_times[:amount_of_border_segment])\n",
    "    if len(segments_times)>amount_of_border_segment:\n",
    "        end = np.median(segments_times[-amount_of_border_segment:])\n",
    "    else:\n",
    "        end = np.median(segments_times)\n",
    "\n",
    "    edges_time_interval[f\"{edge.begin.label},{edge.end.label}\"] = (begin, end)\n",
    "\n",
    "print(edges_time_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Plot random segments min_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "plt.figure(figsize=(20,20))\n",
    "\n",
    "good_segments = []\n",
    "for key, index in segments_index.items():\n",
    "    y, x = segments_center_final[index]\n",
    "    if y < 22000:\n",
    "        good_segments.append(index)\n",
    "\n",
    "\n",
    "for i in range(16):\n",
    "    plt.subplot(4,4,i+1)\n",
    "    times = []\n",
    "    distance = []\n",
    "    randint = random.randint(0, len(good_segments))\n",
    "    for t, activations in enumerate(segments_min_distances):\n",
    "        times.append(t)\n",
    "        distance.append(activations[good_segments[randint]])\n",
    "\n",
    "    plt.plot(times, distance)\n",
    "    plt.title(f\"index:{randint}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Plot Each Segments colored by its activation time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "fig, ax1 = plt.subplots(1, 1, figsize=(14, 8)) \n",
    "\n",
    "for key, edge in enumerate(graph_segemented_final.edges):\n",
    "    begin, end = edge\n",
    "    (y1, x1), (y2, x2) = nodes_pos[begin], nodes_pos[end]\n",
    "    index = segments_index.get(f\"{begin},{end}\")\n",
    "    if index is None:\n",
    "        index = segments_index[f\"{end},{begin}\"]\n",
    "    time = segments_time[index]\n",
    "    color = cm.viridis(time/last_index)\n",
    "    if time < 100:\n",
    "    \n",
    "        ax1.plot([x1, x2], [y1, y2], c=color)\n",
    "\n",
    "sm = plt.cm.ScalarMappable(cmap=cm.viridis) \n",
    "sm.set_array([]) \n",
    "plt.colorbar(sm, ax=ax1) \n",
    "\n",
    "plt.xlim(0, 56000)\n",
    "plt.ylim(0, 30000)\n",
    "plt.gca().invert_yaxis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Plot each edge colored by its activation time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "fig, ax1 = plt.subplots(1, 1, figsize=(14, 8))\n",
    "\n",
    "for e in final_graph.edges:\n",
    "    edge = Edge(Node(e[0], exp), Node(e[1], exp), exp)\n",
    "    time_interval = edges_time_interval.get(f\"{edge.begin.label},{edge.end.label}\")\n",
    "    time = (time_interval[0]+time_interval[1])/2 # type: ignore\n",
    "    pixels = edge.pixel_list(last_index)\n",
    "    y, x = zip(*pixels)\n",
    "    color = cm.viridis(time/last_index)\n",
    "    plt.plot(x, y, color=color)\n",
    "\n",
    "sm = plt.cm.ScalarMappable(cmap=cm.viridis)\n",
    "sm.set_array([]) \n",
    "plt.colorbar(sm, ax=ax1) \n",
    "\n",
    "plt.gca().invert_yaxis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. HyperGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \\* need to be run for this part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm  # for Jupyter notebook or IPython\n",
    "\n",
    "positions = exp.positions[last_index]\n",
    "\n",
    "def angle_between(vec1, vec2):\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm_product = np.linalg.norm(vec1) * np.linalg.norm(vec2)\n",
    "    return np.arccos(np.clip(dot_product / norm_product, -1.0, 1.0))\n",
    "\n",
    "def score_angle(v1, v2, v, positions):\n",
    "    vec1 = np.array(positions[v1]) - np.array(positions[v])\n",
    "    vec2 = np.array(positions[v2]) - np.array(positions[v])\n",
    "    angle = np.abs(angle_between(vec1, vec2) - np.pi)\n",
    "    return angle\n",
    "\n",
    "def score(v1, v2, v, positions, edges_time_interval):\n",
    "    vec1 = np.array(positions[v1]) - np.array(positions[v])\n",
    "    vec2 = np.array(positions[v2]) - np.array(positions[v])\n",
    "    angle = np.abs(angle_between(vec1, vec2) - np.pi)\n",
    "\n",
    "    time_interval1 = edges_time_interval.get(f\"{v1},{v}\")\n",
    "    if time_interval1 is None:\n",
    "        time1, _ = edges_time_interval[f\"{v},{v1}\"]\n",
    "    else:\n",
    "        time1 = time_interval1[1]\n",
    "    time_interval2 = edges_time_interval.get(f\"{v2},{v}\")\n",
    "    if time_interval2 is None:\n",
    "        time2, _ = edges_time_interval[f\"{v},{v2}\"]\n",
    "    else:\n",
    "        time2 = time_interval2[1]\n",
    "\n",
    "    time_diff = np.abs(time1-time2)\n",
    "\n",
    "    return -2*angle/np.pi - time_diff\n",
    "\n",
    "\n",
    "def relation(v, e1, e2, EExtract, E, positions, edges_time_interval):\n",
    "    v_i = E[e1][0] if E[e1][1] == v else E[e1][1]\n",
    "    v_j = E[e2][0] if E[e2][1] == v else E[e2][1]\n",
    "\n",
    "    time_score_ij = score(v_i, v_j, v, positions, edges_time_interval)\n",
    "\n",
    "    # Check the second condition\n",
    "    for e in EExtract:\n",
    "        if e != e1 and e != e2:\n",
    "            v_k = E[e][0] if E[e][1] == v else E[e][1]\n",
    "\n",
    "            time_score_vi = score(v_i, v_k, v, positions, edges_time_interval)\n",
    "            time_score_vj = score(v_j, v_k, v, positions, edges_time_interval)\n",
    "            if (time_score_ij < time_score_vi or time_score_ij< time_score_vj):\n",
    "                return False\n",
    "            if time_score_ij==time_score_vi or time_score_ij==time_score_vj:\n",
    "                print('equal')\n",
    "    return True\n",
    "\n",
    "\n",
    "def edge_matches(v, EExtract, E, positions, edges_time_interval) -> list:\n",
    "    if len(EExtract) < 2:\n",
    "        return []\n",
    "\n",
    "    times = []\n",
    "    vs = []\n",
    "    for e in EExtract:\n",
    "        v_i =  E[e][0] if E[e][1] == v else E[e][1]\n",
    "        time_interval = edges_time_interval.get(f\"{v_i},{v}\")\n",
    "        if time_interval is None:\n",
    "            time, _ = edges_time_interval[f\"{v},{v_i}\"]\n",
    "        else:\n",
    "            time = time_interval[1]\n",
    "        vs.append(v_i)\n",
    "        times.append(time)\n",
    "\n",
    "    min_time = min(times)\n",
    "    min_time_edges = [index for index, time in enumerate(times) if time==min_time]\n",
    "\n",
    "    if len(min_time_edges)==2:\n",
    "        e1 = EExtract[min_time_edges[0]]\n",
    "        e2 = EExtract[min_time_edges[1]]\n",
    "        return [(e1, e2, 'time_resolved')] + edge_matches(v, [edge_index for edge_index in EExtract if (edge_index!=e1 and edge_index!=e2)], E, positions, edges_time_interval)\n",
    "\n",
    "    if len(min_time_edges) >= 2:\n",
    "        pairs = combinations(min_time_edges, 2)\n",
    "        angle = np.pi\n",
    "        for index1, index2 in pairs:\n",
    "            angle_between = score_angle(vs[index1], vs[index2], v, positions)\n",
    "            if angle_between < angle:\n",
    "                angle = angle_between\n",
    "                e1 = EExtract[index1]\n",
    "                e2 = EExtract[index2]\n",
    "        return [(e1, e2, 'geometricaly_resolved')] + edge_matches(v, [edge_index for edge_index in EExtract if (edge_index!=e1 and edge_index!=e2)], E, positions, edges_time_interval)\n",
    "\n",
    "    min_time_edge = min_time_edges[0]\n",
    "    second_min_time = min([time for time in times if time!=min_time])\n",
    "    second_time_edges = [index for index, time in enumerate(times) if time==second_min_time]\n",
    "    \n",
    "    if len(second_time_edges)==1:\n",
    "        e1 = EExtract[min_time_edge]\n",
    "        e2 = EExtract[second_time_edges[0]]\n",
    "        return [(e1, e2, 'time_resolved')] + edge_matches(v, [edge_index for edge_index in EExtract if (edge_index!=e1 and edge_index!=e2)], E, positions, edges_time_interval)\n",
    "\n",
    "    e1 = EExtract[min_time_edge]\n",
    "    angle = np.pi\n",
    "    for index in second_time_edges:\n",
    "        angle_between = score_angle(vs[min_time_edge], vs[index], v, positions)\n",
    "        if angle_between < angle:\n",
    "            angle = angle_between\n",
    "            e2 = EExtract[index]\n",
    "\n",
    "    return [(e1, e2, 'geometricaly_resolved')] + edge_matches(v, [edge_index for edge_index in EExtract if (edge_index!=e1 and edge_index!=e2)], E, positions, edges_time_interval)\n",
    "\n",
    "\n",
    "def hypergraph_from_graph(G, positions, edges_time_interval, get_time_resolved_intersections=False):\n",
    "    V = list(G.nodes())\n",
    "    E = list(G.edges())\n",
    "    e = len(E)\n",
    "    v = len(V)\n",
    "\n",
    "    H = [0] * e\n",
    "    Cor = [[0] * 10 for _ in range(e)]\n",
    "\n",
    "    if get_time_resolved_intersections:\n",
    "        time_resolved_intersections = []\n",
    "\n",
    "    # STEP 1\n",
    "    for i in tqdm(V, desc=\"Processing vertices\"):\n",
    "        EExtract = [edge_idx for edge_idx, edge in enumerate(E) if i in edge]\n",
    "        matches = edge_matches(i, EExtract, E, positions, edges_time_interval)\n",
    "        for match in matches:\n",
    "            e1, e2 = match[0], match[1]\n",
    "            Cor[e1][Cor[e1].index(0)] = e2\n",
    "            Cor[e2][Cor[e2].index(0)] = e1\n",
    "        if get_time_resolved_intersections and matches and matches[0][2]=='time_resolved':\n",
    "            time_resolved_intersections.append((EExtract, matches[0][0], matches[0][1], positions[i]))\n",
    "\n",
    "    # STEP 2\n",
    "    CurrentMark = 1\n",
    "    for i in tqdm(range(e), desc=\"Processing stack\"):\n",
    "        if H[i] == 0:\n",
    "            stack = [i]\n",
    "            visited = set()  # To keep track of edges that have been added to the stack\n",
    "            while stack:\n",
    "                current = stack.pop()\n",
    "                H[current] = CurrentMark\n",
    "                # Only add edges to the stack that haven't been assigned to a hyperedge and aren't already on the stack\n",
    "                related_edges = [\n",
    "                    cor\n",
    "                    for cor in Cor[current]\n",
    "                    if cor != 0 and H[cor] == 0 and cor not in visited\n",
    "                ]\n",
    "                stack.extend(related_edges)\n",
    "                visited.update(related_edges)\n",
    "            CurrentMark += 1\n",
    "    H = {edge: H[i] for i, edge in enumerate(E)}\n",
    "    if get_time_resolved_intersections:\n",
    "        return H, time_resolved_intersections\n",
    "    return H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Instanciation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "G = final_graph\n",
    "E = list(G.edges())\n",
    "\n",
    "# Add edges to G...\n",
    "H = hypergraph_from_graph(G, positions, edges_time_interval)\n",
    "H = {Edge(Node(edge[0], exp), Node(edge[1], exp), exp): H[edge] for edge in H.keys()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "fig, ax1 = plt.subplots(1, 1, figsize=(12, 8))\n",
    "\n",
    "def random_color():\n",
    "    return tuple(random.random() for _ in range(3))\n",
    "\n",
    "colors = {}\n",
    "for _, value in H.items():\n",
    "    colors[value] = random_color()\n",
    "\n",
    "for edge, value in H.items():\n",
    "    pixels = edge.pixel_list(last_index)\n",
    "    x, y = zip(*pixels)\n",
    "    plt.plot(y, x, color=colors[value])\n",
    "\n",
    "plt.xlim(0, 56000)\n",
    "plt.ylim(0, 30000)\n",
    "plt.gca().invert_yaxis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Create a dataset to analyze intersections geometricaly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \\* and 3.1 need to be run for this section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Acquire useful intersections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "G = final_graph\n",
    "E = list(G.edges())\n",
    "\n",
    "# Add edges to G...\n",
    "_, time_resolved_intersections = hypergraph_from_graph(G, positions, edges_time_interval, get_time_resolved_intersections=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Create the dataset: set of 3 edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "\n",
    "for edge_list, e1, e2, intersection in time_resolved_intersections:\n",
    "    if len(edge_list) > 2:\n",
    "        edge1 = Edge(Node(E[e1][0], exp), Node(E[e1][1], exp), exp)\n",
    "        pixels1 = np.array(edge1.pixel_list(last_index)) - intersection\n",
    "        if np.linalg.norm(pixels1[0]) > np.linalg.norm(pixels1[-1]):\n",
    "            pixels1 = np.flip(pixels1, 0)\n",
    "\n",
    "        edge2 = Edge(Node(E[e2][0], exp), Node(E[e2][1], exp), exp)\n",
    "        pixels2 = edge2.pixel_list(last_index) - intersection\n",
    "        if np.linalg.norm(pixels2[0]) > np.linalg.norm(pixels2[-1]):\n",
    "            pixels2 = np.flip(pixels2, 0)\n",
    "\n",
    "        for e in edge_list:\n",
    "            if e!=e1 and e!=e2:\n",
    "                edge = Edge(Node(E[e][0], exp), Node(E[e][1], exp), exp)\n",
    "                pixels = np.array(edge.pixel_list(last_index)) - intersection\n",
    "                if np.linalg.norm(pixels[0]) > np.linalg.norm(pixels[-1]):\n",
    "                    pixels = np.flip(pixels, 0)\n",
    "                data = [(pixels1, 0), (pixels2, 0), (pixels, 1)]\n",
    "                random.shuffle(data)\n",
    "                label = [label for _, label in data]\n",
    "                pixels_lists = [list(pixels_list) for pixels_list, _ in data]\n",
    "        dataset.append((pixels_lists, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "\n",
    "index = random.randint(0, len(dataset)-1)\n",
    "for pixels_list in dataset[index][0]:\n",
    "    y, x = zip(*pixels_list)\n",
    "    plt.plot(x, y)\n",
    "\n",
    "color_index = {0:'Blue', 1:'Orange', 2:'Green'}\n",
    "plt.title(f'Wrong is {color_index[np.argmax(dataset[index][1])]}')\n",
    "plt.gca().invert_yaxis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Save the dataset: set of 3 edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = f\"/Users/amin/Documents/AMOLF/Data/models/Intersection_dataset/{plates[0]}.p\"\n",
    "\n",
    "with open(dataset_path, 'wb') as f:\n",
    "    pickle.dump(dataset, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Create the dataset: set of 2 edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_2 = []\n",
    "\n",
    "for edge_list, e1, e2, intersection in time_resolved_intersections:\n",
    "    if len(edge_list) > 2:\n",
    "        edge1 = Edge(Node(E[e1][0], exp), Node(E[e1][1], exp), exp)\n",
    "        pixels1 = np.array(edge1.pixel_list(last_index)) - intersection\n",
    "        if np.linalg.norm(pixels1[0]) > np.linalg.norm(pixels1[-1]):\n",
    "            pixels1 = np.flip(pixels1, 0)\n",
    "\n",
    "        edge2 = Edge(Node(E[e2][0], exp), Node(E[e2][1], exp), exp)\n",
    "        pixels2 = edge2.pixel_list(last_index) - intersection\n",
    "        if np.linalg.norm(pixels2[0]) > np.linalg.norm(pixels2[-1]):\n",
    "            pixels2 = np.flip(pixels2, 0)\n",
    "\n",
    "        dataset_2.append(([pixels1, pixels2], 1))\n",
    "\n",
    "        for e in edge_list:\n",
    "            if e!=e1 and e!=e2:\n",
    "                edge = Edge(Node(E[e][0], exp), Node(E[e][1], exp), exp)\n",
    "                pixels = np.array(edge.pixel_list(last_index)) - intersection\n",
    "                if np.linalg.norm(pixels[0]) > np.linalg.norm(pixels[-1]):\n",
    "                    pixels = np.flip(pixels, 0)\n",
    "                dataset_2.append(([pixels1, pixels], 0))\n",
    "                dataset_2.append(([pixels2, pixels], 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 Save the dataset: set of 2 edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path_2 = f\"/Users/amin/Documents/AMOLF/Data/models/Intersection_dataset_2/{plates[0]}.p\"\n",
    "\n",
    "with open(dataset_path_2, 'wb') as f:\n",
    "    pickle.dump(dataset_2, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. ML to geometricaly learn intersections: set of 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = f\"/Users/amin/Documents/AMOLF/Data/models/Intersection_dataset/{plates[0]}.p\"\n",
    "\n",
    "with open(dataset_path, \"rb\") as fp:   # Unpickling\n",
    "    dataset = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Distribution of pixels_list length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "lengths = []\n",
    "for intersection, _ in dataset:\n",
    "    for pixels in intersection:\n",
    "        lengths.append(len(pixels))\n",
    "\n",
    "weights = np.ones_like(lengths) / len(lengths)\n",
    "plt.hist(lengths, weights=weights);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "small_length = [l for l in lengths if l <100]\n",
    "weights = np.ones_like(small_length) / len(lengths)\n",
    "plt.hist(small_length, weights=weights, bins=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "\n",
    "index = random.randint(0, len(dataset)-1)\n",
    "for pixels_list in dataset[index][0]:\n",
    "    y, x = zip(*pixels_list[:20])\n",
    "    plt.plot(x, y)\n",
    "\n",
    "color_index = {0:'Blue', 1:'Orange', 2:'Green'}\n",
    "plt.title(f'Wrong is {color_index[np.argmax(dataset[index][1])]}')\n",
    "plt.gca().invert_yaxis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Format the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_pixel_list = 100\n",
    "\n",
    "X, y = [], []\n",
    "\n",
    "for pixels_lists, label in dataset:\n",
    "    pixels_lists_sliced = []\n",
    "    for pixels in pixels_lists:\n",
    "        pixels_to_add = (pixels+([pixels[-1]]*length_pixel_list))[:length_pixel_list]\n",
    "        pixels_lists_sliced.extend(pixels_to_add)\n",
    "    X.append(np.array(pixels_lists_sliced).flatten())\n",
    "    y.append(np.array(label))\n",
    "\n",
    "X_train, X_test = X[:400], np.array(X[400:])\n",
    "y_train, y_test = y[:400], np.array(y[400:])\n",
    "\n",
    "# Train on all rotations\n",
    "for pixels, labels in zip(X_train.copy(), y_train.copy()):\n",
    "    X_train.append(np.roll(pixels, 2*length_pixel_list))\n",
    "    y_train.append(np.roll(labels, 1))\n",
    "    X_train.append(np.roll(pixels, -2*length_pixel_list))\n",
    "    y_train.append(np.roll(labels, -1))\n",
    "\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = Input(shape=(length_pixel_list*2*3,))\n",
    "h = Dense(256, activation='relu')(x)\n",
    "y = Dense(3, activation='softmax')(h)\n",
    "model = Model(x, y)\n",
    "\n",
    "model.compile(optimizer=RMSprop(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "print(\"input shape \", model.input_shape)\n",
    "print(\"output shape \", model.output_shape)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    batch_size=64,\n",
    "    epochs=150,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/Users/amin/Documents/AMOLF/Data/models/intersection_model.keras\"\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.6 Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(6, 9))\n",
    "\n",
    "ax1.plot(history.history[\"val_accuracy\"])\n",
    "ax1.set_ylabel(\"Accuracy\")\n",
    "ax1.set_ylim([0, 1])\n",
    "ax1.set_xlabel(\"Epoch\")\n",
    "\n",
    "ax2.plot(history.history[\"val_loss\"])\n",
    "ax2.set_ylabel(\"Loss\")\n",
    "# ax2.set_ylim(top=2.5)\n",
    "ax2.set_xlabel(\"Epoch\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_label_pred = np.argmax(y_pred, axis=1)\n",
    "y_label = np.argmax(y_test, axis=1)\n",
    "\n",
    "plt.close('all')\n",
    "plt.figure(figsize=(20,20))\n",
    "color_index = {0:'Blue', 1:'Orange', 2:'Green'}\n",
    "i=0\n",
    "for y_pred, y_true, pixels in zip(y_label_pred, y_label, X_test):\n",
    "    if y_pred != y_true and i<16:\n",
    "        i+=1\n",
    "        plt.subplot(4,4,i)\n",
    "        for k in range(3):\n",
    "            plt.plot(pixels[length_pixel_list*2*k:length_pixel_list*(2*k+2):2], pixels[1+length_pixel_list*2*k:length_pixel_list*(2*k+2):2])\n",
    "        plt.title(f'Wrong is {color_index[y_true]}/ Predicted is {color_index[y_pred]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Hypergraph using ml set of 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The * need to be run for this section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm  # for Jupyter notebook or IPython\n",
    "\n",
    "length_pixel_list = 100\n",
    "model_path = \"/Users/amin/Documents/AMOLF/Data/models/intersection_model.keras\"\n",
    "model = load_model(model_path)\n",
    "positions = exp.positions[last_index]\n",
    "\n",
    "def angle_between(vec1, vec2):\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm_product = np.linalg.norm(vec1) * np.linalg.norm(vec2)\n",
    "    return np.arccos(np.clip(dot_product / norm_product, -1.0, 1.0))\n",
    "\n",
    "def score_angle(v1, v2, v, positions):\n",
    "    vec1 = np.array(positions[v1]) - np.array(positions[v])\n",
    "    vec2 = np.array(positions[v2]) - np.array(positions[v])\n",
    "    angle = np.abs(angle_between(vec1, vec2) - np.pi)\n",
    "    return angle\n",
    "\n",
    "def score_ml(v1, v2, v3, v, positions):\n",
    "    intersection = positions[v]\n",
    "    data = []\n",
    "    for vi in [v1, v2, v3]:\n",
    "        edge = Edge(Node(v, exp), Node(vi, exp), exp)\n",
    "        pixels = np.array(edge.pixel_list(last_index)) - intersection\n",
    "        if np.linalg.norm(pixels[0]) > np.linalg.norm(pixels[-1]):\n",
    "            pixels = np.flip(pixels, 0)\n",
    "        pixels = (list(pixels) + [pixels[-1]]*length_pixel_list)[:length_pixel_list]\n",
    "        data.extend(pixels)\n",
    "    data = np.array(data).reshape(1, -1)\n",
    "    return model.predict(data, verbose=0)[0]\n",
    "    \n",
    "\n",
    "def edge_matches_ml(v, EExtract, E, positions, edges_time_interval) -> list:\n",
    "    if len(EExtract) < 2:\n",
    "        return []\n",
    "\n",
    "    times = []\n",
    "    vs = []\n",
    "    for e in EExtract:\n",
    "        v_i =  E[e][0] if E[e][1] == v else E[e][1]\n",
    "        time_interval = edges_time_interval.get(f\"{v_i},{v}\")\n",
    "        if time_interval is None:\n",
    "            time, _ = edges_time_interval[f\"{v},{v_i}\"]\n",
    "        else:\n",
    "            time = time_interval[1]\n",
    "        vs.append(v_i)\n",
    "        times.append(time)\n",
    "\n",
    "    min_time = min(times)\n",
    "    min_time_edges = [index for index, time in enumerate(times) if time==min_time]\n",
    "\n",
    "    if len(min_time_edges)==2:\n",
    "        e1 = EExtract[min_time_edges[0]]\n",
    "        e2 = EExtract[min_time_edges[1]]\n",
    "        return [(e1, e2, 'time_resolved')] + edge_matches_ml(v, [edge_index for edge_index in EExtract if (edge_index!=e1 and edge_index!=e2)], E, positions, edges_time_interval)\n",
    "\n",
    "    if len(min_time_edges) > 2:\n",
    "        index1, index2, index3 = min_time_edges[:3]\n",
    "        scores = score_ml(vs[index1], vs[index2], vs[index3], v, positions)\n",
    "        wrong_index = np.argmax(scores)\n",
    "        indexes = ((wrong_index+1)%3, (wrong_index+2)%3)\n",
    "        e1 = EExtract[min_time_edges[indexes[0]]]\n",
    "        e2 = EExtract[min_time_edges[indexes[1]]]\n",
    "        return [(e1, e2, 'geometricaly_resolved')] + edge_matches_ml(v, [edge_index for edge_index in EExtract if (edge_index!=e1 and edge_index!=e2)], E, positions, edges_time_interval)\n",
    "\n",
    "    min_time_edge = min_time_edges[0]\n",
    "    second_min_time = min([time for time in times if time!=min_time])\n",
    "    second_time_edges = [index for index, time in enumerate(times) if time==second_min_time]\n",
    "    \n",
    "    if len(second_time_edges)==1:\n",
    "        e1 = EExtract[min_time_edge]\n",
    "        e2 = EExtract[second_time_edges[0]]\n",
    "        return [(e1, e2, 'time_resolved')] + edge_matches_ml(v, [edge_index for edge_index in EExtract if (edge_index!=e1 and edge_index!=e2)], E, positions, edges_time_interval)\n",
    "\n",
    "    e1 = EExtract[min_time_edge]\n",
    "    min_score = 1\n",
    "    for indexes in combinations(second_time_edges, 2):\n",
    "        score = score_ml(vs[indexes[0]], vs[indexes[1]], vs[min_time_edge], v, positions)\n",
    "        index_min_score = np.argmin(score[:2])\n",
    "        if score[index_min_score] < min_score:\n",
    "            index = index_min_score\n",
    "    e2 = EExtract[index]\n",
    "    return [(e1, e2, 'geometricaly_resolved')] + edge_matches_ml(v, [edge_index for edge_index in EExtract if (edge_index!=e1 and edge_index!=e2)], E, positions, edges_time_interval)\n",
    "\n",
    "\n",
    "def hypergraph_from_graph_ml(G, positions, edges_time_interval, get_time_resolved_intersections=False):\n",
    "    V = list(G.nodes())\n",
    "    E = list(G.edges())\n",
    "    e = len(E)\n",
    "    v = len(V)\n",
    "\n",
    "    H = [0] * e\n",
    "    Cor = [[0] * 10 for _ in range(e)]\n",
    "\n",
    "    if get_time_resolved_intersections:\n",
    "        time_resolved_intersections = []\n",
    "\n",
    "    # STEP 1\n",
    "    for i in tqdm(V, desc=\"Processing vertices\"):\n",
    "        EExtract = [edge_idx for edge_idx, edge in enumerate(E) if i in edge]\n",
    "        matches = edge_matches_ml(i, EExtract, E, positions, edges_time_interval)\n",
    "        for match in matches:\n",
    "            e1, e2 = match[0], match[1]\n",
    "            Cor[e1][Cor[e1].index(0)] = e2\n",
    "            Cor[e2][Cor[e2].index(0)] = e1\n",
    "        if get_time_resolved_intersections and matches and matches[0][2]=='time_resolved':\n",
    "            time_resolved_intersections.append((EExtract, matches[0][0], matches[0][1], positions[i]))\n",
    "\n",
    "    # STEP 2\n",
    "    CurrentMark = 1\n",
    "    for i in tqdm(range(e), desc=\"Processing stack\"):\n",
    "        if H[i] == 0:\n",
    "            stack = [i]\n",
    "            visited = set()  # To keep track of edges that have been added to the stack\n",
    "            while stack:\n",
    "                current = stack.pop()\n",
    "                H[current] = CurrentMark\n",
    "                # Only add edges to the stack that haven't been assigned to a hyperedge and aren't already on the stack\n",
    "                related_edges = [\n",
    "                    cor\n",
    "                    for cor in Cor[current]\n",
    "                    if cor != 0 and H[cor] == 0 and cor not in visited\n",
    "                ]\n",
    "                stack.extend(related_edges)\n",
    "                visited.update(related_edges)\n",
    "            CurrentMark += 1\n",
    "    H = {edge: H[i] for i, edge in enumerate(E)}\n",
    "    if get_time_resolved_intersections:\n",
    "        return H, time_resolved_intersections\n",
    "    return H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Instanciation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "G = final_graph\n",
    "E = list(G.edges())\n",
    "\n",
    "# Add edges to G...\n",
    "H_ml = hypergraph_from_graph_ml(G, positions, edges_time_interval)\n",
    "H_ml = {Edge(Node(edge[0], exp), Node(edge[1], exp), exp): H_ml[edge] for edge in H_ml.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = np.array\n",
    "plt.close('all')\n",
    "d=[array([0, 0]), array([1, 0]), array([2, 0]), array([3, 0]), array([4, 0]), array([ 5, -1]), array([ 6, -1]), array([ 7, -1]), array([ 8, -1]), array([ 9, -1]), array([10, -1]), array([11, -1]), array([12, -1]), array([13, -1]), array([14, -1]), array([15, -1]), array([16, -1]), array([17, -1]), array([18, -1]), array([19, -1]), array([20, -2]), array([21, -2]), array([22, -2]), array([23, -2]), array([24, -3]), array([25, -3]), array([26, -3]), array([27, -3]), array([28, -4]), array([29, -4]), array([30, -4]), array([31, -4]), array([32, -4]), array([33, -4]), array([34, -5]), array([35, -5]), array([36, -5]), array([37, -5]), array([38, -6]), array([39, -6]), array([40, -6]), array([41, -6]), array([42, -6]), array([43, -7]), array([44, -7]), array([45, -7]), array([46, -7]), array([46, -8]), array([47, -8]), array([48, -8]), array([49, -8]), array([49, -9]), array([50, -9]), array([51, -9]), array([ 52, -10]), array([ 53, -10]), array([ 54, -10]), array([ 55, -11]), array([ 56, -11]), array([ 57, -11]), array([ 58, -12]), array([ 59, -12]), array([ 60, -13]), array([ 61, -13]), array([ 61, -14]), array([ 62, -14]), array([ 62, -15]), array([ 62, -16]), array([ 63, -16]), array([ 64, -16]), array([ 65, -16]), array([ 66, -16]), array([ 67, -16]), array([ 68, -16]), array([ 69, -16]), array([ 70, -16]), array([ 71, -16]), array([ 72, -16]), array([ 73, -17]), array([ 74, -17]), array([ 75, -17]), array([ 76, -18]), array([ 77, -18]), array([ 78, -18]), array([ 79, -19]), array([ 80, -19]), array([ 81, -19]), array([ 81, -20]), array([ 82, -20]), array([ 83, -20]), array([ 84, -20]), array([ 85, -21]), array([ 86, -21]), array([ 87, -22]), array([ 88, -22]), array([ 89, -22]), array([ 90, -22]), array([ 91, -22]), array([ 92, -23]), array([ 93, -23]), array([0, 0]), array([ 0, -1]), array([ 0, -2]), array([ 0, -3]), array([ 0, -4]), array([ 0, -5]), array([ 0, -6]), array([-1, -7]), array([-1, -8]), array([-1, -9]), array([ -1, -10]), array([ -1, -11]), array([ -1, -12]), array([ -2, -13]), array([ -2, -14]), array([ -2, -15]), array([ -3, -15]), array([ -3, -16]), array([ -3, -17]), array([ -3, -18]), array([ -4, -19]), array([ -4, -20]), array([ -4, -21]), array([ -4, -22]), array([ -5, -22]), array([ -5, -23]), array([ -5, -24]), array([ -6, -25]), array([ -6, -26]), array([ -7, -26]), array([ -7, -27]), array([ -8, -28]), array([ -9, -29]), array([-10, -30]), array([-10, -31]), array([-11, -31]), array([-12, -32]), array([-13, -33]), array([-14, -34]), array([-15, -34]), array([-15, -35]), array([-16, -36]), array([-17, -36]), array([-18, -37]), array([-19, -37]), array([-20, -37]), array([-20, -38]), array([-21, -38]), array([-22, -39]), array([-23, -40]), array([-24, -40]), array([-24, -41]), array([-25, -41]), array([-26, -42]), array([-27, -42]), array([-28, -43]), array([-29, -43]), array([-29, -44]), array([-30, -44]), array([-31, -44]), array([-32, -44]), array([-32, -45]), array([-33, -45]), array([-34, -45]), array([-35, -45]), array([-36, -46]), array([-37, -46]), array([-38, -46]), array([-39, -47]), array([-40, -47]), array([-41, -48]), array([-42, -48]), array([-43, -49]), array([-44, -49]), array([-44, -50]), array([-45, -50]), array([-46, -50]), array([-46, -51]), array([-47, -51]), array([-48, -52]), array([-49, -52]), array([-50, -53]), array([-51, -53]), array([-52, -54]), array([-53, -54]), array([-53, -55]), array([-54, -55]), array([-55, -55]), array([-55, -56]), array([-56, -56]), array([-57, -57]), array([-58, -57]), array([-59, -58]), array([-60, -59]), array([-61, -59]), array([-62, -60]), array([-63, -61]), array([-64, -62]), array([-65, -62]), array([-65, -63]), array([0, 0]), array([0, 1]), array([-1,  2]), array([-1,  3]), array([-2,  4]), array([-2,  5]), array([-3,  5]), array([-3,  6]), array([-4,  6]), array([-5,  7]), array([-6,  7]), array([-7,  7]), array([-7,  8]), array([-8,  8]), array([-9,  8]), array([-10,   9]), array([-11,   9]), array([-12,  10]), array([-13,  10]), array([-14,  10]), array([-15,  11]), array([-16,  11]), array([-17,  12]), array([-18,  12]), array([-19,  12]), array([-19,  13]), array([-20,  13]), array([-21,  13]), array([-21,  14]), array([-22,  14]), array([-23,  14]), array([-23,  15]), array([-24,  15]), array([-25,  15]), array([-26,  15]), array([-26,  16]), array([-27,  16]), array([-28,  16]), array([-29,  17]), array([-30,  17]), array([-31,  18]), array([-32,  18]), array([-33,  19]), array([-34,  19]), array([-35,  20]), array([-36,  21]), array([-37,  22]), array([-37,  23]), array([-38,  23]), array([-38,  24]), array([-39,  24]), array([-40,  25]), array([-41,  25]), array([-42,  25]), array([-43,  25]), array([-44,  25]), array([-45,  25]), array([-46,  25]), array([-47,  25]), array([-48,  25]), array([-49,  25]), array([-50,  25]), array([-51,  25]), array([-51,  25]), array([-51,  25]), array([-51,  25]), array([-51,  25]), array([-51,  25]), array([-51,  25]), array([-51,  25]), array([-51,  25]), array([-51,  25]), array([-51,  25]), array([-51,  25]), array([-51,  25]), array([-51,  25]), array([-51,  25]), array([-51,  25]), array([-51,  25]), array([-51,  25]), array([-51,  25]), array([-51,  25]), array([-51,  25]), array([-51,  25]), array([-51,  25]), array([-51,  25]), array([-51,  25]), array([-51,  25]), array([-51,  25]), array([-51,  25]), array([-51,  25]), array([-51,  25]), array([-51,  25]), array([-51,  25]), array([-51,  25]), array([-51,  25]), array([-51,  25]), array([-51,  25]), array([-51,  25]), array([-51,  25])]\n",
    "\n",
    "c1, c2, c3 = d[:100], d[100:200], d[200:]\n",
    "for c in [c1, c2, c3]:\n",
    "    y, x = zip(*c)\n",
    "    plt.plot(x, y)\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "d = c3+c1+c2\n",
    "d = np.array(d).reshape(1, -1)\n",
    "model.predict(d, verbose=0)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "fig, ax1 = plt.subplots(1, 1, figsize=(12, 8))\n",
    "\n",
    "def random_color():\n",
    "    return tuple(random.random() for _ in range(3))\n",
    "\n",
    "colors = {}\n",
    "for _, value in H_ml.items():\n",
    "    colors[value] = random_color()\n",
    "\n",
    "for edge, value in H_ml.items():\n",
    "    pixels = edge.pixel_list(last_index)\n",
    "    x, y = zip(*pixels)\n",
    "    plt.plot(y, x, color=colors[value])\n",
    "\n",
    "plt.xlim(0, 56000)\n",
    "plt.ylim(0, 30000)\n",
    "plt.gca().invert_yaxis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. ML to geometricaly learn intersections: set of 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path_2 = f\"/Users/amin/Documents/AMOLF/Data/models/Intersection_dataset_2/{plates[0]}.p\"\n",
    "\n",
    "with open(dataset_path_2, \"rb\") as fp:   # Unpickling\n",
    "    dataset_2 = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 Format the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_pixel_list = 100\n",
    "\n",
    "X, y = [], []\n",
    "\n",
    "for pixels_lists, label in dataset_2:\n",
    "    pixels_lists_sliced = []\n",
    "    for pixels in pixels_lists:\n",
    "        pixels_to_add = (list(pixels)+([pixels[-1]]*length_pixel_list))[:length_pixel_list]\n",
    "        pixels_lists_sliced.extend(pixels_to_add)\n",
    "    X.append(np.array(pixels_lists_sliced).flatten())\n",
    "    y.append(label)\n",
    "\n",
    "split_index = int(len(X)*0.9)\n",
    "\n",
    "X_train, X_test = X[:split_index], np.array(X[split_index:])\n",
    "y_train, y_test = y[:split_index], np.array(y[split_index:])\n",
    "\n",
    "# Train on all rotations\n",
    "for pixels, label in zip(X_train.copy(), y_train.copy()):\n",
    "    X_train.append(np.roll(pixels, 2*length_pixel_list))\n",
    "    y_train.append(label)\n",
    "\n",
    "zipped = list(zip(X_train, y_train))\n",
    "random.shuffle(zipped)\n",
    "X_train, y_train = zip(*zipped)\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3 Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Input(shape=(length_pixel_list*2*2,))\n",
    "h = Dense(64, activation='relu')(x)\n",
    "y = Dense(1, activation='sigmoid')(h)\n",
    "model = Model(x, y)\n",
    "\n",
    "model.compile(optimizer=RMSprop(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "print(\"input shape \", model.input_shape)\n",
    "print(\"output shape \", model.output_shape)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    batch_size=128,\n",
    "    epochs=500,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4 Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(6, 9))\n",
    "\n",
    "ax1.plot(history.history[\"val_accuracy\"])\n",
    "ax1.set_ylabel(\"Accuracy\")\n",
    "ax1.set_ylim([0, 1])\n",
    "ax1.set_xlabel(\"Epoch\")\n",
    "\n",
    "ax2.plot(history.history[\"val_loss\"])\n",
    "ax2.set_ylabel(\"Loss\")\n",
    "ax2.set_ylim(top=2.5)\n",
    "ax2.set_xlabel(\"Epoch\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_2 = model.predict(np.roll(X_test, 2*length_pixel_list, axis=1))\n",
    "y_label_pred = np.where(y_pred<0.5, 0, 1)\n",
    "y_label = y_test\n",
    "\n",
    "plt.close('all')\n",
    "plt.figure(figsize=(20,20))\n",
    "i=0\n",
    "for y_pr, y_pr_2, y_pred_label, y_true, pixels in zip(y_pred, y_pred_2, y_label_pred, y_label, X_test):\n",
    "    if y_pred_label != y_true and i<16:\n",
    "        i+=1\n",
    "        plt.subplot(4,4,i)\n",
    "        for k in range(2):\n",
    "            plt.plot(pixels[length_pixel_list*2*k:length_pixel_list*(2*k+2):2], pixels[1+length_pixel_list*2*k:length_pixel_list*(2*k+2):2])\n",
    "        plt.title(f'y_true={y_true}/y_pred={y_pr[0]:.3f}/y_pred_2={y_pr_2[0]:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred_2 = model.predict(np.roll(X_test, 2*length_pixel_list, axis=1))\n",
    "y_label_pred = np.where(y_pred<0.5, 0, 1)\n",
    "y_label = y_test\n",
    "\n",
    "plt.close('all')\n",
    "plt.figure(figsize=(20,20))\n",
    "i=0\n",
    "for y_pr, y_pr_2, y_pred_label, y_true, pixels in zip(y_pred, y_pred_2, y_label_pred, y_label, X_test):\n",
    "    if abs(y_pr[0]-y_pr_2[0])>0.1 and i<16:\n",
    "        i+=1\n",
    "        plt.subplot(4,4,i)\n",
    "        for k in range(2):\n",
    "            plt.plot(pixels[length_pixel_list*2*k:length_pixel_list*(2*k+2):2], pixels[1+length_pixel_list*2*k:length_pixel_list*(2*k+2):2])\n",
    "        plt.title(f'y_true={y_true}/y_pred={y_pr[0]:.3f}/y_pred_2={y_pr_2[0]:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.5 Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/Users/amin/Documents/AMOLF/Data/models/intersection_model_2.keras\"\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Hypergraph using ml set of 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The * need to be run for this section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1 Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_pixel_list = 100\n",
    "model_path = \"/Users/amin/Documents/AMOLF/Data/models/intersection_model_2.keras\"\n",
    "model = load_model(model_path)\n",
    "positions = exp.positions[last_index]\n",
    "\n",
    "def score_ml_2(v1, v2, v, positions):\n",
    "    intersection = positions[v]\n",
    "    data = []\n",
    "    for vi in [v1, v2]:\n",
    "        edge = Edge(Node(v, exp), Node(vi, exp), exp)\n",
    "        pixels = np.array(edge.pixel_list(last_index)) - intersection\n",
    "        if np.linalg.norm(pixels[0]) > np.linalg.norm(pixels[-1]):\n",
    "            pixels = np.flip(pixels, 0)\n",
    "        pixels = (list(pixels) + [pixels[-1]]*length_pixel_list)[:length_pixel_list]\n",
    "        data.extend(pixels)\n",
    "    data = np.array(data).reshape(1, -1)\n",
    "    score = model.predict(data, verbose=0)[0] + model.predict(np.roll(data, 2*length_pixel_list), verbose=0)[0]\n",
    "    return score\n",
    "    \n",
    "\n",
    "def edge_matches_ml_2(v, EExtract, E, positions, edges_time_interval) -> list:\n",
    "    if len(EExtract) < 2:\n",
    "        return []\n",
    "\n",
    "    times = []\n",
    "    vs = []\n",
    "    for e in EExtract:\n",
    "        v_i =  E[e][0] if E[e][1] == v else E[e][1]\n",
    "        time_interval = edges_time_interval.get(f\"{v_i},{v}\")\n",
    "        if time_interval is None:\n",
    "            time, _ = edges_time_interval[f\"{v},{v_i}\"]\n",
    "        else:\n",
    "            time = time_interval[1]\n",
    "        vs.append(v_i)\n",
    "        times.append(time)\n",
    "\n",
    "    min_time = min(times)\n",
    "    min_time_edges = [index for index, time in enumerate(times) if time==min_time]\n",
    "\n",
    "    if len(min_time_edges)==2:\n",
    "        e1 = EExtract[min_time_edges[0]]\n",
    "        e2 = EExtract[min_time_edges[1]]\n",
    "        return [(e1, e2, 'time_resolved')] + edge_matches_ml_2(v, [edge_index for edge_index in EExtract if (edge_index!=e1 and edge_index!=e2)], E, positions, edges_time_interval)\n",
    "\n",
    "    if len(min_time_edges) > 2:\n",
    "        pairs = combinations(min_time_edges, 2)\n",
    "        best_score = 0\n",
    "        for index1, index2 in pairs:\n",
    "            score = score_ml_2(vs[index1], vs[index2], v, positions)\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                e1 = EExtract[index1]\n",
    "                e2 = EExtract[index2]\n",
    "        return [(e1, e2, 'geometricaly_resolved')] + edge_matches_ml_2(v, [edge_index for edge_index in EExtract if (edge_index!=e1 and edge_index!=e2)], E, positions, edges_time_interval)\n",
    "\n",
    "    min_time_edge = min_time_edges[0]\n",
    "    second_min_time = min([time for time in times if time!=min_time])\n",
    "    second_time_edges = [index for index, time in enumerate(times) if time==second_min_time]\n",
    "    \n",
    "    if len(second_time_edges)==1:\n",
    "        e1 = EExtract[min_time_edge]\n",
    "        e2 = EExtract[second_time_edges[0]]\n",
    "        return [(e1, e2, 'time_resolved')] + edge_matches_ml_2(v, [edge_index for edge_index in EExtract if (edge_index!=e1 and edge_index!=e2)], E, positions, edges_time_interval)\n",
    "\n",
    "    e1 = EExtract[min_time_edge]\n",
    "    best_score = 0\n",
    "    for index in second_time_edges:\n",
    "        score = score_ml_2(vs[index], vs[min_time_edge], v, positions)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_index= index\n",
    "    e2 = EExtract[best_index]\n",
    "    return [(e1, e2, 'geometricaly_resolved')] + edge_matches_ml_2(v, [edge_index for edge_index in EExtract if (edge_index!=e1 and edge_index!=e2)], E, positions, edges_time_interval)\n",
    "\n",
    "\n",
    "def hypergraph_from_graph_ml_2(G, positions, edges_time_interval, get_time_resolved_intersections=False):\n",
    "    V = list(G.nodes())\n",
    "    E = list(G.edges())\n",
    "    e = len(E)\n",
    "    v = len(V)\n",
    "\n",
    "    H = [0] * e\n",
    "    Cor = [[0] * 10 for _ in range(e)]\n",
    "\n",
    "    if get_time_resolved_intersections:\n",
    "        time_resolved_intersections = []\n",
    "\n",
    "    # STEP 1\n",
    "    for i in tqdm(V, desc=\"Processing vertices\"):\n",
    "        EExtract = [edge_idx for edge_idx, edge in enumerate(E) if i in edge]\n",
    "        matches = edge_matches_ml_2(i, EExtract, E, positions, edges_time_interval)\n",
    "        for match in matches:\n",
    "            e1, e2 = match[0], match[1]\n",
    "            Cor[e1][Cor[e1].index(0)] = e2\n",
    "            Cor[e2][Cor[e2].index(0)] = e1\n",
    "        if get_time_resolved_intersections and matches and matches[0][2]=='time_resolved':\n",
    "            time_resolved_intersections.append((EExtract, matches[0][0], matches[0][1], positions[i]))\n",
    "\n",
    "    # STEP 2\n",
    "    CurrentMark = 1\n",
    "    for i in tqdm(range(e), desc=\"Processing stack\"):\n",
    "        if H[i] == 0:\n",
    "            stack = [i]\n",
    "            visited = set()  # To keep track of edges that have been added to the stack\n",
    "            while stack:\n",
    "                current = stack.pop()\n",
    "                H[current] = CurrentMark\n",
    "                # Only add edges to the stack that haven't been assigned to a hyperedge and aren't already on the stack\n",
    "                related_edges = [\n",
    "                    cor\n",
    "                    for cor in Cor[current]\n",
    "                    if cor != 0 and H[cor] == 0 and cor not in visited\n",
    "                ]\n",
    "                stack.extend(related_edges)\n",
    "                visited.update(related_edges)\n",
    "            CurrentMark += 1\n",
    "    H = {edge: H[i] for i, edge in enumerate(E)}\n",
    "    if get_time_resolved_intersections:\n",
    "        return H, time_resolved_intersections\n",
    "    return H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2 Instanciation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "G = final_graph\n",
    "E = list(G.edges())\n",
    "\n",
    "# Add edges to G...\n",
    "H = hypergraph_from_graph_ml_2(G, positions, edges_time_interval)\n",
    "H = {Edge(Node(edge[0], exp), Node(edge[1], exp), exp): H[edge] for edge in H.keys()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.3 Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "fig, ax1 = plt.subplots(1, 1, figsize=(12, 8))\n",
    "\n",
    "def random_color():\n",
    "    return tuple(random.random() for _ in range(3))\n",
    "\n",
    "colors = {}\n",
    "for _, value in H.items():\n",
    "    colors[value] = random_color()\n",
    "\n",
    "for edge, value in H.items():\n",
    "    pixels = edge.pixel_list(last_index)\n",
    "    x, y = zip(*pixels)\n",
    "    plt.plot(y, x, color=colors[value])\n",
    "\n",
    "plt.xlim(0, 56000)\n",
    "plt.ylim(0, 30000)\n",
    "plt.gca().invert_yaxis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. WIP"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
