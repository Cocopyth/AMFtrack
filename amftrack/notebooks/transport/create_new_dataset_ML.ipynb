{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f70c80be-987f-4332-8255-b30b9bae5afb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/home2/cbisot/pycode/AMFtrack/amftrack/util/dbx.py:3: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n",
      "2024-06-24 09:09:36.472671: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-24 09:09:36.482335: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-24 09:09:36.575383: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-24 09:09:39.725843: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-24 09:09:45,673-[WARNING]- absl:256 -> Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "2024-06-24 09:09:45,687-[WARNING]- absl:184 -> Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cbisot/miniconda3/envs/amftrack/lib/python3.12/site-packages/keras/src/optimizers/base_optimizer.py:33: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "import re\n",
    "import dropbox\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import imageio.v2 as imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import logging\n",
    "import datetime\n",
    "import glob\n",
    "import json\n",
    "import scipy\n",
    "import matplotlib as mpl\n",
    "\n",
    "from subprocess import call\n",
    "from tifffile import imwrite\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from amftrack.util.dbx import (\n",
    "    upload_folder,\n",
    "    download,\n",
    "    read_saved_dropbox_state,\n",
    "    save_dropbox_state,\n",
    "    load_dbx,\n",
    "    get_dropbox_folders_prince,\n",
    "    get_dropbox_video_folders,\n",
    "    download_video_folders_drop,\n",
    "    download_analysis_folders_drop,\n",
    ")\n",
    "from amftrack.pipeline.launching.run import (\n",
    "    run_transfer,\n",
    ")\n",
    "from amftrack.pipeline.launching.run_super import run_parallel_transfer\n",
    "from amftrack.pipeline.launching.run_super import run_parallel_flows\n",
    "from amftrack.pipeline.functions.transport_processing.high_mag_videos.plot_data import (\n",
    "    plot_summary,\n",
    "    save_raw_data,\n",
    ")\n",
    "from amftrack.pipeline.functions.transport_processing.high_mag_videos.high_mag_analysis import (\n",
    "    HighmagDataset,\n",
    "    VideoDataset,\n",
    "    EdgeDataset,\n",
    "    index_videos_dropbox_new,\n",
    "    analysis_run,\n",
    ")\n",
    "from amftrack.pipeline.functions.transport_processing.high_mag_videos.kymo_class import (\n",
    "    KymoVideoAnalysis,\n",
    "    KymoEdgeAnalysis,\n",
    ")\n",
    "from amftrack.util.dbx import upload\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib widget\n",
    "\n",
    "from amftrack.pipeline.launching.run_super import (\n",
    "    run_launcher,\n",
    "    directory_scratch,\n",
    "    directory_project,\n",
    "    directory_project,\n",
    "    run_parallel_stitch,\n",
    "    run_parallel_transfer,\n",
    ")\n",
    "import os\n",
    "from amftrack.pipeline.functions.image_processing.experiment_class_surf import (\n",
    "    Experiment,\n",
    "    save_graphs,\n",
    "    load_graphs,\n",
    "    Edge,\n",
    "    Node,\n",
    ")\n",
    "from amftrack.pipeline.functions.image_processing.experiment_util import (\n",
    "    get_random_edge,\n",
    "    distance_point_edge,\n",
    "    plot_edge,\n",
    "    plot_edge_cropped,\n",
    "    find_nearest_edge,\n",
    "    get_edge_from_node_labels,\n",
    "    plot_full_image_with_features,\n",
    "    get_all_edges,\n",
    "    get_all_nodes,\n",
    "    find_neighboring_edges,\n",
    "    reconstruct_image,\n",
    "    reconstruct_skeletton_from_edges,\n",
    "    reconstruct_skeletton_unicolor,\n",
    "    reconstruct_image_from_general,\n",
    "    plot_full,\n",
    "    plot_edge_color_value,\n",
    ")\n",
    "from amftrack.transport.align_video_network import identify_nodes\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.debug)\n",
    "from amftrack.util.sys import (\n",
    "    get_dates_datetime,\n",
    "    get_dirname,\n",
    "    temp_path,\n",
    "    get_data_info,\n",
    "    update_plate_info,\n",
    "    update_analysis_info,\n",
    "    get_analysis_info,\n",
    "    get_current_folders,\n",
    "    get_folders_by_plate_id,\n",
    ")\n",
    "\n",
    "mpl.rcParams[\"figure.dpi\"] = 100\n",
    "from amftrack.pipeline.functions.transport_processing.high_mag_videos.register_videos import *\n",
    "from amftrack.pipeline.functions.transport_processing.high_mag_videos.loading import (\n",
    "    load_video_dataset,\n",
    ")\n",
    "from amftrack.pipeline.functions.transport_processing.high_mag_videos.make_ML_dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b12b3cb0-d1db-41a6-a3e0-cb90aff8b2fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.rmtree(\"/scratch-shared/amftrack/ML_dataset/\", ignore_errors=True)\n",
    "os.mkdir(\"/scratch-shared/amftrack/ML_dataset/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ec88104-cf1c-4cbe-afa1-093e6686e3da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plate_id = \"310_20230830\"\n",
    "plate_id_video = \"20230903_Plate310\"\n",
    "plate_id = \"441_20230807\"\n",
    "\n",
    "videos_folder = \"/projects/0/einf914/videos/\"\n",
    "\n",
    "analysis_folder = \"/projects/0/einf914/analysis_videos/CocoTransport/\"\n",
    "analysis_folder_root = \"/projects/0/einf914/analysis_videos/\"\n",
    "directory_targ = \"/projects/0/einf914/transport/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20a22211-6911-468a-bdfb-868110775800",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "indexes ={\n",
    "        \"20230901_Plate310\": \"20230901_0719_Plate06\",\n",
    "        \"20230902_Plate310\": \"20230902_1343_Plate07\",\n",
    "        \"20230903_Plate310\": \"20230903_1143_Plate07\",\n",
    "        \"20230904_Plate310\": \"20230904_0942_Plate07\",\n",
    "        \"20230905_Plate310\": \"20230905_1345_Plate07\",\n",
    "        # \"20230906_Plate310\" : \"20230906_1220_Plate07\",\n",
    "    }\n",
    "indexes = {\n",
    "\"20230810_Plate441\" : \"20230810_1005_Plate14\",\n",
    "\"20230811_Plate441\" : \"20230811_1605_Plate14\",\n",
    "\"20230812_Plate441\" : \"20230812_1006_Plate14\",\n",
    "\"20230813_Plate441\" : \"20230813_1618_Plate14\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "515db227-60eb-4f6a-8b79-e6b6d7a2658c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80ef0aa9c39c43079b7549ead08eb1ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "analysed:   0%|          | 0/494 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "update_plate_info(directory_targ, local=True)\n",
    "all_folders = get_current_folders(directory_targ, local=True)\n",
    "folders = all_folders.loc[all_folders[\"unique_id\"] == plate_id]\n",
    "folders = folders.loc[folders[\"/Analysis/nx_graph_pruned_labeled.p\"] == True]\n",
    "folders = folders.sort_values(by=\"datetime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c3490ba-718e-416b-9620-078460dafe5d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find the edges data file at /projects/0/einf914/analysis_videos/CocoTransport/20230810_Plate441/009/Img/edges_data.csv. Check analysis for 20230810_Plate441_009\n",
      "Couldn't find the edges data file at /projects/0/einf914/analysis_videos/CocoTransport/20230810_Plate441/010/Img/edges_data.csv. Check analysis for 20230810_Plate441_010\n",
      "Couldn't find the edges data file at /projects/0/einf914/analysis_videos/CocoTransport/20230810_Plate441/029/Img/edges_data.csv. Check analysis for 20230810_Plate441_029\n",
      "Couldn't find the edges data file at /projects/0/einf914/analysis_videos/CocoTransport/20230810_Plate441/036/Img/edges_data.csv. Check analysis for 20230810_Plate441_036\n",
      "Couldn't find the edges data file at /projects/0/einf914/analysis_videos/CocoTransport/20230810_Plate441/047/Img/edges_data.csv. Check analysis for 20230810_Plate441_047\n",
      "Couldn't find the edges data file at /projects/0/einf914/analysis_videos/CocoTransport/20230810_Plate441/053/Img/edges_data.csv. Check analysis for 20230810_Plate441_053\n",
      "Couldn't find the edges data file at /projects/0/einf914/analysis_videos/CocoTransport/20230810_Plate441/097/Img/edges_data.csv. Check analysis for 20230810_Plate441_097\n",
      "Couldn't find the edges data file at /projects/0/einf914/analysis_videos/CocoTransport/20230810_Plate441/102/Img/edges_data.csv. Check analysis for 20230810_Plate441_102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/home2/cbisot/pycode/AMFtrack/amftrack/pipeline/functions/image_processing/experiment_class_surf.py:103: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.folders[\"datetime\"] = pd.to_datetime(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-10 10:05:00\n",
      "2023-08-10 18:06:00\n"
     ]
    }
   ],
   "source": [
    "for plate_id_video in list(indexes.keys()):\n",
    "    data_obj = load_video_dataset(\n",
    "        plate_id_video, videos_folder, analysis_folder, analysis_folder_root\n",
    "    )\n",
    "\n",
    "    exp = Experiment(directory_targ)\n",
    "    i = np.where(folders['folder'] == indexes[plate_id_video])[0][0]\n",
    "\n",
    "    selection = folders.iloc[i:i+2]\n",
    "    exp.load(selection, suffix=\"_labeled\")\n",
    "    for t in range(exp.ts):\n",
    "        exp.load_tile_information(t)\n",
    "\n",
    "    data_obj.video_objs = sorted(\n",
    "        data_obj.video_objs, key=lambda video: video.dataset[\"video_int\"]\n",
    "    )\n",
    "    make_images(data_obj, videos_folder)\n",
    "    make_profile(data_obj, exp, t)\n",
    "    break\n",
    "# from amftrack.util.dbx import upload_folder\n",
    "\n",
    "# path = f\"/scratch-shared/amftrack/ML_dataset/\"\n",
    "# target_drop = \"/DATA/CocoTransport/NewMLDataset\"\n",
    "# upload_folder(path, target_drop, delete=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45c13b29-5a4f-4455-ae66-47a45919e2ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                                                             0\n",
       "edge_name                                                       (93, 12)\n",
       "edge_length                                                       583.05\n",
       "straight_length                                                635.61042\n",
       "speed_max                                                      16.774734\n",
       "speed_min                                                      -4.885203\n",
       "speed_mean                                                     -1.122974\n",
       "flux_avg                                                      -14.324099\n",
       "flux_min                                                      -72.140963\n",
       "flux_max                                                       70.663096\n",
       "flux_left                                                      36.605064\n",
       "flux_right                                                    -25.896939\n",
       "speed_left                                                     -2.895412\n",
       "speed_right                                                     7.063084\n",
       "speed_left_std                                                  0.197392\n",
       "speed_right_std                                                 1.504825\n",
       "coverage_left                                                   0.529625\n",
       "coverage_right                                                  0.137219\n",
       "coverage_tot                                                    0.584438\n",
       "edge_xpos_1                                                        765.0\n",
       "edge_ypos_1                                                        882.0\n",
       "edge_xpos_2                                                         26.0\n",
       "edge_ypos_2                                                       1234.0\n",
       "imaging_day                                                     20230810\n",
       "storage_path                                  Dropbox\\DATA\\CocoTransport\n",
       "plate_id                                               20230810_Plate441\n",
       "root                                                              Carrot\n",
       "strain                                                                C2\n",
       "treatment                                                   001P100N100C\n",
       "crossing_day                                                    20230807\n",
       "video_int                                                              1\n",
       "time_(s)                                                            30.0\n",
       "mode                                                                  BF\n",
       "exposure_time_(us)                                                 400.0\n",
       "fps                                                                  5.0\n",
       "binning                                                                2\n",
       "gain                                                                 0.0\n",
       "gamma                                                                1.0\n",
       "Fiber Led                                                             On\n",
       "xpos                                                              -4.652\n",
       "ypos                                                               3.576\n",
       "zpos                                                              13.258\n",
       "unique_id                                          20230810_Plate441_001\n",
       "folder                           CocoTransport/20230810_Plate441/001/Img\n",
       "tot_path_drop               DATA/CocoTransport/20230810_Plate441/001/Img\n",
       "record_time                                                     13:14:28\n",
       "days_after_crossing                                                    3\n",
       "magnification                                                        4.0\n",
       "analysis_folder                     /projects/0/einf914/analysis_videos/\n",
       "videos_folder          /projects/0/einf914/videos/CocoTransport/20230...\n",
       "xpos_network                                                25324.037591\n",
       "ypos_network                                                 27399.55359\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_obj.video_objs[0].edge_objs[0].mean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7334ae46-8df7-4ef7-b5e6-797ac49747fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "folders = folders.sort_values(by=\"datetime\")\n",
    "\n",
    "exp = Experiment(directory_targ)\n",
    "i = indexes[plate_id_video]\n",
    "exp.load(folders.iloc[i : i + 1], suffix=\"_labeled\")\n",
    "for t in range(exp.ts):\n",
    "    exp.load_tile_information(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975dd667-5995-4eda-8a57-b4ec35d4c554",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mpl.rcParams[\"figure.dpi\"] = 50\n",
    "\n",
    "from random import choice\n",
    "\n",
    "vid_obj = data_obj.video_objs[21]\n",
    "vid_obj.plot_speed_arrows(plot_both=True, video_txt_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cba9a20-ef48-494e-8693-f18e1220074e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "font_size = 24  # Change this to your desired font size\n",
    "font = ImageFont.truetype(\n",
    "    \"/usr/share/fonts/dejavu/DejaVuSansMono.ttf\", font_size\n",
    ")  # 'arial.ttf' might need to be adjusted based on your system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44ed820-9d22-4328-b73d-d0e67b9f63a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ec2159-8651-4872-87d8-b2cf2d818e46",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "weight = 0.1\n",
    "for vid_obj in data_obj.video_objs:\n",
    "    if vid_obj.dataset[\"mode\"] == \"BF\":\n",
    "\n",
    "        first_frame = vid_obj.get_first_frame()\n",
    "\n",
    "        first_frame_img = Image.fromarray(first_frame)\n",
    "        draw = ImageDraw.Draw(first_frame_img)\n",
    "\n",
    "        # Optionally, specify a font for the text\n",
    "        # font = ImageFont.truetype(\"path_to_font.ttf\", font_size)\n",
    "\n",
    "        for edge in vid_obj.edge_objs:\n",
    "            begin = edge.edge_name.split(\",\")[0][1:]\n",
    "            end = edge.edge_name.split(\",\")[1][1:-1]\n",
    "            ypos_1 = edge.edge_infos[\"edge_ypos_1\"]\n",
    "            xpos_1 = edge.edge_infos[\"edge_xpos_1\"]\n",
    "            ypos_2 = edge.edge_infos[\"edge_ypos_2\"]\n",
    "            xpos_2 = edge.edge_infos[\"edge_xpos_2\"]\n",
    "\n",
    "            # Calculate positions for the start and end texts\n",
    "            start_pos = (0.9 * ypos_1 + 0.1 * ypos_2, 0.9 * xpos_1 + 0.1 * xpos_2)\n",
    "            end_pos = (0.9 * ypos_2 + 0.1 * ypos_1, 0.9 * xpos_2 + 0.1 * xpos_1)\n",
    "\n",
    "            # Draw the start and end texts on the image\n",
    "            draw.text(\n",
    "                start_pos, str(begin), fill=\"white\", font=font\n",
    "            )  # , font=font) if using a custom font\n",
    "            draw.text(\n",
    "                end_pos, str(end), fill=\"white\", font=font\n",
    "            )  # , font=font) if using a custom font\n",
    "\n",
    "        # Save the modified image or display it\n",
    "        unique_id = vid_obj.dataset[\"unique_id\"]\n",
    "        path = f\"/scratch-shared/amftrack/ML_dataset/{unique_id}.png\"\n",
    "        first_frame_img.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05a81b2-71ee-4a19-98f8-6f398e7e0dfe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "load_graphs(exp, directory_targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f4055f-c15b-4818-9e83-3207d5d06c91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from amftrack.pipeline.functions.image_processing.extract_width_fun import (\n",
    "    extract_section_profiles_for_edge_exp,\n",
    ")\n",
    "\n",
    "for index, vid_obj in enumerate(data_obj.video_objs):\n",
    "    if check_hasedges(vid_obj) and vid_obj.dataset[\"mode\"] == \"BF\":\n",
    "        for edge in vid_obj.edge_objs:\n",
    "            edge_begin = int(edge.mean_data[\"network_begin\"])\n",
    "            edge_end = int(edge.mean_data[\"network_end\"])\n",
    "            network_edge = Edge(Node(edge_begin, exp), Node(edge_end, exp), exp)\n",
    "            (\n",
    "                profiles,\n",
    "                transects,\n",
    "                new_section_coord_list,\n",
    "            ) = extract_section_profiles_for_edge_exp(\n",
    "                exp,\n",
    "                t,\n",
    "                network_edge,\n",
    "                resolution=5,\n",
    "                offset=10,\n",
    "                step=3,\n",
    "                target_length=120,\n",
    "            )\n",
    "            unique_id = vid_obj.dataset[\"unique_id\"]\n",
    "\n",
    "            os.makedirs(\n",
    "                f\"/scratch-shared/amftrack/ML_dataset/{unique_id}/\", exist_ok=True\n",
    "            )\n",
    "            for index in [5, 10, 15]:\n",
    "                if index < len(profiles):\n",
    "                    path = f\"/scratch-shared/amftrack/ML_dataset/{unique_id}/{edge.edge_name}_{index}.npy\"\n",
    "                    np.save(path, profiles[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cd2af0-fb22-4f52-8140-13494d023007",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from amftrack.util.dbx import upload_folder\n",
    "\n",
    "path = f\"/scratch-shared/amftrack/ML_dataset/\"\n",
    "target_drop = \"/DATA/CocoTransport/NewMLDataset\"\n",
    "upload_folder(path, target_drop, delete=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c962022-c44a-4908-a1a1-9b5f400c1d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ezzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a65a44b-b551-49e4-a9d5-85fb8efc0f7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "edge = vid_obj.edge_objs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3471b80-569c-4a20-a8da-5652c8c88f15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "edge_begin = int(edge.mean_data[\"network_begin\"])\n",
    "edge_end = int(edge.mean_data[\"network_end\"])\n",
    "edge_begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac604ad-798f-4977-b096-cb89cbb72789",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "network_edge = Edge(Node(edge_begin, exp), Node(edge_end, exp), exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54470fe2-0f2d-413d-a253-cb0756a3fa89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from amftrack.pipeline.functions.transport_processing.high_mag_videos.plotting import *\n",
    "\n",
    "plot_full_video(\n",
    "    exp,\n",
    "    t,\n",
    "    downsizing=downsizing,\n",
    "    points=positions_list,\n",
    "    video_num=[0],\n",
    "    edges=[network_edge],\n",
    "    dilation=10,\n",
    "    region=region,\n",
    "    segments=segments,\n",
    "    nodes=[network_edge.begin, network_edge.end],\n",
    "    node_size=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956c111d-ae9f-4071-a9fe-83dc38488e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from amftrack.pipeline.functions.image_processing.extract_width_fun import (\n",
    "    extract_section_profiles_for_edge_exp,\n",
    ")\n",
    "\n",
    "profiles, transects, new_section_coord_list = extract_section_profiles_for_edge_exp(\n",
    "    exp,\n",
    "    t,\n",
    "    network_edge,\n",
    "    resolution=5,\n",
    "    offset=10,\n",
    "    step=3,\n",
    "    target_length=120,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49704ef-a2a0-412c-b33a-4e4cbcbe1c43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "index = 5\n",
    "os.mkdir(f\"/scratch-shared/amftrack/ML_dataset/{unique_id}/\")\n",
    "path = f\"/scratch-shared/amftrack/ML_dataset/{unique_id}/{edge.edge_name}_{index}.npy\"\n",
    "np.save(path, profiles[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661c4941-1070-4543-9a19-0e0b114db944",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "edge.edge_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdb07ae-b6fb-46ac-adb0-f8328f5e2a87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(profiles[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01013d9-a214-4674-b2d7-52620113bb75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from amftrack.pipeline.functions.transport_processing.high_mag_videos.plotting import *\n",
    "\n",
    "plot_full_video(\n",
    "    exp,\n",
    "    t,\n",
    "    downsizing=downsizing,\n",
    "    points=positions_list,\n",
    "    video_num=[0],\n",
    "    edges=[network_edge],\n",
    "    dilation=10,\n",
    "    region=region,\n",
    "    # segments = transects[-5:],\n",
    "    nodes=[network_edge.begin, network_edge.end],\n",
    "    node_size=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cf2118-5620-47a2-96d5-b56d18a16285",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "px, py = zip(*transects)  # Unpacking points into x and y coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b6e0a6-4a08-4230-aec3-3794279cedf9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "network_edge.begin.pos(t), network_edge.end.pos(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac2f093-16cf-4b46-9062-7ac439b9d47c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "for segment in [transects[0], transects[-1]]:\n",
    "    x_values = [\n",
    "        segment[0][0],\n",
    "        segment[1][0],\n",
    "    ]  # Extracting x-coordinates of the segment's endpoints\n",
    "    y_values = [\n",
    "        segment[0][1],\n",
    "        segment[1][1],\n",
    "    ]  # Extracting y-coordinates of the segment's endpoints\n",
    "    ax.plot(x_values, y_values, marker=\"o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f519b6e-dce9-4c70-8467-bf2bb0d91f99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "positions = np.array(vid_obj.dataset[[\"xpos_network\", \"ypos_network\"]])\n",
    "positions_list = [positions.tolist()]\n",
    "window = np.array([400, 400])\n",
    "begin = (positions - window).astype(int)\n",
    "end = (positions + window).astype(int)\n",
    "region = [[begin[0], begin[1]], [end[0], end[1]]]\n",
    "# region = [[100, 100], [2000,2000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4124b186-28d9-48de-bd3c-1491d18acccd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shiftx = vid_obj.img_dim[0] * vid_obj.space_res / 1.725 / 2\n",
    "shifty = vid_obj.img_dim[1] * vid_obj.space_res / 1.725 / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762e589a-9dff-41ea-9701-24b8b17377cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "segments = []\n",
    "for i in range(len(vid_obj.edge_objs)):\n",
    "    edge = vid_obj.edge_objs[i]\n",
    "    edge_dat_adr = (\n",
    "        Path(f\"{analysis_folder_root}{edge.mean_data['folder']}\") / f\"edges_data.csv\"\n",
    "    )\n",
    "    edges = pd.read_csv(edge_dat_adr)\n",
    "    edge.edge_infos = edges[edges[\"edge_name\"] == edge.edge_name].iloc[0]\n",
    "    edge.edge_infos[\"edge_xpos_1\"]\n",
    "    x_pos_video = edge.mean_data[\"xpos_network\"]\n",
    "    y_pos_video = edge.mean_data[\"ypos_network\"]\n",
    "\n",
    "    x_pos1 = (\n",
    "        edge.edge_infos[\"edge_xpos_1\"] * edge.space_res / 1.725 + x_pos_video - shiftx\n",
    "    )\n",
    "    x_pos2 = (\n",
    "        edge.edge_infos[\"edge_xpos_2\"] * edge.space_res / 1.725 + x_pos_video - shiftx\n",
    "    )\n",
    "    y_pos1 = (\n",
    "        edge.edge_infos[\"edge_ypos_1\"] * edge.space_res / 1.725 + y_pos_video - shifty\n",
    "    )\n",
    "    y_pos2 = (\n",
    "        edge.edge_infos[\"edge_ypos_2\"] * edge.space_res / 1.725 + y_pos_video - shifty\n",
    "    )\n",
    "    dist = np.linalg.norm(np.array([x_pos1, y_pos1]) - np.array([x_pos2, y_pos2]))\n",
    "    if dist > 40:\n",
    "        segments.append([[x_pos1, y_pos1], [x_pos2, y_pos2]])\n",
    "        # print(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ceaf751-7a5f-4eac-86b3-4dcf72f56dd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "edges = get_all_edges(exp, t)\n",
    "\n",
    "edges = [edge for edge in edges if dist_edge(edge, positions, t) <= 100]\n",
    "pixels = [pixel for edge in edges for pixel in edge.pixel_list(t)]\n",
    "pixels = [pixel for pixel in pixels if np.linalg.norm(pixel - positions) <= 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd13782-0d6c-4032-8963-2cbc331e97e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "segment_points = []\n",
    "for begin, end in segments:\n",
    "    # Include the start point, interpolated points, and the end point\n",
    "    interpolated_points = interpolate_points(begin, end)\n",
    "    segment_points.extend(interpolated_points)\n",
    "    segment_points.append(end)  # Ensure the end point is included\n",
    "\n",
    "segment_points = np.array(segment_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacaa927-5bfb-4acd-ad0d-9d529ceef2ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "positions_list = [positions.tolist()]\n",
    "plt.close(\"all\")\n",
    "t = 0\n",
    "vmax = 9\n",
    "vmin = 3\n",
    "nodes = get_all_nodes(exp, t)\n",
    "edges = get_all_edges(exp, t)\n",
    "edges = [edge for edge in edges if dist_edge(edge, positions, t) <= 150]\n",
    "downsizing = 1\n",
    "\n",
    "plot_full_video(\n",
    "    exp,\n",
    "    t,\n",
    "    downsizing=downsizing,\n",
    "    points=positions_list,\n",
    "    video_num=[0],\n",
    "    edges=edges,\n",
    "    dilation=5,\n",
    "    region=region,\n",
    "    segments=segments,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174b2b25-63e8-42b3-af5a-dcf4d8c7c7b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plotting point cloud\n",
    "px, py = zip(*pixels)  # Unpacking points into x and y coordinates\n",
    "ax.scatter(px, py, color=\"blue\")  # Plot points in blue\n",
    "px, py = zip(*segment_points)  # Unpacking points into x and y coordinates\n",
    "ax.scatter(px, py, color=\"red\")  # Plot points in blue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff95ba3-2bcf-46f3-baab-7b0e0be23e22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Rfound, tfound = register_rot_trans(vid_obj, exp, t, dist=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c16bcf0-aeb5-4083-80b5-b9769965804e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transformed_points = np.transpose(\n",
    "    Rfound @ np.transpose(segment_points)[[0, 1], :] + tfound[:, np.newaxis]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2497c2d5-c14a-4e0c-a771-09b714f0cf83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plotting point cloud\n",
    "px, py = zip(*pixels)  # Unpacking points into x and y coordinates\n",
    "ax.scatter(px, py, color=\"blue\")  # Plot points in\n",
    "px, py = zip(*transformed_points)  # Unpacking points into x and y coordinates\n",
    "ax.scatter(px, py, color=\"red\")  # Plot points in blue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9cfa50-f92c-479f-9113-1baf8abcb844",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "edges = get_all_edges(exp, t)\n",
    "\n",
    "edges = [\n",
    "    edge\n",
    "    for edge in edges\n",
    "    if dist_edge(edge, transform(positions, Rfound, tfound), t) <= 100\n",
    "]\n",
    "network_edge_segments = [edge.pixel_list(t) for edge in edges]\n",
    "network_edge_segments = [\n",
    "    [pixel for pixel in pixels if np.linalg.norm(pixel - positions) <= 1.5 * dist]\n",
    "    for pixels in network_edge_segments\n",
    "]\n",
    "network_edge_segments = [[pixels[0], pixels[-1]] for pixels in network_edge_segments]\n",
    "# edge_names = [edge.begin. for edge in edges]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a72e35b-fbe3-4df4-bc4c-4ba318755f0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def initialize_transformation():\n",
    "    return np.array([[1, 0], [0, 1]]), np.array([0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e4a6ce-2dc9-4d40-ad4d-a55748f9ded3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Rcurrent, tcurrent = initialize_transformation()\n",
    "mapping, dist, Rfound, tfound = make_whole_mapping(\n",
    "    vid_obj, exp, t, dist=100, R=Rcurrent, trans=tcurrent\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46675f1f-e230-4402-864f-a17c1c0bb47d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1a8830-bc2f-4dd1-9741-5c764faffd07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mpl.rcParams[\"figure.dpi\"] = 100\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for segment in network_edge_segments:\n",
    "    x_values = [\n",
    "        segment[0][0],\n",
    "        segment[1][0],\n",
    "    ]  # Extracting x-coordinates of the segment's endpoints\n",
    "    y_values = [\n",
    "        segment[0][1],\n",
    "        segment[1][1],\n",
    "    ]  # Extracting y-coordinates of the segment's endpoints\n",
    "    ax.plot(\n",
    "        x_values, y_values, marker=\"o\"\n",
    "    )  # Plotting the segment with points at the endpoints\n",
    "\n",
    "px, py = zip(*transformed_points)  # Unpacking points into x and y coordinates\n",
    "ax.scatter(px, py, color=\"red\")  # Plot points in blue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81d7801-a217-4e0b-a269-c1af798f2a14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "edge_names = [edge.edge_name for edge in vid_obj.edge_objs]\n",
    "segments_final = get_segments_ends(vid_obj, shiftx, shifty, 0, Rfound, tfound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37df6fd7-5ead-438b-bf22-1c6d40047b86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mpl.rcParams[\"figure.dpi\"] = 100\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for segment in network_edge_segments:\n",
    "    x_values = [\n",
    "        segment[0][0],\n",
    "        segment[1][0],\n",
    "    ]  # Extracting x-coordinates of the segment's endpoints\n",
    "    y_values = [\n",
    "        segment[0][1],\n",
    "        segment[1][1],\n",
    "    ]  # Extracting y-coordinates of the segment's endpoints\n",
    "    ax.plot(\n",
    "        x_values, y_values, marker=\"o\", color=\"blue\"\n",
    "    )  # Plotting the segment with points at the endpoints\n",
    "for segment in segments_final:\n",
    "    x_values = [\n",
    "        segment[0][0],\n",
    "        segment[1][0],\n",
    "    ]  # Extracting x-coordinates of the segment's endpoints\n",
    "    y_values = [\n",
    "        segment[0][1],\n",
    "        segment[1][1],\n",
    "    ]  # Extracting y-coordinates of the segment's endpoints\n",
    "    ax.plot(\n",
    "        x_values, y_values, marker=\"o\", color=\"red\"\n",
    "    )  # Plotting the segment with points at the endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be007e5-800b-445e-9c58-a34a21181ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70245099-2e80-4b5f-ba3c-beb0cfdf245c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for transport_edge_name, transport_edge_segment in zip(edge_names, segments_final):\n",
    "    index = edges.index(mapping[transport_edge_name])\n",
    "    segment_network = np.array(network_edge_segments[index])\n",
    "    vector_network = segment_network[0] - segment_network[1]\n",
    "    segment_video = np.array(transport_edge_segment)\n",
    "    vector_video = segment_video[0] - segment_video[1]\n",
    "    print(np.dot(vector_network, vector_video))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59dad26e-4338-4a73-b40d-ef48c9a06659",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "index = edges.index(mapping[transport_edge_name])\n",
    "segment_network = np.array(network_edge_segments[index])\n",
    "vector_network = segment_network[0] - segment_network[1]\n",
    "segment_video = np.array(transport_edge_segment)\n",
    "vector_video = segment_video[0] - segment_video[1]\n",
    "np.dot(vector_network, vector_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557ede8e-c016-476c-98c2-a2057f900b73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vector_video"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
