{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70c80be-987f-4332-8255-b30b9bae5afb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "import re\n",
    "import dropbox\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import imageio.v2 as imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import logging\n",
    "import datetime\n",
    "import glob\n",
    "import json\n",
    "import scipy\n",
    "import matplotlib as mpl\n",
    "\n",
    "from subprocess import call\n",
    "from tifffile import imwrite\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from amftrack.util.dbx import (\n",
    "    upload_folder,\n",
    "    download,\n",
    "    read_saved_dropbox_state,\n",
    "    save_dropbox_state,\n",
    "    load_dbx,\n",
    "    get_dropbox_folders_prince,\n",
    "    get_dropbox_video_folders,\n",
    "    download_video_folders_drop,\n",
    "    download_analysis_folders_drop,\n",
    ")\n",
    "from amftrack.pipeline.launching.run import (\n",
    "    run_transfer,\n",
    ")\n",
    "from amftrack.pipeline.launching.run_super import run_parallel_transfer\n",
    "from amftrack.pipeline.launching.run_super import run_parallel_flows\n",
    "from amftrack.pipeline.functions.transport_processing.high_mag_videos.plot_data import (\n",
    "    plot_summary,\n",
    "    save_raw_data,\n",
    ")\n",
    "from amftrack.pipeline.functions.transport_processing.high_mag_videos.high_mag_analysis import (\n",
    "    HighmagDataset,\n",
    "    VideoDataset,\n",
    "    EdgeDataset,\n",
    "    index_videos_dropbox_new,\n",
    "    analysis_run,\n",
    ")\n",
    "from amftrack.pipeline.functions.transport_processing.high_mag_videos.kymo_class import (\n",
    "    KymoVideoAnalysis,\n",
    "    KymoEdgeAnalysis,\n",
    ")\n",
    "from amftrack.util.dbx import upload\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib widget\n",
    "\n",
    "from amftrack.pipeline.launching.run_super import (\n",
    "    run_launcher,\n",
    "    directory_scratch,\n",
    "    directory_project,\n",
    "    directory_project,\n",
    "    run_parallel_stitch,\n",
    "    run_parallel_transfer,\n",
    ")\n",
    "import os\n",
    "from amftrack.pipeline.functions.image_processing.experiment_class_surf import (\n",
    "    Experiment,\n",
    "    save_graphs,\n",
    "    load_graphs,\n",
    "    Edge,\n",
    "    Node,\n",
    ")\n",
    "from amftrack.pipeline.functions.image_processing.experiment_util import (\n",
    "    get_random_edge,\n",
    "    distance_point_edge,\n",
    "    plot_edge,\n",
    "    plot_edge_cropped,\n",
    "    find_nearest_edge,\n",
    "    get_edge_from_node_labels,\n",
    "    plot_full_image_with_features,\n",
    "    get_all_edges,\n",
    "    get_all_nodes,\n",
    "    find_neighboring_edges,\n",
    "    reconstruct_image,\n",
    "    reconstruct_skeletton_from_edges,\n",
    "    reconstruct_skeletton_unicolor,\n",
    "    reconstruct_image_from_general,\n",
    "    plot_full,\n",
    "    plot_edge_color_value,\n",
    ")\n",
    "from amftrack.transport.align_video_network import identify_nodes\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.debug)\n",
    "from amftrack.util.sys import (\n",
    "    get_dates_datetime,\n",
    "    get_dirname,\n",
    "    temp_path,\n",
    "    get_data_info,\n",
    "    update_plate_info,\n",
    "    update_analysis_info,\n",
    "    get_analysis_info,\n",
    "    get_current_folders,\n",
    "    get_folders_by_plate_id,\n",
    ")\n",
    "\n",
    "mpl.rcParams[\"figure.dpi\"] = 100\n",
    "from amftrack.pipeline.functions.transport_processing.high_mag_videos.register_videos import *\n",
    "from amftrack.pipeline.functions.transport_processing.high_mag_videos.loading import (\n",
    "    load_video_dataset,\n",
    ")\n",
    "from amftrack.pipeline.functions.transport_processing.high_mag_videos.make_ML_dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12b3cb0-d1db-41a6-a3e0-cb90aff8b2fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.rmtree(\"/scratch-shared/amftrack/ML_dataset/\", ignore_errors=True)\n",
    "os.mkdir(\"/scratch-shared/amftrack/ML_dataset/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec88104-cf1c-4cbe-afa1-093e6686e3da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plate_id = \"310_20230830\"\n",
    "plate_id_video = \"20230903_Plate310\"\n",
    "plate_id = \"441_20230807\"\n",
    "\n",
    "videos_folder = \"/projects/0/einf914/videos/\"\n",
    "\n",
    "analysis_folder = \"/projects/0/einf914/analysis_videos/CocoTransport/\"\n",
    "analysis_folder_root = \"/projects/0/einf914/analysis_videos/\"\n",
    "directory_targ = \"/projects/0/einf914/transport/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a22211-6911-468a-bdfb-868110775800",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "indexes = {\n",
    "    \"20230901_Plate310\": 20,\n",
    "    \"20230902_Plate310\": 33,\n",
    "    \"20230903_Plate310\": 42,\n",
    "    \"20230904_Plate310\": 52,\n",
    "    \"20230905_Plate310\": 64,\n",
    "    \"20230906_Plate310\": 73,\n",
    "}\n",
    "indexes = {\n",
    "    \"20230810_Plate441\": 29,\n",
    "    \"20230811_Plate441\": 41,\n",
    "    \"20230812_Plate441\": 47,\n",
    "    \"20230813_Plate441\": 60,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515db227-60eb-4f6a-8b79-e6b6d7a2658c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "update_plate_info(directory_targ, local=True)\n",
    "all_folders = get_current_folders(directory_targ, local=True)\n",
    "folders = all_folders.loc[all_folders[\"unique_id\"] == plate_id]\n",
    "folders = folders.loc[folders[\"/Analysis/nx_graph_pruned_labeled.p\"] == True]\n",
    "folders = folders.sort_values(by=\"datetime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3490ba-718e-416b-9620-078460dafe5d",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for plate_id_video in list(indexes.keys()):\n",
    "    data_obj = load_video_dataset(\n",
    "        plate_id_video, videos_folder, analysis_folder, analysis_folder_root\n",
    "    )\n",
    "\n",
    "    exp = Experiment(directory_targ)\n",
    "    i = indexes[plate_id_video]\n",
    "    exp.load(folders.iloc[i : i + 1], suffix=\"_labeled\")\n",
    "    for t in range(exp.ts):\n",
    "        exp.load_tile_information(t)\n",
    "\n",
    "    data_obj.video_objs = sorted(\n",
    "        data_obj.video_objs, key=lambda video: video.dataset[\"video_int\"]\n",
    "    )\n",
    "    make_images(data_obj, videos_folder)\n",
    "    make_profile(data_obj, exp, t)\n",
    "    # break\n",
    "from amftrack.util.dbx import upload_folder\n",
    "\n",
    "path = f\"/scratch-shared/amftrack/ML_dataset/\"\n",
    "target_drop = \"/DATA/CocoTransport/NewMLDataset\"\n",
    "upload_folder(path, target_drop, delete=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7334ae46-8df7-4ef7-b5e6-797ac49747fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "folders = folders.sort_values(by=\"datetime\")\n",
    "\n",
    "exp = Experiment(directory_targ)\n",
    "i = indexes[plate_id_video]\n",
    "exp.load(folders.iloc[i : i + 1], suffix=\"_labeled\")\n",
    "for t in range(exp.ts):\n",
    "    exp.load_tile_information(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975dd667-5995-4eda-8a57-b4ec35d4c554",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mpl.rcParams[\"figure.dpi\"] = 50\n",
    "\n",
    "from random import choice\n",
    "\n",
    "vid_obj = data_obj.video_objs[21]\n",
    "vid_obj.plot_speed_arrows(plot_both=True, video_txt_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cba9a20-ef48-494e-8693-f18e1220074e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "font_size = 24  # Change this to your desired font size\n",
    "font = ImageFont.truetype(\n",
    "    \"/usr/share/fonts/dejavu/DejaVuSansMono.ttf\", font_size\n",
    ")  # 'arial.ttf' might need to be adjusted based on your system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44ed820-9d22-4328-b73d-d0e67b9f63a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ec2159-8651-4872-87d8-b2cf2d818e46",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "weight = 0.1\n",
    "for vid_obj in data_obj.video_objs:\n",
    "    if vid_obj.dataset[\"mode\"] == \"BF\":\n",
    "\n",
    "        first_frame = vid_obj.get_first_frame()\n",
    "\n",
    "        first_frame_img = Image.fromarray(first_frame)\n",
    "        draw = ImageDraw.Draw(first_frame_img)\n",
    "\n",
    "        # Optionally, specify a font for the text\n",
    "        # font = ImageFont.truetype(\"path_to_font.ttf\", font_size)\n",
    "\n",
    "        for edge in vid_obj.edge_objs:\n",
    "            begin = edge.edge_name.split(\",\")[0][1:]\n",
    "            end = edge.edge_name.split(\",\")[1][1:-1]\n",
    "            ypos_1 = edge.edge_infos[\"edge_ypos_1\"]\n",
    "            xpos_1 = edge.edge_infos[\"edge_xpos_1\"]\n",
    "            ypos_2 = edge.edge_infos[\"edge_ypos_2\"]\n",
    "            xpos_2 = edge.edge_infos[\"edge_xpos_2\"]\n",
    "\n",
    "            # Calculate positions for the start and end texts\n",
    "            start_pos = (0.9 * ypos_1 + 0.1 * ypos_2, 0.9 * xpos_1 + 0.1 * xpos_2)\n",
    "            end_pos = (0.9 * ypos_2 + 0.1 * ypos_1, 0.9 * xpos_2 + 0.1 * xpos_1)\n",
    "\n",
    "            # Draw the start and end texts on the image\n",
    "            draw.text(\n",
    "                start_pos, str(begin), fill=\"white\", font=font\n",
    "            )  # , font=font) if using a custom font\n",
    "            draw.text(\n",
    "                end_pos, str(end), fill=\"white\", font=font\n",
    "            )  # , font=font) if using a custom font\n",
    "\n",
    "        # Save the modified image or display it\n",
    "        unique_id = vid_obj.dataset[\"unique_id\"]\n",
    "        path = f\"/scratch-shared/amftrack/ML_dataset/{unique_id}.png\"\n",
    "        first_frame_img.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05a81b2-71ee-4a19-98f8-6f398e7e0dfe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "load_graphs(exp, directory_targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f4055f-c15b-4818-9e83-3207d5d06c91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from amftrack.pipeline.functions.image_processing.extract_width_fun import (\n",
    "    extract_section_profiles_for_edge_exp,\n",
    ")\n",
    "\n",
    "for index, vid_obj in enumerate(data_obj.video_objs):\n",
    "    if check_hasedges(vid_obj) and vid_obj.dataset[\"mode\"] == \"BF\":\n",
    "        for edge in vid_obj.edge_objs:\n",
    "            edge_begin = int(edge.mean_data[\"network_begin\"])\n",
    "            edge_end = int(edge.mean_data[\"network_end\"])\n",
    "            network_edge = Edge(Node(edge_begin, exp), Node(edge_end, exp), exp)\n",
    "            (\n",
    "                profiles,\n",
    "                transects,\n",
    "                new_section_coord_list,\n",
    "            ) = extract_section_profiles_for_edge_exp(\n",
    "                exp,\n",
    "                t,\n",
    "                network_edge,\n",
    "                resolution=5,\n",
    "                offset=10,\n",
    "                step=3,\n",
    "                target_length=120,\n",
    "            )\n",
    "            unique_id = vid_obj.dataset[\"unique_id\"]\n",
    "\n",
    "            os.makedirs(\n",
    "                f\"/scratch-shared/amftrack/ML_dataset/{unique_id}/\", exist_ok=True\n",
    "            )\n",
    "            for index in [5, 10, 15]:\n",
    "                if index < len(profiles):\n",
    "                    path = f\"/scratch-shared/amftrack/ML_dataset/{unique_id}/{edge.edge_name}_{index}.npy\"\n",
    "                    np.save(path, profiles[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cd2af0-fb22-4f52-8140-13494d023007",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from amftrack.util.dbx import upload_folder\n",
    "\n",
    "path = f\"/scratch-shared/amftrack/ML_dataset/\"\n",
    "target_drop = \"/DATA/CocoTransport/NewMLDataset\"\n",
    "upload_folder(path, target_drop, delete=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c962022-c44a-4908-a1a1-9b5f400c1d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ezzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a65a44b-b551-49e4-a9d5-85fb8efc0f7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "edge = vid_obj.edge_objs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3471b80-569c-4a20-a8da-5652c8c88f15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "edge_begin = int(edge.mean_data[\"network_begin\"])\n",
    "edge_end = int(edge.mean_data[\"network_end\"])\n",
    "edge_begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac604ad-798f-4977-b096-cb89cbb72789",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "network_edge = Edge(Node(edge_begin, exp), Node(edge_end, exp), exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54470fe2-0f2d-413d-a253-cb0756a3fa89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from amftrack.pipeline.functions.transport_processing.high_mag_videos.plotting import *\n",
    "\n",
    "plot_full_video(\n",
    "    exp,\n",
    "    t,\n",
    "    downsizing=downsizing,\n",
    "    points=positions_list,\n",
    "    video_num=[0],\n",
    "    edges=[network_edge],\n",
    "    dilation=10,\n",
    "    region=region,\n",
    "    segments=segments,\n",
    "    nodes=[network_edge.begin, network_edge.end],\n",
    "    node_size=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956c111d-ae9f-4071-a9fe-83dc38488e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from amftrack.pipeline.functions.image_processing.extract_width_fun import (\n",
    "    extract_section_profiles_for_edge_exp,\n",
    ")\n",
    "\n",
    "profiles, transects, new_section_coord_list = extract_section_profiles_for_edge_exp(\n",
    "    exp,\n",
    "    t,\n",
    "    network_edge,\n",
    "    resolution=5,\n",
    "    offset=10,\n",
    "    step=3,\n",
    "    target_length=120,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49704ef-a2a0-412c-b33a-4e4cbcbe1c43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "index = 5\n",
    "os.mkdir(f\"/scratch-shared/amftrack/ML_dataset/{unique_id}/\")\n",
    "path = f\"/scratch-shared/amftrack/ML_dataset/{unique_id}/{edge.edge_name}_{index}.npy\"\n",
    "np.save(path, profiles[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661c4941-1070-4543-9a19-0e0b114db944",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "edge.edge_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdb07ae-b6fb-46ac-adb0-f8328f5e2a87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(profiles[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01013d9-a214-4674-b2d7-52620113bb75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from amftrack.pipeline.functions.transport_processing.high_mag_videos.plotting import *\n",
    "\n",
    "plot_full_video(\n",
    "    exp,\n",
    "    t,\n",
    "    downsizing=downsizing,\n",
    "    points=positions_list,\n",
    "    video_num=[0],\n",
    "    edges=[network_edge],\n",
    "    dilation=10,\n",
    "    region=region,\n",
    "    # segments = transects[-5:],\n",
    "    nodes=[network_edge.begin, network_edge.end],\n",
    "    node_size=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cf2118-5620-47a2-96d5-b56d18a16285",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "px, py = zip(*transects)  # Unpacking points into x and y coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b6e0a6-4a08-4230-aec3-3794279cedf9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "network_edge.begin.pos(t), network_edge.end.pos(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac2f093-16cf-4b46-9062-7ac439b9d47c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "for segment in [transects[0], transects[-1]]:\n",
    "    x_values = [\n",
    "        segment[0][0],\n",
    "        segment[1][0],\n",
    "    ]  # Extracting x-coordinates of the segment's endpoints\n",
    "    y_values = [\n",
    "        segment[0][1],\n",
    "        segment[1][1],\n",
    "    ]  # Extracting y-coordinates of the segment's endpoints\n",
    "    ax.plot(x_values, y_values, marker=\"o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f519b6e-dce9-4c70-8467-bf2bb0d91f99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "positions = np.array(vid_obj.dataset[[\"xpos_network\", \"ypos_network\"]])\n",
    "positions_list = [positions.tolist()]\n",
    "window = np.array([400, 400])\n",
    "begin = (positions - window).astype(int)\n",
    "end = (positions + window).astype(int)\n",
    "region = [[begin[0], begin[1]], [end[0], end[1]]]\n",
    "# region = [[100, 100], [2000,2000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4124b186-28d9-48de-bd3c-1491d18acccd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shiftx = vid_obj.img_dim[0] * vid_obj.space_res / 1.725 / 2\n",
    "shifty = vid_obj.img_dim[1] * vid_obj.space_res / 1.725 / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762e589a-9dff-41ea-9701-24b8b17377cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "segments = []\n",
    "for i in range(len(vid_obj.edge_objs)):\n",
    "    edge = vid_obj.edge_objs[i]\n",
    "    edge_dat_adr = (\n",
    "        Path(f\"{analysis_folder_root}{edge.mean_data['folder']}\") / f\"edges_data.csv\"\n",
    "    )\n",
    "    edges = pd.read_csv(edge_dat_adr)\n",
    "    edge.edge_infos = edges[edges[\"edge_name\"] == edge.edge_name].iloc[0]\n",
    "    edge.edge_infos[\"edge_xpos_1\"]\n",
    "    x_pos_video = edge.mean_data[\"xpos_network\"]\n",
    "    y_pos_video = edge.mean_data[\"ypos_network\"]\n",
    "\n",
    "    x_pos1 = (\n",
    "        edge.edge_infos[\"edge_xpos_1\"] * edge.space_res / 1.725 + x_pos_video - shiftx\n",
    "    )\n",
    "    x_pos2 = (\n",
    "        edge.edge_infos[\"edge_xpos_2\"] * edge.space_res / 1.725 + x_pos_video - shiftx\n",
    "    )\n",
    "    y_pos1 = (\n",
    "        edge.edge_infos[\"edge_ypos_1\"] * edge.space_res / 1.725 + y_pos_video - shifty\n",
    "    )\n",
    "    y_pos2 = (\n",
    "        edge.edge_infos[\"edge_ypos_2\"] * edge.space_res / 1.725 + y_pos_video - shifty\n",
    "    )\n",
    "    dist = np.linalg.norm(np.array([x_pos1, y_pos1]) - np.array([x_pos2, y_pos2]))\n",
    "    if dist > 40:\n",
    "        segments.append([[x_pos1, y_pos1], [x_pos2, y_pos2]])\n",
    "        # print(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ceaf751-7a5f-4eac-86b3-4dcf72f56dd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "edges = get_all_edges(exp, t)\n",
    "\n",
    "edges = [edge for edge in edges if dist_edge(edge, positions, t) <= 100]\n",
    "pixels = [pixel for edge in edges for pixel in edge.pixel_list(t)]\n",
    "pixels = [pixel for pixel in pixels if np.linalg.norm(pixel - positions) <= 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd13782-0d6c-4032-8963-2cbc331e97e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "segment_points = []\n",
    "for begin, end in segments:\n",
    "    # Include the start point, interpolated points, and the end point\n",
    "    interpolated_points = interpolate_points(begin, end)\n",
    "    segment_points.extend(interpolated_points)\n",
    "    segment_points.append(end)  # Ensure the end point is included\n",
    "\n",
    "segment_points = np.array(segment_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacaa927-5bfb-4acd-ad0d-9d529ceef2ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "positions_list = [positions.tolist()]\n",
    "plt.close(\"all\")\n",
    "t = 0\n",
    "vmax = 9\n",
    "vmin = 3\n",
    "nodes = get_all_nodes(exp, t)\n",
    "edges = get_all_edges(exp, t)\n",
    "edges = [edge for edge in edges if dist_edge(edge, positions, t) <= 150]\n",
    "downsizing = 1\n",
    "\n",
    "plot_full_video(\n",
    "    exp,\n",
    "    t,\n",
    "    downsizing=downsizing,\n",
    "    points=positions_list,\n",
    "    video_num=[0],\n",
    "    edges=edges,\n",
    "    dilation=5,\n",
    "    region=region,\n",
    "    segments=segments,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174b2b25-63e8-42b3-af5a-dcf4d8c7c7b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plotting point cloud\n",
    "px, py = zip(*pixels)  # Unpacking points into x and y coordinates\n",
    "ax.scatter(px, py, color=\"blue\")  # Plot points in blue\n",
    "px, py = zip(*segment_points)  # Unpacking points into x and y coordinates\n",
    "ax.scatter(px, py, color=\"red\")  # Plot points in blue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff95ba3-2bcf-46f3-baab-7b0e0be23e22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Rfound, tfound = register_rot_trans(vid_obj, exp, t, dist=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c16bcf0-aeb5-4083-80b5-b9769965804e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transformed_points = np.transpose(\n",
    "    Rfound @ np.transpose(segment_points)[[0, 1], :] + tfound[:, np.newaxis]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2497c2d5-c14a-4e0c-a771-09b714f0cf83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plotting point cloud\n",
    "px, py = zip(*pixels)  # Unpacking points into x and y coordinates\n",
    "ax.scatter(px, py, color=\"blue\")  # Plot points in\n",
    "px, py = zip(*transformed_points)  # Unpacking points into x and y coordinates\n",
    "ax.scatter(px, py, color=\"red\")  # Plot points in blue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9cfa50-f92c-479f-9113-1baf8abcb844",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "edges = get_all_edges(exp, t)\n",
    "\n",
    "edges = [\n",
    "    edge\n",
    "    for edge in edges\n",
    "    if dist_edge(edge, transform(positions, Rfound, tfound), t) <= 100\n",
    "]\n",
    "network_edge_segments = [edge.pixel_list(t) for edge in edges]\n",
    "network_edge_segments = [\n",
    "    [pixel for pixel in pixels if np.linalg.norm(pixel - positions) <= 1.5 * dist]\n",
    "    for pixels in network_edge_segments\n",
    "]\n",
    "network_edge_segments = [[pixels[0], pixels[-1]] for pixels in network_edge_segments]\n",
    "# edge_names = [edge.begin. for edge in edges]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a72e35b-fbe3-4df4-bc4c-4ba318755f0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def initialize_transformation():\n",
    "    return np.array([[1, 0], [0, 1]]), np.array([0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e4a6ce-2dc9-4d40-ad4d-a55748f9ded3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Rcurrent, tcurrent = initialize_transformation()\n",
    "mapping, dist, Rfound, tfound = make_whole_mapping(\n",
    "    vid_obj, exp, t, dist=100, R=Rcurrent, trans=tcurrent\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46675f1f-e230-4402-864f-a17c1c0bb47d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1a8830-bc2f-4dd1-9741-5c764faffd07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mpl.rcParams[\"figure.dpi\"] = 100\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for segment in network_edge_segments:\n",
    "    x_values = [\n",
    "        segment[0][0],\n",
    "        segment[1][0],\n",
    "    ]  # Extracting x-coordinates of the segment's endpoints\n",
    "    y_values = [\n",
    "        segment[0][1],\n",
    "        segment[1][1],\n",
    "    ]  # Extracting y-coordinates of the segment's endpoints\n",
    "    ax.plot(\n",
    "        x_values, y_values, marker=\"o\"\n",
    "    )  # Plotting the segment with points at the endpoints\n",
    "\n",
    "px, py = zip(*transformed_points)  # Unpacking points into x and y coordinates\n",
    "ax.scatter(px, py, color=\"red\")  # Plot points in blue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81d7801-a217-4e0b-a269-c1af798f2a14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "edge_names = [edge.edge_name for edge in vid_obj.edge_objs]\n",
    "segments_final = get_segments_ends(vid_obj, shiftx, shifty, 0, Rfound, tfound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37df6fd7-5ead-438b-bf22-1c6d40047b86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mpl.rcParams[\"figure.dpi\"] = 100\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for segment in network_edge_segments:\n",
    "    x_values = [\n",
    "        segment[0][0],\n",
    "        segment[1][0],\n",
    "    ]  # Extracting x-coordinates of the segment's endpoints\n",
    "    y_values = [\n",
    "        segment[0][1],\n",
    "        segment[1][1],\n",
    "    ]  # Extracting y-coordinates of the segment's endpoints\n",
    "    ax.plot(\n",
    "        x_values, y_values, marker=\"o\", color=\"blue\"\n",
    "    )  # Plotting the segment with points at the endpoints\n",
    "for segment in segments_final:\n",
    "    x_values = [\n",
    "        segment[0][0],\n",
    "        segment[1][0],\n",
    "    ]  # Extracting x-coordinates of the segment's endpoints\n",
    "    y_values = [\n",
    "        segment[0][1],\n",
    "        segment[1][1],\n",
    "    ]  # Extracting y-coordinates of the segment's endpoints\n",
    "    ax.plot(\n",
    "        x_values, y_values, marker=\"o\", color=\"red\"\n",
    "    )  # Plotting the segment with points at the endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be007e5-800b-445e-9c58-a34a21181ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70245099-2e80-4b5f-ba3c-beb0cfdf245c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for transport_edge_name, transport_edge_segment in zip(edge_names, segments_final):\n",
    "    index = edges.index(mapping[transport_edge_name])\n",
    "    segment_network = np.array(network_edge_segments[index])\n",
    "    vector_network = segment_network[0] - segment_network[1]\n",
    "    segment_video = np.array(transport_edge_segment)\n",
    "    vector_video = segment_video[0] - segment_video[1]\n",
    "    print(np.dot(vector_network, vector_video))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59dad26e-4338-4a73-b40d-ef48c9a06659",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "index = edges.index(mapping[transport_edge_name])\n",
    "segment_network = np.array(network_edge_segments[index])\n",
    "vector_network = segment_network[0] - segment_network[1]\n",
    "segment_video = np.array(transport_edge_segment)\n",
    "vector_video = segment_video[0] - segment_video[1]\n",
    "np.dot(vector_network, vector_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557ede8e-c016-476c-98c2-a2057f900b73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vector_video"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
