{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70c80be-987f-4332-8255-b30b9bae5afb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "import re\n",
    "import dropbox\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import imageio.v2 as imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import logging\n",
    "import datetime\n",
    "import glob\n",
    "import json\n",
    "import scipy\n",
    "import matplotlib as mpl\n",
    "\n",
    "from subprocess import call\n",
    "from tifffile import imwrite\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from amftrack.util.dbx import (\n",
    "    upload_folder,\n",
    "    download,\n",
    "    read_saved_dropbox_state,\n",
    "    save_dropbox_state,\n",
    "    load_dbx,\n",
    "    get_dropbox_folders_prince,\n",
    "    get_dropbox_video_folders,\n",
    "    download_video_folders_drop,\n",
    "    download_analysis_folders_drop,\n",
    ")\n",
    "from amftrack.pipeline.launching.run import (\n",
    "    run_transfer,\n",
    ")\n",
    "from amftrack.pipeline.launching.run_super import run_parallel_transfer\n",
    "from amftrack.pipeline.launching.run_super import run_parallel_flows\n",
    "from amftrack.pipeline.functions.transport_processing.high_mag_videos.plot_data import (\n",
    "    plot_summary,\n",
    "    save_raw_data,\n",
    ")\n",
    "from amftrack.pipeline.functions.transport_processing.high_mag_videos.high_mag_analysis import (\n",
    "    HighmagDataset,\n",
    "    VideoDataset,\n",
    "    EdgeDataset,\n",
    "    index_videos_dropbox_new,\n",
    "    analysis_run,\n",
    ")\n",
    "from amftrack.pipeline.functions.transport_processing.high_mag_videos.kymo_class import (\n",
    "    KymoVideoAnalysis,\n",
    "    KymoEdgeAnalysis,\n",
    ")\n",
    "from amftrack.util.dbx import upload\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from amftrack.pipeline.launching.run_super import (\n",
    "    run_launcher,\n",
    "    directory_scratch,\n",
    "    directory_project,\n",
    "    directory_project,\n",
    "    run_parallel_stitch,\n",
    "    run_parallel_transfer,\n",
    ")\n",
    "import os\n",
    "from amftrack.pipeline.functions.image_processing.experiment_class_surf import (\n",
    "    Experiment,\n",
    "    save_graphs,\n",
    "    load_graphs,\n",
    "    Edge,\n",
    "    Node,\n",
    ")\n",
    "from amftrack.util.sys import (\n",
    "    get_dates_datetime,\n",
    "    get_dirname,\n",
    "    temp_path,\n",
    "    get_data_info,\n",
    "    update_plate_info,\n",
    "    update_analysis_info,\n",
    "    get_analysis_info,\n",
    "    get_current_folders,\n",
    "    get_folders_by_plate_id,\n",
    ")\n",
    "from amftrack.pipeline.functions.image_processing.experiment_util import (\n",
    "    get_random_edge,\n",
    "    distance_point_edge,\n",
    "    plot_edge,\n",
    "    plot_edge_cropped,\n",
    "    find_nearest_edge,\n",
    "    get_edge_from_node_labels,\n",
    "    plot_full_image_with_features,\n",
    "    get_all_edges,\n",
    "    get_all_nodes,\n",
    "    find_neighboring_edges,\n",
    "    reconstruct_image,\n",
    "    reconstruct_skeletton_from_edges,\n",
    "    reconstruct_skeletton_unicolor,\n",
    "    reconstruct_image_from_general,\n",
    "    plot_full,\n",
    "    plot_edge_color_value,\n",
    ")\n",
    "from amftrack.transport.align_video_network import identify_nodes\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.debug)\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec88104-cf1c-4cbe-afa1-093e6686e3da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plate_id = \"449_20230807\"\n",
    "plate_id_video = \"20230818_Plate449\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7c4140-1f08-49d7-b140-d338a9c3c0a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "analysis_folder = \"/projects/0/einf914/analysis_videos/\"\n",
    "# analysis_folder = f\"{analysis_folder}{plate_id_video}/\"\n",
    "\n",
    "img_infos = glob.glob(f\"{analysis_folder}/**/video_data.json\", recursive=True)\n",
    "vid_anls_frame = pd.DataFrame()\n",
    "add_infos = []\n",
    "for address in img_infos:\n",
    "    add_infos.append(pd.read_json(address, orient=\"index\").T)\n",
    "vid_anls_frame = pd.concat([vid_anls_frame] + add_infos, ignore_index=True)\n",
    "\n",
    "vid_anls_frame = vid_anls_frame.sort_values(\"unique_id\").reset_index(drop=True)\n",
    "vid_anls_frame_select = vid_anls_frame.loc[vid_anls_frame[\"plate_id\"] == plate_id_video]\n",
    "# vid_anls_frame_select = vid_anls_frame_select[vid_anls_frame_select[\"video_int\"]<=102]\n",
    "values_id = list(vid_anls_frame_select[\"unique_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcffcad5-55ab-4559-bf8c-d67c5f656f86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190395ee-6c25-4d1a-8e25-6ab0756d77a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# img_infos = glob.glob(f\"{analysis_folder}/**/video_data.json\", recursive=True)\n",
    "# vid_anls_frame = pd.DataFrame()\n",
    "# for address in img_infos:\n",
    "#     add_info = pd.read_json(address, orient=\"index\").T\n",
    "#     if add_info[\"plate_id\"].iloc[0] == plate_id_video:\n",
    "#         original_path = add_info[\"tot_path_drop\"].iloc[0]\n",
    "\n",
    "#         # Replace the specific substring in the target path\n",
    "#         target_path = original_path.replace(\n",
    "#             f\"/{plate_id_video}\", f\"/KymoSpeeDExtract/{plate_id_video}\"\n",
    "#         )\n",
    "#         target = \"/\" + target_path + \"/video_data_network.json\"\n",
    "#         source = address\n",
    "#         upload(\n",
    "#             source,\n",
    "#             target,\n",
    "#             chunk_size=256 * 1024 * 1024,\n",
    "#         )\n",
    "#         print(target)\n",
    "#     # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b7ad48-d011-4606-bfe8-2455e3fc9f74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vid_anls_frame_select[\"record_time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f535df95-c0e8-4153-9a02-615bf4db8485",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mpl.rcParams[\"figure.dpi\"] = 100\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "vid_anls_frame_select[\"timedelta\"] = pd.to_timedelta(\n",
    "    vid_anls_frame_select[\"record_time\"]\n",
    ")\n",
    "\n",
    "ax.scatter(vid_anls_frame_select[\"video_int\"], vid_anls_frame_select[\"timedelta\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8326966c-d1ac-44ce-b7ab-df708a5c45c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a860d58-60f0-48f5-9782-6ea2a6b41331",
   "metadata": {},
   "outputs": [],
   "source": [
    "plates = [plate_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515db227-60eb-4f6a-8b79-e6b6d7a2658c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# directory_targ = os.path.join(directory_scratch, \"stitch_temp2\") + \"/\"\n",
    "directory_targ = directory_project\n",
    "directory_targ = \"/projects/0/einf914/transport/\"\n",
    "\n",
    "update_plate_info(directory_targ, local=True)\n",
    "all_folders = get_current_folders(directory_targ, local=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54265cf6-9ab6-4d8e-bd26-85929d63ab06",
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = all_folders.loc[all_folders[\"unique_id\"] == plates[0]]\n",
    "folders = folders.loc[folders[\"/Analysis/nx_graph_pruned_labeled.p\"] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c5e87e-f7af-4192-b2fa-86b4284eec0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "folders.iloc[i][\"folder\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7334ae46-8df7-4ef7-b5e6-797ac49747fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = folders.sort_values(by=\"datetime\")\n",
    "\n",
    "exp = Experiment(directory_targ)\n",
    "i = 111\n",
    "exp.load(folders.iloc[i : i + 2], suffix=\"_width\")\n",
    "for t in range(exp.ts):\n",
    "    exp.load_tile_information(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a8ea47-2fb5-4709-9d1f-cbd94f6c1f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = np.array(vid_anls_frame_select[[\"ypos\", \"xpos\"]]) * 1000 / 1.725\n",
    "fig, ax = plt.subplots()\n",
    "for i, pos in enumerate(positions):\n",
    "    ax.text(int(pos[1]), -int(pos[0]), str(i))\n",
    "    ax.scatter(int(pos[1]), -int(pos[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da9428c-076e-4f6a-ae9d-0a10f6958ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cid, dicopoint = identify_nodes(exp, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f312b6b-0071-4618-bb06-f5e93c993b32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "del dicopoint[\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849eb1c6-5160-4526-8dd5-13695754f96d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dicopoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d050fe27-2916-40d4-991f-7adc440e2d3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dicopoint = {\n",
    "    \"34\": Node(5224, exp),\n",
    "    \"1\": Node(3471, exp),\n",
    "    \"8\": Node(1586, exp),\n",
    "    \"9\": Node(808, exp),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596af8df-b902-4a58-90cb-810de1c7b6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(dicopoint.keys())\n",
    "posnodes = [dicopoint[key].pos(0).tolist() for key in keys]\n",
    "posvideoslines = [\n",
    "    vid_anls_frame_select.loc[vid_anls_frame_select[\"video_int\"] == int(key)]\n",
    "    for key in keys\n",
    "]\n",
    "posvideos = [\n",
    "    [\n",
    "        posvideosline[\"ypos\"].astype(float).iloc[0] * 1000 / 1.725,\n",
    "        posvideosline[\"xpos\"].astype(float).iloc[0] * 1000 / 1.725,\n",
    "    ]\n",
    "    for posvideosline in posvideoslines\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e855bf74-8291-474a-9a1a-bef5df6520b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from amftrack.util.image_analysis import find_transformation, find_similarity\n",
    "\n",
    "transform = find_similarity(posvideos, posnodes)\n",
    "transform = find_similarity(posvideos, posnodes, ratio=1.128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1dad28b-0974-4f19-bcde-435c79d792a3",
   "metadata": {},
   "source": [
    "similarity_ratio should be 1.128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8762d16-84f4-4e04-bfb2-a20a8163c24c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "posvideos_new = [transform(pos) for pos in posvideos]\n",
    "posvideos_new, posnodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a026ea3-2f77-44aa-b039-99be977b23f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = np.array(vid_anls_frame_select[[\"ypos\", \"xpos\"]]) * 1000 / 1.725\n",
    "positions_list = positions.tolist()\n",
    "posvideos_new_list = [transform(pos) for pos in positions_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1baa1cd8-01cc-4acf-a7fc-274eb970880f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# analysis_folder = \"/projects/0/einf914/analysis_videos/\"\n",
    "# # analysis_folder = f\"{analysis_folder}{plate_id_video}/\"\n",
    "\n",
    "# img_infos = glob.glob(f\"{analysis_folder}/**/video_data_network.json\", recursive=True)\n",
    "# vid_anls_frame = pd.DataFrame()\n",
    "# add_infos = []\n",
    "# for address in img_infos:\n",
    "#     add_infos.append(pd.read_json(address, orient=\"index\").T)\n",
    "# vid_anls_frame = pd.concat([vid_anls_frame] + add_infos, ignore_index=True)\n",
    "\n",
    "# vid_anls_frame = vid_anls_frame.sort_values(\"unique_id\").reset_index(drop=True)\n",
    "# vid_anls_frame_select = vid_anls_frame.loc[vid_anls_frame[\"plate_id\"] == plate_id_video]\n",
    "# positions = np.array(vid_anls_frame_select[[\"ypos_network\", \"xpos_network\"]]) * 1000 / 1.725\n",
    "# positions_list = positions.tolist()\n",
    "# posvideos_new_list = [pos for pos in positions_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d7b98b-16cb-4f1b-8ea0-a346a9f71906",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t = 0\n",
    "vmax = 9\n",
    "vmin = 3\n",
    "region = None\n",
    "nodes = get_all_nodes(exp, t)\n",
    "edges = get_all_edges(exp, t)\n",
    "\n",
    "downsizing = 5\n",
    "\n",
    "plot_full_video(\n",
    "    exp,\n",
    "    t,\n",
    "    downsizing=downsizing,\n",
    "    points=posvideos_new_list,\n",
    "    video_num=list(vid_anls_frame_select[\"video_int\"]),\n",
    "    edges=edges,\n",
    "    dilation=5,\n",
    "    figsize=(12, 6),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16525cd1-0eba-43da-938c-b3b58614edaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "analysis_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2b7d7e-2b83-48ab-ab72-9e2b464b3c03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_infos = glob.glob(\n",
    "    f\"{analysis_folder}/CocoTransport/{plate_id_video}/**/video_data.json\",\n",
    "    recursive=True,\n",
    ")\n",
    "for address in img_infos:\n",
    "    add_info = pd.read_json(address, orient=\"index\").T\n",
    "    if add_info[\"plate_id\"].iloc[0] == plate_id_video:\n",
    "        if add_info[\"unique_id\"].iloc[0] in values_id:\n",
    "            positions = np.array(add_info[[\"ypos\", \"xpos\"]]) * 1000 / 1.725\n",
    "            positions_list = positions.tolist()\n",
    "            posvideos_new_list = [transform(pos) for pos in positions_list]\n",
    "            add_info[\"xpos_network\"] = posvideos_new_list[0][0]\n",
    "            add_info[\"ypos_network\"] = posvideos_new_list[0][1]\n",
    "            add_info.to_json(address)\n",
    "        # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1448949f-0ab2-4642-afa1-6d237010a23e",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_infos = glob.glob(\n",
    "    f\"{analysis_folder}/CocoTransport/{plate_id_video}/**/video_data.json\",\n",
    "    recursive=True,\n",
    ")\n",
    "vid_anls_frame = pd.DataFrame()\n",
    "for address in img_infos:\n",
    "    add_info = pd.read_json(address, orient=\"index\").T\n",
    "    if add_info[\"plate_id\"].iloc[0] == plate_id_video:\n",
    "        if add_info[\"unique_id\"].iloc[0] in values_id:\n",
    "\n",
    "            original_path = add_info[\"tot_path_drop\"].iloc[0]\n",
    "\n",
    "            # Replace the specific substring in the target path\n",
    "            target_path = original_path.replace(\n",
    "                f\"/{plate_id_video}\", f\"/KymoSpeeDExtract/{plate_id_video}\"\n",
    "            )\n",
    "            target = \"/\" + target_path + \"/video_data_network.json\"\n",
    "            source = address\n",
    "            upload(\n",
    "                source,\n",
    "                target,\n",
    "                chunk_size=256 * 1024 * 1024,\n",
    "            )\n",
    "            print(target)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d784a8-5a8b-4eae-b5da-615035e47900",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t = 0\n",
    "im, skel_im = make_full_image(\n",
    "    exp, t, downsizing=5, dilation=5, edges=get_all_edges(exp, t)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c17d7b9-7090-4366-ae6f-5c6c0f48dc58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# im_rgba = np.stack([im, im, im, np.ones(im.shape, dtype=im.dtype) * 255], axis=-1)\n",
    "# white_mask = np.all(skel_im[:, :, :3] == 255, axis=-1)\n",
    "# skel_im[white_mask, 3] = 0  # setting alpha to 0 where it's white\n",
    "# # Convert numpy arrays to PIL images\n",
    "# im_pil = Image.fromarray(im_rgba.astype(np.uint8))\n",
    "# skel_im_pil = Image.fromarray(skel_im.astype(np.uint8))\n",
    "\n",
    "\n",
    "# Overlay the images\n",
    "# combined = Image.alpha_composite(im_pil, skel_im_pil)\n",
    "combined.save(os.path.join(analysis_folder, \"network_overlay.png\"))\n",
    "im_pil.save(os.path.join(analysis_folder, \"stitched.png\"))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.imshow(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a352f21-9fc2-4d6c-82a7-51e02085e4c7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if im_pil.size[1] < skel_im_pil.size[1]:\n",
    "    # Create a new image with one more pixel in height\n",
    "    new_im = Image.new(\"RGBA\", (im_pil.width, im_pil.height + 1), (255, 255, 255, 0))\n",
    "    # Paste the original image into the new image\n",
    "    new_im.paste(im_pil, (0, 0))\n",
    "else:\n",
    "    # Create a new image with one more pixel in height for skel_im_pil if needed\n",
    "    new_im = Image.new(\n",
    "        \"RGBA\", (skel_im_pil.width, skel_im_pil.height + 1), (255, 255, 255, 0)\n",
    "    )\n",
    "    # Paste the original skel_im_pil into the new image\n",
    "    new_im.paste(skel_im_pil, (0, 0))\n",
    "    # Since we modified skel_im_pil, we'll use it in the composition\n",
    "    skel_im_pil = new_im\n",
    "\n",
    "# Now you can use Image.alpha_composite if im_pil was modified\n",
    "if im_pil.size[1] < skel_im_pil.size[1]:\n",
    "    combined = Image.alpha_composite(new_im, skel_im_pil)\n",
    "else:\n",
    "    combined = Image.alpha_composite(im_pil, skel_im_pil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2eca0a-3377-4b4f-a1e0-e72b374078be",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = os.path.join(analysis_folder, \"network_overlay.png\")\n",
    "original_path = vid_anls_frame_select[\"tot_path_drop\"].iloc[0]\n",
    "new_path = os.path.dirname(os.path.dirname(original_path))\n",
    "new_path = \"/\" + new_path\n",
    "target = new_path + \"/network_overlay.png\"\n",
    "target = target.replace(f\"/{plate_id_video}\", f\"/Analysis/{plate_id_video}\")\n",
    "\n",
    "upload(\n",
    "    source,\n",
    "    target,\n",
    "    chunk_size=256 * 1024 * 1024,\n",
    ")\n",
    "source = os.path.join(analysis_folder, \"stitched.png\")\n",
    "\n",
    "target = new_path + \"/stitched.png\"\n",
    "target = target.replace(f\"/{plate_id_video}\", f\"/Analysis/{plate_id_video}\")\n",
    "\n",
    "upload(\n",
    "    source,\n",
    "    target,\n",
    "    chunk_size=256 * 1024 * 1024,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5938473d-c541-4b37-9c99-3555be4abc30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plate_id_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0448dc-8ff7-4d56-93b6-a7176f3bb03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_full_video(\n",
    "    exp: Experiment,\n",
    "    t: int,\n",
    "    region=None,\n",
    "    edges: List[Edge] = [],\n",
    "    points: List[coord_int] = [],\n",
    "    video_num: List[int] = [],\n",
    "    segments: List[List[coord_int]] = [],\n",
    "    nodes: List[Node] = [],\n",
    "    downsizing=5,\n",
    "    dilation=1,\n",
    "    save_path=\"\",\n",
    "    prettify=False,\n",
    "    with_point_label=False,\n",
    "    figsize=(12, 8),\n",
    "    dpi=None,\n",
    "    node_size=5,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    This is the general purpose function to plot the full image or a region `region` of the image at\n",
    "    any given timestep t. The region being specified in the GENERAL coordinates.\n",
    "    The image can be downsized by a chosen factor `downsized` with additionnal features such as: edges, nodes, points, segments.\n",
    "    The coordinates for all the objects are provided in the GENERAL referential.\n",
    "\n",
    "    :param region: choosen region in the full image, such as [[100, 100], [2000,2000]], if None the full image is shown\n",
    "    :param edges: list of edges to plot, it is the pixel list that is plotted, not a straight line\n",
    "    :param nodes: list of nodes to plot (only nodes in the `region` will be shown)\n",
    "    :param points: points such as [123, 234] to plot with a red cross on the image\n",
    "    :param segments: plot lines between two points that are provided\n",
    "    :param downsizing: factor by which we reduce the image resolution (5 -> image 25 times lighter)\n",
    "    :param dilation: only for edges: thickness of the edges (dilation applied to the pixel list)\n",
    "    :param save_path: full path to the location where the plot will be saved\n",
    "    :param prettify: if True, the image will be enhanced by smoothing the intersections between images\n",
    "    :param with_point_label: if True, the index of the point is ploted on top of it\n",
    "\n",
    "    NB: the full region of a full image is typically [[0, 0], [26000, 52000]]\n",
    "    NB: the interesting region of a full image is typically [[12000, 15000], [26000, 35000]]\n",
    "    NB: the colors are chosen randomly for edges\n",
    "    NB: giving a smaller region greatly increase computation time\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO(FK): fetch image size from experiment object here, and use it in reconstruct image\n",
    "    # TODO(FK): colors for edges are not consistent\n",
    "    # NB: possible other parameters that could be added: alpha between layers, colors for object, figure_size\n",
    "    DIM_X, DIM_Y = get_dimX_dimY(exp)\n",
    "\n",
    "    if region == None:\n",
    "        # Full image\n",
    "        image_coodinates = exp.image_coordinates[t]\n",
    "        region = get_bounding_box(image_coodinates)\n",
    "        region[1][0] += DIM_X  # TODO(FK): Shouldn't be hardcoded\n",
    "        region[1][1] += DIM_Y\n",
    "\n",
    "    # 1/ Image layer\n",
    "    im, f = reconstruct_image_from_general(\n",
    "        exp,\n",
    "        t,\n",
    "        downsizing=downsizing,\n",
    "        region=region,\n",
    "        prettify=prettify,\n",
    "        white_background=False,  # TODO(FK): add image dimention here dimx = ..\n",
    "    )\n",
    "    f_int = lambda c: f(c).astype(int)\n",
    "    new_region = [\n",
    "        f_int(region[0]),\n",
    "        f_int(region[1]),\n",
    "    ]  # should be [[0, 0], [d_x/downsized, d_y/downsized]]\n",
    "\n",
    "    # 2/ Edges layer\n",
    "    skel_im, _ = reconstruct_skeletton(\n",
    "        [edge.pixel_list(t) for edge in edges],\n",
    "        region=region,\n",
    "        color_seeds=[(edge.begin.label + edge.end.label) % 255 for edge in edges],\n",
    "        downsizing=downsizing,\n",
    "        dilation=dilation,\n",
    "    )\n",
    "\n",
    "    # 3/ Fusing layers\n",
    "    fig = plt.figure(\n",
    "        figsize=figsize\n",
    "    )  # width: 30 cm height: 20 cm # TODO(FK): change dpi\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.imshow(im, cmap=\"gray\", interpolation=\"none\")\n",
    "    ax.imshow(skel_im, alpha=0.5, interpolation=\"none\")\n",
    "\n",
    "    # 3/ Plotting the Nodes\n",
    "    size = node_size\n",
    "    for node in nodes:\n",
    "        c = f(list(node.pos(t)))\n",
    "        color = make_random_color(node.label)[:3]\n",
    "        reciprocal_color = 255 - color\n",
    "        color = tuple(color / 255)\n",
    "        reciprocal_color = tuple(reciprocal_color / 255)\n",
    "        bbox_props = dict(boxstyle=\"circle\", fc=color, edgecolor=\"none\")\n",
    "        if is_in_bounding_box(c, new_region):\n",
    "            node_text = ax.text(\n",
    "                c[1],\n",
    "                c[0],\n",
    "                str(node.label),\n",
    "                ha=\"center\",\n",
    "                va=\"center\",\n",
    "                bbox=bbox_props,\n",
    "                font=fpath,\n",
    "                fontdict={\"color\": reciprocal_color},\n",
    "                size=size,\n",
    "                # alpha = 0.5\n",
    "            )\n",
    "    # 4/ Plotting coordinates\n",
    "    points = [f(c) for c in points]\n",
    "    for i, c in enumerate(points):\n",
    "        if is_in_bounding_box(c, new_region):\n",
    "            color = make_random_color(video_num[i])[:3]\n",
    "            color = tuple(color / 255)\n",
    "            plt.text(c[1], c[0], video_num[i], color=\"black\", fontsize=20, alpha=1)\n",
    "            plt.plot(c[1], c[0], marker=\"x\", color=\"black\", markersize=10, alpha=0.5)\n",
    "\n",
    "            if with_point_label:\n",
    "                plt.text(c[1], c[0], f\"{i}\")\n",
    "\n",
    "    # 5/ Plotting segments\n",
    "    segments = [[f(segment[0]), f(segment[1])] for segment in segments]\n",
    "    for s in segments:\n",
    "        plt.plot(\n",
    "            [s[0][1], s[1][1]],  # x1, x2\n",
    "            [s[0][0], s[1][0]],  # y1, y2\n",
    "            color=\"white\",\n",
    "            linewidth=2,\n",
    "        )\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=dpi)\n",
    "    else:\n",
    "        plt.show()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973efe1e-74c5-40c4-8eb6-6a030f0bc0df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from amftrack.pipeline.functions.image_processing.experiment_util import *\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def make_full_image(\n",
    "    exp: Experiment,\n",
    "    t: int,\n",
    "    region=None,\n",
    "    edges: List[Edge] = [],\n",
    "    points: List[coord_int] = [],\n",
    "    video_num: List[int] = [],\n",
    "    segments: List[List[coord_int]] = [],\n",
    "    nodes: List[Node] = [],\n",
    "    downsizing=5,\n",
    "    dilation=1,\n",
    "    save_path=\"\",\n",
    "    prettify=False,\n",
    "    with_point_label=False,\n",
    "    figsize=(12, 8),\n",
    "    dpi=None,\n",
    "    node_size=5,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    This is the general purpose function to plot the full image or a region `region` of the image at\n",
    "    any given timestep t. The region being specified in the GENERAL coordinates.\n",
    "    The image can be downsized by a chosen factor `downsized` with additionnal features such as: edges, nodes, points, segments.\n",
    "    The coordinates for all the objects are provided in the GENERAL referential.\n",
    "\n",
    "    :param region: choosen region in the full image, such as [[100, 100], [2000,2000]], if None the full image is shown\n",
    "    :param edges: list of edges to plot, it is the pixel list that is plotted, not a straight line\n",
    "    :param nodes: list of nodes to plot (only nodes in the `region` will be shown)\n",
    "    :param points: points such as [123, 234] to plot with a red cross on the image\n",
    "    :param segments: plot lines between two points that are provided\n",
    "    :param downsizing: factor by which we reduce the image resolution (5 -> image 25 times lighter)\n",
    "    :param dilation: only for edges: thickness of the edges (dilation applied to the pixel list)\n",
    "    :param save_path: full path to the location where the plot will be saved\n",
    "    :param prettify: if True, the image will be enhanced by smoothing the intersections between images\n",
    "    :param with_point_label: if True, the index of the point is ploted on top of it\n",
    "\n",
    "    NB: the full region of a full image is typically [[0, 0], [26000, 52000]]\n",
    "    NB: the interesting region of a full image is typically [[12000, 15000], [26000, 35000]]\n",
    "    NB: the colors are chosen randomly for edges\n",
    "    NB: giving a smaller region greatly increase computation time\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO(FK): fetch image size from experiment object here, and use it in reconstruct image\n",
    "    # TODO(FK): colors for edges are not consistent\n",
    "    # NB: possible other parameters that could be added: alpha between layers, colors for object, figure_size\n",
    "    DIM_X, DIM_Y = get_dimX_dimY(exp)\n",
    "\n",
    "    if region == None:\n",
    "        # Full image\n",
    "        image_coodinates = exp.image_coordinates[t]\n",
    "        region = get_bounding_box(image_coodinates)\n",
    "        region[1][0] += DIM_X  # TODO(FK): Shouldn't be hardcoded\n",
    "        region[1][1] += DIM_Y\n",
    "\n",
    "    # 1/ Image layer\n",
    "    im, f = reconstruct_image_from_general(\n",
    "        exp,\n",
    "        t,\n",
    "        downsizing=downsizing,\n",
    "        region=region,\n",
    "        prettify=prettify,\n",
    "        white_background=False,  # TODO(FK): add image dimention here dimx = ..\n",
    "    )\n",
    "    f_int = lambda c: f(c).astype(int)\n",
    "    new_region = [\n",
    "        f_int(region[0]),\n",
    "        f_int(region[1]),\n",
    "    ]  # should be [[0, 0], [d_x/downsized, d_y/downsized]]\n",
    "\n",
    "    # 2/ Edges layer\n",
    "    skel_im, _ = reconstruct_skeletton(\n",
    "        [edge.pixel_list(t) for edge in edges],\n",
    "        region=region,\n",
    "        color_seeds=[(edge.begin.label + edge.end.label) % 255 for edge in edges],\n",
    "        downsizing=downsizing,\n",
    "        dilation=dilation,\n",
    "    )\n",
    "    return (im, skel_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a34b84-7533-429b-9876-558e906ec3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(skel_im)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
