{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70c80be-987f-4332-8255-b30b9bae5afb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "import re\n",
    "import dropbox\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import imageio.v2 as imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import logging\n",
    "import datetime\n",
    "import glob\n",
    "import json\n",
    "import scipy\n",
    "import matplotlib as mpl\n",
    "\n",
    "from subprocess import call\n",
    "from tifffile import imwrite\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from amftrack.util.dbx import (\n",
    "    upload_folder,\n",
    "    download,\n",
    "    read_saved_dropbox_state,\n",
    "    save_dropbox_state,\n",
    "    load_dbx,\n",
    "    get_dropbox_folders_prince,\n",
    "    get_dropbox_video_folders,\n",
    "    download_video_folders_drop,\n",
    "    download_analysis_folders_drop,\n",
    ")\n",
    "from amftrack.pipeline.launching.run import (\n",
    "    run_transfer,\n",
    ")\n",
    "from amftrack.pipeline.launching.run_super import run_parallel_transfer\n",
    "from amftrack.pipeline.launching.run_super import run_parallel_flows\n",
    "from amftrack.pipeline.functions.transport_processing.high_mag_videos.plot_data import (\n",
    "    plot_summary,\n",
    "    save_raw_data,\n",
    ")\n",
    "from amftrack.pipeline.functions.transport_processing.high_mag_videos.high_mag_analysis import (\n",
    "    HighmagDataset,\n",
    "    VideoDataset,\n",
    "    EdgeDataset,\n",
    "    index_videos_dropbox_new,\n",
    "    analysis_run,\n",
    ")\n",
    "from amftrack.pipeline.functions.transport_processing.high_mag_videos.kymo_class import (\n",
    "    KymoVideoAnalysis,\n",
    "    KymoEdgeAnalysis,\n",
    ")\n",
    "from amftrack.util.dbx import (upload\n",
    ")\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib widget\n",
    "\n",
    "from amftrack.pipeline.launching.run_super import (\n",
    "    run_launcher,\n",
    "    directory_scratch,\n",
    "    directory_project,\n",
    "    directory_project,\n",
    "    run_parallel_stitch,\n",
    "    run_parallel_transfer,\n",
    ")\n",
    "import os\n",
    "from amftrack.pipeline.functions.image_processing.experiment_class_surf import (\n",
    "    Experiment,\n",
    "    save_graphs,\n",
    "    load_graphs,\n",
    "    Edge,\n",
    "    Node,\n",
    "\n",
    ")\n",
    "from amftrack.pipeline.functions.image_processing.experiment_util import (\n",
    "    get_random_edge,\n",
    "    distance_point_edge,\n",
    "    plot_edge,\n",
    "    plot_edge_cropped,\n",
    "    find_nearest_edge,\n",
    "    get_edge_from_node_labels,\n",
    "    plot_full_image_with_features,\n",
    "    get_all_edges,\n",
    "    get_all_nodes,\n",
    "    find_neighboring_edges,\n",
    "    reconstruct_image,\n",
    "    reconstruct_skeletton_from_edges,\n",
    "    reconstruct_skeletton_unicolor,\n",
    "    reconstruct_image_from_general,\n",
    "    plot_full,\n",
    "    plot_edge_color_value,\n",
    ")\n",
    "from amftrack.transport.align_video_network import identify_nodes\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.debug)\n",
    "from amftrack.util.sys import (\n",
    "    get_dates_datetime,\n",
    "    get_dirname,\n",
    "    temp_path,\n",
    "    get_data_info,\n",
    "    update_plate_info,\n",
    "    update_analysis_info,\n",
    "    get_analysis_info,\n",
    "    get_current_folders,\n",
    "    get_folders_by_plate_id,\n",
    ")\n",
    "mpl.rcParams[\"figure.dpi\"] = 100\n",
    "from amftrack.pipeline.functions.transport_processing.high_mag_videos.register_videos import *\n",
    "from amftrack.pipeline.functions.transport_processing.high_mag_videos.loading import load_video_dataset\n",
    "from amftrack.pipeline.functions.transport_processing.high_mag_videos.add_BC import *\n",
    "\n",
    "from amftrack.pipeline.functions.post_processing.time_hypha import *\n",
    "from amftrack.pipeline.functions.post_processing.extract_study_zone import (\n",
    "    load_study_zone,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec88104-cf1c-4cbe-afa1-093e6686e3da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "videos_folder = \"/projects/0/einf914/videos/\"\n",
    "\n",
    "analysis_folder = \"/projects/0/einf914/analysis_videos/CocoTransport/\"\n",
    "analysis_folder_root = \"/projects/0/einf914/analysis_videos/\"\n",
    "directory_targ = '/projects/0/einf914/transport/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a22211-6911-468a-bdfb-868110775800",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "indexes = {\n",
    "\"20230901_Plate310\" : 20,\n",
    "\"20230902_Plate310\" : 33,\n",
    "\"20230903_Plate310\" : 42,\n",
    "\"20230904_Plate310\" : 52,\n",
    "\"20230905_Plate310\" : 64,\n",
    "\"20230906_Plate310\" : 73,\n",
    "}\n",
    "indexes = {\n",
    "\"20230810_Plate441\" : 29,\n",
    "\"20230811_Plate441\" : 41,\n",
    "\"20230812_Plate441\" : 47,\n",
    "\"20230813_Plate441\" : 60,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90564821-bd0e-4830-a360-2c7a873343b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plate_id = \"441_20230807\"\n",
    "plate_id_video = \"20230810_Plate441\"\n",
    "data_obj = load_video_dataset(plate_id_video, videos_folder, analysis_folder, analysis_folder_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ce99f8-b0d4-4049-a521-cc716dc84e8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "update_plate_info(directory_targ, local=True)\n",
    "all_folders = get_current_folders(directory_targ, local=True)\n",
    "folders = all_folders.loc[all_folders[\"unique_id\"] == plate_id]\n",
    "folders = folders.loc[folders[\"/Analysis/nx_graph_pruned_labeled.p\"] == True]\n",
    "folders = folders.sort_values(by=\"datetime\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80213b3d-62fe-4624-ba92-5e5027cbed98",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dropbox_address = \"/DATA/CocoTransport/\"\n",
    "upl_targ = dropbox_address\n",
    "\n",
    "for plate_id_video in list(indexes.keys()):\n",
    "    data_obj = load_video_dataset(plate_id_video, videos_folder, analysis_folder, analysis_folder_root)\n",
    "\n",
    "    exp = Experiment(directory_targ)\n",
    "    i = indexes[plate_id_video]\n",
    "    exp.load(folders.iloc[i : i + 1], suffix=\"_labeled\")\n",
    "    for t in range(exp.ts):\n",
    "        exp.load_tile_information(t)\n",
    "    add_betweenness(exp,t)\n",
    "    # break\n",
    "    data_obj.video_objs = sorted(data_obj.video_objs, key = lambda video : video.dataset['video_int'])\n",
    "    for vid_obj in data_obj.video_objs:\n",
    "        drop_targ = os.path.relpath(f\"/{vid_obj.dataset['tot_path_drop']}\", upl_targ)\n",
    "        db_address = f\"{upl_targ}KymoSpeeDExtract/{drop_targ}\"\n",
    "        if check_hasedges(vid_obj):\n",
    "            edge_data_csv = pd.read_csv(vid_obj.edge_adr)\n",
    "            mapping = {}\n",
    "            for edge in vid_obj.edge_objs:\n",
    "                if \"network_begin\" in edge.mean_data.keys():\n",
    "                    edge_begin = edge.mean_data[\"network_begin\"]\n",
    "                    edge_end = edge.mean_data[\"network_end\"]    # break\n",
    "                    network_edge = Edge(Node(edge_begin,exp),Node(edge_end,exp),exp) \n",
    "                    mapping[edge.edge_name] = network_edge\n",
    "            for edge in vid_obj.edge_objs:\n",
    "                if \"network_begin\" in edge.mean_data.keys():\n",
    "                    add_attribute(edge_data_csv, edge, lambda edge: edge.width(t), \"width_automate\", mapping)\n",
    "                    add_attribute(edge_data_csv, edge, lambda edge: edge.betweeness(t), \"betweenness_automate\", mapping)\n",
    "                    add_attribute(edge_data_csv, edge, lambda edge: get_derivative(edge,t,fun), \"betweenness_derivative\", mapping)\n",
    "                    \n",
    "            edge_data_csv.to_csv(vid_obj.edge_adr,index=False)\n",
    "            drop_targ = os.path.relpath(f\"/{vid_obj.dataset['tot_path_drop']}\", upl_targ)\n",
    "            db_address = f\"{upl_targ}KymoSpeeDExtract/{drop_targ}\"\n",
    "            source = vid_obj.edge_adr\n",
    "            target = db_address+\"/edges_data.csv\"\n",
    "            print(source,target)\n",
    "            upload(source,target)\n",
    "    #         break\n",
    "    # break\n",
    "    \n",
    "    \n",
    "# edge.time_data[\"flux_mean\"].mean()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b220a2bb-8751-4eec-8b2e-cfdf1a06bbb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dropbox_address = \"/DATA/CocoTransport/\"\n",
    "analysis_folder = \"/projects/0/einf914/analysis_videos/\"\n",
    "folder_filter = dropbox_address[5:]\n",
    "\n",
    "img_infos = glob.glob(\n",
    "    f\"{analysis_folder}{folder_filter}/**/video_data.json\", recursive=True\n",
    ")\n",
    "vid_anls_frame = pd.DataFrame()\n",
    "for address in img_infos:\n",
    "    add_info = pd.read_json(address, orient=\"index\").T\n",
    "    vid_anls_frame = pd.concat([vid_anls_frame, add_info], ignore_index=True)\n",
    "\n",
    "vid_anls_frame = vid_anls_frame.sort_values(\"unique_id\").reset_index(drop=True)\n",
    "analysis_frame = vid_anls_frame\n",
    "print(f\"Number of videos to be uploaded: {len(analysis_frame)}\")\n",
    "### LARGE VIDEO ANALYSIS\n",
    "\n",
    "nr_parallel = np.min([len(analysis_frame.index), 1])\n",
    "\n",
    "# run_parallel_flows(\n",
    "#     \"flux_upload.py\",\n",
    "#     [analysis_folder, 9, 0.95, 0.005, 200, dropbox_address],\n",
    "#     analysis_frame,\n",
    "#     nr_parallel,\n",
    "#     \"2:00:00\",\n",
    "#     \"flux_upload\",\n",
    "#     node = \"staging\",\n",
    "#     cpus = 1,\n",
    "#     # dependency = \"flux_extract.sh\",\n",
    "#     name_job = \"flux_upload.sh\"\n",
    "# )\n",
    "# clear_output(wait=False)\n",
    "\n",
    "# print(\n",
    "#     \"Sent all the jobs! Use the command '$ squeue' in the terminal to see the progress\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d642ee5a-5dc7-4d46-9ec1-fdb3511f3332",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "analysis_frame[\"analysis_folder\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7334ae46-8df7-4ef7-b5e6-797ac49747fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plate_id_video = \"20230812_Plate441\"\n",
    "\n",
    "folders = folders.sort_values(by=\"datetime\")\n",
    "\n",
    "exp = Experiment(directory_targ)\n",
    "i = indexes[plate_id_video]\n",
    "exp.load(folders.iloc[i : i + 1], suffix=\"_labeled\")\n",
    "for t in range(exp.ts):\n",
    "    exp.load_tile_information(t)\n",
    "    add_betweenness(exp,t)\n",
    "\n",
    "# load_graphs(exp, directory_targ,indexes = [0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975dd667-5995-4eda-8a57-b4ec35d4c554",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mpl.rcParams[\"figure.dpi\"] = 50\n",
    "\n",
    "from random import choice\n",
    "vid_obj = data_obj.video_objs[25]\n",
    "vid_obj.plot_speed_arrows(plot_both=True, video_txt_size=30,plot_flux = True,plot_text=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb9da6a-aa33-4d80-8e1b-3a24d839c4c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "for edge in vid_obj.edge_objs:\n",
    "    if \"network_begin\" in edge.mean_data.keys():\n",
    "        edge_begin = edge.mean_data[\"network_begin\"]\n",
    "        edge_end = edge.mean_data[\"network_end\"]    # break\n",
    "        network_edge = Edge(Node(edge_begin,exp),Node(edge_end,exp),exp) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60829887-9df0-4bd2-9f7b-072ef3d01e02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def get_derivative(edge,t,fun):\n",
    "edge = network_edge\n",
    "fun = lambda edge: edge.betweeness(t)\n",
    "def get_derivative(edge_d,t,fun):\n",
    "    edges_begin = edge_d.begin.edges(t)\n",
    "    edges_begin.remove(edge_d)\n",
    "    edges_end = edge_d.end.edges(t)\n",
    "    edges_end.remove(edge_d)\n",
    "    weight_begin = np.sum([fun(edge) for edge in edges_begin])\n",
    "    weight_end = np.sum([fun(edge) for edge in edges_end])\n",
    "    return(weight_end-weight_begin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da3f43a-c504-4247-bcb0-2eca2833e320",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "edges = get_all_edges(exp,t)\n",
    "np.sum[len(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a65a44b-b551-49e4-a9d5-85fb8efc0f7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "edges_network = []\n",
    "derivatives = []\n",
    "\n",
    "coverage_tot = []\n",
    "for index,vid_obj in enumerate(data_obj.video_objs):\n",
    "    if vid_obj.dataset['mode']==\"BF\" and check_hasedges(vid_obj):\n",
    "        for edge in vid_obj.edge_objs:\n",
    "            if \"network_begin\" in edge.mean_data.keys():\n",
    "                edge_begin = edge.mean_data[\"network_begin\"]\n",
    "                edge_end = edge.mean_data[\"network_end\"]    # break\n",
    "                network_edge = Edge(Node(edge_begin,exp),Node(edge_end,exp),exp) \n",
    "                if network_edge.is_in(t): \n",
    "                    edges_network.append(network_edge)\n",
    "                    derivatives.append(get_derivative(network_edge,t,fun))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3471b80-569c-4a20-a8da-5652c8c88f15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from amftrack.pipeline.functions.transport_processing.high_mag_videos.plotting import *\n",
    "downsizing = 5\n",
    "ax,f = plot_full_video( \n",
    "    exp,\n",
    "    t,\n",
    "    downsizing=5,\n",
    "    # points=positions_list,\n",
    "    video_num=[0],\n",
    "    edges=edges_network,\n",
    "    dilation=downsizing,\n",
    "    # region = region,\n",
    "    figsize = (18,12),\n",
    ")\n",
    "for derivative,edge in zip(derivatives,edges_network):\n",
    "    pixels = edge.pixel_list(t)\n",
    "    center_arrow = f(pixels[len(pixels)//2])\n",
    "\n",
    "    begin_arrow = f(pixels[10])\n",
    "    end_arrow = f(pixels[-10])\n",
    "    # begin_arrow = edges_network[0].begin.pos(t)\n",
    "    # end_arrow = edges_network[0].pixel_list(t)[10]\n",
    "    vector = (end_arrow-begin_arrow)\n",
    "    vector = vector/np.linalg.norm(vector)*100/downsizing*(1-2*(derivative>0))\n",
    "    ax.arrow(center_arrow[1],center_arrow[0],vector[1],vector[0],width = 10)\n",
    "plt.savefig(f\"test_{plate_id_video}_derivative.png\", dpi=600)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
