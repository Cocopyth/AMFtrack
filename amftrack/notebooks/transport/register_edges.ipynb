{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70c80be-987f-4332-8255-b30b9bae5afb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "import re\n",
    "import dropbox\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import imageio.v2 as imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import logging\n",
    "import datetime\n",
    "import glob\n",
    "import json\n",
    "import scipy\n",
    "import matplotlib as mpl\n",
    "\n",
    "from subprocess import call\n",
    "from tifffile import imwrite\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from amftrack.util.dbx import (\n",
    "    upload_folder,\n",
    "    download,\n",
    "    read_saved_dropbox_state,\n",
    "    save_dropbox_state,\n",
    "    load_dbx,\n",
    "    get_dropbox_folders_prince,\n",
    "    get_dropbox_video_folders,\n",
    "    download_video_folders_drop,\n",
    "    download_analysis_folders_drop,\n",
    ")\n",
    "from amftrack.pipeline.launching.run import (\n",
    "    run_transfer,\n",
    ")\n",
    "from amftrack.pipeline.launching.run_super import run_parallel_transfer\n",
    "from amftrack.pipeline.launching.run_super import run_parallel_flows\n",
    "from amftrack.pipeline.functions.transport_processing.high_mag_videos.plot_data import (\n",
    "    plot_summary,\n",
    "    save_raw_data,\n",
    ")\n",
    "from amftrack.pipeline.functions.transport_processing.high_mag_videos.high_mag_analysis import (\n",
    "    HighmagDataset,\n",
    "    VideoDataset,\n",
    "    EdgeDataset,\n",
    "    index_videos_dropbox_new,\n",
    "    analysis_run,\n",
    ")\n",
    "from amftrack.pipeline.functions.transport_processing.high_mag_videos.kymo_class import (\n",
    "    KymoVideoAnalysis,\n",
    "    KymoEdgeAnalysis,\n",
    ")\n",
    "from amftrack.util.dbx import (upload\n",
    ")\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib widget\n",
    "\n",
    "from amftrack.pipeline.launching.run_super import (\n",
    "    run_launcher,\n",
    "    directory_scratch,\n",
    "    directory_project,\n",
    "    directory_project,\n",
    "    run_parallel_stitch,\n",
    "    run_parallel_transfer,\n",
    ")\n",
    "import os\n",
    "from amftrack.pipeline.functions.image_processing.experiment_class_surf import (\n",
    "    Experiment,\n",
    "    save_graphs,\n",
    "    load_graphs,\n",
    "    Edge,\n",
    "    Node,\n",
    "\n",
    ")\n",
    "from amftrack.pipeline.functions.image_processing.experiment_util import (\n",
    "    get_random_edge,\n",
    "    distance_point_edge,\n",
    "    plot_edge,\n",
    "    plot_edge_cropped,\n",
    "    find_nearest_edge,\n",
    "    get_edge_from_node_labels,\n",
    "    plot_full_image_with_features,\n",
    "    get_all_edges,\n",
    "    get_all_nodes,\n",
    "    find_neighboring_edges,\n",
    "    reconstruct_image,\n",
    "    reconstruct_skeletton_from_edges,\n",
    "    reconstruct_skeletton_unicolor,\n",
    "    reconstruct_image_from_general,\n",
    "    plot_full,\n",
    "    plot_edge_color_value,\n",
    ")\n",
    "from amftrack.transport.align_video_network import identify_nodes\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.debug)\n",
    "from amftrack.util.sys import (\n",
    "    get_dates_datetime,\n",
    "    get_dirname,\n",
    "    temp_path,\n",
    "    get_data_info,\n",
    "    update_plate_info,\n",
    "    update_analysis_info,\n",
    "    get_analysis_info,\n",
    "    get_current_folders,\n",
    "    get_folders_by_plate_id,\n",
    ")\n",
    "mpl.rcParams[\"figure.dpi\"] = 100\n",
    "from amftrack.pipeline.functions.transport_processing.high_mag_videos.register_videos import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec88104-cf1c-4cbe-afa1-093e6686e3da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plate_id = \"310_20230830\"\n",
    "plate_id_video = \"20230904_Plate310\"\n",
    "videos_folder = \"/projects/0/einf914/videos/\"\n",
    "plate_id = \"441_20230807\"\n",
    "plate_id_video = \"20230811_Plate441\"\n",
    "videos_folder = \"/projects/0/einf914/videos/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a22211-6911-468a-bdfb-868110775800",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "indexes = {\n",
    "\"20230901_Plate310\" : 20,\n",
    "\"20230902_Plate310\" : 33,\n",
    "\"20230903_Plate310\" : 42,\n",
    "\"20230904_Plate310\" : 52,\n",
    "\"20230905_Plate310\" : 64,\n",
    "\"20230906_Plate310\" : 73,\n",
    "}\n",
    "indexes = {\n",
    "\"20230810_Plate441\" : 29,\n",
    "\"20230811_Plate441\" : 41,\n",
    "\"20230812_Plate441\" : 47,\n",
    "\"20230813_Plate441\" : 60,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755db006-2e57-49ae-86e0-79730f9b8dc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "analysis_folder = \"/projects/0/einf914/analysis_videos/CocoTransport/\"\n",
    "analysis_folder = f\"{analysis_folder}{plate_id_video}/\"\n",
    "\n",
    "img_infos = glob.glob(f\"{analysis_folder}/**/video_data.json\", recursive=True)\n",
    "vid_anls_frame = pd.DataFrame()\n",
    "add_infos = []\n",
    "for address in img_infos:\n",
    "    add_infos.append(pd.read_json(address, orient=\"index\").T)\n",
    "vid_anls_frame = pd.concat([vid_anls_frame] + add_infos, ignore_index=True)\n",
    "\n",
    "vid_anls_frame = vid_anls_frame.sort_values(\"unique_id\").reset_index(drop=True)\n",
    "vid_anls_frame_select = vid_anls_frame.loc[vid_anls_frame[\"plate_id\"] == plate_id_video]\n",
    "columns_to_drop = ['xpos_network', 'ypos_network']\n",
    "\n",
    "# Dropping columns from vid_anls_frame_select_network if they exist\n",
    "for column in columns_to_drop:\n",
    "    if column in vid_anls_frame_select.columns:\n",
    "        vid_anls_frame_select = vid_anls_frame_select.drop(column, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190395ee-6c25-4d1a-8e25-6ab0756d77a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "analysis_folder = \"/projects/0/einf914/analysis_videos/CocoTransport/\"\n",
    "analysis_folder = f\"{analysis_folder}{plate_id_video}/\"\n",
    "\n",
    "img_infos = glob.glob(f\"{analysis_folder}/**/video_data_network.json\", recursive=True)\n",
    "vid_anls_frame = pd.DataFrame()\n",
    "add_infos = []\n",
    "for address in img_infos:\n",
    "    add_infos.append(pd.read_json(address, orient=\"index\").T)\n",
    "vid_anls_frame = pd.concat([vid_anls_frame] + add_infos, ignore_index=True)\n",
    "\n",
    "vid_anls_frame = vid_anls_frame.sort_values(\"unique_id\").reset_index(drop=True)\n",
    "vid_anls_frame_select_network = vid_anls_frame.loc[vid_anls_frame[\"plate_id\"] == plate_id_video]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd003a92-2802-4eba-ae67-6b2e66eb6f38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vid_anls_frame_merged = vid_anls_frame_select.merge(vid_anls_frame_select_network[['xpos_network','ypos_network','unique_id']],on = 'unique_id')\n",
    "# vid_anls_frame_merged = vid_anls_frame_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cde5f8-0af4-4234-8244-18df636b5e99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# vid_anls_frame_merged['folder'] = vid_anls_frame_merged['folder'].str.replace('/Img','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ce99f8-b0d4-4049-a521-cc716dc84e8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "analysis_folder_root = \"/projects/0/einf914/analysis_videos/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7ebbd1-52f6-4767-aa91-2a2cbeaeae26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vid_anls_frame_merged[\"analysis_folder\"] = analysis_folder_root\n",
    "vid_anls_frame_merged[\"videos_folder\"] = [\n",
    "    str(Path(videos_folder) / entry[\"folder\"])\n",
    "    for index, entry in vid_anls_frame_merged.iterrows()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f535df95-c0e8-4153-9a02-615bf4db8485",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_obj = HighmagDataset(vid_anls_frame_merged, analysis_folder_root, videos_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515db227-60eb-4f6a-8b79-e6b6d7a2658c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# directory_targ = os.path.join(directory_scratch, \"stitch_temp2\") + \"/\"\n",
    "directory_targ = '/projects/0/einf914/transport/'\n",
    "update_plate_info(directory_targ, local=True)\n",
    "all_folders = get_current_folders(directory_targ, local=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcaf393-92d6-42fe-bd10-dfd64a496391",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_folders['unique_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54265cf6-9ab6-4d8e-bd26-85929d63ab06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "folders = all_folders.loc[all_folders[\"unique_id\"] == plate_id]\n",
    "folders = folders.loc[folders[\"/Analysis/nx_graph_pruned_labeled.p\"] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7334ae46-8df7-4ef7-b5e6-797ac49747fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "folders = folders.sort_values(by=\"datetime\")\n",
    "\n",
    "exp = Experiment(directory_targ)\n",
    "i = 41\n",
    "exp.load(folders.iloc[i : i + 1], suffix=\"_width\")\n",
    "for t in range(exp.ts):\n",
    "    exp.load_tile_information(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092fef5c-e1c7-49fb-8a8a-5cb20c00a8de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_obj.video_objs = sorted(data_obj.video_objs,key = lambda video : video.dataset['video_int'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975dd667-5995-4eda-8a57-b4ec35d4c554",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mpl.rcParams[\"figure.dpi\"] = 50\n",
    "\n",
    "from random import choice\n",
    "vid_obj = choice(data_obj.video_objs)\n",
    "vid_obj = data_obj.video_objs[34]\n",
    "\n",
    "vid_obj.plot_speed_arrows(plot_both=True, video_txt_size=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f519b6e-dce9-4c70-8467-bf2bb0d91f99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Rcurrent,tcurrent = np.array([[1,0],[0,1]]), np.array([0 ,0])   \n",
    "\n",
    "positions = Rcurrent@np.array(vid_obj.dataset[[\"xpos_network\", \"ypos_network\"]])+tcurrent\n",
    "positions_list = [positions.tolist()]\n",
    "window = np.array([100,100])\n",
    "begin= (positions-window).astype(int)\n",
    "end = (positions+window).astype(int)\n",
    "region=[[begin[0],begin[1]],[end[0],end[1]]]\n",
    "# region = [[100, 100], [2000,2000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03660efe-f6f8-41a9-9fd3-5e54ba2c0a01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4124b186-28d9-48de-bd3c-1491d18acccd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shiftx = vid_obj.img_dim[0]*vid_obj.space_res/1.725/2\n",
    "shifty = vid_obj.img_dim[1]*vid_obj.space_res/1.725/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04027ec0-14e2-40b2-97fc-1f19c29121e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "segments = get_segments_ends(vid_obj,shiftx,shifty,20,Rcurrent,tcurrent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ceaf751-7a5f-4eac-86b3-4dcf72f56dd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "edges = get_all_edges(exp, t)\n",
    "\n",
    "edges = [edge for edge in edges if dist_edge(edge,positions,t)<=100]\n",
    "pixels = [pixel for edge in edges for pixel in edge.pixel_list(t)]\n",
    "pixels = [pixel for pixel in pixels if np.linalg.norm(pixel-positions)<=150]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd13782-0d6c-4032-8963-2cbc331e97e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "segment_points = []\n",
    "for begin, end in segments:\n",
    "    # Include the start point, interpolated points, and the end point\n",
    "    interpolated_points = interpolate_points(begin, end)\n",
    "    segment_points.extend(interpolated_points)\n",
    "    segment_points.append(end)  # Ensure the end point is included\n",
    "\n",
    "segment_points = np.array(segment_points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacaa927-5bfb-4acd-ad0d-9d529ceef2ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from amftrack.pipeline.functions.transport_processing.high_mag_videos.plotting import *\n",
    "\n",
    "positions_list = [positions.tolist()]\n",
    "# plt.close(\"all\")\n",
    "t = 0\n",
    "vmax = 9\n",
    "vmin = 3\n",
    "nodes = get_all_nodes(exp, t)\n",
    "edges = get_all_edges(exp, t)\n",
    "edges = [edge for edge in edges if dist_edge(edge,positions,t)<=100]\n",
    "downsizing = 1\n",
    "\n",
    "plot_full_video(\n",
    "    exp,\n",
    "    t,\n",
    "    downsizing=downsizing,\n",
    "    points=positions_list,\n",
    "    video_num=[0],\n",
    "    edges=edges,\n",
    "    dilation=5,\n",
    "    region = region,\n",
    "    segments = segments\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174b2b25-63e8-42b3-af5a-dcf4d8c7c7b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "\n",
    "# Plotting point cloud\n",
    "px, py = zip(*pixels)  # Unpacking points into x and y coordinates\n",
    "ax.scatter(px, py, color='blue')  # Plot points in blue\n",
    "px, py = zip(*segment_points)  # Unpacking points into x and y coordinates\n",
    "ax.scatter(px, py, color='red')  # Plot points in blue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00f5e8d-c6f5-4f6e-9f05-a89947b4a947",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Y = np.array(pixels)\n",
    "X = np.array(segment_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d038f29-ca62-4e32-a21b-7ac819e34abd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import probreg as pr\n",
    "# X = np.insert(X, 2, values=0, axis=1)  # Inserting a Z-axis with zero values\n",
    "# Y = np.insert(Y, 2, values=0, axis=1)  # Inserting a Z-axis with zero values\n",
    "\n",
    "# Convert numpy arrays to point clouds.\n",
    "# In probreg, point clouds can be represented directly as numpy arrays.\n",
    "source = X\n",
    "target = Y\n",
    "# reg = cpd.registration(target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd85d9ba-ead0-4155-9da2-a8dad6df367d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Rcurrent,tcurrent = find_optimal_R_and_t(source, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa935e3-e657-4382-9957-4908eae95c5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Rcurrent,tcurrent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046d3727-29f4-4704-8c2f-c39364007c0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transformation_matrix = np.eye(4)\n",
    "transformation_matrix[:3, :3] = cpd.transformation.rot  # Rotation\n",
    "transformation_matrix[:3, 3] = cpd.transformation.t  # Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54168528-c25b-4573-a22c-863ed19b4fec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Transform the source point cloud using the obtained transformation matrix\n",
    "transformed_source = np.dot(R, source.T).T + t\n",
    "\n",
    "# Calculate distances between each pair of corresponding points\n",
    "distances = average_min_distance_to_set(transformed_source, target)\n",
    "\n",
    "# Compute the root mean square deviation\n",
    "rmsd = np.sqrt(np.mean(distances**2))\n",
    "\n",
    "rmsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e10ca0-a0ef-45cc-adca-c6acb3a7c100",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Rcurrent,tcurrent = cpd.transformation.rot[:2,:2],cpd.transformation.t[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b42d1e5-68eb-4c93-80e6-a1177643cae2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Rcurrent,tcurrent = np.array([[1,0],[0,1]]), np.array([0 ,0])   \n",
    "mapping, dist,Rfound,tfound = make_whole_mapping(vid_obj,exp,t,dist = 100,R=Rcurrent,trans = tcurrent)\n",
    "if np.linalg.det(Rfound)>0:\n",
    "    Rcurrent = Rfound@Rcurrent\n",
    "    tcurrent = Rfound@tcurrent+tfound\n",
    "    if dist>20:\n",
    "        mapping, dist,Rfound,tfound = make_whole_mapping(vid_obj,exp,t,dist = 100,R=Rcurrent,trans = tcurrent)\n",
    "        if np.linalg.det(Rfound)>0:\n",
    "            Rcurrent = Rfound@Rcurrent\n",
    "            tcurrent = Rfound@tcurrent+tfound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b34ea09-00c5-4b52-aa69-b1b0eea8675d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.linalg.det(Rfound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3e83c9-aad6-47cc-82f2-1e0de72c27a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for edge in vid_obj.edge_objs:\n",
    "\n",
    "    edge_data_csv.loc[edge_data_csv['edge_name'] == edge.edge_name, 'width'] = 2\n",
    "edge_data_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacf5b27-4bfe-411f-bc13-e704eb80124b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_attribute(edge_data_csv,vid_edge_obj,network_edge_attribute,name_new_col,mapping):\n",
    "    new_attribute = network_edge_attribute(mapping[vid_edge_obj.edge_name])   \n",
    "    # print(new_attribute)\n",
    "    edge_data_csv.loc[edge_data_csv['edge_name'] == vid_edge_obj.edge_name, name_new_col] = new_attribute\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15019ef5-9bca-4a1e-a500-c912712c8c83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for edge in vid_obj.edge_objs:\n",
    "    add_attribute(edge_data_csv,edge,lambda edge: edge.width(t),\"width\",mapping)\n",
    "    add_attribute(edge_data_csv,edge,lambda edge: edge.end.label,\"network_end\",mapping)\n",
    "    add_attribute(edge_data_csv,edge,lambda edge: edge.begin.label,\"network_begin\",mapping) \n",
    "    add_attribute(edge_data_csv,edge,lambda edge : dist,\"mapping_quality\",mapping)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d1a294-b411-4cb5-a5f0-fa5fa5c6b80b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "edge_data_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb50c7a6-219a-4b80-b39c-eb050d18ea33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "def check_hasedges(vid_obj):\n",
    "    shiftx = vid_obj.img_dim[0]*vid_obj.space_res/1.725/2\n",
    "    shifty = vid_obj.img_dim[1]*vid_obj.space_res/1.725/2\n",
    "    segments = get_segments_ends(vid_obj,shiftx,shifty,40)\n",
    "    return(len(segments)>0)\n",
    "\n",
    "def initialize_transformation():\n",
    "    return np.array([[1,0],[0,1]]), np.array([0,0])\n",
    "\n",
    "def update_transformation(Rcurrent, tcurrent, Rfound, tfound):\n",
    "    Rcurrent = Rfound @ Rcurrent\n",
    "    tcurrent = Rfound @ tcurrent + tfound\n",
    "    return Rcurrent, tcurrent\n",
    "\n",
    "def should_reset(Rfound):\n",
    "    return np.linalg.det(Rfound) <= 0 or Rfound[0][0] <= 0.99\n",
    "\n",
    "def attempt_mapping(vid_obj, exp, t, Rcurrent, tcurrent):\n",
    "    try:\n",
    "        mapping, dist, Rfound, tfound = make_whole_mapping(vid_obj, exp, t, dist=100, R=Rcurrent, trans=tcurrent)\n",
    "    except IndexError:\n",
    "        Rcurrent, tcurrent = initialize_transformation()\n",
    "        mapping, dist, Rfound, tfound = make_whole_mapping(vid_obj, exp, t, dist=100, R=Rcurrent, trans=tcurrent)\n",
    "    return mapping, dist, Rfound, tfound\n",
    "\n",
    "def process_video_object(vid_obj, exp, t, Rcurrent, tcurrent):\n",
    "    mapping, dist, Rfound, tfound = attempt_mapping(vid_obj, exp, t, Rcurrent, tcurrent)\n",
    "    if np.linalg.det(Rfound) > 0 and Rfound[0][0] > 0.99:\n",
    "        Rcurrent, tcurrent = update_transformation(Rcurrent, tcurrent, Rfound, tfound)\n",
    "        if dist > 20:\n",
    "            mapping, dist, Rfound, tfound = attempt_mapping(vid_obj, exp, t, Rcurrent, tcurrent)\n",
    "            if should_reset(Rfound):\n",
    "                Rcurrent, tcurrent = initialize_transformation()\n",
    "    else:\n",
    "        Rcurrent, tcurrent = initialize_transformation()\n",
    "    return Rcurrent, tcurrent, mapping, dist\n",
    "\n",
    "def register_dataset(data_obj, exp, t):\n",
    "    Rcurrent, tcurrent = initialize_transformation()\n",
    "\n",
    "    for index, vid_obj in enumerate(data_obj.video_objs[35:]):\n",
    "        if check_hasedges(vid_obj):\n",
    "            Rcurrent, tcurrent, mapping, dist = process_video_object(vid_obj, exp, t, Rcurrent, tcurrent)\n",
    "            print(index, dist, Rcurrent, tcurrent)\n",
    "            update_edge_attributes(vid_obj, mapping, dist, t)\n",
    "\n",
    "def update_edge_attributes(vid_obj, mapping, dist, t):\n",
    "    edge_data_csv = pd.read_csv(vid_obj.edge_adr)\n",
    "    for edge in vid_obj.edge_objs:\n",
    "        add_attribute(edge_data_csv, edge, lambda edge: edge.width(t), \"width\", mapping)\n",
    "        add_attribute(edge_data_csv, edge, lambda edge: edge.end.label, \"network_end\", mapping)\n",
    "        add_attribute(edge_data_csv, edge, lambda edge: edge.begin.label, \"network_begin\", mapping)\n",
    "        add_attribute(edge_data_csv, edge, lambda edge: dist, \"mapping_quality\", mapping)\n",
    "    edge_data_csv.to_csv(vid_obj.edge_adr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32764354-77cb-48ac-816f-d07dd352be04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "register_dataset(data_obj,exp,t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
