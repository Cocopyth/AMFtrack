{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27731bd0-cdcb-4159-a744-a0ecd3510489",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/home2/cbisot/pycode/AMFtrack/amftrack/util/dbx.py:3: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n",
      "2023-07-13 19:32:48.563602: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-13 19:32:49.178971: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /gpfs/home2/cbisot/miniconda3/envs/amftrack/lib/python3.7/site-packages/cv2/../../lib64:\n",
      "2023-07-13 19:32:49.179022: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-07-13 19:32:49.282284: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-07-13 19:32:52.003038: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /gpfs/home2/cbisot/miniconda3/envs/amftrack/lib/python3.7/site-packages/cv2/../../lib64:\n",
      "2023-07-13 19:32:52.003261: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /gpfs/home2/cbisot/miniconda3/envs/amftrack/lib/python3.7/site-packages/cv2/../../lib64:\n",
      "2023-07-13 19:32:52.003276: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-07-13 19:32:55.243403: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /gpfs/home2/cbisot/miniconda3/envs/amftrack/lib/python3.7/site-packages/cv2/../../lib64:\n",
      "2023-07-13 19:32:55.243510: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-07-13 19:32:55.243552: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (int6): /proc/driver/nvidia/version does not exist\n",
      "2023-07-13 19:32:55.244197: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%matplotlib widget\n",
    "%autoreload 2\n",
    "from amftrack.pipeline.launching.run_super import (\n",
    "    run_launcher,\n",
    "    directory_scratch,\n",
    "    directory_project,\n",
    "    directory_project,\n",
    "    run_parallel_stitch,\n",
    "    run_parallel_transfer,\n",
    ")\n",
    "import os\n",
    "from amftrack.util.sys import (\n",
    "    get_dates_datetime,\n",
    "    get_dirname,\n",
    "    temp_path,\n",
    "    get_data_info,\n",
    "    update_plate_info,\n",
    "    update_analysis_info,\n",
    "    get_analysis_info,\n",
    "    get_current_folders,\n",
    "    get_folders_by_plate_id,\n",
    ")\n",
    "from time import time_ns\n",
    "from amftrack.util.dbx import upload_folders, load_dbx, download, get_dropbox_folders\n",
    "from datetime import datetime\n",
    "\n",
    "from amftrack.pipeline.functions.image_processing.experiment_class_surf import (\n",
    "    load_graphs,\n",
    ")\n",
    "from amftrack.pipeline.functions.post_processing.extract_study_zone import (\n",
    "    load_study_zone,\n",
    ")\n",
    "from amftrack.pipeline.functions.image_processing.experiment_util import (\n",
    "    get_random_edge,\n",
    "    distance_point_edge,\n",
    "    plot_edge,\n",
    "    plot_edge_cropped,\n",
    "    find_nearest_edge,\n",
    "    get_edge_from_node_labels,\n",
    "    plot_full_image_with_features,\n",
    "    get_all_edges,\n",
    "    get_all_nodes,\n",
    "    find_neighboring_edges,\n",
    "    reconstruct_image,\n",
    "    reconstruct_skeletton_from_edges,\n",
    "    reconstruct_skeletton_unicolor,\n",
    "    plot_edge_color_value,\n",
    "    reconstruct_image_from_general,\n",
    "    plot_full,\n",
    "    find_nearest_edge,\n",
    ")\n",
    "from amftrack.pipeline.functions.image_processing.extract_width_fun import (\n",
    "    get_width_info,\n",
    "    get_width_info_new,\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "from amftrack.pipeline.functions.image_processing.experiment_class_surf import (\n",
    "    Experiment,\n",
    "    save_graphs,\n",
    "    find_node_equ,\n",
    ")\n",
    "import pandas as pd\n",
    "from amftrack.pipeline.functions.spore_processing.spore_id import make_spore_data\n",
    "from amftrack.pipeline.functions.image_processing.hyphae_id_surf import (\n",
    "    resolve_anastomosis_crossing_by_root,\n",
    ")\n",
    "from amftrack.pipeline.functions.post_processing.time_hypha import *\n",
    "from amftrack.pipeline.functions.image_processing.experiment_class_surf import (\n",
    "    Node,\n",
    "    Edge,\n",
    "    Hyphae,\n",
    "    get_distance,\n",
    ")\n",
    "from amftrack.util.sys import (\n",
    "    get_analysis_folders,\n",
    "    get_time_plate_info_from_analysis,\n",
    "    get_time_hypha_info_from_analysis,\n",
    "    get_global_hypha_info_from_analysis,\n",
    ")\n",
    "\n",
    "from datetime import datetime\n",
    "from matplotlib import cm\n",
    "from amftrack.pipeline.functions.post_processing.extract_study_zone import (\n",
    "    load_study_zone,\n",
    ")\n",
    "from IPython.display import clear_output\n",
    "from amftrack.pipeline.functions.post_processing.exp_plot import *\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfcad819-350a-41c3-80b0-5cf5666a8f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time(exp, t, tp1):  # redefined here to avoid loop in import\n",
    "    seconds = (exp.dates[tp1] - exp.dates[t]).total_seconds()\n",
    "    return seconds / 3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "921460cd-7047-4c2b-ac87-05b2ca6178a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plates = [\"94_20201123\"]\n",
    "directory_targ = directory_project\n",
    "directory_targ = os.path.join(directory_scratch, \"stitch_temp2\") + \"/\"\n",
    "update_analysis_info(directory_targ)\n",
    "analysis_info = get_analysis_info(directory_targ)\n",
    "analysis_folders = analysis_info.loc[analysis_info[\"unique_id\"].isin(plates)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4b6b210-76c3-408e-afb5-780c96c61df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_analysis_folders = get_analysis_folders(directory_targ)\n",
    "analysis_folders_info = all_analysis_folders.loc[\n",
    "    all_analysis_folders[\"unique_id\"].isin(plates)\n",
    "]\n",
    "folders, time_plate_info = get_time_plate_info_from_analysis(\n",
    "    analysis_folders_info, use_saved=False\n",
    ")\n",
    "folders, time_hypha_info = get_time_hypha_info_from_analysis(\n",
    "    analysis_folders_info, use_saved=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "129252ad-8035-4427-be7b-84c0ba20d5b8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/scratch-local/cbisot/ipykernel_91855/3849905796.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabeled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mload_graphs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirectory_targ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m# load_graphs(exp, directory_targ, indexes=[90, 70, 60])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/gpfs/home2/cbisot/pycode/AMFtrack/amftrack/pipeline/functions/image_processing/experiment_class_surf.py\u001b[0m in \u001b[0;36mload_graphs\u001b[0;34m(exp, directory, indexes, reload, post_process, suffix)\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m             \u001b[0medge_empty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0medge\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0medge\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medges\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m             \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_edge_attributes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_empty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"pixel_list\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m             \u001b[0mnx_graph_poss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m     \u001b[0mnx_graphs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnx_graph_pos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnx_graph_pos\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnx_graph_poss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/amftrack/lib/python3.7/site-packages/networkx/classes/function.py\u001b[0m in \u001b[0;36mset_edge_attributes\u001b[0;34m(G, values, name)\u001b[0m\n\u001b[1;32m    799\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 801\u001b[0;31m                         \u001b[0mG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    802\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m                         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "path_exp = f'{directory_targ}{analysis_folders[\"path_exp\"].iloc[0]}'\n",
    "exp = pickle.load(open(path_exp, \"rb\"))\n",
    "exp.save_location = \"/\"\n",
    "try:\n",
    "    exp.labeled\n",
    "except AttributeError:\n",
    "    exp.labeled = True\n",
    "load_graphs(exp, directory_targ, indexes=range(0, 40))\n",
    "# load_graphs(exp, directory_targ, indexes=[90, 70, 60])\n",
    "\n",
    "load_study_zone(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27d10877-f02b-424c-91af-da2812a0870c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c977271cc974dfc999a89666e529bd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "analysed:   0%|          | 0/341 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "directory_targ = os.path.join(directory_scratch, \"stitch_temp2\") + \"/\"\n",
    "# directory_targ = directory_project\n",
    "\n",
    "update_plate_info(directory_targ, local=True)\n",
    "all_folders = get_current_folders(directory_targ, local=True)\n",
    "folders = all_folders.loc[all_folders['unique_id']=='94_20201123']\n",
    "folders = folders.loc[folders[\"/Analysis/nx_graph_pruned_labeled.p\"] == True]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "427f8e97-7242-4a85-9d06-ed7611f3aac9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/home2/cbisot/pycode/AMFtrack/amftrack/pipeline/functions/image_processing/experiment_class_surf.py:104: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.folders[\"date\"], format=\"%d.%m.%Y, %H:%M:\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-23 12:53:00\n",
      "2020-11-23 14:00:00\n",
      "2020-11-24 03:01:00\n",
      "2020-11-24 05:01:00\n",
      "2020-11-24 12:02:00\n",
      "2020-11-24 21:02:00\n",
      "2020-11-25 18:02:00\n",
      "2020-11-25 23:02:00\n",
      "2020-11-26 04:02:00\n",
      "2020-11-26 06:02:00\n",
      "2020-11-26 20:09:00\n",
      "2020-11-27 16:13:00\n",
      "2020-11-28 01:12:00\n",
      "2020-11-28 05:13:00\n",
      "2020-11-29 06:13:00\n",
      "2020-11-29 18:13:00\n",
      "2020-12-02 06:09:00\n",
      "2020-12-03 14:05:00\n",
      "2020-12-05 21:23:00\n",
      "2020-12-07 01:24:00\n"
     ]
    }
   ],
   "source": [
    "exp = Experiment(directory_targ)\n",
    "exp.load(folders.iloc[:20])\n",
    "exp.dates.sort()\n",
    "# when no width is included\n",
    "resolve_anastomosis_crossing_by_root(exp, lim_considered=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836b630b-232b-480f-ab9a-cb09d9bcce5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(exp.ts):\n",
    "    exp.load_tile_information(t)\n",
    "im = exp.get_image(0, 0)\n",
    "exp.dimX_dimY = im.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42c6bb7-0fbb-4b48-b776-f878894b0ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_length_fast(edge, t):\n",
    "    return np.linalg.norm(edge.begin.pos(t) - edge.end.pos(t))\n",
    "\n",
    "\n",
    "fbas = lambda edge: np.log(\n",
    "    edge.width(edge.ts()[-1])\n",
    "    * edge.length_um(edge.ts()[-1])\n",
    "    * edge.end.degree(edge.ts()[-1])\n",
    "    * edge.begin.degree(edge.ts()[-1])\n",
    ")  # function to evaluate BASness, typical threshold is 10\n",
    "f = lambda edge: np.log(\n",
    "    edge.width(edge.ts()[-1])\n",
    "    * get_length_fast(edge, edge.ts()[-1])\n",
    "    * edge.end.degree(edge.ts()[-1])\n",
    "    * edge.begin.degree(edge.ts()[-1])\n",
    ")  # function to evaluate BASness, typical threshold is 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7c4e901-0ac8-4c84-b10b-4850be24df81",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_hyph = [0, 6, 118, 58, 1, 85]\n",
    "tf = 90\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4d4b47b8-1d55-4226-91e4-c1754d16a837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "networkx.exception.NetworkXNoPath"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.NetworkXNoPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbcd9ddc-2326-4a71-9374-a922efe7e6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_orientation(hypha, t, start, length=50):\n",
    "    nodes, edges = hypha.get_nodes_within(t)\n",
    "    pixel_list_list = []\n",
    "    #     print(edges[start:])\n",
    "    for edge in edges[start:]:\n",
    "        pixel_list_list += edge.pixel_list(t)\n",
    "    pixel_list = np.array(pixel_list_list)\n",
    "    vector = pixel_list[min(length, len(pixel_list) - 1)] - pixel_list[0]\n",
    "    unit_vector = vector / np.linalg.norm(vector)\n",
    "    vertical_vector = np.array([-1, 0])\n",
    "    dot_product = np.dot(vertical_vector, unit_vector)\n",
    "    if (\n",
    "        vertical_vector[1] * vector[0] - vertical_vector[0] * vector[1] >= 0\n",
    "    ):  # determinant\n",
    "        angle = np.arccos(dot_product) / (2 * np.pi) * 360\n",
    "    else:\n",
    "        angle = -np.arccos(dot_product) / (2 * np.pi) * 360\n",
    "    return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebe6b47c-5532-4348-843a-27d1f730975c",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/scratch-local/cbisot/ipykernel_630051/2498796845.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhyph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mhyph\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mhyph\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyphaes\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhyph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mhyph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m44\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mhyph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mhyph\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mhyph\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyphaes\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhyph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mhyph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m147\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "hyph = [hyph for hyph in exp.hyphaes if hyph.end.label == 0][0]\n",
    "hyph.root = Node(44, exp)\n",
    "hyph = [hyph for hyph in exp.hyphaes if hyph.end.label == 6][0]\n",
    "hyph.root = Node(147, exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0d061b1-ae58-4dc9-963f-08c6bc11a686",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_angle(exp):\n",
    "    (\n",
    "        RH,\n",
    "        BAS,\n",
    "        max_speeds,\n",
    "        total_growths,\n",
    "        widths,\n",
    "        lengths,\n",
    "        branch_frequ,\n",
    "        select_hyph,\n",
    "    ) = get_rh_bas(exp)\n",
    "    branch_root = []\n",
    "    branch_anastomose = []\n",
    "    two_time = []\n",
    "    angles = []\n",
    "    for rh in RH:\n",
    "        #     rh = choice(RH)\n",
    "        t = rh.ts[-1]\n",
    "        nodes, edges = rh.get_nodes_within(t)\n",
    "        for i, node in enumerate(nodes[1:-1]):\n",
    "            found = False\n",
    "            for hyph in exp.hyphaes:\n",
    "                if hyph.root.label == node:\n",
    "                    if found:\n",
    "                        two_time.append(hyph.root)\n",
    "                    branch_root.append(hyph.root)\n",
    "                    if t in hyph.ts:\n",
    "                        nodes_h, edges_h = hyph.get_nodes_within(t)\n",
    "                        if len(edges_h) > 0:\n",
    "                            edge_main = edges[i + 1]\n",
    "                            edge_branch = edges_h[0]\n",
    "                            angle_main = get_orientation(rh, t, i + 1, 100)\n",
    "                            angle_branch = get_orientation(hyph, t, 0, 100)\n",
    "                            angles.append(((angle_main - angle_branch), (rh, hyph, t)))\n",
    "                            #                         print(node,edges[i+1],edges_h[0],angle_main-angle_branch)\n",
    "                            #                         exp.plot([t],[[node,edge_main.begin.label,edge_main.end.label,edge_branch.begin.label,edge_branch.end.label]])\n",
    "                            found = True\n",
    "            if not found:\n",
    "                branch_anastomose.append(Node(node, exp))\n",
    "    angles_180 = [(angle + 180) % 360 - 180 for angle, infos in angles]\n",
    "    angles_rh = [(c[0] + 180) % 360 - 180 for c in angles if c[1][1] in RH]\n",
    "    angles_bas = [(c[0] + 180) % 360 - 180 for c in angles if c[1][1] in BAS]\n",
    "    return (angles_rh, angles_bas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b06f7e2b-8fc2-4ddd-97ec-1b42b0086c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from amftrack.pipeline.functions.post_processing.util import measure_length_um\n",
    "\n",
    "def get_rh_bas(exp):\n",
    "    select_hyph = get_hyph_infos(exp)\n",
    "    max_speeds = []\n",
    "    total_growths = []\n",
    "    lengths = []\n",
    "    branch_frequ = []\n",
    "    hyph_l = []\n",
    "    RH = []\n",
    "    BAS = []\n",
    "    widths = []\n",
    "    for hyph in exp.hyphaes:\n",
    "        speeds = [c[2] for c in select_hyph[hyph]]\n",
    "        ts = [c[0] for c in select_hyph[hyph]]\n",
    "        tp1s = [c[1] for c in select_hyph[hyph]]\n",
    "        if len(speeds) > 0:\n",
    "            node = hyph.end\n",
    "            length = np.linalg.norm(node.pos(node.ts()[0]) - node.pos(node.ts()[-1]))\n",
    "            nodes = hyph.get_nodes_within(hyph.ts[-1])[0]\n",
    "            max_speed = np.max(speeds)\n",
    "            total_growth = np.sum(\n",
    "                [\n",
    "                    speed * get_time(exp, ts[i], tp1s[i])\n",
    "                    for i, speed in enumerate(speeds)\n",
    "                ]\n",
    "            )\n",
    "            if length>=1500:\n",
    "                RH.append(hyph)\n",
    "            else:\n",
    "                BAS.append(hyph)\n",
    "            lengths.append(length)\n",
    "            max_speeds.append(max_speed)\n",
    "            total_growths.append(total_growth)\n",
    "            branch_frequ.append((len(nodes) - 1) / (length + 1))\n",
    "            hyph_l.append(hyph)\n",
    "            #             widths.append(get_width_hypha(hyph,hyph.ts[-1]))\n",
    "            widths.append(5)\n",
    "\n",
    "        else:\n",
    "            BAS.append(hyph)\n",
    "    return (\n",
    "        RH,\n",
    "        BAS,\n",
    "        max_speeds,\n",
    "        total_growths,\n",
    "        widths,\n",
    "        lengths,\n",
    "        branch_frequ,\n",
    "        select_hyph,\n",
    "    )\n",
    "def get_length_um(seg):\n",
    "    pixel_conversion_factor = 1.725\n",
    "    pixels = seg\n",
    "    length_edge = 0\n",
    "    for i in range(len(pixels) // 10 + 1):\n",
    "        if i * 10 <= len(pixels) - 1:\n",
    "            length_edge += np.linalg.norm(\n",
    "                np.array(pixels[i * 10])\n",
    "                - np.array(pixels[min((i + 1) * 10, len(pixels) - 1)])\n",
    "            )\n",
    "    #         length_edge+=np.linalg.norm(np.array(pixels[len(pixels)//10-1*10-1])-np.array(pixels[-1]))\n",
    "    return length_edge * pixel_conversion_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3f9a722-da06-4d6a-aef3-cf219f93338e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hyph_infos(exp):\n",
    "    select_hyph = {}\n",
    "    for hyph in exp.hyphaes:\n",
    "        select_hyph[hyph] = []\n",
    "        for i, t in enumerate(hyph.ts[:-1]):\n",
    "            tp1 = hyph.ts[i + 1]\n",
    "            try:\n",
    "                pixels, nodes = get_pixel_growth_and_new_children(hyph, t, tp1)\n",
    "                speed = np.sum([get_length_um(seg) for seg in pixels]) / get_time(\n",
    "                    exp, t, tp1\n",
    "                )\n",
    "                select_hyph[hyph].append((t, hyph.ts[i + 1], speed, pixels))\n",
    "            except nx.NetworkXNoPath:\n",
    "                pass\n",
    "    return select_hyph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ca0084c-93ec-4948-816e-4edc0f3ebc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "angles_rh, angles_bas = estimate_angle(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27f5fda9-ed49-4c31-8838-6a5e4ef25e5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[81.59404923858648,\n",
       " 66.6042524355534,\n",
       " -77.32115012112179,\n",
       " -80.69565626974519,\n",
       " 0.0,\n",
       " -81.63529125101888,\n",
       " 90.35875113716509,\n",
       " -83.08052678065816,\n",
       " 63.2214324339879,\n",
       " -66.22401270682784,\n",
       " -85.52748709352427,\n",
       " -85.52748709352427,\n",
       " 66.48891034073085,\n",
       " -75.8614769941459,\n",
       " -66.4572259241238,\n",
       " -53.05491108562444,\n",
       " 67.36554820221608,\n",
       " -47.96768199156833,\n",
       " -81.62053202841668,\n",
       " 86.97260657584928,\n",
       " 0.0,\n",
       " -79.15870574121844,\n",
       " 77.75766880112553,\n",
       " 65.73004273825777,\n",
       " 67.72815667539282,\n",
       " 0.0,\n",
       " -74.95343468844287,\n",
       " -65.4731358266329,\n",
       " -89.18652432618711]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "angles_rh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fad15f5d-7b6d-48fb-b7d0-f41b9c1ecdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "row = [row for index, row in analysis_folders.iterrows()][0]\n",
    "path = f'{directory_targ}{row[\"folder_analysis\"]}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6609077b-9e94-43a7-84be-e35f89c09681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/scratch-shared/amftrack/stitch_temp2/Analysis_94_20201123_166_Version1'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0aa76be5-6992-42ba-b4d4-a5daa1d1da82",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(path,\"rh_angle\"),angles_rh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f511cfa8-2a2f-47f7-8465-fc77e459f1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sbatch: Single-node jobs run on a shared node by default. Add --exclusive if you want to use a node exclusively.\n",
      "sbatch: A full node consists of 128 CPU cores, 983040 MiB of memory and 0 GPUs and can be shared by up to 4 jobs.\n",
      "sbatch: By default shared jobs get 7680 MiB of memory per CPU core, unless explicitly overridden with --mem-per-cpu, --mem-per-gpu or --mem.\n",
      "sbatch: You will be charged for 1.0 node, based on the number of CPUs, GPUs and the amount memory that you've requested.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 3062523\n"
     ]
    }
   ],
   "source": [
    "from amftrack.pipeline.launching.run_super import run_parallel_post\n",
    "name_job = \"angles\"\n",
    "time = \"2:00:00\"\n",
    "list_f = []\n",
    "\n",
    "list_args = [[]] * len(list_f)\n",
    "overwrite = True\n",
    "num_parallel = 30\n",
    "run_parallel_post(\n",
    "    \"angle_extractor.py\",\n",
    "    list_f,\n",
    "    list_args,\n",
    "    [directory_targ, overwrite],\n",
    "    analysis_folders,\n",
    "    num_parallel,\n",
    "    time,\n",
    "    \"global_plate_post_process\",\n",
    "    cpus=128,\n",
    "    name_job=name_job,\n",
    "    node=\"fat\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "93e1efbd-36a1-4112-b751-6da5dfd867be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "angles = []\n",
    "for rh_label in list_hyph:\n",
    "    rh = [hyph for hyph in exp.hyphaes if hyph.end.label == rh_label][0]\n",
    "    #     rh = choice(RH)\n",
    "    t = tf\n",
    "    nodes, edges = rh.get_nodes_within(t)\n",
    "    for i, node in enumerate(nodes[1:-1]):\n",
    "        found = False\n",
    "        for hyph in exp.hyphaes:\n",
    "            if hyph.root.label == node:\n",
    "                # if found:\n",
    "                #     two_time.append(hyph.root)\n",
    "                # branch_root.append(hyph.root)\n",
    "                if t in hyph.ts:\n",
    "                    try:\n",
    "                        nodes_h, edges_h = hyph.get_nodes_within(t)\n",
    "                        if len(edges_h) > 0:\n",
    "                            edge_main = edges[i + 1]\n",
    "                            edge_branch = edges_h[0]\n",
    "                            angle_main = get_orientation(rh, t, i + 1, 100)\n",
    "                            angle_branch = get_orientation(hyph, t, 0, 100)\n",
    "                            angles.append(((angle_main - angle_branch), (rh, hyph, t)))\n",
    "                            #                         print(node,edges[i+1],edges_h[0],angle_main-angle_branch)\n",
    "                            #                         exp.plot([t],[[node,edge_main.begin.label,edge_main.end.label,edge_branch.begin.label,edge_branch.end.label]])\n",
    "                            found = True\n",
    "                    except nx.NodeNotFound:\n",
    "                        pass\n",
    "        # if not found:\n",
    "        #     branch_anastomose.append(Node(node, exp))\n",
    "# angles_180 = [(angle + 180) % 360 - 180 for angle, infos in angles]\n",
    "angles_rh = [(c[0] + 180) % 360 - 180 for c in angles if c[1][1].end.label in list_hyph]\n",
    "# angles_bas = [(c[0] + 180) % 360 - 180 for c in angles if c[1][1] in BAS]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fd62b5eb-54a1-40a9-8978-f192c03a466b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-73.61045966596524, (Hyphae(0,44), Hyphae(1,226), 90)),\n",
       " (-68.13619382771023, (Hyphae(0,44), Hyphae(90,134), 90)),\n",
       " (47.179261996599834, (Hyphae(0,44), Hyphae(174,237), 90)),\n",
       " (96.10314910865742, (Hyphae(118,209), Hyphae(187,207), 90)),\n",
       " (255.5538211067594, (Hyphae(118,209), Hyphae(230,191), 90)),\n",
       " (88.49818585380926, (Hyphae(118,209), Hyphae(258,194), 90)),\n",
       " (-65.56724731167884, (Hyphae(118,209), Hyphae(273,270), 90)),\n",
       " (104.41473121842165, (Hyphae(1,226), Hyphae(63,91), 90)),\n",
       " (73.19302370567745, (Hyphae(85,60), Hyphae(74,5), 90))]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c791e202-bb59-45ba-94ad-2c7564cd62ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-73.61045966596524]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for end in list_hyph:\n",
    "    hyph_label = end\n",
    "    hyph = [hyph for hyph in exp.hyphaes if hyph.end.label == end][0]\n",
    "    t0 = hyph.ts[0]\n",
    "    if hyph.end.is_in(t0):\n",
    "        exp = hyph.experiment\n",
    "        thresh = 1600\n",
    "        junctions_found = [hyph.end.neighbours(t0)[0]]\n",
    "        ts = []\n",
    "        mult = []\n",
    "        speeds = []\n",
    "        print(end)\n",
    "        select = time_hypha_info.loc[time_hypha_info[\"end\"] == end]\n",
    "\n",
    "        for t in hyph.ts:\n",
    "            select_t = select.loc[select[\"timestep\"] == t - 1]\n",
    "            speed = select_t[\"speed\"].iloc[0] if len(select_t) > 0 else -1\n",
    "            if t < tf:\n",
    "                try:\n",
    "                    G = exp.nx_graph[t]\n",
    "                    G = G.subgraph(nx.node_connected_component(G, hyph.end.label))\n",
    "                    tim = hyph.end.ts()[-1]\n",
    "                    tip = hyph.end\n",
    "                    if hyph.end.degree(t) == 1 and np.linalg.norm(tip.pos(tim) - tip.pos(t)) >= 40:\n",
    "                        tot_speeds.append(speed)\n",
    "                        nodes, edges = hyph.get_nodes_within(t)\n",
    "                        potentials = []\n",
    "                        nodes = [Node(node, exp) for node in nodes]\n",
    "                        try:\n",
    "                            last_junction_index = nodes.index(junctions_found[-1])\n",
    "                        except:\n",
    "                            last_junction_index = 0\n",
    "                        for node in nodes[last_junction_index + 1 : -1]:\n",
    "                            dist = np.linalg.norm(node.pos(t) - hyph.end.pos(t))\n",
    "                            # To avoid detecting two times the same  node with different labels\n",
    "                            dists_junction_found = [np.inf] + [\n",
    "                                np.linalg.norm(node.pos(t) - nodo.pos(t))\n",
    "                                for nodo in junctions_found\n",
    "                                if nodo.is_in(t)\n",
    "                            ]\n",
    "                            if (\n",
    "                                dist < thresh\n",
    "                                and min(dists_junction_found) > 40\n",
    "                                and (node not in junctions_found)\n",
    "                            ):\n",
    "                                extra_hypha_neighbours = [\n",
    "                                    nodo for nodo in node.neighbours(t) if nodo not in nodes\n",
    "                                ]\n",
    "\n",
    "                                edges = [\n",
    "                                    Edge(node, nodo, exp) for nodo in extra_hypha_neighbours\n",
    "                                ]\n",
    "                                is_rh = [f(edge) >= 10 for edge in edges]\n",
    "                                tips = [\n",
    "                                    nodo\n",
    "                                    for nodo in extra_hypha_neighbours\n",
    "                                    if nx.edge_connectivity(G, nodo.label, node.label) == 1\n",
    "                                ]\n",
    "                                # if len(tips) == node.degree(t) - 2:\n",
    "\n",
    "                                if len(tips) == node.degree(t) - 2 and np.any(is_rh):\n",
    "                                    edge_for_angle = [edge for edge in edges if f(edge) >= 10]\n",
    "                                    angles = []"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
