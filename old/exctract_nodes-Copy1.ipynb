{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\coren\\anaconda3\\envs\\cleanMsc\\lib\\importlib\\_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib widget\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from PIL import Image\n",
    "from scipy import sparse\n",
    "import cv2\n",
    "from pymatreader import read_mat\n",
    "\n",
    "# from extract_graph import dic_to_sparse\n",
    "from util.sys import get_path, shift_skeleton\n",
    "from plotutil import (\n",
    "    show_im,\n",
    "    overlap,\n",
    "    show_im_rgb,\n",
    "    plot_nodes,\n",
    "    plot_nodes_from_list,\n",
    "    plot_t_tp1,\n",
    ")\n",
    "from extract_graph import (\n",
    "    generate_graph_tab_from_skeleton,\n",
    "    generate_nx_graph_from_skeleton,\n",
    "    generate_skeleton,\n",
    "    clean,\n",
    ")\n",
    "import networkx as nx\n",
    "from node_id import (\n",
    "    second_identification,\n",
    "    whole_movement_identification,\n",
    "    first_identification,\n",
    "    relabel_nodes,\n",
    "    clean_nodes,\n",
    "    orient,\n",
    ")\n",
    "from extract_graph import (\n",
    "    dic_to_sparse,\n",
    "    from_sparse_to_graph,\n",
    "    generate_nx_graph,\n",
    "    prune_graph,\n",
    "    from_nx_to_tab,\n",
    "    from_nx_to_tab_matlab,\n",
    "    sparse_to_doc,\n",
    "    connections_pixel_list_to_tab,\n",
    "    transform_list,\n",
    "    clean_degree_4,\n",
    ")\n",
    "from sparse_util import dilate, zhangSuen\n",
    "from realign import realign, reconnect, realign2\n",
    "from util.sys import get_path\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import ast\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = (\n",
    "    \"//sun.amolf.nl/shimizu-data/home-folder/oyartegalvez/Drive_AMFtopology/PRINCE\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "listdir = os.listdir(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "plate = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dir_interest = [\n",
    "    name\n",
    "    for name in listdir\n",
    "    if name.split(\"_\")[-1] == f'Plate{0 if plate<10 else \"\"}{plate}'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = [name.split(\"_\")[0] for name in list_dir_interest]\n",
    "ff = [name.split(\"_\")[1] for name in list_dir_interest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_datetime = [\n",
    "    datetime(\n",
    "        year=int(ss[i][:4]),\n",
    "        month=int(ss[i][4:6]),\n",
    "        day=int(ss[i][6:8]),\n",
    "        hour=int(ff[i][0:2]),\n",
    "        minute=int(ff[i][2:4]),\n",
    "    )\n",
    "    for i in range(len(list_dir_interest))\n",
    "]\n",
    "dates_datetime.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates_datetime_chosen = dates_datetime[1:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = [\n",
    "    f'{0 if date.month<10 else \"\"}{date.month}{0 if date.day<10 else \"\"}{date.day}_{0 if date.hour<10 else \"\"}{date.hour}{0 if date.minute<10 else \"\"}{date.minute}'\n",
    "    for date in dates_datetime_chosen\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_skels = [read_mat(get_path(date, plate, True))[\"skel\"] for date in dates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_skels = [dic_to_sparse(mat_skel) for mat_skel in mat_skels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "skeleton_docs = [sparse_to_doc(sparse_skel) for sparse_skel in dic_skels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skeletons_aligned = [skeleton_docs[0]]\n",
    "for i in range(1, len(skeleton_docs)):\n",
    "    print(\"working on\", i)\n",
    "    skeletons_aligned.append(\n",
    "        realign2(\n",
    "            skeleton_docs[i],\n",
    "            skeletons_aligned[-1],\n",
    "            2,\n",
    "            maxdist=50,\n",
    "            save=get_path(dates[i], plate, True, extension=\"\"),\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nx_graph_poss=[generate_nx_graph(from_sparse_to_graph(realign(skeleton_doc,nx_graph_pivot,pos_pivot,2,maxdist = 50,\n",
    "#                                                               save=get_path(dates[i],plate,True,extension='')))) for i,skeleton_doc in enumerate(skeleton_docs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx_graph_poss = []\n",
    "for date in dates:\n",
    "    nx_graph_poss.append(\n",
    "        generate_nx_graph(\n",
    "            pd.read_csv(\n",
    "                get_path(date, plate, True, extension=\"_raw_aligned_skeleton.csv\"),\n",
    "                converters={\n",
    "                    \"origin_pos\": transform_list,\n",
    "                    \"end_pos\": transform_list,\n",
    "                    \"pixel_list\": ast.literal_eval,\n",
    "                },\n",
    "            ),\n",
    "            labeled=True,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx_graph_poss = [\n",
    "    generate_nx_graph(from_sparse_to_graph(skeleton)) for skeleton in skeletons_aligned\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nx_graph_poss=[]\n",
    "# for date in dates:\n",
    "#     nx_graph_poss.append(generate_nx_graph(pd.read_csv(get_path(date,plate,True,extension='_raw_aligned_skeleton.csv'),\n",
    "#                                     converters={'origin_pos' : transform_list,'end_pos' : transform_list,'pixel_list' : ast.literal_eval}),labeled=True))\n",
    "# nx_graph_poss=[generate_nx_graph(from_sparse_to_graph(realign(skeleton_doc,nx_graph_pivot,pos_pivot,2,maxdist = 50,\n",
    "#                                                               save=get_path(date,plate,True,extension='')))) for skeleton_doc in skeleton_docs]\n",
    "nx_graphs_aligned = [nx_graph_pos[0] for nx_graph_pos in nx_graph_poss]\n",
    "poss_aligned = [nx_graph_pos[1] for nx_graph_pos in nx_graph_poss]\n",
    "nx_graph_pruned = [\n",
    "    clean_degree_4(prune_graph(nx_graph), poss_aligned[i])[0]\n",
    "    for i, nx_graph in enumerate(nx_graphs_aligned)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\coren\\anaconda3\\envs\\cleanMsc\\lib\\site-packages\\scipy\\sparse\\_index.py:82: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first_id 7.913223743438721\n",
      "relabel 0.04000544548034668\n",
      "tip_id 160.06710720062256\n",
      "5 0 [ 3406 15651]\n",
      "5 1 [ 3403 15655]\n",
      "i= 21\n",
      "first_id 7.777533054351807\n",
      "relabel 0.08900618553161621\n",
      "tip_id 165.76901292800903\n",
      "12 0 [ 4196 16086]\n",
      "12 1 [ 4198 16079]\n",
      "12 2 [ 4195 16085]\n",
      "i= 20\n",
      "first_id 9.634658813476562\n",
      "relabel 0.2010173797607422\n",
      "tip_id 167.84908080101013\n",
      "7 0 [ 4201 16085]\n",
      "7 1 [ 4196 16086]\n",
      "7 2 [ 4198 16079]\n",
      "7 3 [ 4195 16085]\n",
      "i= 19\n",
      "first_id 8.555251836776733\n",
      "relabel 0.237015962600708\n",
      "tip_id 193.70619773864746\n",
      "13 0 [ 5059 18376]\n",
      "13 1 [ 5057 18369]\n",
      "13 2 [ 5051 18370]\n",
      "13 3 [ 5050 18363]\n",
      "13 4 [ 5049 18368]\n",
      "i= 18\n",
      "first_id 8.268914461135864\n",
      "relabel 1.1230995655059814\n",
      "tip_id 174.11471939086914\n",
      "4 0 [ 5054 18364]\n",
      "4 1 [ 5059 18376]\n",
      "4 2 [ 5057 18369]\n",
      "4 3 [ 5051 18370]\n",
      "4 4 [ 5050 18363]\n",
      "4 5 [ 5049 18368]\n",
      "i= 17\n",
      "first_id 10.595516920089722\n",
      "relabel 1.3076305389404297\n",
      "tip_id 165.38880920410156\n",
      "4 0 [ 5057 18366]\n",
      "4 1 [ 5054 18364]\n",
      "4 2 [ 5059 18376]\n",
      "4 3 [ 5057 18369]\n",
      "4 4 [ 5051 18370]\n",
      "4 5 [ 5050 18363]\n",
      "4 6 [ 5049 18368]\n",
      "i= 16\n",
      "first_id 8.85805082321167\n",
      "relabel 0.2992680072784424\n",
      "tip_id 150.84380459785461\n",
      "9 0 [5657 9155]\n",
      "9 1 [5656 9161]\n",
      "9 2 [5656 9159]\n",
      "9 3 [5657 9165]\n",
      "9 4 [5658 9166]\n",
      "9 5 [5649 9168]\n",
      "i= 15\n",
      "first_id 7.28759241104126\n",
      "relabel 0.4095628261566162\n",
      "tip_id 142.42938995361328\n",
      "6 0 [5678 9180]\n",
      "i= 14\n",
      "first_id 10.198918581008911\n",
      "relabel 1.407649040222168\n",
      "tip_id 138.38396072387695\n",
      "4 0 [6017 8687]\n",
      "4 1 [6012 8688]\n",
      "4 2 [6004 8676]\n",
      "i= 13\n",
      "first_id 6.8314878940582275\n",
      "relabel 1.4236242771148682\n",
      "tip_id 133.02997469902039\n",
      "4 0 [6273 8705]\n",
      "4 1 [6277 8711]\n",
      "4 2 [6296 8725]\n",
      "i= 12\n",
      "first_id 7.254310131072998\n",
      "relabel 0.3990304470062256\n",
      "tip_id 129.23797345161438\n",
      "8 0 [7028 8858]\n",
      "i= 11\n",
      "first_id 7.145195245742798\n",
      "relabel 1.5221190452575684\n",
      "100 805 9170 [12366 32225]\n",
      "71.22196677755446 [12365 32225]\n",
      "101 805 9169 [12365 32225]\n",
      "44.656915600476474 [12363 32226]\n",
      "102 805 9166 [12363 32226]\n",
      "95.38553546869446 [12383 32225]\n",
      "103 805 9174 [12383 32225]\n",
      "71.22196677755446 [12366 32225]\n",
      "104 805 9170 [12366 32225]\n",
      "71.22196677755446 [12365 32225]\n",
      "tip_id 126.0282711982727\n",
      "5 0 [7103 8876]\n",
      "5 1 [7098 8870]\n",
      "5 2 [7102 8875]\n",
      "5 3 [7105 8882]\n",
      "5 4 [7115 8895]\n",
      "5 5 [7102 8874]\n",
      "5 6 [7101 8877]\n",
      "5 7 [7102 8884]\n",
      "5 8 [7103 8883]\n",
      "5 9 [7100 8881]\n",
      "5 10 [7096 8886]\n",
      "5 11 [7107 8883]\n",
      "5 12 [7089 8894]\n",
      "i= 10\n",
      "first_id 5.737791538238525\n",
      "relabel 0.4990386962890625\n",
      "tip_id 121.93976140022278\n",
      "1 0 [7105 8881]\n",
      "1 1 [7103 8876]\n",
      "1 2 [7098 8870]\n",
      "1 3 [7102 8875]\n",
      "1 4 [7105 8882]\n",
      "1 5 [7115 8895]\n",
      "1 6 [7102 8874]\n",
      "1 7 [7101 8877]\n",
      "1 8 [7102 8884]\n",
      "1 9 [7103 8883]\n",
      "1 10 [7100 8881]\n",
      "1 11 [7096 8886]\n",
      "1 12 [7107 8883]\n",
      "1 13 [7089 8894]\n",
      "i= 9\n",
      "first_id 5.41946268081665\n",
      "relabel 0.5850436687469482\n",
      "tip_id 119.27777457237244\n",
      "7 0 [7783 8864]\n",
      "7 1 [7787 8864]\n",
      "7 2 [7785 8860]\n",
      "7 3 [7780 8852]\n",
      "7 4 [7786 8861]\n",
      "7 5 [7788 8866]\n",
      "7 6 [7788 8867]\n",
      "7 7 [7783 8859]\n",
      "7 8 [7783 8860]\n",
      "7 9 [7787 8870]\n",
      "7 10 [7784 8866]\n",
      "7 11 [7784 8857]\n",
      "7 12 [7779 8870]\n",
      "7 13 [7784 8869]\n",
      "7 14 [7783 8874]\n",
      "i= 8\n",
      "first_id 5.099566221237183\n",
      "relabel 0.5510404109954834\n",
      "tip_id 114.36331748962402\n",
      "7 0 [7782 8862]\n",
      "7 1 [7783 8864]\n",
      "7 2 [7787 8864]\n",
      "7 3 [7785 8860]\n",
      "7 4 [7780 8852]\n",
      "7 5 [7786 8861]\n",
      "7 6 [7788 8866]\n",
      "7 7 [7788 8867]\n",
      "7 8 [7783 8859]\n",
      "7 9 [7783 8860]\n",
      "7 10 [7787 8870]\n",
      "7 11 [7784 8866]\n",
      "7 12 [7784 8857]\n",
      "7 13 [7779 8870]\n",
      "7 14 [7784 8869]\n",
      "7 15 [7783 8874]\n",
      "i= 7\n",
      "first_id 5.7386016845703125\n",
      "relabel 1.4781112670898438\n",
      "tip_id 108.5124180316925\n",
      "6 0 [7925 6767]\n",
      "6 1 [7925 6763]\n",
      "6 2 [7926 6762]\n",
      "6 3 [7930 6763]\n",
      "6 4 [7927 6756]\n",
      "6 5 [7924 6747]\n",
      "6 6 [7932 6758]\n",
      "6 7 [7933 6763]\n",
      "6 8 [7932 6767]\n",
      "6 9 [7928 6757]\n",
      "6 10 [7927 6757]\n",
      "i= 6\n",
      "first_id 5.228394508361816\n",
      "relabel 0.5930426120758057\n",
      "tip_id 105.21151685714722\n",
      "2 0 [7918 6760]\n",
      "2 1 [7925 6767]\n",
      "2 2 [7925 6763]\n",
      "2 3 [7926 6762]\n",
      "2 4 [7930 6763]\n",
      "2 5 [7927 6756]\n",
      "2 6 [7924 6747]\n",
      "2 7 [7932 6758]\n",
      "2 8 [7933 6763]\n",
      "2 9 [7932 6767]\n",
      "2 10 [7928 6757]\n",
      "2 11 [7927 6757]\n",
      "i= 5\n",
      "first_id 4.951909065246582\n",
      "relabel 1.6666879653930664\n",
      "tip_id 101.11192750930786\n",
      "2 0 [7929 6757]\n",
      "2 1 [7918 6760]\n",
      "2 2 [7925 6767]\n",
      "2 3 [7925 6763]\n",
      "2 4 [7926 6762]\n",
      "2 5 [7930 6763]\n",
      "2 6 [7927 6756]\n",
      "2 7 [7924 6747]\n",
      "2 8 [7932 6758]\n",
      "2 9 [7933 6763]\n",
      "2 10 [7932 6767]\n",
      "2 11 [7928 6757]\n",
      "2 12 [7927 6757]\n",
      "i= 4\n",
      "first_id 4.507380247116089\n",
      "relabel 1.7421507835388184\n",
      "tip_id 93.43810153007507\n",
      "4 0 [8810 6734]\n",
      "4 1 [8815 6738]\n",
      "4 2 [8805 6743]\n",
      "4 3 [8812 6749]\n",
      "4 4 [8811 6746]\n",
      "4 5 [8812 6744]\n",
      "4 6 [8818 6743]\n",
      "4 7 [8814 6737]\n",
      "4 8 [8809 6728]\n",
      "4 9 [8818 6740]\n",
      "4 10 [8820 6745]\n",
      "4 11 [8819 6749]\n",
      "4 12 [8813 6740]\n",
      "4 13 [8813 6738]\n",
      "i= 3\n",
      "first_id 5.680941820144653\n",
      "relabel 1.5891318321228027\n",
      "tip_id 92.2586612701416\n",
      "2 0 [8804 6718]\n",
      "2 1 [8810 6734]\n",
      "2 2 [8815 6738]\n",
      "2 3 [8805 6743]\n",
      "2 4 [8812 6749]\n",
      "2 5 [8811 6746]\n",
      "2 6 [8812 6744]\n",
      "2 7 [8818 6743]\n",
      "2 8 [8814 6737]\n",
      "2 9 [8809 6728]\n",
      "2 10 [8818 6740]\n",
      "2 11 [8820 6745]\n",
      "2 12 [8819 6749]\n",
      "2 13 [8813 6740]\n",
      "2 14 [8813 6738]\n",
      "i= 2\n",
      "first_id 5.231926202774048\n",
      "relabel 0.7795627117156982\n",
      "tip_id 1311.5529448986053\n",
      "2 0 [8813 6741]\n",
      "2 1 [8804 6718]\n",
      "2 2 [8810 6734]\n",
      "2 3 [8815 6738]\n",
      "2 4 [8805 6743]\n",
      "2 5 [8812 6749]\n",
      "2 6 [8811 6746]\n",
      "2 7 [8812 6744]\n",
      "2 8 [8818 6743]\n",
      "2 9 [8814 6737]\n",
      "2 10 [8809 6728]\n",
      "2 11 [8818 6740]\n",
      "2 12 [8820 6745]\n",
      "2 13 [8819 6749]\n",
      "2 14 [8813 6740]\n",
      "2 15 [8813 6738]\n",
      "i= 1\n",
      "first_id 6.815885305404663\n",
      "relabel 0.6315672397613525\n",
      "tip_id 85.79951095581055\n",
      "12 0 [10838  6560]\n",
      "12 1 [10842  6568]\n",
      "12 2 [10855  6559]\n",
      "12 3 [10844  6559]\n",
      "12 4 [10847  6563]\n",
      "12 5 [10854  6557]\n",
      "12 6 [10842  6570]\n",
      "12 7 [10842  6565]\n",
      "12 8 [10846  6566]\n",
      "12 9 [10846  6565]\n",
      "12 10 [10846  6565]\n",
      "12 11 [10846  6558]\n",
      "12 12 [10846  6566]\n",
      "12 13 [10849  6565]\n",
      "12 14 [10845  6570]\n",
      "12 15 [10846  6562]\n",
      "12 16 [10844  6563]\n",
      "12 17 [10842  6567]\n",
      "12 18 [10847  6568]\n",
      "12 19 [10851  6565]\n",
      "12 20 [10841  6570]\n",
      "12 21 [10843  6570]\n",
      "12 22 [10836  6568]\n",
      "i= 0\n",
      "first_id 5.396606683731079\n",
      "relabel 0.6420490741729736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\coren\\anaconda3\\envs\\cleanMsc\\lib\\site-packages\\ipykernel_launcher.py:347: RuntimeWarning: invalid value encountered in arccos\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tip_id 85.17978525161743\n",
      "6 0 [10618  7242]\n",
      "6 1 [10610  7236]\n",
      "6 2 [10615  7242]\n",
      "6 3 [10627  7233]\n",
      "6 4 [10617  7234]\n",
      "6 5 [10619  7237]\n",
      "6 6 [10626  7232]\n",
      "6 7 [10614  7245]\n",
      "6 8 [10615  7241]\n",
      "6 9 [10618  7241]\n",
      "6 10 [10618  7241]\n",
      "6 11 [10619  7240]\n",
      "6 12 [10619  7234]\n",
      "6 13 [10618  7241]\n",
      "6 14 [10622  7240]\n",
      "6 15 [10616  7246]\n",
      "6 16 [10619  7235]\n",
      "6 17 [10616  7239]\n",
      "6 18 [10614  7241]\n",
      "6 19 [10619  7244]\n",
      "6 20 [10622  7241]\n",
      "6 21 [10615  7245]\n",
      "6 22 [10615  7244]\n",
      "6 23 [10608  7245]\n"
     ]
    }
   ],
   "source": [
    "downstream_graphs = []\n",
    "downstream_pos = []\n",
    "begin = len(dates) - 1\n",
    "downstream_graphs = [nx_graph_pruned[begin]]\n",
    "downstream_poss = [poss_aligned[begin]]\n",
    "for i in range(begin - 1, -1, -1):\n",
    "    print(\"i=\", i)\n",
    "    new_graphs, new_poss = second_identification(\n",
    "        nx_graph_pruned[i],\n",
    "        downstream_graphs[0],\n",
    "        poss_aligned[i],\n",
    "        downstream_poss[0],\n",
    "        50,\n",
    "        downstream_graphs[1:],\n",
    "        downstream_poss[1:],\n",
    "        tolerance=30,\n",
    "    )\n",
    "    downstream_graphs = new_graphs\n",
    "    downstream_poss = new_poss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx_graph_pruned = downstream_graphs\n",
    "poss_aligned = downstream_poss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, date in enumerate(dates):\n",
    "#     sparse.save_npz(f'Data/skeleton_{date}_{plate}_full_clean',sparse.csc_matrix(skeleton_docs_cleaned[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, date in enumerate(dates):\n",
    "    from_nx_to_tab(nx_graph_pruned[i], poss_aligned[i]).to_csv(\n",
    "        get_path(date, plate, True, extension=\"_full_labeled.csv\")\n",
    "    )\n",
    "#     from_nx_to_tab_matlab(nx_graph_pruned[i],poss_aligned[i]).to_csv(get_path(date,plate,True,extension='_full_labeled_matlab.csv'))\n",
    "#     tabs[i].to_csv(get_path(date,plate,True,extension='_full.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, date in enumerate(dates):\n",
    "    from_nx_to_tab(nx_graph_pruned[i], poss_aligned[i]).to_csv(\n",
    "        f\"Data/graph_{date}_{plate}_full_labeled.csv\"\n",
    "    )\n",
    "#     from_nx_to_tab_matlab(nx_graph_pruned[i],poss_aligned[i]).to_csv(f'Data/graph_{date}_{plate}_full_labeled_matlab.csv')\n",
    "# for i, date in enumerate(dates):\n",
    "#     tabs_labeled[i].to_csv(f'Data/graph_{date}_{plate}_full_labeled.csv')\n",
    "#     tabs[i].to_csv(f'Data/graph_{date}_{plate}_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.13513513513513514\n",
      "0.2702702702702703\n",
      "0.40540540540540543\n",
      "0.5405405405405406\n",
      "0.6756756756756757\n",
      "0.8108108108108109\n",
      "0.9459459459459459\n",
      "0.0\n",
      "0.1272264631043257\n",
      "0.2544529262086514\n",
      "0.3816793893129771\n",
      "0.5089058524173028\n",
      "0.6361323155216285\n",
      "0.7633587786259542\n",
      "0.8905852417302799\n",
      "0.0\n",
      "0.11668611435239207\n",
      "0.23337222870478413\n",
      "0.3500583430571762\n",
      "0.46674445740956827\n",
      "0.5834305717619603\n",
      "0.7001166861143524\n",
      "0.8168028004667445\n",
      "0.9334889148191365\n"
     ]
    }
   ],
   "source": [
    "connections_growth_pattern = [\n",
    "    whole_movement_identification(\n",
    "        nx_graph_pruned[i], nx_graph_pruned[i + 1], poss_aligned[i], poss_aligned[i + 1]\n",
    "    )\n",
    "    for i in range(len(dates) - 1)\n",
    "]\n",
    "tip_origins = [c[0] for c in connections_growth_pattern]\n",
    "growth_pattern = [c[1] for c in connections_growth_pattern]\n",
    "# for i in range(len(tip_origins)):\n",
    "#     connections_pixel_list_to_tab(tip_origins[i],growth_pattern[i]).to_csv(get_path(dates[i],plate,True,extension='_connection.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connections_pixel_list_to_tab(origin_tips, pattern_growth):\n",
    "    column_names = [\"tip_origin\", \"nodes_from_tip\", \"growth_pattern\"]\n",
    "    tab = pd.DataFrame(columns=column_names)\n",
    "    pattern_growth = {\n",
    "        tip: [\n",
    "            [(pixel[0], pixel[1]) for pixel in branch] for branch in pattern_growth[tip]\n",
    "        ]\n",
    "        for tip in pattern_growth.keys()\n",
    "    }\n",
    "    for tip in origin_tips.keys():\n",
    "        new_line = pd.DataFrame(\n",
    "            {\n",
    "                \"tip_origin\": [tip],\n",
    "                \"nodes_from_tip\": [origin_tips[tip]],\n",
    "                \"growth_pattern\": [pattern_growth[tip]],\n",
    "            }\n",
    "        )\n",
    "        tab = tab.append(new_line, ignore_index=True)\n",
    "    return tab\n",
    "\n",
    "\n",
    "# for i in range(len(tip_origins)):\n",
    "#     connections_pixel_list_to_tab(tip_origins[i],growth_pattern[i]).to_csv(get_path(dates[i],plate,True,extension='_connection.csv'))\n",
    "for i in range(len(tip_origins)):\n",
    "    connections_pixel_list_to_tab(tip_origins[i], growth_pattern[i]).to_csv(\n",
    "        f\"Data/graph_{dates[i]}_{plate}_connection.csv\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poss_aligned = [nx_graph_pos[1] for nx_graph_pos in nx_graph_poss]\n",
    "nx_graph_pruned = [prune_graph(nx_graph) for nx_graph in nx_graphs_aligned]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xbegin = 14000\n",
    "xend = 18000\n",
    "ybegin = 8000\n",
    "yend = 16000\n",
    "sub_nx_graphs = [\n",
    "    sub_graph(nx_graph, poss_aligned[i], xbegin, xend, ybegin, yend)\n",
    "    for i, nx_graph in enumerate(nx_graph_pruned)\n",
    "]\n",
    "# sub_skeleton= [generate_skeleton(nx_graph,(xend-xbegin,yend-ybegin),(xbegin,ybegin)) for nx_graph in sub_nx_graphs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 3\n",
      "number removed first phase 19\n",
      "number removed second phase 36\n",
      "116 0 [16887  8355]\n",
      "116 1 [16893  8366]\n",
      "i= 2\n",
      "number removed first phase 13\n",
      "number removed second phase 27\n",
      "121 0 [17317  9088]\n",
      "121 1 [17312  9091]\n",
      "121 2 [17311  9107]\n",
      "i= 1\n",
      "number removed first phase 12\n",
      "number removed second phase 32\n",
      "119 0 [17318  9090]\n",
      "119 1 [17317  9088]\n",
      "119 2 [17312  9091]\n",
      "119 3 [17311  9107]\n"
     ]
    }
   ],
   "source": [
    "downstream_graphs = []\n",
    "downstream_pos = []\n",
    "begin = len(dates) - 2\n",
    "downstream_graphs = [sub_nx_graphs[begin]]\n",
    "downstream_poss = [poss_aligned[begin]]\n",
    "for i in range(begin - 1, 0, -1):\n",
    "    print(\"i=\", i)\n",
    "    new_graphs, new_poss = second_identification(\n",
    "        sub_nx_graphs[i],\n",
    "        downstream_graphs[0],\n",
    "        poss_aligned[i],\n",
    "        downstream_poss[0],\n",
    "        50,\n",
    "        downstream_graphs[1:],\n",
    "        downstream_poss[1:],\n",
    "        tolerance=30,\n",
    "    )\n",
    "    downstream_graphs = new_graphs\n",
    "    downstream_poss = new_poss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotutil import plot_t_tp1, compress_skeleton\n",
    "\n",
    "\n",
    "def compress_skeleton(skeleton_doc, factor, dim):\n",
    "    shape = dim\n",
    "    final_picture = np.zeros(shape=(shape[0] // factor, shape[1] // factor))\n",
    "    for pixel in skeleton_doc.keys():\n",
    "        x = min(round(pixel[0] / factor), shape[0] // factor - 1)\n",
    "        y = min(round(pixel[1] / factor), shape[1] // factor - 1)\n",
    "        final_picture[x, y] += 1\n",
    "    return final_picture\n",
    "\n",
    "\n",
    "factor = 5\n",
    "final_pictures = [\n",
    "    compress_skeleton(skeleton_docs[i], factor, dim=(20800, 46000)) >= 1\n",
    "    for i in range(len(skeleton_docs))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.3784093856811523\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "Sedge1 = sparse.csr_matrix((22000, 46000))\n",
    "for edge in nx_graphs_aligned[3].edges:\n",
    "    Sedge1[poss_aligned[3][edge[0]][0], poss_aligned[3][edge[0]][1]] = edge[0]\n",
    "print(t - time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.3656890392303467\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "for i in range(16000):\n",
    "    Sedge1[10000:20000, 10000:20000]\n",
    "print(t - time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from PIL import Image\n",
    "from scipy import sparse\n",
    "import cv2\n",
    "from pymatreader import read_mat\n",
    "from util.sys import get_path\n",
    "from plotutil import show_im, overlap, show_im_rgb\n",
    "from extract_graph import (\n",
    "    generate_graph_tab_from_skeleton,\n",
    "    generate_nx_graph_from_skeleton,\n",
    "    generate_skeleton,\n",
    ")\n",
    "import networkx as nx\n",
    "from copy import deepcopy\n",
    "from sparse_util import dilate\n",
    "from scipy.optimize import minimize\n",
    "from time import time\n",
    "\n",
    "\n",
    "def node_dist(\n",
    "    node1,\n",
    "    node2,\n",
    "    nx_graph_tm1,\n",
    "    nx_graph_t,\n",
    "    pos_tm1,\n",
    "    pos_t,\n",
    "    tolerance,\n",
    "    show=False,\n",
    "):\n",
    "    #!!! assumed shape == 3000,4096\n",
    "    sparse_cross1 = sparse.dok_matrix((4 * tolerance, 4 * tolerance), dtype=bool)\n",
    "    sparse_cross2 = sparse.dok_matrix((4 * tolerance, 4 * tolerance), dtype=bool)\n",
    "    for edge in nx_graph_tm1.edges(node1):\n",
    "        list_pixel = nx_graph_tm1.get_edge_data(*edge)[\"pixel_list\"]\n",
    "        if (pos_tm1[node1] != list_pixel[0]).any():\n",
    "            list_pixel = list(reversed(list_pixel))\n",
    "        #         print(list_pixel[0],pos_tm1[node1],list_pixel[-1])\n",
    "        for pixel in list_pixel[:20]:\n",
    "            sparse_cross1[\n",
    "                np.array(pixel) - np.array(pos_tm1[node1]) + np.array((50, 50))\n",
    "            ] = 1\n",
    "    for edge in nx_graph_t.edges(node2):\n",
    "        list_pixel = nx_graph_t.get_edge_data(*edge)[\"pixel_list\"]\n",
    "        if (pos_t[node2] != list_pixel[0]).any():\n",
    "            list_pixel = list(reversed(list_pixel))\n",
    "        #         print(list_pixel[0],pos_t[node2],list_pixel[-1])\n",
    "        for pixel in list_pixel[:20]:\n",
    "            #             if np.any(np.array(pixel)-np.array(pos_tm1[node1])+np.array((50,50))>=100):\n",
    "            #                 print(list_pixel[0],pos_t[node2],list_pixel[-1])\n",
    "            sparse_cross2[\n",
    "                np.array(pixel) - np.array(pos_tm1[node1]) + np.array((50, 50))\n",
    "            ] = 1\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    dilation1 = cv2.dilate(\n",
    "        sparse_cross1.todense().astype(np.uint8), kernel, iterations=3\n",
    "    )\n",
    "    dilation2 = cv2.dilate(\n",
    "        sparse_cross2.todense().astype(np.uint8), kernel, iterations=3\n",
    "    )\n",
    "    if show:\n",
    "        plt.imshow(dilation1)\n",
    "        plt.imshow(dilation2, alpha=0.5)\n",
    "        plt.show()\n",
    "    return np.linalg.norm(dilation1 - dilation2)\n",
    "\n",
    "\n",
    "def first_identification(nx_graph_tm1, nx_graph_t, pos_tm1, pos_t, tolerance):\n",
    "    corresp = {}\n",
    "    ambiguous = set()\n",
    "    to_remove = set()\n",
    "    degree_3sup_nodes_tm1 = [\n",
    "        node for node in nx_graph_tm1.nodes if nx_graph_tm1.degree(node) >= 3\n",
    "    ]\n",
    "    degree_3sup_nodes_t = [\n",
    "        node for node in nx_graph_t.nodes if nx_graph_t.degree(node) >= 3\n",
    "    ]\n",
    "    Stm1 = sparse.csr_matrix((22000, 46000))\n",
    "    St = sparse.csr_matrix((22000, 46000))\n",
    "    for node in degree_3sup_nodes_tm1:\n",
    "        Stm1[pos_tm1[node][0], pos_tm1[node][1]] = node\n",
    "    for node in degree_3sup_nodes_t:\n",
    "        St[pos_t[node][0], pos_t[node][1]] = node\n",
    "    for node1 in degree_3sup_nodes_tm1:\n",
    "        mini = np.inf\n",
    "        posanchor = pos_tm1[node1]\n",
    "        window = 150\n",
    "        potential_surrounding_t = St[\n",
    "            max(0, posanchor[0] - 2 * window) : posanchor[0] + 2 * window,\n",
    "            max(0, posanchor[1] - 2 * window) : posanchor[1] + 2 * window,\n",
    "        ]\n",
    "        for node2 in potential_surrounding_t.data:\n",
    "            distance = np.linalg.norm(pos_tm1[node1] - pos_t[node2])\n",
    "            if distance < mini:\n",
    "                mini = distance\n",
    "                identifier = node2\n",
    "        if mini < tolerance:\n",
    "            if identifier in corresp.values():\n",
    "                ambiguous.add(node1)\n",
    "            corresp[node1] = identifier\n",
    "        else:\n",
    "            to_remove.add(node1)\n",
    "    while len(ambiguous) > 0:\n",
    "        node = ambiguous.pop()\n",
    "        identifier = corresp[node]\n",
    "        candidates = [nod for nod in corresp.keys() if corresp[nod] == identifier]\n",
    "        mini = np.inf\n",
    "        for candidate in candidates:\n",
    "            distance = node_dist(\n",
    "                candidate,\n",
    "                identifier,\n",
    "                nx_graph_tm1,\n",
    "                nx_graph_t,\n",
    "                pos_tm1,\n",
    "                pos_t,\n",
    "                tolerance,\n",
    "            )\n",
    "            if distance < mini:\n",
    "                right_candidate = candidate\n",
    "                mini = distance\n",
    "        for candidate in candidates:\n",
    "            if candidate != right_candidate:\n",
    "                corresp.pop(candidate)\n",
    "                to_remove.add(candidate)\n",
    "                ambiguous.discard(candidate)\n",
    "    return (corresp, to_remove)\n",
    "\n",
    "\n",
    "def relabel_nodes(corresp, nx_graph_t, pos_t):\n",
    "    invert_corresp = {}\n",
    "    new_pos = {}\n",
    "    maxi = max(nx_graph_t.nodes) + 1\n",
    "    for key in corresp.keys():\n",
    "        invert_corresp[corresp[key]] = key\n",
    "\n",
    "    def mapping(node):\n",
    "        if node in invert_corresp.keys():\n",
    "            return invert_corresp[node]\n",
    "        else:\n",
    "            return maxi + node\n",
    "\n",
    "    for node in nx_graph_t.nodes:\n",
    "        pos = pos_t[node]\n",
    "        if node in invert_corresp.keys():\n",
    "            new_pos[invert_corresp[node]] = pos\n",
    "        else:\n",
    "            new_pos[maxi + node] = pos\n",
    "    new_graph = nx.relabel_nodes(nx_graph_t, mapping)\n",
    "    return (new_pos, new_graph)\n",
    "\n",
    "\n",
    "def relabel_nodes_downstream(corresp, nx_graph_list, pos_list):\n",
    "    invert_corresp = {}\n",
    "    new_poss = [{} for i in range(len(nx_graph_list))]\n",
    "    new_graphs = []\n",
    "    all_nodes = set()\n",
    "    for nx_graph in nx_graph_list:\n",
    "        all_nodes = all_nodes.union(set(nx_graph.nodes))\n",
    "    all_nodes = all_nodes.union(set(corresp.keys()))\n",
    "    all_nodes = all_nodes.union(set(corresp.values()))\n",
    "    maxi = max(all_nodes) + 1\n",
    "    for key in corresp.keys():\n",
    "        invert_corresp[corresp[key]] = key\n",
    "\n",
    "    def mapping(node):\n",
    "        if node in invert_corresp.keys():\n",
    "            return invert_corresp[node]\n",
    "        else:\n",
    "            return maxi + node\n",
    "\n",
    "    for i, nx_graph in enumerate(nx_graph_list):\n",
    "        for node in nx_graph.nodes:\n",
    "            pos = pos_list[i][node]\n",
    "            new_poss[i][mapping(node)] = pos\n",
    "        new_graphs.append(nx.relabel_nodes(nx_graph, mapping, copy=True))\n",
    "    return (new_graphs, new_poss)\n",
    "\n",
    "\n",
    "def reduce_labels(nx_graph_list, pos_list):\n",
    "    new_poss = [{} for i in range(len(nx_graph_list))]\n",
    "    new_graphs = []\n",
    "    all_node_labels = set()\n",
    "    node = [node for node in nx_graph_list[0].nodes if node in nx_graph_list[1]][0]\n",
    "    for nx_graph in nx_graph_list:\n",
    "        all_node_labels = all_node_labels.union(set(nx_graph.nodes))\n",
    "    all_node_labels = sorted(all_node_labels)\n",
    "\n",
    "    def mapping(node):\n",
    "        return all_node_labels.index(node)\n",
    "\n",
    "    for i, nx_graph in enumerate(nx_graph_list):\n",
    "        for node in nx_graph.nodes:\n",
    "            pos = pos_list[i][node]\n",
    "            new_poss[i][mapping(node)] = pos\n",
    "        new_graphs.append(nx.relabel_nodes(nx_graph, mapping, copy=True))\n",
    "    node = [node for node in new_graphs[0].nodes if new_graphs[0].degree(node) == 3][0]\n",
    "    for i, nx_graph in enumerate(nx_graph_list):\n",
    "        if node in new_poss[i].keys():\n",
    "            print(node, i, new_poss[i][node])\n",
    "    return (new_graphs, new_poss)\n",
    "\n",
    "\n",
    "def reconnect_degree_2(nx_graph, pos):\n",
    "    degree_2_nodes = [node for node in nx_graph.nodes if nx_graph.degree(node) == 2]\n",
    "    while len(degree_2_nodes) > 0:\n",
    "        node = degree_2_nodes.pop()\n",
    "        neighbours = list(nx_graph.neighbors(node))\n",
    "        right_n = neighbours[0]\n",
    "        left_n = neighbours[1]\n",
    "        right_edge = nx_graph.get_edge_data(node, right_n)[\"pixel_list\"]\n",
    "        left_edge = nx_graph.get_edge_data(node, left_n)[\"pixel_list\"]\n",
    "        if np.any(right_edge[0] != pos[node]):\n",
    "            right_edge = list(reversed(right_edge))\n",
    "        if np.any(left_edge[-1] != pos[node]):\n",
    "            left_edge = list(reversed(left_edge))\n",
    "        pixel_list = left_edge + right_edge[1:]\n",
    "        info = {\"weight\": len(pixel_list), \"pixel_list\": pixel_list}\n",
    "        if right_n != left_n:\n",
    "            connection_data = nx_graph.get_edge_data(right_n, left_n)\n",
    "            if connection_data is None or connection_data[\"weight\"] >= info[\"weight\"]:\n",
    "                if not connection_data is None:\n",
    "                    nx_graph.remove_edge(right_n, left_n)\n",
    "                nx_graph.add_edges_from([(right_n, left_n, info)])\n",
    "        nx_graph.remove_node(node)\n",
    "        degree_2_nodes = [node for node in nx_graph.nodes if nx_graph.degree(node) == 2]\n",
    "\n",
    "\n",
    "def clean_nodes(nx_graph, to_remove, pos):\n",
    "    nx_graph = deepcopy(nx_graph)  # could be removed to speed up\n",
    "    is_hair = True\n",
    "    i = 0\n",
    "    while is_hair:\n",
    "        is_hair = False\n",
    "        to_remove_possibly = list(to_remove)\n",
    "        for node in to_remove_possibly:\n",
    "            neighbours = nx_graph.neighbors(node)\n",
    "            candidate_to_remove = []\n",
    "            weight_candidate = []\n",
    "            for neighbour in neighbours:\n",
    "                if nx_graph.degree(neighbour) == 1:\n",
    "                    is_hair = True\n",
    "                    candidate_to_remove.append(neighbour)\n",
    "                    weight_candidate.append(\n",
    "                        len(nx_graph.get_edge_data(node, neighbour)[\"pixel_list\"])\n",
    "                    )\n",
    "            if len(candidate_to_remove) > 0:\n",
    "                node_to_remove = candidate_to_remove[np.argmin(weight_candidate)]\n",
    "                nx_graph.remove_node(node_to_remove)\n",
    "                i += 1\n",
    "                if nx_graph.degree(node) == 2:\n",
    "                    to_remove.discard(node)\n",
    "    print(\"number removed first phase\", i)\n",
    "    reconnect_degree_2(nx_graph, pos)  # could possibly be done faster\n",
    "    for node in to_remove:\n",
    "        if node in nx_graph:\n",
    "            neighbours = list(nx_graph.neighbors(node))\n",
    "            candidate_to_fuse = []\n",
    "            weight_candidate = []\n",
    "            for neighbour in neighbours:\n",
    "                candidate_to_fuse.append(neighbour)\n",
    "                weight_candidate.append(\n",
    "                    len(nx_graph.get_edge_data(node, neighbour)[\"pixel_list\"])\n",
    "                )\n",
    "            node_to_fuse = candidate_to_fuse[np.argmin(weight_candidate)]\n",
    "            if nx_graph.degree(node) == 1 and node_to_fuse not in to_remove:\n",
    "                print(pos[node])\n",
    "                continue\n",
    "            for neighbour in neighbours:\n",
    "                right_n = node_to_fuse\n",
    "                left_n = neighbour\n",
    "                right_edge = nx_graph.get_edge_data(node, right_n)[\"pixel_list\"]\n",
    "                left_edge = nx_graph.get_edge_data(node, left_n)[\"pixel_list\"]\n",
    "                if np.any(right_edge[0] != pos[node]):\n",
    "                    right_edge = list(reversed(right_edge))\n",
    "                if np.any(left_edge[-1] != pos[node]):\n",
    "                    left_edge = list(reversed(left_edge))\n",
    "                pixel_list = left_edge + right_edge[1:]\n",
    "                info = {\"weight\": len(pixel_list), \"pixel_list\": pixel_list}\n",
    "                if right_n != left_n:\n",
    "                    connection_data = nx_graph.get_edge_data(right_n, left_n)\n",
    "                    if (\n",
    "                        connection_data is None\n",
    "                        or connection_data[\"weight\"] >= info[\"weight\"]\n",
    "                    ):\n",
    "                        if not connection_data is None:\n",
    "                            nx_graph.remove_edge(right_n, left_n)\n",
    "                        nx_graph.add_edges_from([(right_n, left_n, info)])\n",
    "            nx_graph.remove_node(node)\n",
    "            i += 1\n",
    "    print(\"number removed second phase\", i)\n",
    "    reconnect_degree_2(nx_graph, pos)\n",
    "    return nx_graph\n",
    "\n",
    "\n",
    "def orient(pixel_list, root_pos):\n",
    "    if np.all(root_pos == pixel_list[0]):\n",
    "        return pixel_list\n",
    "    else:\n",
    "        return list(reversed(pixel_list))\n",
    "\n",
    "\n",
    "def second_identification(\n",
    "    nx_graph_tm1,\n",
    "    nx_graph_t,\n",
    "    pos_tm1,\n",
    "    pos_t,\n",
    "    length_id=50,\n",
    "    downstream_graphs=[],\n",
    "    downstream_pos=[],\n",
    "    tolerance=50,\n",
    "):\n",
    "    reconnect_degree_2(nx_graph_t, pos_t)\n",
    "    t = time()\n",
    "    corresp, to_remove = first_identification(\n",
    "        nx_graph_tm1, nx_graph_t, pos_tm1, pos_t, tolerance\n",
    "    )\n",
    "    print(\"first_id\", time() - t)\n",
    "    t = time()\n",
    "    #     nx_graph_tm1=clean_nodes(nx_graph_tm1,to_remove,pos_tm1)\n",
    "    #     print(\"clean_node\",time()-t)\n",
    "    #     t=time()\n",
    "    downstream_graphs = [nx_graph_t] + downstream_graphs\n",
    "    downstream_pos = [pos_t] + downstream_pos\n",
    "    new_graphs, new_poss = relabel_nodes_downstream(\n",
    "        corresp, downstream_graphs, downstream_pos\n",
    "    )\n",
    "    print(\"relabel\", time() - t)\n",
    "    t = time()\n",
    "    pos_t = new_poss[0]\n",
    "    nx_graph_t = new_graphs[0]\n",
    "    downstream_pos = new_poss\n",
    "    downstream_graphs = new_graphs\n",
    "    corresp_tips = {node: node for node in corresp.keys()}\n",
    "    tips = [node for node in nx_graph_tm1.nodes if nx_graph_tm1.degree(node) == 1]\n",
    "    ambiguous = set()\n",
    "    Sedge = sparse.csr_matrix((22000, 46000))\n",
    "    for edge in nx_graph_t.edges:\n",
    "        pixel_list = nx_graph_t.get_edge_data(*edge)[\"pixel_list\"]\n",
    "        pixela = pixel_list[0]\n",
    "        pixelb = pixel_list[-1]\n",
    "        Sedge[pixela[0], pixela[1]] = edge[0]\n",
    "        Sedge[pixelb[0], pixelb[1]] = edge[1]\n",
    "    for tip in tips:\n",
    "        mini1 = np.inf\n",
    "        posanchor = pos_tm1[tip]\n",
    "        window = 1000\n",
    "        potential_surrounding_t = Sedge[\n",
    "            max(0, posanchor[0] - 2 * window) : posanchor[0] + 2 * window,\n",
    "            max(0, posanchor[1] - 2 * window) : posanchor[1] + 2 * window,\n",
    "        ]\n",
    "        #         potential_surrounding_t=Sedge\n",
    "        #         for edge in nx_graph_t.edges:\n",
    "        #             pixel_list=nx_graph_t.get_edge_data(*edge)['pixel_list']\n",
    "        #             if np.linalg.norm(np.array(pixel_list[0])-np.array(pos_tm1[tip]))<=5000:\n",
    "        #                 distance=np.min(np.linalg.norm(np.array(pixel_list)-np.array(pos_tm1[tip]),axis=1))\n",
    "        #                 if distance<mini1:\n",
    "        #                     mini1=distance\n",
    "        #                     right_edge1 = edge\n",
    "        #         print('t1 re',right_edge)\n",
    "        mini = np.inf\n",
    "        for node_root in potential_surrounding_t.data:\n",
    "            for edge in nx_graph_t.edges(int(node_root)):\n",
    "                pixel_list = nx_graph_t.get_edge_data(*edge)[\"pixel_list\"]\n",
    "                if (\n",
    "                    np.linalg.norm(np.array(pixel_list[0]) - np.array(pos_tm1[tip]))\n",
    "                    <= 5000\n",
    "                ):\n",
    "                    distance = np.min(\n",
    "                        np.linalg.norm(\n",
    "                            np.array(pixel_list) - np.array(pos_tm1[tip]), axis=1\n",
    "                        )\n",
    "                    )\n",
    "                    if distance < mini:\n",
    "                        mini = distance\n",
    "                        right_edge = edge\n",
    "        #         print('t2 re',right_edge)\n",
    "        #         if right_edge!=right_edge1:\n",
    "        #             print('alaba',right_edge,right_edge1)\n",
    "        #             print('len(surrounding)',len(potential_surrounding_t.data))\n",
    "        origin = np.array(\n",
    "            orient(\n",
    "                nx_graph_tm1.get_edge_data(*list(nx_graph_tm1.edges(tip))[0])[\n",
    "                    \"pixel_list\"\n",
    "                ],\n",
    "                pos_tm1[tip],\n",
    "            )\n",
    "        )\n",
    "        origin_vector = origin[0] - origin[-1]\n",
    "        branch = np.array(\n",
    "            orient(\n",
    "                nx_graph_t.get_edge_data(*right_edge)[\"pixel_list\"],\n",
    "                pos_t[right_edge[0]],\n",
    "            )\n",
    "        )\n",
    "        candidate_vector = branch[-1] - branch[0]\n",
    "        dot_product = np.dot(origin_vector, candidate_vector)\n",
    "        if dot_product >= 0:\n",
    "            root = right_edge[0]\n",
    "            next_node = right_edge[1]\n",
    "        else:\n",
    "            root = right_edge[1]\n",
    "            next_node = right_edge[0]\n",
    "        last_node = root\n",
    "        current_node = next_node\n",
    "        last_branch = np.array(\n",
    "            orient(\n",
    "                nx_graph_t.get_edge_data(root, next_node)[\"pixel_list\"],\n",
    "                pos_t[current_node],\n",
    "            )\n",
    "        )\n",
    "        i = 0\n",
    "        loop = []\n",
    "        while (\n",
    "            nx_graph_t.degree(current_node) != 1\n",
    "            and not current_node in nx_graph_tm1.nodes\n",
    "        ):  # Careful : if there is a cycle with low angle this might loop indefinitely but unprobable\n",
    "            i += 1\n",
    "            if i >= 100:\n",
    "                print(i, tip, current_node, pos_t[current_node])\n",
    "            mini = np.inf\n",
    "            origin_vector = (\n",
    "                last_branch[0] - last_branch[min(length_id, len(last_branch) - 1)]\n",
    "            )\n",
    "            unit_vector_origin = origin_vector / np.linalg.norm(origin_vector)\n",
    "            candidate_vectors = []\n",
    "            for neighbours_t in nx_graph_t.neighbors(current_node):\n",
    "                if neighbours_t != last_node:\n",
    "                    branch_candidate = np.array(\n",
    "                        orient(\n",
    "                            nx_graph_t.get_edge_data(current_node, neighbours_t)[\n",
    "                                \"pixel_list\"\n",
    "                            ],\n",
    "                            pos_t[current_node],\n",
    "                        )\n",
    "                    )\n",
    "                    candidate_vector = (\n",
    "                        branch_candidate[min(length_id, len(branch_candidate) - 1)]\n",
    "                        - branch_candidate[0]\n",
    "                    )\n",
    "                    unit_vector_candidate = candidate_vector / np.linalg.norm(\n",
    "                        candidate_vector\n",
    "                    )\n",
    "                    candidate_vectors.append(unit_vector_candidate)\n",
    "                    dot_product = np.dot(unit_vector_origin, unit_vector_candidate)\n",
    "                    angle = np.arccos(dot_product)\n",
    "                    if angle < mini:\n",
    "                        mini = angle\n",
    "                        next_node = neighbours_t\n",
    "            #                     print('angle',dot_product,pos_t[last_node],pos_t[current_node],pos_t[neighbours_t],angle/(2*np.pi)*360)\n",
    "            #!!!bug may happen here if two nodes are direct neighbours : I would nee to check further why it the case, optimal segmentation should avoid this issue.\n",
    "            # This is especially a problem for degree 4 nodes. Maybe fuse nodes that are closer than 3 pixels.\n",
    "            if i >= 100:\n",
    "                print(mini / (2 * np.pi) * 360, pos_t[next_node])\n",
    "                if next_node in loop:\n",
    "                    break\n",
    "                else:\n",
    "                    loop.append(next_node)\n",
    "            if len(candidate_vectors) < 2:\n",
    "                print(\n",
    "                    \"candidate_vectors < 2\",\n",
    "                    nx_graph_t.degree(current_node),\n",
    "                    pos_t[current_node],\n",
    "                    [node for node in nx_graph_t.nodes if nx_graph_t.degree(node) == 2],\n",
    "                )\n",
    "            competitor = np.arccos(np.dot(candidate_vectors[0], -candidate_vectors[1]))\n",
    "            if mini < competitor:\n",
    "                current_node, last_node = next_node, current_node\n",
    "            else:\n",
    "                break\n",
    "        if current_node in nx_graph_tm1.nodes:\n",
    "            if last_node not in nx_graph_tm1.nodes:\n",
    "                if last_node in corresp_tips.values():\n",
    "                    ambiguous.add(tip)\n",
    "                corresp_tips[tip] = last_node\n",
    "        else:\n",
    "            if current_node in corresp_tips.values():\n",
    "                ambiguous.add(tip)\n",
    "            corresp_tips[tip] = current_node\n",
    "    print(\"tip_id\", time() - t)\n",
    "    t = time()\n",
    "    while len(ambiguous) > 0:\n",
    "        node = ambiguous.pop()\n",
    "        identifier = corresp_tips[node]\n",
    "        candidates = [\n",
    "            nod for nod in corresp_tips.keys() if corresp_tips[nod] == identifier\n",
    "        ]\n",
    "        mini = np.inf\n",
    "        for candidate in candidates:\n",
    "            distance = np.linalg.norm(pos_tm1[candidate] - pos_t[identifier])\n",
    "            #             print(identifier,distance)\n",
    "            if distance < mini:\n",
    "                right_candidate = candidate\n",
    "                mini = distance\n",
    "        for candidate in candidates:\n",
    "            if candidate != right_candidate:\n",
    "                corresp_tips.pop(candidate)\n",
    "                ambiguous.discard(candidate)\n",
    "    new_graphs, new_poss = relabel_nodes_downstream(\n",
    "        corresp_tips, downstream_graphs, downstream_pos\n",
    "    )\n",
    "    downstream_pos = new_poss\n",
    "    downstream_graphs = new_graphs\n",
    "    #     print(\"second relabeling\")\n",
    "    #     print(len(nx_graph_tm1.nodes),len(new_graphs[0].nodes))\n",
    "    new_graphs, new_poss = reduce_labels(\n",
    "        [nx_graph_tm1] + downstream_graphs, [pos_tm1] + downstream_pos\n",
    "    )\n",
    "    #     print(\"third relabeling\")\n",
    "    #     print(len(new_graphs[0].nodes),len(new_graphs[1].nodes))\n",
    "    return (new_graphs, new_poss)\n",
    "\n",
    "\n",
    "def whole_movement_identification(\n",
    "    nx_graph_tm1, nx_graph_t, pos_tm1, pos_t, length_id=50\n",
    "):\n",
    "    tips = [node for node in nx_graph_tm1.nodes if nx_graph_tm1.degree(node) == 1]\n",
    "    tip_origin = {tip: [tip] for tip in tips}\n",
    "    pixels_from_tip = {tip: [] for tip in tips}\n",
    "    for number, tip in enumerate(tips):\n",
    "        #         print('tip',pos_tm1[tip],tip)\n",
    "        labeled = []\n",
    "        if number % 100 == 0:\n",
    "            print(number / len(tips))\n",
    "        mini = np.inf\n",
    "        for edge in nx_graph_t.edges:\n",
    "            pixel_list = nx_graph_t.get_edge_data(*edge)[\"pixel_list\"]\n",
    "            if np.linalg.norm(np.array(pixel_list[0]) - np.array(pos_tm1[tip])) <= 5000:\n",
    "                distance = np.min(\n",
    "                    np.linalg.norm(\n",
    "                        np.array(pixel_list) - np.array(pos_tm1[tip]), axis=1\n",
    "                    )\n",
    "                )\n",
    "                if distance < mini:\n",
    "                    mini = distance\n",
    "                    right_edge = edge\n",
    "        origin = np.array(\n",
    "            orient(\n",
    "                nx_graph_tm1.get_edge_data(*list(nx_graph_tm1.edges(tip))[0])[\n",
    "                    \"pixel_list\"\n",
    "                ],\n",
    "                pos_tm1[tip],\n",
    "            )\n",
    "        )\n",
    "        origin_vector = origin[0] - origin[-1]\n",
    "        branch = np.array(\n",
    "            orient(\n",
    "                nx_graph_t.get_edge_data(*right_edge)[\"pixel_list\"],\n",
    "                pos_t[right_edge[0]],\n",
    "            )\n",
    "        )\n",
    "        index_nearest_pixel = np.argmin(\n",
    "            np.linalg.norm(branch - np.array(pos_tm1[tip]), axis=1)\n",
    "        )\n",
    "        candidate_vector = branch[-1] - branch[0]\n",
    "        dot_product = np.dot(origin_vector, candidate_vector)\n",
    "        #         if tip==5260:\n",
    "        #             print(list(branch[index_nearest_pixel:]))\n",
    "        #             print(list(branch[:index_nearest_pixel]))\n",
    "        if dot_product >= 0:\n",
    "            root = right_edge[0]\n",
    "            next_node = right_edge[1]\n",
    "            pixels_from_tip[tip].append(list(branch[index_nearest_pixel:]))\n",
    "        else:\n",
    "            root = right_edge[1]\n",
    "            next_node = right_edge[0]\n",
    "            pixels_from_tip[tip].append(\n",
    "                list(reversed(list(branch[:index_nearest_pixel])))\n",
    "            )\n",
    "        # Could improve the candidate vector by chosing pixel around the forme tip but this identification should be rather unambiguous\n",
    "        last_node = root\n",
    "        current_node = next_node\n",
    "        last_branch = np.array(\n",
    "            orient(\n",
    "                nx_graph_t.get_edge_data(root, next_node)[\"pixel_list\"],\n",
    "                pos_t[current_node],\n",
    "            )\n",
    "        )\n",
    "\n",
    "        def label_node_recursive(last_node, current_node, corresp_label, labeled):\n",
    "            if not current_node in labeled and not current_node in nx_graph_tm1.nodes:\n",
    "                corresp_label[tip].append(current_node)\n",
    "                labeled.append(current_node)\n",
    "                pixel_list = nx_graph_t.get_edge_data(last_node, current_node)[\n",
    "                    \"pixel_list\"\n",
    "                ]\n",
    "                pixels_from_tip[tip].append(pixel_list)\n",
    "                if nx_graph_t.degree(current_node) >= 3:\n",
    "                    for neighbour_t in nx_graph_t.neighbors(current_node):\n",
    "                        if neighbour_t != last_node:\n",
    "                            label_node_recursive(\n",
    "                                current_node, neighbour_t, corresp_label, labeled\n",
    "                            )\n",
    "\n",
    "        label_node_recursive(last_node, current_node, tip_origin, labeled)\n",
    "    return (tip_origin, pixels_from_tip)\n",
    "\n",
    "\n",
    "def shift(skeleton1, skeleton2):\n",
    "    skeleton1_dilated = dilate(dilate(skeleton1)).astype(np.float)\n",
    "    skeleton2_dilated = dilate(dilate(skeleton2)).astype(np.float)\n",
    "\n",
    "    def distance(shift):\n",
    "        distance = 0\n",
    "        #         print(shift)\n",
    "        for pixel in skeleton1_dilated.keys():\n",
    "            #             print(pixel[0]+shift[0],pixel[1]+shift[1])\n",
    "            if (\n",
    "                skeleton2_dilated.shape[0] > np.ceil(pixel[0] + shift[0]) >= 0\n",
    "                and skeleton2_dilated.shape[1] > np.ceil(pixel[1] + shift[1]) >= 0\n",
    "            ):\n",
    "                shifted_pixel = (int(pixel[0] + shift[0]), int(pixel[1] + shift[1]))\n",
    "                shifted_pixel_next = (\n",
    "                    np.ceil(pixel[0] + shift[0]),\n",
    "                    np.ceil(pixel[1] + shift[1]),\n",
    "                )\n",
    "                #                 print(shifted_pixel)\n",
    "                prop = (\n",
    "                    1\n",
    "                    / 2\n",
    "                    * (\n",
    "                        pixel[0]\n",
    "                        + shift[0]\n",
    "                        - int(pixel[0] + shift[0])\n",
    "                        + pixel[1]\n",
    "                        + shift[1]\n",
    "                        - int(pixel[1] + shift[1])\n",
    "                    )\n",
    "                )\n",
    "                float_value = (1 - prop) * skeleton2_dilated[\n",
    "                    shifted_pixel[0], shifted_pixel[1]\n",
    "                ] + prop * (\n",
    "                    skeleton2_dilated[shifted_pixel_next[0], shifted_pixel_next[1]]\n",
    "                )\n",
    "                distance += abs(skeleton1_dilated[pixel] - float_value)\n",
    "            else:\n",
    "                distance += 1\n",
    "        #         for pixel in skeleton2_dilated.keys():\n",
    "        #             if (skeleton2_dilated.shape[0]>pixel[0]-shift[0]>=0 and skeleton2_dilated.shape[1]>pixel[1]-shift[1]>=0):\n",
    "        #                 shifted_pixel = (int(pixel[0]-shift[0]),int(pixel[1]-shift[1]))\n",
    "        #                 distance+=abs(skeleton1_dilated[shifted_pixel[0],shifted_pixel[1]]^skeleton2_dilated[pixel])\n",
    "        #             else:\n",
    "        #                 distance+=1\n",
    "        #         print(distance)\n",
    "        return distance\n",
    "\n",
    "    return minimize(\n",
    "        distance,\n",
    "        np.array([10, 10]),\n",
    "        method=\"nelder-mead\",\n",
    "        options={\"xatol\": 1, \"disp\": True, \"fatol\": 0.1},\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sedge1 = sparse.csr_matrix((22000, 46000))\n",
    "Sedge1[10000, 10000] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    if i == 5:\n",
    "        continue\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cleanMsc",
   "language": "python",
   "name": "cleanmsc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
